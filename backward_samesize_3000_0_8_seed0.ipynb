{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "backward_samesize_3000_0.8_seed0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMoh1baxC1+QKpfqxk1FC1Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nomchanz/graduation_thesis_new/blob/main/backward_samesize_3000_0_8_seed0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97L2vb2JQR7l"
      },
      "source": [
        "# 必要なライブラリのimport\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Input, concatenate, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "import sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasRegressor"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdDJ_XFBiu22"
      },
      "source": [
        "# データの準備、読み込み\n",
        "\n",
        "\n",
        "## データファイルのpath\n",
        "no_hole_path = 'no_hole_data.csv'\n",
        "one_hole_size_path = 'one_hole_size_data.csv'\n",
        "one_hole_position_path = 'one_hole_position_data.csv'\n",
        "four_holes_size_path = 'four_holes_size_data.csv'\n",
        "four_holes_position_path = 'four_holes_position_data.csv'\n",
        "nine_holes_size_path = 'nine_holes_size_data.csv'\n",
        "nine_holes_position_path = 'nine_holes_position_data.csv'\n",
        "sixteen_holes_size_path = 'sixteen_holes_size_data.csv'\n",
        "sixteen_holes_position_path = 'sixteen_holes_position_data.csv'\n",
        "twentyfive_holes_size_path = 'twentyfive_holes_size_data.csv'\n",
        "twentyfive_holes_position_path = 'twentyfive_holes_position_data.csv'\n",
        "\n",
        "one_hole_position_raw_path = 'one_hole_position_data_raw.csv'\n",
        "four_holes_position_raw_path = 'four_holes_position_data_raw.csv'\n",
        "nine_holes_position_raw_path = 'nine_holes_position_data_raw.csv'\n",
        "sixteen_holes_position_raw_path = 'sixteen_holes_position_data_raw.csv'\n",
        "twentyfive_holes_position_raw_path = 'twentyfive_holes_position_data_raw.csv'\n",
        "\n",
        "\n",
        "## csvファイルをリスト化\n",
        "\n",
        "### 穴なしの温度分布データ\n",
        "with open(no_hole_path) as f0:\n",
        "  lst_f0 = list(csv.reader(f0))\n",
        "lst_f0 = [r[:-1] for r in lst_f0]\n",
        "\n",
        "### 大きさに関するデータ\n",
        "with open(one_hole_size_path) as fs1:\n",
        "  lst_fs1 = list(csv.reader(fs1))\n",
        "with open(four_holes_size_path) as fs2:\n",
        "  lst_fs2 = list(csv.reader(fs2))\n",
        "with open(nine_holes_size_path) as fs3:\n",
        "  lst_fs3 = list(csv.reader(fs3))\n",
        "with open(sixteen_holes_size_path) as fs4:\n",
        "  lst_fs4 = list(csv.reader(fs4))\n",
        "with open(twentyfive_holes_size_path) as fs5:\n",
        "  lst_fs5 = list(csv.reader(fs5))\n",
        "\n",
        "### 位置に関するデータ\n",
        "with open(one_hole_position_path) as fp1:\n",
        "  lst_fp1 = list(csv.reader(fp1))\n",
        "with open(four_holes_position_path) as fp2:\n",
        "  lst_fp2 = list(csv.reader(fp2))\n",
        "with open(nine_holes_position_path) as fp3:\n",
        "  lst_fp3 = list(csv.reader(fp3))\n",
        "with open(sixteen_holes_position_path) as fp4:\n",
        "  lst_fp4 = list(csv.reader(fp4))\n",
        "with open(twentyfive_holes_position_path) as fp5:\n",
        "  lst_fp5 = list(csv.reader(fp5))\n",
        "\n",
        "### raw位置に関するデータ\n",
        "with open(one_hole_position_raw_path) as fp1_raw:\n",
        "  lst_fp1_raw = list(csv.reader(fp1_raw))\n",
        "with open(four_holes_position_raw_path) as fp2_raw:\n",
        "  lst_fp2_raw = list(csv.reader(fp2_raw))\n",
        "with open(nine_holes_position_raw_path) as fp3_raw:\n",
        "  lst_fp3_raw = list(csv.reader(fp3_raw))\n",
        "with open(sixteen_holes_position_raw_path) as fp4_raw:\n",
        "  lst_fp4_raw = list(csv.reader(fp4_raw))\n",
        "with open(twentyfive_holes_position_raw_path) as fp5_raw:\n",
        "  lst_fp5_raw = list(csv.reader(fp5_raw))"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zboAkcSShjrH"
      },
      "source": [
        "# model_1\n",
        "\n",
        "# データの前処理\n",
        "\n",
        "\n",
        "## 変数設定(各条件を変えてたくさん試すため)\n",
        "n = 3000                    #nは総抽出データ数\n",
        "train = 0.8                 #train:validのtrainデータの割合\n",
        "seed = 0                       \n",
        "random.seed(seed)           #乱数seed固定\n",
        "\n",
        "\n",
        "## データ加工\n",
        "\n",
        "### データ抽出(各データをランダムにシャッフル→train,valid,testに分割。各大きさのデータが同じ数だけ抽出される。)\n",
        "for i in range (1,6):\n",
        "  exec(\"dummy_lst_fs\"+str(i)+\"_shuffle = random.sample(lst_fs\"+str(i)+\", len(lst_fs\"+str(i)+\"))\")  \n",
        "  exec(\"dummy_lst_fs\"+str(i)+\"_train = dummy_lst_fs\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")       \n",
        "  exec(\"dummy_lst_fs\"+str(i)+\"_valid = dummy_lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\") \n",
        "  exec(\"dummy_lst_fs\"+str(i)+\"_test_samesize = dummy_lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":\"+str(int(n*2/5))+\"]\")  #拡張前と同数の拡張用データセットを作成                  \n",
        "  exec(\"dummy_lst_fs\"+str(i)+\"_test = dummy_lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "  \n",
        "  exec(\"lst_fp\"+str(i)+\"_shuffle = random.sample(lst_fp\"+str(i)+\", len(lst_fp\"+str(i)+\"))\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_train = lst_fp\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_valid = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\") \n",
        "  exec(\"lst_fp\"+str(i)+\"_test_samesize = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":\"+str(int(n*2/5))+\"]\")  #拡張前と同数の拡張用データセットを作成         \n",
        "  exec(\"lst_fp\"+str(i)+\"_test = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "\n",
        "random.seed(seed)\n",
        "\n",
        "for i in range(1,6):\n",
        "  exec(\"lst_fs\"+str(i)+\"_shuffle = random.sample(lst_fs\"+str(i)+\", len(lst_fs\"+str(i)+\"))\")  \n",
        "  exec(\"lst_fs\"+str(i)+\"_train = lst_fs\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")       \n",
        "  exec(\"lst_fs\"+str(i)+\"_valid = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\") \n",
        "  exec(\"lst_fs\"+str(i)+\"_test_samesize = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":\"+str(int(n*2/5))+\"]\")  #拡張前と同数の拡張用データセットを作成         \n",
        "  exec(\"lst_fs\"+str(i)+\"_test = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "  \n",
        "  exec(\"lst_fp\"+str(i)+\"_raw_shuffle = random.sample(lst_fp\"+str(i)+\"_raw, len(lst_fp\"+str(i)+\"_raw))\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_raw_train = lst_fp\"+str(i)+\"_raw_shuffle[0:\"+str(int(n/5*train))+\"]\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_raw_valid = lst_fp\"+str(i)+\"_raw_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\") \n",
        "  exec(\"lst_fp\"+str(i)+\"_raw_test_samesize = lst_fp\"+str(i)+\"_raw_shuffle[\"+str(int(n/5))+\":\"+str(int(n*2/5))+\"]\")  #拡張前と同数の拡張用データセットを作成         \n",
        "  exec(\"lst_fp\"+str(i)+\"_raw_test = lst_fp\"+str(i)+\"_raw_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "\n",
        "### train,valid,testの各々について、大きさ、位置、表面温度分布データに分割\n",
        "for i in range (1,6):\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_train = [r[0] for r in lst_fs\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_train = [r[0] for r in lst_fp\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_train = [r[1:-1] for r in lst_fp\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_valid = [r[0] for r in lst_fs\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_valid = [r[0] for r in lst_fp\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_valid = [r[1:-1] for r in lst_fp\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_test = [r[0] for r in lst_fs\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_test = [r[0] for r in lst_fp\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_test = [r[1:-1] for r in lst_fp\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_test_samesize = [r[0] for r in lst_fs\"+str(i)+\"_test_samesize]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_test_samesize = [r[0] for r in lst_fp\"+str(i)+\"_test_samesize]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_test_samesize = [r[1:-1] for r in lst_fp\"+str(i)+\"_test_samesize]\")\n",
        "\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_raw_train = [r[0:2] for r in lst_fp\"+str(i)+\"_raw_train]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_raw_valid = [r[0:2] for r in lst_fp\"+str(i)+\"_raw_valid]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_raw_test = [r[0:2] for r in lst_fp\"+str(i)+\"_raw_test]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_raw_test_samesize = [r[0:2] for r in lst_fp\"+str(i)+\"_raw_test_samesize]\")\n",
        "\n",
        "\n",
        "### データを結合(入力データ・正解データの大枠完成)\n",
        "lst_x_fs_train = lst_x_fs1_train + lst_x_fs2_train + lst_x_fs3_train + lst_x_fs4_train + lst_x_fs5_train\n",
        "lst_x_fp_train = lst_x_fp1_train + lst_x_fp2_train + lst_x_fp3_train + lst_x_fp4_train + lst_x_fp5_train\n",
        "lst_y_train = lst_y1_train + lst_y2_train + lst_y3_train + lst_y4_train + lst_y5_train\n",
        "\n",
        "lst_x_fs_valid = lst_x_fs1_valid + lst_x_fs2_valid + lst_x_fs3_valid + lst_x_fs4_valid + lst_x_fs5_valid\n",
        "lst_x_fp_valid = lst_x_fp1_valid + lst_x_fp2_valid + lst_x_fp3_valid + lst_x_fp4_valid + lst_x_fp5_valid\n",
        "lst_y_valid = lst_y1_valid + lst_y2_valid + lst_y3_valid + lst_y4_valid + lst_y5_valid\n",
        "\n",
        "lst_x_fs_test = lst_x_fs1_test + lst_x_fs2_test + lst_x_fs3_test + lst_x_fs4_test + lst_x_fs5_test\n",
        "lst_x_fp_test = lst_x_fp1_test + lst_x_fp2_test + lst_x_fp3_test + lst_x_fp4_test + lst_x_fp5_test\n",
        "lst_y_test = lst_y1_test + lst_y2_test + lst_y3_test + lst_y4_test + lst_y5_test\n",
        "lst_x_fs_test_samesize = lst_x_fs1_test_samesize + lst_x_fs2_test_samesize + lst_x_fs3_test_samesize + lst_x_fs4_test_samesize + lst_x_fs5_test_samesize\n",
        "lst_x_fp_test_samesize = lst_x_fp1_test_samesize + lst_x_fp2_test_samesize + lst_x_fp3_test_samesize + lst_x_fp4_test_samesize + lst_x_fp5_test_samesize\n",
        "lst_y_test_samesize = lst_y1_test_samesize + lst_y2_test_samesize + lst_y3_test_samesize + lst_y4_test_samesize + lst_y5_test_samesize\n",
        "\n",
        "lst_x_fp_raw_train = lst_x_fp1_raw_train + lst_x_fp2_raw_train + lst_x_fp3_raw_train + lst_x_fp4_raw_train + lst_x_fp5_raw_train\n",
        "lst_x_fp_raw_valid = lst_x_fp1_raw_valid + lst_x_fp2_raw_valid + lst_x_fp3_raw_valid + lst_x_fp4_raw_valid + lst_x_fp5_raw_valid\n",
        "lst_x_fp_raw_test = lst_x_fp1_raw_test + lst_x_fp2_raw_test + lst_x_fp3_raw_test + lst_x_fp4_raw_test + lst_x_fp5_raw_test\n",
        "lst_x_fp_raw_test_samesize = lst_x_fp1_raw_test_samesize + lst_x_fp2_raw_test_samesize + lst_x_fp3_raw_test_samesize + lst_x_fp4_raw_test_samesize + lst_x_fp5_raw_test_samesize\n",
        "\n",
        "\n",
        "### np.arrayで変換\n",
        "lst_f0 = np.array(lst_f0, dtype=float)\n",
        "lst_x_fs_train = np.array(lst_x_fs_train, dtype=int)\n",
        "lst_x_fp_train = np.array(lst_x_fp_train, dtype=int)\n",
        "lst_x_fs_valid = np.array(lst_x_fs_valid, dtype=int)\n",
        "lst_x_fp_valid = np.array(lst_x_fp_valid, dtype=int)\n",
        "lst_x_fs_test = np.array(lst_x_fs_test, dtype=int)\n",
        "lst_x_fp_test = np.array(lst_x_fp_test, dtype=int)\n",
        "lst_y_train = np.array(lst_y_train, dtype=float)\n",
        "lst_y_valid = np.array(lst_y_valid, dtype=float)\n",
        "lst_y_test = np.array(lst_y_test, dtype=float)\n",
        "\n",
        "lst_x_fp_raw_train = np.array(lst_x_fp_raw_train, dtype=int)\n",
        "lst_x_fp_raw_valid = np.array(lst_x_fp_raw_valid, dtype=int)\n",
        "lst_x_fp_raw_test = np.array(lst_x_fp_raw_test, dtype=int)\n",
        "\n",
        "lst_x_fs_test_samesize = np.array(lst_x_fs_test_samesize, dtype=int)\n",
        "lst_x_fp_test_samesize = np.array(lst_x_fp_test_samesize, dtype=int)\n",
        "lst_y_test_samesize = np.array(lst_y_test_samesize, dtype=float)\n",
        "lst_x_fp_raw_test_samesize = np.array(lst_x_fp_raw_test_samesize, dtype=int)\n",
        "\n",
        "### 大きさデータを二次元化\n",
        "x_fs_train = lst_x_fs_train.reshape(-1, 1)\n",
        "x_fs_valid = lst_x_fs_valid.reshape(-1, 1)\n",
        "x_fs_test = lst_x_fs_test.reshape(-1, 1)\n",
        "x_fs_test_samesize = lst_x_fs_test_samesize.reshape(-1, 1)\n",
        "x_fp_train = lst_x_fp_train.reshape(-1, 1)\n",
        "x_fp_valid = lst_x_fp_valid.reshape(-1, 1)\n",
        "x_fp_test = lst_x_fp_test.reshape(-1, 1)\n",
        "x_fp_test_samesize = lst_x_fp_test_samesize.reshape(-1, 1)\n",
        "\n",
        "### 温度分布データを、穴なし温度分布データとの差に変換\n",
        "y_train = lst_y_train - lst_f0\n",
        "y_valid = lst_y_valid - lst_f0\n",
        "y_test = lst_y_test - lst_f0\n",
        "y_test_samesize = lst_y_test_samesize - lst_f0\n",
        "\n",
        "### 入力データの正規化\n",
        "scaler_x = MinMaxScaler()\n",
        "x_fs_train_n = scaler_x.fit_transform(x_fs_train)\n",
        "x_fs_valid_n = scaler_x.fit_transform(x_fs_valid)\n",
        "x_fs_test_n = scaler_x.fit_transform(x_fs_test) \n",
        "x_fs_test_samesize_n = scaler_x.fit_transform(x_fs_test_samesize) \n",
        "x_fp_train_n = scaler_x.fit_transform(x_fp_train)\n",
        "x_fp_valid_n = scaler_x.fit_transform(x_fp_valid)\n",
        "x_fp_test_n = scaler_x.fit_transform(x_fp_test) \n",
        "x_fp_test_samesize_n = scaler_x.fit_transform(x_fp_test_samesize) \n",
        "\n",
        "x_fp_raw_train_n = scaler_x.fit_transform(lst_x_fp_raw_train)\n",
        "x_fp_raw_valid_n = scaler_x.fit_transform(lst_x_fp_raw_valid)\n",
        "x_fp_raw_test_n = scaler_x.fit_transform(lst_x_fp_raw_test)\n",
        "x_fp_raw_test_samesize_n = scaler_x.fit_transform(lst_x_fp_raw_test_samesize)"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C5wMk9Q-Bpq",
        "outputId": "f4471c55-1c52-42d8-fcb5-4fd8d05b5f9c"
      },
      "source": [
        "# データ拡張\n",
        "# 余りの全データ使用\n",
        "## 作成済モデルでデータ生成\n",
        "\n",
        "model = load_model(str(n)+\"_random.seed(\"+str(seed)+\")_train\"+str(train)+\"_raw.h5\")\n",
        "y_expand_data = model.predict([x_fs_test_n, x_fp_raw_test_n])\n",
        "y_expand_data"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01554966, -0.01298701, -0.01270833, ..., -0.03566506,\n",
              "        -0.03311147, -0.0311748 ],\n",
              "       [-0.08306216, -0.06377483, -0.06278316, ..., -0.15449256,\n",
              "        -0.15744057, -0.15693665],\n",
              "       [ 0.00976466,  0.00957876,  0.00945746, ...,  0.02329478,\n",
              "         0.02325381,  0.02323581],\n",
              "       ...,\n",
              "       [-0.42708534, -0.4113872 , -0.36762628, ..., -0.05424393,\n",
              "        -0.05348612, -0.05821864],\n",
              "       [ 0.05507591,  0.05540215,  0.05522765, ..., -0.9289188 ,\n",
              "        -1.0048972 , -1.028476  ],\n",
              "       [ 1.7214499 ,  1.7214303 ,  1.7144221 , ...,  0.18058905,\n",
              "         0.18049407,  0.18053292]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE-1YQ_dhzV2",
        "outputId": "8cb93eba-df98-4d65-c8d3-51b2c2c50fd9"
      },
      "source": [
        "# データ拡張\n",
        "# 余ったデータ全てではなく、拡張用も一部のみを利用\n",
        "## 作成済モデルでデータ生成\n",
        "\n",
        "model = load_model(str(n)+\"_random.seed(\"+str(seed)+\")_train\"+str(train)+\"_raw.h5\")\n",
        "y_expand_samesize_data = model.predict([x_fs_test_samesize_n, x_fp_raw_test_samesize_n])\n",
        "y_expand_samesize_data"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01554966, -0.01298701, -0.01270833, ..., -0.03566506,\n",
              "        -0.03311147, -0.0311748 ],\n",
              "       [-0.08306216, -0.06377483, -0.06278316, ..., -0.15449256,\n",
              "        -0.15744057, -0.15693665],\n",
              "       [ 0.00976466,  0.00957876,  0.00945746, ...,  0.02329478,\n",
              "         0.02325381,  0.02323581],\n",
              "       ...,\n",
              "       [ 0.25422186,  0.25320676,  0.25398946, ...,  1.2881317 ,\n",
              "         1.2959726 ,  1.2985694 ],\n",
              "       [ 1.4908283 ,  1.4906737 ,  1.4855137 , ...,  0.30842057,\n",
              "         0.30819866,  0.30809298],\n",
              "       [ 0.20113724,  0.20179945,  0.20192052, ...,  2.0161104 ,\n",
              "         2.0303125 ,  2.0357776 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eemGhqD3Rmmw"
      },
      "source": [
        "## データセット作成\n",
        "\n",
        "### 拡張前セット\n",
        "X_not_expanded_data = np.concatenate([y_train, y_valid])\n",
        "size_Y_not_expanded_data = np.concatenate([x_fs_train, x_fs_valid])\n",
        "position_Y_not_expanded_data = np.concatenate([x_fp_train, x_fp_valid])\n",
        "\n",
        "### 拡張前セット(nが2倍)\n",
        "X_ne_ss_data = np.concatenate([y_train, y_valid, y_test_samesize])\n",
        "size_Y_ne_ss_data = np.concatenate([x_fs_train, x_fs_valid, x_fs_test_samesize])\n",
        "position_Y_ne_ss_data = np.concatenate([x_fp_train, x_fp_valid, x_fp_test_samesize])\n",
        "\n",
        "### 拡張後セット(全データ使用)\n",
        "X_data = np.concatenate([y_train, y_valid, y_expand_data])\n",
        "size_Y_data = np.concatenate([x_fs_train, x_fs_valid, x_fs_test])\n",
        "position_Y_data = np.concatenate([x_fp_train, x_fp_valid, x_fp_test])\n",
        "\n",
        "### 拡張後セット(一部データ使用)\n",
        "X_samesize_data = np.concatenate([y_train, y_valid, y_expand_samesize_data])\n",
        "size_Y_samesize_data = np.concatenate([x_fs_train, x_fs_valid, x_fs_test_samesize])\n",
        "position_Y_samesize_data = np.concatenate([x_fp_train, x_fp_valid, x_fp_test_samesize])\n",
        "\n",
        "### 正解データセット\n",
        "X_ans_data = np.concatenate([y_train, y_valid, y_test])\n",
        "size_Y_ans_data = np.concatenate([x_fs_train, x_fs_valid, x_fs_test])\n",
        "position_Y_ans_data = np.concatenate([x_fp_train, x_fp_valid, x_fp_test])"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUXPDkV4sud0"
      },
      "source": [
        "## データ加工\n",
        "size_Y_data = keras.utils.to_categorical(size_Y_data, 6)\n",
        "position_Y_data = keras.utils.to_categorical(position_Y_data, 26)\n",
        "\n",
        "size_Y_samesize_data = keras.utils.to_categorical(size_Y_samesize_data, 6)\n",
        "position_Y_samesize_data = keras.utils.to_categorical(position_Y_samesize_data, 26)\n",
        "\n",
        "size_Y_not_expanded_data = keras.utils.to_categorical(size_Y_not_expanded_data, 6)\n",
        "position_Y_not_expanded_data = keras.utils.to_categorical(position_Y_not_expanded_data, 26)\n",
        "\n",
        "size_Y_ne_ss_data = keras.utils.to_categorical(size_Y_ne_ss_data, 6)\n",
        "position_Y_ne_ss_data = keras.utils.to_categorical(position_Y_ne_ss_data, 26)\n",
        "\n",
        "size_Y_ans_data = keras.utils.to_categorical(size_Y_ans_data, 6)\n",
        "position_Y_ans_data = keras.utils.to_categorical(position_Y_ans_data, 26)"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYIF7o9oq7mc"
      },
      "source": [
        "### train用とtest用に分割(4:1)\n",
        "random.seed(seed)\n",
        "X_train, X_test, size_Y_train, size_Y_test, position_Y_train, position_Y_test = train_test_split(X_data, size_Y_data, position_Y_data, test_size=0.20)\n",
        "X_ss_train, X_ss_test, size_Y_ss_train, size_Y_ss_test, position_Y_ss_train, position_Y_ss_test = train_test_split(X_samesize_data, size_Y_samesize_data, position_Y_samesize_data, test_size=0.20)\n",
        "\n",
        "random.seed(seed)\n",
        "X_ne_train, X_ne_test, size_Y_ne_train, size_Y_ne_test, position_Y_ne_train, position_Y_ne_test = train_test_split(X_not_expanded_data, size_Y_not_expanded_data, position_Y_not_expanded_data, test_size=0.20)\n",
        "X_ne_ss_train, X_ne_ss_test, size_Y_ne_ss_train, size_Y_ne_ss_test, position_Y_ne_ss_train, position_Y_ne_ss_test = train_test_split(X_ne_ss_data, size_Y_ne_ss_data, position_Y_ne_ss_data, test_size=0.20)"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGmR447Eq9aR"
      },
      "source": [
        "X_train = X_train.reshape(-1, 50, 1)\n",
        "X_test = X_test.reshape(-1, 50, 1)\n",
        "X_ss_train = X_ss_train.reshape(-1, 50, 1)\n",
        "X_ss_test = X_ss_test.reshape(-1, 50, 1)\n",
        "X_ne_train = X_ne_train.reshape(-1, 50, 1)\n",
        "X_ne_test = X_ne_test.reshape(-1, 50, 1)\n",
        "X_ne_ss_train = X_ne_ss_train.reshape(-1, 50, 1)\n",
        "X_ne_ss_test = X_ne_ss_test.reshape(-1, 50, 1)\n",
        "X_ans_data = X_ans_data.reshape(-1, 50, 1)"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNuAsg61sJkf"
      },
      "source": [
        "## CNN(大きさ)\n",
        "\n",
        "### modelの作成\n",
        "size_model = Sequential()\n",
        "### 畳み込み層\n",
        "size_model.add(Conv1D(32, 3, padding='same', activation='relu', input_shape=(50, 1)))\n",
        "### プーリング層\n",
        "size_model.add(MaxPooling1D(2, padding='same'))\n",
        "### Flatten層\n",
        "size_model.add(Flatten())\n",
        "### 全結合層\n",
        "size_model.add(Dense(6, activation='softmax'))\n",
        "### バッチ正規化\n",
        "BatchNormalization()\n",
        "### optimizer\n",
        "adam = keras.optimizers.Adam()\n",
        "###modelのコンパイル\n",
        "size_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0GgEku6uLKG",
        "outputId": "0d6c0a5c-7956-4e0d-ec95-b3fb8946ed7c"
      },
      "source": [
        "# 学習(大きさ)\n",
        "epochs = 500\n",
        "batch_size = 128\n",
        "size_history = size_model.fit(X_ss_train, size_Y_ss_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_ss_test, size_Y_ss_test))"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "38/38 [==============================] - 1s 12ms/step - loss: 1.6429 - accuracy: 0.1981 - val_loss: 1.3624 - val_accuracy: 0.4175\n",
            "Epoch 2/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2953 - accuracy: 0.4457 - val_loss: 1.0468 - val_accuracy: 0.5942\n",
            "Epoch 3/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0061 - accuracy: 0.6740 - val_loss: 0.8422 - val_accuracy: 0.7642\n",
            "Epoch 4/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8089 - accuracy: 0.8257 - val_loss: 0.7079 - val_accuracy: 0.8925\n",
            "Epoch 5/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6821 - accuracy: 0.9030 - val_loss: 0.6094 - val_accuracy: 0.9125\n",
            "Epoch 6/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5818 - accuracy: 0.9161 - val_loss: 0.5295 - val_accuracy: 0.9083\n",
            "Epoch 7/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5075 - accuracy: 0.9209 - val_loss: 0.4683 - val_accuracy: 0.9200\n",
            "Epoch 8/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4453 - accuracy: 0.9287 - val_loss: 0.4208 - val_accuracy: 0.9250\n",
            "Epoch 9/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3938 - accuracy: 0.9336 - val_loss: 0.3856 - val_accuracy: 0.9242\n",
            "Epoch 10/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3742 - accuracy: 0.9277 - val_loss: 0.3637 - val_accuracy: 0.9225\n",
            "Epoch 11/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3394 - accuracy: 0.9278 - val_loss: 0.3387 - val_accuracy: 0.9317\n",
            "Epoch 12/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3168 - accuracy: 0.9267 - val_loss: 0.3196 - val_accuracy: 0.9283\n",
            "Epoch 13/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2958 - accuracy: 0.9354 - val_loss: 0.3179 - val_accuracy: 0.9233\n",
            "Epoch 14/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2939 - accuracy: 0.9347 - val_loss: 0.3089 - val_accuracy: 0.9292\n",
            "Epoch 15/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2697 - accuracy: 0.9393 - val_loss: 0.2946 - val_accuracy: 0.9292\n",
            "Epoch 16/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2721 - accuracy: 0.9358 - val_loss: 0.2887 - val_accuracy: 0.9308\n",
            "Epoch 17/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2495 - accuracy: 0.9372 - val_loss: 0.2935 - val_accuracy: 0.9292\n",
            "Epoch 18/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2584 - accuracy: 0.9353 - val_loss: 0.2718 - val_accuracy: 0.9317\n",
            "Epoch 19/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2421 - accuracy: 0.9397 - val_loss: 0.2931 - val_accuracy: 0.9292\n",
            "Epoch 20/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2408 - accuracy: 0.9392 - val_loss: 0.2805 - val_accuracy: 0.9275\n",
            "Epoch 21/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2424 - accuracy: 0.9380 - val_loss: 0.2623 - val_accuracy: 0.9325\n",
            "Epoch 22/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2487 - accuracy: 0.9309 - val_loss: 0.2599 - val_accuracy: 0.9325\n",
            "Epoch 23/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2339 - accuracy: 0.9382 - val_loss: 0.2589 - val_accuracy: 0.9308\n",
            "Epoch 24/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2153 - accuracy: 0.9390 - val_loss: 0.2570 - val_accuracy: 0.9342\n",
            "Epoch 25/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2229 - accuracy: 0.9368 - val_loss: 0.2671 - val_accuracy: 0.9275\n",
            "Epoch 26/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2197 - accuracy: 0.9404 - val_loss: 0.2638 - val_accuracy: 0.9375\n",
            "Epoch 27/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2354 - accuracy: 0.9386 - val_loss: 0.2477 - val_accuracy: 0.9300\n",
            "Epoch 28/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2098 - accuracy: 0.9455 - val_loss: 0.2452 - val_accuracy: 0.9300\n",
            "Epoch 29/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1990 - accuracy: 0.9485 - val_loss: 0.2433 - val_accuracy: 0.9358\n",
            "Epoch 30/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2134 - accuracy: 0.9402 - val_loss: 0.2526 - val_accuracy: 0.9300\n",
            "Epoch 31/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2092 - accuracy: 0.9383 - val_loss: 0.2507 - val_accuracy: 0.9367\n",
            "Epoch 32/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1995 - accuracy: 0.9453 - val_loss: 0.2708 - val_accuracy: 0.9317\n",
            "Epoch 33/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1948 - accuracy: 0.9466 - val_loss: 0.2468 - val_accuracy: 0.9342\n",
            "Epoch 34/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1989 - accuracy: 0.9473 - val_loss: 0.2535 - val_accuracy: 0.9392\n",
            "Epoch 35/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2054 - accuracy: 0.9460 - val_loss: 0.2392 - val_accuracy: 0.9342\n",
            "Epoch 36/500\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2037 - accuracy: 0.9430 - val_loss: 0.2364 - val_accuracy: 0.9358\n",
            "Epoch 37/500\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2048 - accuracy: 0.9442 - val_loss: 0.2315 - val_accuracy: 0.9375\n",
            "Epoch 38/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1861 - accuracy: 0.9477 - val_loss: 0.2344 - val_accuracy: 0.9375\n",
            "Epoch 39/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1928 - accuracy: 0.9424 - val_loss: 0.2502 - val_accuracy: 0.9333\n",
            "Epoch 40/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1807 - accuracy: 0.9491 - val_loss: 0.2285 - val_accuracy: 0.9383\n",
            "Epoch 41/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1849 - accuracy: 0.9476 - val_loss: 0.2310 - val_accuracy: 0.9383\n",
            "Epoch 42/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1946 - accuracy: 0.9463 - val_loss: 0.2288 - val_accuracy: 0.9367\n",
            "Epoch 43/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1773 - accuracy: 0.9518 - val_loss: 0.2554 - val_accuracy: 0.9367\n",
            "Epoch 44/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1840 - accuracy: 0.9479 - val_loss: 0.2391 - val_accuracy: 0.9367\n",
            "Epoch 45/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1845 - accuracy: 0.9457 - val_loss: 0.2357 - val_accuracy: 0.9350\n",
            "Epoch 46/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1782 - accuracy: 0.9484 - val_loss: 0.2419 - val_accuracy: 0.9400\n",
            "Epoch 47/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1942 - accuracy: 0.9453 - val_loss: 0.2953 - val_accuracy: 0.9367\n",
            "Epoch 48/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2069 - accuracy: 0.9514 - val_loss: 0.2587 - val_accuracy: 0.9375\n",
            "Epoch 49/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2009 - accuracy: 0.9406 - val_loss: 0.2317 - val_accuracy: 0.9392\n",
            "Epoch 50/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1737 - accuracy: 0.9506 - val_loss: 0.2206 - val_accuracy: 0.9350\n",
            "Epoch 51/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1812 - accuracy: 0.9479 - val_loss: 0.2516 - val_accuracy: 0.9375\n",
            "Epoch 52/500\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1848 - accuracy: 0.9426 - val_loss: 0.2353 - val_accuracy: 0.9392\n",
            "Epoch 53/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1736 - accuracy: 0.9470 - val_loss: 0.2289 - val_accuracy: 0.9392\n",
            "Epoch 54/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1806 - accuracy: 0.9472 - val_loss: 0.2305 - val_accuracy: 0.9450\n",
            "Epoch 55/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1839 - accuracy: 0.9523 - val_loss: 0.2235 - val_accuracy: 0.9433\n",
            "Epoch 56/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1788 - accuracy: 0.9470 - val_loss: 0.2279 - val_accuracy: 0.9400\n",
            "Epoch 57/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1818 - accuracy: 0.9454 - val_loss: 0.2295 - val_accuracy: 0.9408\n",
            "Epoch 58/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.1715 - accuracy: 0.9485 - val_loss: 0.2162 - val_accuracy: 0.9433\n",
            "Epoch 59/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1709 - accuracy: 0.9527 - val_loss: 0.2164 - val_accuracy: 0.9400\n",
            "Epoch 60/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1790 - accuracy: 0.9468 - val_loss: 0.2189 - val_accuracy: 0.9358\n",
            "Epoch 61/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1733 - accuracy: 0.9482 - val_loss: 0.2312 - val_accuracy: 0.9358\n",
            "Epoch 62/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1725 - accuracy: 0.9447 - val_loss: 0.2150 - val_accuracy: 0.9400\n",
            "Epoch 63/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1587 - accuracy: 0.9512 - val_loss: 0.2135 - val_accuracy: 0.9400\n",
            "Epoch 64/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1623 - accuracy: 0.9500 - val_loss: 0.2181 - val_accuracy: 0.9400\n",
            "Epoch 65/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1710 - accuracy: 0.9527 - val_loss: 0.2106 - val_accuracy: 0.9442\n",
            "Epoch 66/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1613 - accuracy: 0.9491 - val_loss: 0.2144 - val_accuracy: 0.9458\n",
            "Epoch 67/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1609 - accuracy: 0.9499 - val_loss: 0.2462 - val_accuracy: 0.9383\n",
            "Epoch 68/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1694 - accuracy: 0.9459 - val_loss: 0.2086 - val_accuracy: 0.9417\n",
            "Epoch 69/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1689 - accuracy: 0.9448 - val_loss: 0.2299 - val_accuracy: 0.9358\n",
            "Epoch 70/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1643 - accuracy: 0.9476 - val_loss: 0.2171 - val_accuracy: 0.9342\n",
            "Epoch 71/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1599 - accuracy: 0.9517 - val_loss: 0.2132 - val_accuracy: 0.9392\n",
            "Epoch 72/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1559 - accuracy: 0.9540 - val_loss: 0.2051 - val_accuracy: 0.9442\n",
            "Epoch 73/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1529 - accuracy: 0.9541 - val_loss: 0.2019 - val_accuracy: 0.9425\n",
            "Epoch 74/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1555 - accuracy: 0.9529 - val_loss: 0.2036 - val_accuracy: 0.9425\n",
            "Epoch 75/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1521 - accuracy: 0.9521 - val_loss: 0.2075 - val_accuracy: 0.9442\n",
            "Epoch 76/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1685 - accuracy: 0.9497 - val_loss: 0.2083 - val_accuracy: 0.9408\n",
            "Epoch 77/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1599 - accuracy: 0.9490 - val_loss: 0.2109 - val_accuracy: 0.9392\n",
            "Epoch 78/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1592 - accuracy: 0.9502 - val_loss: 0.2076 - val_accuracy: 0.9458\n",
            "Epoch 79/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1441 - accuracy: 0.9527 - val_loss: 0.2051 - val_accuracy: 0.9425\n",
            "Epoch 80/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1485 - accuracy: 0.9512 - val_loss: 0.2052 - val_accuracy: 0.9467\n",
            "Epoch 81/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1581 - accuracy: 0.9526 - val_loss: 0.1994 - val_accuracy: 0.9425\n",
            "Epoch 82/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1550 - accuracy: 0.9486 - val_loss: 0.2102 - val_accuracy: 0.9400\n",
            "Epoch 83/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1602 - accuracy: 0.9499 - val_loss: 0.2043 - val_accuracy: 0.9383\n",
            "Epoch 84/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1468 - accuracy: 0.9554 - val_loss: 0.2177 - val_accuracy: 0.9342\n",
            "Epoch 85/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1519 - accuracy: 0.9528 - val_loss: 0.1996 - val_accuracy: 0.9433\n",
            "Epoch 86/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1478 - accuracy: 0.9572 - val_loss: 0.2000 - val_accuracy: 0.9400\n",
            "Epoch 87/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1563 - accuracy: 0.9514 - val_loss: 0.2109 - val_accuracy: 0.9483\n",
            "Epoch 88/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1501 - accuracy: 0.9539 - val_loss: 0.2089 - val_accuracy: 0.9458\n",
            "Epoch 89/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 0.9590 - val_loss: 0.1979 - val_accuracy: 0.9458\n",
            "Epoch 90/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1533 - accuracy: 0.9505 - val_loss: 0.1938 - val_accuracy: 0.9433\n",
            "Epoch 91/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1335 - accuracy: 0.9582 - val_loss: 0.2117 - val_accuracy: 0.9467\n",
            "Epoch 92/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1435 - accuracy: 0.9561 - val_loss: 0.1895 - val_accuracy: 0.9458\n",
            "Epoch 93/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9493 - val_loss: 0.2034 - val_accuracy: 0.9417\n",
            "Epoch 94/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1448 - accuracy: 0.9548 - val_loss: 0.1996 - val_accuracy: 0.9425\n",
            "Epoch 95/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1324 - accuracy: 0.9592 - val_loss: 0.1902 - val_accuracy: 0.9392\n",
            "Epoch 96/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1354 - accuracy: 0.9569 - val_loss: 0.1976 - val_accuracy: 0.9467\n",
            "Epoch 97/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1383 - accuracy: 0.9556 - val_loss: 0.2272 - val_accuracy: 0.9467\n",
            "Epoch 98/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1518 - accuracy: 0.9565 - val_loss: 0.1911 - val_accuracy: 0.9433\n",
            "Epoch 99/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1317 - accuracy: 0.9590 - val_loss: 0.1992 - val_accuracy: 0.9408\n",
            "Epoch 100/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1382 - accuracy: 0.9542 - val_loss: 0.1969 - val_accuracy: 0.9425\n",
            "Epoch 101/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1466 - accuracy: 0.9521 - val_loss: 0.1874 - val_accuracy: 0.9425\n",
            "Epoch 102/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1511 - accuracy: 0.9515 - val_loss: 0.1894 - val_accuracy: 0.9417\n",
            "Epoch 103/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1474 - accuracy: 0.9575 - val_loss: 0.1810 - val_accuracy: 0.9433\n",
            "Epoch 104/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1299 - accuracy: 0.9611 - val_loss: 0.1852 - val_accuracy: 0.9408\n",
            "Epoch 105/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1415 - accuracy: 0.9597 - val_loss: 0.1895 - val_accuracy: 0.9433\n",
            "Epoch 106/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1402 - accuracy: 0.9545 - val_loss: 0.1836 - val_accuracy: 0.9450\n",
            "Epoch 107/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1303 - accuracy: 0.9609 - val_loss: 0.2096 - val_accuracy: 0.9442\n",
            "Epoch 108/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1483 - accuracy: 0.9561 - val_loss: 0.1765 - val_accuracy: 0.9492\n",
            "Epoch 109/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1211 - accuracy: 0.9602 - val_loss: 0.1780 - val_accuracy: 0.9458\n",
            "Epoch 110/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1419 - accuracy: 0.9545 - val_loss: 0.1857 - val_accuracy: 0.9417\n",
            "Epoch 111/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1235 - accuracy: 0.9569 - val_loss: 0.1950 - val_accuracy: 0.9433\n",
            "Epoch 112/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1278 - accuracy: 0.9632 - val_loss: 0.1800 - val_accuracy: 0.9450\n",
            "Epoch 113/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1212 - accuracy: 0.9590 - val_loss: 0.1972 - val_accuracy: 0.9450\n",
            "Epoch 114/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1352 - accuracy: 0.9595 - val_loss: 0.1902 - val_accuracy: 0.9417\n",
            "Epoch 115/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1385 - accuracy: 0.9559 - val_loss: 0.1943 - val_accuracy: 0.9417\n",
            "Epoch 116/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.1317 - accuracy: 0.9588 - val_loss: 0.1804 - val_accuracy: 0.9425\n",
            "Epoch 117/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1267 - accuracy: 0.9582 - val_loss: 0.1906 - val_accuracy: 0.9433\n",
            "Epoch 118/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1290 - accuracy: 0.9571 - val_loss: 0.1738 - val_accuracy: 0.9475\n",
            "Epoch 119/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1344 - accuracy: 0.9570 - val_loss: 0.1841 - val_accuracy: 0.9408\n",
            "Epoch 120/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1207 - accuracy: 0.9594 - val_loss: 0.1795 - val_accuracy: 0.9442\n",
            "Epoch 121/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1237 - accuracy: 0.9629 - val_loss: 0.1762 - val_accuracy: 0.9417\n",
            "Epoch 122/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1219 - accuracy: 0.9619 - val_loss: 0.1998 - val_accuracy: 0.9492\n",
            "Epoch 123/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1326 - accuracy: 0.9595 - val_loss: 0.1786 - val_accuracy: 0.9458\n",
            "Epoch 124/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1286 - accuracy: 0.9628 - val_loss: 0.1984 - val_accuracy: 0.9483\n",
            "Epoch 125/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1454 - accuracy: 0.9579 - val_loss: 0.1723 - val_accuracy: 0.9500\n",
            "Epoch 126/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1154 - accuracy: 0.9660 - val_loss: 0.1725 - val_accuracy: 0.9450\n",
            "Epoch 127/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1188 - accuracy: 0.9620 - val_loss: 0.1774 - val_accuracy: 0.9475\n",
            "Epoch 128/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1396 - accuracy: 0.9529 - val_loss: 0.1743 - val_accuracy: 0.9442\n",
            "Epoch 129/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1140 - accuracy: 0.9660 - val_loss: 0.1731 - val_accuracy: 0.9442\n",
            "Epoch 130/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1150 - accuracy: 0.9626 - val_loss: 0.1994 - val_accuracy: 0.9517\n",
            "Epoch 131/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1189 - accuracy: 0.9621 - val_loss: 0.1660 - val_accuracy: 0.9492\n",
            "Epoch 132/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1236 - accuracy: 0.9629 - val_loss: 0.1650 - val_accuracy: 0.9500\n",
            "Epoch 133/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1230 - accuracy: 0.9632 - val_loss: 0.1662 - val_accuracy: 0.9433\n",
            "Epoch 134/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1140 - accuracy: 0.9642 - val_loss: 0.1698 - val_accuracy: 0.9458\n",
            "Epoch 135/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1108 - accuracy: 0.9661 - val_loss: 0.1722 - val_accuracy: 0.9417\n",
            "Epoch 136/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1233 - accuracy: 0.9617 - val_loss: 0.1649 - val_accuracy: 0.9483\n",
            "Epoch 137/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1170 - accuracy: 0.9606 - val_loss: 0.1628 - val_accuracy: 0.9475\n",
            "Epoch 138/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1111 - accuracy: 0.9642 - val_loss: 0.1653 - val_accuracy: 0.9500\n",
            "Epoch 139/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1272 - accuracy: 0.9571 - val_loss: 0.1616 - val_accuracy: 0.9483\n",
            "Epoch 140/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1078 - accuracy: 0.9675 - val_loss: 0.1613 - val_accuracy: 0.9475\n",
            "Epoch 141/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1106 - accuracy: 0.9607 - val_loss: 0.1669 - val_accuracy: 0.9500\n",
            "Epoch 142/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1100 - accuracy: 0.9666 - val_loss: 0.1630 - val_accuracy: 0.9492\n",
            "Epoch 143/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1227 - accuracy: 0.9593 - val_loss: 0.1671 - val_accuracy: 0.9517\n",
            "Epoch 144/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1144 - accuracy: 0.9646 - val_loss: 0.1808 - val_accuracy: 0.9492\n",
            "Epoch 145/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1157 - accuracy: 0.9651 - val_loss: 0.1730 - val_accuracy: 0.9442\n",
            "Epoch 146/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1213 - accuracy: 0.9633 - val_loss: 0.1796 - val_accuracy: 0.9425\n",
            "Epoch 147/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1073 - accuracy: 0.9630 - val_loss: 0.1556 - val_accuracy: 0.9508\n",
            "Epoch 148/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1059 - accuracy: 0.9658 - val_loss: 0.1614 - val_accuracy: 0.9517\n",
            "Epoch 149/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1137 - accuracy: 0.9633 - val_loss: 0.1625 - val_accuracy: 0.9467\n",
            "Epoch 150/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1054 - accuracy: 0.9670 - val_loss: 0.1791 - val_accuracy: 0.9467\n",
            "Epoch 151/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1054 - accuracy: 0.9643 - val_loss: 0.1610 - val_accuracy: 0.9475\n",
            "Epoch 152/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1038 - accuracy: 0.9666 - val_loss: 0.1548 - val_accuracy: 0.9483\n",
            "Epoch 153/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1021 - accuracy: 0.9673 - val_loss: 0.1548 - val_accuracy: 0.9508\n",
            "Epoch 154/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1039 - accuracy: 0.9703 - val_loss: 0.1682 - val_accuracy: 0.9525\n",
            "Epoch 155/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1135 - accuracy: 0.9624 - val_loss: 0.1521 - val_accuracy: 0.9533\n",
            "Epoch 156/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1081 - accuracy: 0.9694 - val_loss: 0.1625 - val_accuracy: 0.9492\n",
            "Epoch 157/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1006 - accuracy: 0.9680 - val_loss: 0.1546 - val_accuracy: 0.9517\n",
            "Epoch 158/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1070 - accuracy: 0.9649 - val_loss: 0.1499 - val_accuracy: 0.9517\n",
            "Epoch 159/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0985 - accuracy: 0.9723 - val_loss: 0.1507 - val_accuracy: 0.9500\n",
            "Epoch 160/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0992 - accuracy: 0.9694 - val_loss: 0.1583 - val_accuracy: 0.9558\n",
            "Epoch 161/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0982 - accuracy: 0.9701 - val_loss: 0.1593 - val_accuracy: 0.9508\n",
            "Epoch 162/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0908 - accuracy: 0.9711 - val_loss: 0.1496 - val_accuracy: 0.9508\n",
            "Epoch 163/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0949 - accuracy: 0.9698 - val_loss: 0.1524 - val_accuracy: 0.9558\n",
            "Epoch 164/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0999 - accuracy: 0.9707 - val_loss: 0.1513 - val_accuracy: 0.9558\n",
            "Epoch 165/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.9704 - val_loss: 0.1477 - val_accuracy: 0.9542\n",
            "Epoch 166/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0966 - accuracy: 0.9675 - val_loss: 0.1561 - val_accuracy: 0.9542\n",
            "Epoch 167/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0926 - accuracy: 0.9736 - val_loss: 0.1425 - val_accuracy: 0.9575\n",
            "Epoch 168/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1008 - accuracy: 0.9707 - val_loss: 0.1503 - val_accuracy: 0.9550\n",
            "Epoch 169/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0942 - accuracy: 0.9717 - val_loss: 0.1686 - val_accuracy: 0.9558\n",
            "Epoch 170/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9681 - val_loss: 0.1689 - val_accuracy: 0.9492\n",
            "Epoch 171/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1274 - accuracy: 0.9644 - val_loss: 0.1424 - val_accuracy: 0.9558\n",
            "Epoch 172/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0946 - accuracy: 0.9723 - val_loss: 0.1533 - val_accuracy: 0.9517\n",
            "Epoch 173/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0953 - accuracy: 0.9677 - val_loss: 0.1472 - val_accuracy: 0.9558\n",
            "Epoch 174/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1095 - accuracy: 0.9645 - val_loss: 0.1585 - val_accuracy: 0.9583\n",
            "Epoch 175/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1043 - accuracy: 0.9681 - val_loss: 0.1505 - val_accuracy: 0.9592\n",
            "Epoch 176/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0926 - accuracy: 0.9716 - val_loss: 0.1496 - val_accuracy: 0.9533\n",
            "Epoch 177/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0968 - accuracy: 0.9744 - val_loss: 0.1877 - val_accuracy: 0.9508\n",
            "Epoch 178/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1082 - accuracy: 0.9664 - val_loss: 0.1503 - val_accuracy: 0.9542\n",
            "Epoch 179/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0917 - accuracy: 0.9743 - val_loss: 0.1456 - val_accuracy: 0.9567\n",
            "Epoch 180/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0887 - accuracy: 0.9743 - val_loss: 0.1424 - val_accuracy: 0.9575\n",
            "Epoch 181/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0839 - accuracy: 0.9681 - val_loss: 0.1410 - val_accuracy: 0.9567\n",
            "Epoch 182/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0932 - accuracy: 0.9705 - val_loss: 0.1459 - val_accuracy: 0.9575\n",
            "Epoch 183/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0940 - accuracy: 0.9720 - val_loss: 0.1623 - val_accuracy: 0.9567\n",
            "Epoch 184/500\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0916 - accuracy: 0.9747 - val_loss: 0.1451 - val_accuracy: 0.9542\n",
            "Epoch 185/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1012 - accuracy: 0.9701 - val_loss: 0.1416 - val_accuracy: 0.9550\n",
            "Epoch 186/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0939 - accuracy: 0.9730 - val_loss: 0.1519 - val_accuracy: 0.9550\n",
            "Epoch 187/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0860 - accuracy: 0.9750 - val_loss: 0.1371 - val_accuracy: 0.9608\n",
            "Epoch 188/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0865 - accuracy: 0.9751 - val_loss: 0.1398 - val_accuracy: 0.9575\n",
            "Epoch 189/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0866 - accuracy: 0.9697 - val_loss: 0.1392 - val_accuracy: 0.9600\n",
            "Epoch 190/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0873 - accuracy: 0.9720 - val_loss: 0.1387 - val_accuracy: 0.9608\n",
            "Epoch 191/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0903 - accuracy: 0.9716 - val_loss: 0.1307 - val_accuracy: 0.9617\n",
            "Epoch 192/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0945 - accuracy: 0.9673 - val_loss: 0.1437 - val_accuracy: 0.9592\n",
            "Epoch 193/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0894 - accuracy: 0.9727 - val_loss: 0.1470 - val_accuracy: 0.9608\n",
            "Epoch 194/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0798 - accuracy: 0.9762 - val_loss: 0.1429 - val_accuracy: 0.9567\n",
            "Epoch 195/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0860 - accuracy: 0.9753 - val_loss: 0.1400 - val_accuracy: 0.9583\n",
            "Epoch 196/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0939 - accuracy: 0.9723 - val_loss: 0.1403 - val_accuracy: 0.9600\n",
            "Epoch 197/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9779 - val_loss: 0.1352 - val_accuracy: 0.9617\n",
            "Epoch 198/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9752 - val_loss: 0.1315 - val_accuracy: 0.9625\n",
            "Epoch 199/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0810 - accuracy: 0.9739 - val_loss: 0.1370 - val_accuracy: 0.9592\n",
            "Epoch 200/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0772 - accuracy: 0.9767 - val_loss: 0.1320 - val_accuracy: 0.9650\n",
            "Epoch 201/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0775 - accuracy: 0.9787 - val_loss: 0.1316 - val_accuracy: 0.9583\n",
            "Epoch 202/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.9739 - val_loss: 0.1556 - val_accuracy: 0.9592\n",
            "Epoch 203/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0843 - accuracy: 0.9766 - val_loss: 0.1368 - val_accuracy: 0.9625\n",
            "Epoch 204/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9777 - val_loss: 0.1299 - val_accuracy: 0.9583\n",
            "Epoch 205/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0763 - accuracy: 0.9778 - val_loss: 0.1288 - val_accuracy: 0.9658\n",
            "Epoch 206/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0789 - accuracy: 0.9803 - val_loss: 0.1328 - val_accuracy: 0.9617\n",
            "Epoch 207/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0781 - accuracy: 0.9753 - val_loss: 0.1357 - val_accuracy: 0.9642\n",
            "Epoch 208/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0913 - accuracy: 0.9741 - val_loss: 0.1327 - val_accuracy: 0.9633\n",
            "Epoch 209/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0778 - accuracy: 0.9774 - val_loss: 0.1282 - val_accuracy: 0.9600\n",
            "Epoch 210/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0701 - accuracy: 0.9807 - val_loss: 0.1284 - val_accuracy: 0.9600\n",
            "Epoch 211/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0766 - accuracy: 0.9778 - val_loss: 0.1261 - val_accuracy: 0.9625\n",
            "Epoch 212/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0695 - accuracy: 0.9820 - val_loss: 0.1237 - val_accuracy: 0.9650\n",
            "Epoch 213/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0719 - accuracy: 0.9820 - val_loss: 0.1406 - val_accuracy: 0.9600\n",
            "Epoch 214/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0785 - accuracy: 0.9762 - val_loss: 0.1265 - val_accuracy: 0.9633\n",
            "Epoch 215/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0787 - accuracy: 0.9807 - val_loss: 0.1285 - val_accuracy: 0.9642\n",
            "Epoch 216/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0744 - accuracy: 0.9772 - val_loss: 0.1267 - val_accuracy: 0.9633\n",
            "Epoch 217/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0699 - accuracy: 0.9844 - val_loss: 0.1566 - val_accuracy: 0.9650\n",
            "Epoch 218/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0878 - accuracy: 0.9735 - val_loss: 0.1791 - val_accuracy: 0.9592\n",
            "Epoch 219/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0883 - accuracy: 0.9736 - val_loss: 0.1236 - val_accuracy: 0.9625\n",
            "Epoch 220/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0687 - accuracy: 0.9790 - val_loss: 0.1388 - val_accuracy: 0.9600\n",
            "Epoch 221/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0784 - accuracy: 0.9791 - val_loss: 0.1339 - val_accuracy: 0.9650\n",
            "Epoch 222/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0709 - accuracy: 0.9779 - val_loss: 0.1231 - val_accuracy: 0.9683\n",
            "Epoch 223/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0665 - accuracy: 0.9818 - val_loss: 0.1454 - val_accuracy: 0.9658\n",
            "Epoch 224/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0733 - accuracy: 0.9821 - val_loss: 0.1234 - val_accuracy: 0.9642\n",
            "Epoch 225/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0693 - accuracy: 0.9821 - val_loss: 0.1216 - val_accuracy: 0.9658\n",
            "Epoch 226/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 0.1188 - val_accuracy: 0.9675\n",
            "Epoch 227/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0702 - accuracy: 0.9834 - val_loss: 0.1191 - val_accuracy: 0.9683\n",
            "Epoch 228/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0771 - accuracy: 0.9758 - val_loss: 0.1308 - val_accuracy: 0.9633\n",
            "Epoch 229/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0701 - accuracy: 0.9773 - val_loss: 0.1278 - val_accuracy: 0.9675\n",
            "Epoch 230/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0599 - accuracy: 0.9847 - val_loss: 0.1183 - val_accuracy: 0.9658\n",
            "Epoch 231/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0715 - accuracy: 0.9800 - val_loss: 0.1380 - val_accuracy: 0.9683\n",
            "Epoch 232/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0662 - accuracy: 0.9809 - val_loss: 0.1219 - val_accuracy: 0.9675\n",
            "Epoch 233/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0647 - accuracy: 0.9816 - val_loss: 0.1369 - val_accuracy: 0.9667\n",
            "Epoch 234/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0770 - accuracy: 0.9784 - val_loss: 0.1137 - val_accuracy: 0.9650\n",
            "Epoch 235/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0613 - accuracy: 0.9842 - val_loss: 0.1080 - val_accuracy: 0.9667\n",
            "Epoch 236/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0682 - accuracy: 0.9793 - val_loss: 0.1114 - val_accuracy: 0.9692\n",
            "Epoch 237/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0880 - accuracy: 0.9787 - val_loss: 0.1136 - val_accuracy: 0.9692\n",
            "Epoch 238/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0670 - accuracy: 0.9820 - val_loss: 0.1105 - val_accuracy: 0.9700\n",
            "Epoch 239/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0628 - accuracy: 0.9827 - val_loss: 0.1249 - val_accuracy: 0.9675\n",
            "Epoch 240/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0650 - accuracy: 0.9804 - val_loss: 0.1100 - val_accuracy: 0.9658\n",
            "Epoch 241/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0632 - accuracy: 0.9842 - val_loss: 0.1221 - val_accuracy: 0.9658\n",
            "Epoch 242/500\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0629 - accuracy: 0.9831 - val_loss: 0.1087 - val_accuracy: 0.9733\n",
            "Epoch 243/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0573 - accuracy: 0.9860 - val_loss: 0.1109 - val_accuracy: 0.9683\n",
            "Epoch 244/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0591 - accuracy: 0.9840 - val_loss: 0.1372 - val_accuracy: 0.9675\n",
            "Epoch 245/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0681 - accuracy: 0.9826 - val_loss: 0.1085 - val_accuracy: 0.9708\n",
            "Epoch 246/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0686 - accuracy: 0.9815 - val_loss: 0.1174 - val_accuracy: 0.9675\n",
            "Epoch 247/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0668 - accuracy: 0.9806 - val_loss: 0.1160 - val_accuracy: 0.9675\n",
            "Epoch 248/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0561 - accuracy: 0.9869 - val_loss: 0.1083 - val_accuracy: 0.9700\n",
            "Epoch 249/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0639 - accuracy: 0.9844 - val_loss: 0.1060 - val_accuracy: 0.9733\n",
            "Epoch 250/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0629 - accuracy: 0.9837 - val_loss: 0.1069 - val_accuracy: 0.9675\n",
            "Epoch 251/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0571 - accuracy: 0.9853 - val_loss: 0.1082 - val_accuracy: 0.9692\n",
            "Epoch 252/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0701 - accuracy: 0.9837 - val_loss: 0.1166 - val_accuracy: 0.9625\n",
            "Epoch 253/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0705 - accuracy: 0.9808 - val_loss: 0.1083 - val_accuracy: 0.9717\n",
            "Epoch 254/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0671 - accuracy: 0.9818 - val_loss: 0.1037 - val_accuracy: 0.9725\n",
            "Epoch 255/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0573 - accuracy: 0.9870 - val_loss: 0.1138 - val_accuracy: 0.9692\n",
            "Epoch 256/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0612 - accuracy: 0.9872 - val_loss: 0.1337 - val_accuracy: 0.9700\n",
            "Epoch 257/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0678 - accuracy: 0.9796 - val_loss: 0.1435 - val_accuracy: 0.9667\n",
            "Epoch 258/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0722 - accuracy: 0.9779 - val_loss: 0.1073 - val_accuracy: 0.9717\n",
            "Epoch 259/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0615 - accuracy: 0.9830 - val_loss: 0.1050 - val_accuracy: 0.9725\n",
            "Epoch 260/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0591 - accuracy: 0.9818 - val_loss: 0.1181 - val_accuracy: 0.9733\n",
            "Epoch 261/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0665 - accuracy: 0.9825 - val_loss: 0.1024 - val_accuracy: 0.9758\n",
            "Epoch 262/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0525 - accuracy: 0.9864 - val_loss: 0.1074 - val_accuracy: 0.9692\n",
            "Epoch 263/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0574 - accuracy: 0.9849 - val_loss: 0.1073 - val_accuracy: 0.9683\n",
            "Epoch 264/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0637 - accuracy: 0.9817 - val_loss: 0.1058 - val_accuracy: 0.9708\n",
            "Epoch 265/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9851 - val_loss: 0.1082 - val_accuracy: 0.9708\n",
            "Epoch 266/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0543 - accuracy: 0.9848 - val_loss: 0.1187 - val_accuracy: 0.9667\n",
            "Epoch 267/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9844 - val_loss: 0.1320 - val_accuracy: 0.9692\n",
            "Epoch 268/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0789 - accuracy: 0.9815 - val_loss: 0.1038 - val_accuracy: 0.9733\n",
            "Epoch 269/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0573 - accuracy: 0.9848 - val_loss: 0.1226 - val_accuracy: 0.9717\n",
            "Epoch 270/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0588 - accuracy: 0.9885 - val_loss: 0.0990 - val_accuracy: 0.9692\n",
            "Epoch 271/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0502 - accuracy: 0.9878 - val_loss: 0.1009 - val_accuracy: 0.9742\n",
            "Epoch 272/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0601 - accuracy: 0.9850 - val_loss: 0.1038 - val_accuracy: 0.9675\n",
            "Epoch 273/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0613 - accuracy: 0.9849 - val_loss: 0.0997 - val_accuracy: 0.9742\n",
            "Epoch 274/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9854 - val_loss: 0.0949 - val_accuracy: 0.9742\n",
            "Epoch 275/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0547 - accuracy: 0.9857 - val_loss: 0.0998 - val_accuracy: 0.9758\n",
            "Epoch 276/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 0.9875 - val_loss: 0.0957 - val_accuracy: 0.9700\n",
            "Epoch 277/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0544 - accuracy: 0.9858 - val_loss: 0.0999 - val_accuracy: 0.9750\n",
            "Epoch 278/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0507 - accuracy: 0.9890 - val_loss: 0.0951 - val_accuracy: 0.9750\n",
            "Epoch 279/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0533 - accuracy: 0.9883 - val_loss: 0.0967 - val_accuracy: 0.9733\n",
            "Epoch 280/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0485 - accuracy: 0.9880 - val_loss: 0.0964 - val_accuracy: 0.9742\n",
            "Epoch 281/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0547 - accuracy: 0.9883 - val_loss: 0.1195 - val_accuracy: 0.9708\n",
            "Epoch 282/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0603 - accuracy: 0.9839 - val_loss: 0.0965 - val_accuracy: 0.9767\n",
            "Epoch 283/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0784 - accuracy: 0.9778 - val_loss: 0.0996 - val_accuracy: 0.9692\n",
            "Epoch 284/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0584 - accuracy: 0.9857 - val_loss: 0.1058 - val_accuracy: 0.9717\n",
            "Epoch 285/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0572 - accuracy: 0.9838 - val_loss: 0.1015 - val_accuracy: 0.9700\n",
            "Epoch 286/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0506 - accuracy: 0.9847 - val_loss: 0.1003 - val_accuracy: 0.9717\n",
            "Epoch 287/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0456 - accuracy: 0.9895 - val_loss: 0.1026 - val_accuracy: 0.9692\n",
            "Epoch 288/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0439 - accuracy: 0.9874 - val_loss: 0.0939 - val_accuracy: 0.9742\n",
            "Epoch 289/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0452 - accuracy: 0.9898 - val_loss: 0.0891 - val_accuracy: 0.9817\n",
            "Epoch 290/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0553 - accuracy: 0.9858 - val_loss: 0.0933 - val_accuracy: 0.9758\n",
            "Epoch 291/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0512 - accuracy: 0.9873 - val_loss: 0.0963 - val_accuracy: 0.9792\n",
            "Epoch 292/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0498 - accuracy: 0.9876 - val_loss: 0.0960 - val_accuracy: 0.9783\n",
            "Epoch 293/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0437 - accuracy: 0.9899 - val_loss: 0.0927 - val_accuracy: 0.9783\n",
            "Epoch 294/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0497 - accuracy: 0.9872 - val_loss: 0.0872 - val_accuracy: 0.9767\n",
            "Epoch 295/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0463 - accuracy: 0.9904 - val_loss: 0.0968 - val_accuracy: 0.9800\n",
            "Epoch 296/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0497 - accuracy: 0.9857 - val_loss: 0.0870 - val_accuracy: 0.9800\n",
            "Epoch 297/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0485 - accuracy: 0.9882 - val_loss: 0.0916 - val_accuracy: 0.9775\n",
            "Epoch 298/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0451 - accuracy: 0.9910 - val_loss: 0.0909 - val_accuracy: 0.9792\n",
            "Epoch 299/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0489 - accuracy: 0.9881 - val_loss: 0.1136 - val_accuracy: 0.9783\n",
            "Epoch 300/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0512 - accuracy: 0.9851 - val_loss: 0.0886 - val_accuracy: 0.9792\n",
            "Epoch 301/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0464 - accuracy: 0.9889 - val_loss: 0.0950 - val_accuracy: 0.9767\n",
            "Epoch 302/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0535 - accuracy: 0.9873 - val_loss: 0.0916 - val_accuracy: 0.9792\n",
            "Epoch 303/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0468 - accuracy: 0.9896 - val_loss: 0.1007 - val_accuracy: 0.9733\n",
            "Epoch 304/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 0.9842 - val_loss: 0.0952 - val_accuracy: 0.9725\n",
            "Epoch 305/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0488 - accuracy: 0.9873 - val_loss: 0.1065 - val_accuracy: 0.9717\n",
            "Epoch 306/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0579 - accuracy: 0.9852 - val_loss: 0.0929 - val_accuracy: 0.9758\n",
            "Epoch 307/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0496 - accuracy: 0.9861 - val_loss: 0.0914 - val_accuracy: 0.9750\n",
            "Epoch 308/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0442 - accuracy: 0.9888 - val_loss: 0.0949 - val_accuracy: 0.9775\n",
            "Epoch 309/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0437 - accuracy: 0.9879 - val_loss: 0.0944 - val_accuracy: 0.9742\n",
            "Epoch 310/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0468 - accuracy: 0.9876 - val_loss: 0.0941 - val_accuracy: 0.9783\n",
            "Epoch 311/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0566 - accuracy: 0.9882 - val_loss: 0.0910 - val_accuracy: 0.9758\n",
            "Epoch 312/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0473 - accuracy: 0.9873 - val_loss: 0.0921 - val_accuracy: 0.9783\n",
            "Epoch 313/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0460 - accuracy: 0.9901 - val_loss: 0.0879 - val_accuracy: 0.9767\n",
            "Epoch 314/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0400 - accuracy: 0.9918 - val_loss: 0.0839 - val_accuracy: 0.9783\n",
            "Epoch 315/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0459 - accuracy: 0.9893 - val_loss: 0.0907 - val_accuracy: 0.9767\n",
            "Epoch 316/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0425 - accuracy: 0.9900 - val_loss: 0.0861 - val_accuracy: 0.9792\n",
            "Epoch 317/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0471 - accuracy: 0.9889 - val_loss: 0.0956 - val_accuracy: 0.9775\n",
            "Epoch 318/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9916 - val_loss: 0.0935 - val_accuracy: 0.9808\n",
            "Epoch 319/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0492 - accuracy: 0.9884 - val_loss: 0.1077 - val_accuracy: 0.9775\n",
            "Epoch 320/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0443 - accuracy: 0.9899 - val_loss: 0.0967 - val_accuracy: 0.9750\n",
            "Epoch 321/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0503 - accuracy: 0.9873 - val_loss: 0.0928 - val_accuracy: 0.9758\n",
            "Epoch 322/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0471 - accuracy: 0.9879 - val_loss: 0.0993 - val_accuracy: 0.9758\n",
            "Epoch 323/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 0.9872 - val_loss: 0.0942 - val_accuracy: 0.9792\n",
            "Epoch 324/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0417 - accuracy: 0.9887 - val_loss: 0.0879 - val_accuracy: 0.9767\n",
            "Epoch 325/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0409 - accuracy: 0.9912 - val_loss: 0.0968 - val_accuracy: 0.9800\n",
            "Epoch 326/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0441 - accuracy: 0.9907 - val_loss: 0.0879 - val_accuracy: 0.9808\n",
            "Epoch 327/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0359 - accuracy: 0.9909 - val_loss: 0.0885 - val_accuracy: 0.9792\n",
            "Epoch 328/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0453 - accuracy: 0.9864 - val_loss: 0.0876 - val_accuracy: 0.9833\n",
            "Epoch 329/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0372 - accuracy: 0.9925 - val_loss: 0.0896 - val_accuracy: 0.9800\n",
            "Epoch 330/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9915 - val_loss: 0.1022 - val_accuracy: 0.9783\n",
            "Epoch 331/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0462 - accuracy: 0.9888 - val_loss: 0.0848 - val_accuracy: 0.9825\n",
            "Epoch 332/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0420 - accuracy: 0.9902 - val_loss: 0.0871 - val_accuracy: 0.9808\n",
            "Epoch 333/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0422 - accuracy: 0.9902 - val_loss: 0.0878 - val_accuracy: 0.9758\n",
            "Epoch 334/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9897 - val_loss: 0.0834 - val_accuracy: 0.9800\n",
            "Epoch 335/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0386 - accuracy: 0.9910 - val_loss: 0.0834 - val_accuracy: 0.9808\n",
            "Epoch 336/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0443 - accuracy: 0.9895 - val_loss: 0.0810 - val_accuracy: 0.9825\n",
            "Epoch 337/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9904 - val_loss: 0.0905 - val_accuracy: 0.9792\n",
            "Epoch 338/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0432 - accuracy: 0.9891 - val_loss: 0.1104 - val_accuracy: 0.9625\n",
            "Epoch 339/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0760 - accuracy: 0.9801 - val_loss: 0.0891 - val_accuracy: 0.9758\n",
            "Epoch 340/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0603 - accuracy: 0.9840 - val_loss: 0.0888 - val_accuracy: 0.9800\n",
            "Epoch 341/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9915 - val_loss: 0.0919 - val_accuracy: 0.9767\n",
            "Epoch 342/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0463 - accuracy: 0.9890 - val_loss: 0.0877 - val_accuracy: 0.9800\n",
            "Epoch 343/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0409 - accuracy: 0.9911 - val_loss: 0.0823 - val_accuracy: 0.9808\n",
            "Epoch 344/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0540 - accuracy: 0.9876 - val_loss: 0.0809 - val_accuracy: 0.9808\n",
            "Epoch 345/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0380 - accuracy: 0.9909 - val_loss: 0.0905 - val_accuracy: 0.9817\n",
            "Epoch 346/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0371 - accuracy: 0.9917 - val_loss: 0.1005 - val_accuracy: 0.9767\n",
            "Epoch 347/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0420 - accuracy: 0.9882 - val_loss: 0.0919 - val_accuracy: 0.9775\n",
            "Epoch 348/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0556 - accuracy: 0.9879 - val_loss: 0.0876 - val_accuracy: 0.9783\n",
            "Epoch 349/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0386 - accuracy: 0.9886 - val_loss: 0.1044 - val_accuracy: 0.9767\n",
            "Epoch 350/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0467 - accuracy: 0.9885 - val_loss: 0.0813 - val_accuracy: 0.9792\n",
            "Epoch 351/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 0.9895 - val_loss: 0.0955 - val_accuracy: 0.9775\n",
            "Epoch 352/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0408 - accuracy: 0.9895 - val_loss: 0.0895 - val_accuracy: 0.9792\n",
            "Epoch 353/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0472 - accuracy: 0.9887 - val_loss: 0.0821 - val_accuracy: 0.9792\n",
            "Epoch 354/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0391 - accuracy: 0.9899 - val_loss: 0.0838 - val_accuracy: 0.9775\n",
            "Epoch 355/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0382 - accuracy: 0.9899 - val_loss: 0.0820 - val_accuracy: 0.9825\n",
            "Epoch 356/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9930 - val_loss: 0.0876 - val_accuracy: 0.9817\n",
            "Epoch 357/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9907 - val_loss: 0.0882 - val_accuracy: 0.9800\n",
            "Epoch 358/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0432 - accuracy: 0.9881 - val_loss: 0.0884 - val_accuracy: 0.9800\n",
            "Epoch 359/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9891 - val_loss: 0.0828 - val_accuracy: 0.9850\n",
            "Epoch 360/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0368 - accuracy: 0.9907 - val_loss: 0.0853 - val_accuracy: 0.9817\n",
            "Epoch 361/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 0.9908 - val_loss: 0.0921 - val_accuracy: 0.9750\n",
            "Epoch 362/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9926 - val_loss: 0.0797 - val_accuracy: 0.9842\n",
            "Epoch 363/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 0.9913 - val_loss: 0.0990 - val_accuracy: 0.9758\n",
            "Epoch 364/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0380 - accuracy: 0.9895 - val_loss: 0.0913 - val_accuracy: 0.9792\n",
            "Epoch 365/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0475 - accuracy: 0.9884 - val_loss: 0.0876 - val_accuracy: 0.9775\n",
            "Epoch 366/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0807 - val_accuracy: 0.9817\n",
            "Epoch 367/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9935 - val_loss: 0.0780 - val_accuracy: 0.9800\n",
            "Epoch 368/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9943 - val_loss: 0.0873 - val_accuracy: 0.9833\n",
            "Epoch 369/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0418 - accuracy: 0.9884 - val_loss: 0.0844 - val_accuracy: 0.9792\n",
            "Epoch 370/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9914 - val_loss: 0.0894 - val_accuracy: 0.9800\n",
            "Epoch 371/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0404 - accuracy: 0.9927 - val_loss: 0.0880 - val_accuracy: 0.9817\n",
            "Epoch 372/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0386 - accuracy: 0.9902 - val_loss: 0.0829 - val_accuracy: 0.9808\n",
            "Epoch 373/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9918 - val_loss: 0.0857 - val_accuracy: 0.9808\n",
            "Epoch 374/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 0.9894 - val_loss: 0.0785 - val_accuracy: 0.9833\n",
            "Epoch 375/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9925 - val_loss: 0.0765 - val_accuracy: 0.9817\n",
            "Epoch 376/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0378 - accuracy: 0.9888 - val_loss: 0.0923 - val_accuracy: 0.9800\n",
            "Epoch 377/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0440 - accuracy: 0.9881 - val_loss: 0.0789 - val_accuracy: 0.9808\n",
            "Epoch 378/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9916 - val_loss: 0.0915 - val_accuracy: 0.9792\n",
            "Epoch 379/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0444 - accuracy: 0.9897 - val_loss: 0.0877 - val_accuracy: 0.9825\n",
            "Epoch 380/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0308 - accuracy: 0.9918 - val_loss: 0.0777 - val_accuracy: 0.9858\n",
            "Epoch 381/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9942 - val_loss: 0.0803 - val_accuracy: 0.9817\n",
            "Epoch 382/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.0971 - val_accuracy: 0.9800\n",
            "Epoch 383/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0542 - accuracy: 0.9869 - val_loss: 0.0905 - val_accuracy: 0.9758\n",
            "Epoch 384/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0552 - accuracy: 0.9852 - val_loss: 0.0826 - val_accuracy: 0.9825\n",
            "Epoch 385/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 0.9914 - val_loss: 0.1242 - val_accuracy: 0.9817\n",
            "Epoch 386/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0462 - accuracy: 0.9871 - val_loss: 0.0788 - val_accuracy: 0.9833\n",
            "Epoch 387/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9895 - val_loss: 0.0860 - val_accuracy: 0.9842\n",
            "Epoch 388/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9923 - val_loss: 0.0809 - val_accuracy: 0.9800\n",
            "Epoch 389/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9913 - val_loss: 0.0789 - val_accuracy: 0.9833\n",
            "Epoch 390/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0315 - accuracy: 0.9933 - val_loss: 0.0818 - val_accuracy: 0.9808\n",
            "Epoch 391/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0382 - accuracy: 0.9907 - val_loss: 0.0946 - val_accuracy: 0.9775\n",
            "Epoch 392/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0499 - accuracy: 0.9865 - val_loss: 0.0813 - val_accuracy: 0.9833\n",
            "Epoch 393/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0385 - accuracy: 0.9897 - val_loss: 0.0813 - val_accuracy: 0.9800\n",
            "Epoch 394/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 0.9904 - val_loss: 0.0787 - val_accuracy: 0.9817\n",
            "Epoch 395/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.9930 - val_loss: 0.0766 - val_accuracy: 0.9858\n",
            "Epoch 396/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9929 - val_loss: 0.0964 - val_accuracy: 0.9833\n",
            "Epoch 397/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0391 - accuracy: 0.9899 - val_loss: 0.1077 - val_accuracy: 0.9808\n",
            "Epoch 398/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0378 - accuracy: 0.9913 - val_loss: 0.0856 - val_accuracy: 0.9833\n",
            "Epoch 399/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0373 - accuracy: 0.9917 - val_loss: 0.0832 - val_accuracy: 0.9783\n",
            "Epoch 400/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9903 - val_loss: 0.1079 - val_accuracy: 0.9750\n",
            "Epoch 401/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 0.9895 - val_loss: 0.0846 - val_accuracy: 0.9800\n",
            "Epoch 402/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 0.0841 - val_accuracy: 0.9842\n",
            "Epoch 403/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9910 - val_loss: 0.1064 - val_accuracy: 0.9825\n",
            "Epoch 404/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0343 - accuracy: 0.9901 - val_loss: 0.0823 - val_accuracy: 0.9800\n",
            "Epoch 405/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9919 - val_loss: 0.0796 - val_accuracy: 0.9825\n",
            "Epoch 406/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9875 - val_loss: 0.0765 - val_accuracy: 0.9842\n",
            "Epoch 407/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0287 - accuracy: 0.9932 - val_loss: 0.0748 - val_accuracy: 0.9825\n",
            "Epoch 408/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9945 - val_loss: 0.0799 - val_accuracy: 0.9842\n",
            "Epoch 409/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0325 - accuracy: 0.9917 - val_loss: 0.0825 - val_accuracy: 0.9800\n",
            "Epoch 410/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9913 - val_loss: 0.0810 - val_accuracy: 0.9817\n",
            "Epoch 411/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 0.9933 - val_loss: 0.1061 - val_accuracy: 0.9842\n",
            "Epoch 412/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0486 - accuracy: 0.9871 - val_loss: 0.0793 - val_accuracy: 0.9825\n",
            "Epoch 413/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0352 - accuracy: 0.9887 - val_loss: 0.0829 - val_accuracy: 0.9808\n",
            "Epoch 414/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9954 - val_loss: 0.0740 - val_accuracy: 0.9842\n",
            "Epoch 415/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9939 - val_loss: 0.0791 - val_accuracy: 0.9842\n",
            "Epoch 416/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0287 - accuracy: 0.9942 - val_loss: 0.0934 - val_accuracy: 0.9800\n",
            "Epoch 417/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0389 - accuracy: 0.9893 - val_loss: 0.0751 - val_accuracy: 0.9817\n",
            "Epoch 418/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9923 - val_loss: 0.0800 - val_accuracy: 0.9833\n",
            "Epoch 419/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0335 - accuracy: 0.9939 - val_loss: 0.0878 - val_accuracy: 0.9792\n",
            "Epoch 420/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9889 - val_loss: 0.0788 - val_accuracy: 0.9858\n",
            "Epoch 421/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9938 - val_loss: 0.0774 - val_accuracy: 0.9867\n",
            "Epoch 422/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9948 - val_loss: 0.0934 - val_accuracy: 0.9767\n",
            "Epoch 423/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0549 - accuracy: 0.9875 - val_loss: 0.0829 - val_accuracy: 0.9842\n",
            "Epoch 424/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 0.0786 - val_accuracy: 0.9842\n",
            "Epoch 425/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9942 - val_loss: 0.0833 - val_accuracy: 0.9833\n",
            "Epoch 426/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9932 - val_loss: 0.0811 - val_accuracy: 0.9817\n",
            "Epoch 427/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0334 - accuracy: 0.9918 - val_loss: 0.0811 - val_accuracy: 0.9825\n",
            "Epoch 428/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 0.9917 - val_loss: 0.0998 - val_accuracy: 0.9817\n",
            "Epoch 429/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0374 - accuracy: 0.9912 - val_loss: 0.0781 - val_accuracy: 0.9858\n",
            "Epoch 430/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.0765 - val_accuracy: 0.9842\n",
            "Epoch 431/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 0.9935 - val_loss: 0.0754 - val_accuracy: 0.9825\n",
            "Epoch 432/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0329 - accuracy: 0.9925 - val_loss: 0.0817 - val_accuracy: 0.9825\n",
            "Epoch 433/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0315 - accuracy: 0.9946 - val_loss: 0.0817 - val_accuracy: 0.9833\n",
            "Epoch 434/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 0.9930 - val_loss: 0.0774 - val_accuracy: 0.9800\n",
            "Epoch 435/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.0810 - val_accuracy: 0.9817\n",
            "Epoch 436/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 0.0765 - val_accuracy: 0.9792\n",
            "Epoch 437/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9933 - val_loss: 0.0953 - val_accuracy: 0.9783\n",
            "Epoch 438/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9908 - val_loss: 0.0826 - val_accuracy: 0.9825\n",
            "Epoch 439/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 0.9908 - val_loss: 0.0795 - val_accuracy: 0.9825\n",
            "Epoch 440/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0336 - accuracy: 0.9925 - val_loss: 0.0691 - val_accuracy: 0.9867\n",
            "Epoch 441/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9914 - val_loss: 0.0903 - val_accuracy: 0.9842\n",
            "Epoch 442/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0436 - accuracy: 0.9862 - val_loss: 0.0920 - val_accuracy: 0.9783\n",
            "Epoch 443/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0433 - accuracy: 0.9918 - val_loss: 0.0795 - val_accuracy: 0.9842\n",
            "Epoch 444/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 0.0732 - val_accuracy: 0.9817\n",
            "Epoch 445/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9931 - val_loss: 0.0750 - val_accuracy: 0.9817\n",
            "Epoch 446/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9934 - val_loss: 0.1284 - val_accuracy: 0.9808\n",
            "Epoch 447/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0539 - accuracy: 0.9901 - val_loss: 0.0777 - val_accuracy: 0.9783\n",
            "Epoch 448/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.0927 - val_accuracy: 0.9783\n",
            "Epoch 449/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.0799 - val_accuracy: 0.9850\n",
            "Epoch 450/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9948 - val_loss: 0.0781 - val_accuracy: 0.9808\n",
            "Epoch 451/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9934 - val_loss: 0.0815 - val_accuracy: 0.9842\n",
            "Epoch 452/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9926 - val_loss: 0.0753 - val_accuracy: 0.9867\n",
            "Epoch 453/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9961 - val_loss: 0.0911 - val_accuracy: 0.9800\n",
            "Epoch 454/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9930 - val_loss: 0.0718 - val_accuracy: 0.9883\n",
            "Epoch 455/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0268 - accuracy: 0.9945 - val_loss: 0.0686 - val_accuracy: 0.9867\n",
            "Epoch 456/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.9930 - val_loss: 0.0733 - val_accuracy: 0.9867\n",
            "Epoch 457/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9951 - val_loss: 0.0776 - val_accuracy: 0.9858\n",
            "Epoch 458/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9944 - val_loss: 0.0855 - val_accuracy: 0.9817\n",
            "Epoch 459/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.9937 - val_loss: 0.0721 - val_accuracy: 0.9833\n",
            "Epoch 460/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9962 - val_loss: 0.0938 - val_accuracy: 0.9800\n",
            "Epoch 461/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0401 - accuracy: 0.9875 - val_loss: 0.1048 - val_accuracy: 0.9792\n",
            "Epoch 462/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 0.9891 - val_loss: 0.0829 - val_accuracy: 0.9842\n",
            "Epoch 463/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9924 - val_loss: 0.0710 - val_accuracy: 0.9858\n",
            "Epoch 464/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9949 - val_loss: 0.0705 - val_accuracy: 0.9867\n",
            "Epoch 465/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.0763 - val_accuracy: 0.9833\n",
            "Epoch 466/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9957 - val_loss: 0.0773 - val_accuracy: 0.9842\n",
            "Epoch 467/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0463 - accuracy: 0.9893 - val_loss: 0.0809 - val_accuracy: 0.9858\n",
            "Epoch 468/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9948 - val_loss: 0.0750 - val_accuracy: 0.9867\n",
            "Epoch 469/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9925 - val_loss: 0.0849 - val_accuracy: 0.9842\n",
            "Epoch 470/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.9935 - val_loss: 0.0743 - val_accuracy: 0.9867\n",
            "Epoch 471/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9933 - val_loss: 0.0772 - val_accuracy: 0.9825\n",
            "Epoch 472/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9937 - val_loss: 0.0821 - val_accuracy: 0.9842\n",
            "Epoch 473/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9924 - val_loss: 0.0760 - val_accuracy: 0.9792\n",
            "Epoch 474/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9930 - val_loss: 0.0726 - val_accuracy: 0.9850\n",
            "Epoch 475/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9947 - val_loss: 0.0712 - val_accuracy: 0.9858\n",
            "Epoch 476/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9956 - val_loss: 0.0741 - val_accuracy: 0.9875\n",
            "Epoch 477/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9935 - val_loss: 0.0720 - val_accuracy: 0.9842\n",
            "Epoch 478/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9961 - val_loss: 0.0733 - val_accuracy: 0.9842\n",
            "Epoch 479/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9951 - val_loss: 0.0705 - val_accuracy: 0.9867\n",
            "Epoch 480/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.0710 - val_accuracy: 0.9850\n",
            "Epoch 481/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 0.0709 - val_accuracy: 0.9858\n",
            "Epoch 482/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9941 - val_loss: 0.0769 - val_accuracy: 0.9842\n",
            "Epoch 483/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.0878 - val_accuracy: 0.9850\n",
            "Epoch 484/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.0766 - val_accuracy: 0.9825\n",
            "Epoch 485/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.0697 - val_accuracy: 0.9850\n",
            "Epoch 486/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9953 - val_loss: 0.0732 - val_accuracy: 0.9875\n",
            "Epoch 487/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 0.9903 - val_loss: 0.0734 - val_accuracy: 0.9817\n",
            "Epoch 488/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9947 - val_loss: 0.0746 - val_accuracy: 0.9817\n",
            "Epoch 489/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 0.0677 - val_accuracy: 0.9858\n",
            "Epoch 490/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9964 - val_loss: 0.0729 - val_accuracy: 0.9850\n",
            "Epoch 491/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0272 - accuracy: 0.9924 - val_loss: 0.0723 - val_accuracy: 0.9833\n",
            "Epoch 492/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9953 - val_loss: 0.0692 - val_accuracy: 0.9842\n",
            "Epoch 493/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9934 - val_loss: 0.0772 - val_accuracy: 0.9842\n",
            "Epoch 494/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.0726 - val_accuracy: 0.9858\n",
            "Epoch 495/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9951 - val_loss: 0.0748 - val_accuracy: 0.9850\n",
            "Epoch 496/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9936 - val_loss: 0.0692 - val_accuracy: 0.9858\n",
            "Epoch 497/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.0740 - val_accuracy: 0.9850\n",
            "Epoch 498/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9918 - val_loss: 0.0757 - val_accuracy: 0.9808\n",
            "Epoch 499/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9929 - val_loss: 0.0680 - val_accuracy: 0.9883\n",
            "Epoch 500/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9936 - val_loss: 0.0935 - val_accuracy: 0.9825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bfW5J51uh9G",
        "outputId": "82391340-e405-4fba-8ce2-cc695e346ce8"
      },
      "source": [
        "# モデルの評価(大きさ)\n",
        "size_score = size_model.evaluate(X_ans_data, size_Y_ans_data, verbose=1)\n",
        "print('Test loss:', size_score[0])\n",
        "print('Test accuracy:', size_score[1])"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "317/317 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9812\n",
            "Test loss: 0.09442738443613052\n",
            "Test accuracy: 0.9812438488006592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "TMThsLoXwCpo",
        "outputId": "6436b43f-2e32-4f88-fd9c-f00dce013ca3"
      },
      "source": [
        "# 学習経過の可視化(大きさ)\n",
        "size_loss     = size_history.history['loss']\n",
        "size_val_loss = size_history.history['val_loss']\n",
        "\n",
        "nb_epoch = len(size_loss)\n",
        "plt.plot(range(nb_epoch), size_loss,     marker='.', label='size_loss')\n",
        "plt.plot(range(nb_epoch), size_val_loss, marker='.', label='size_val_loss')\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "TNNm9I_swIz7",
        "outputId": "ca074e62-b08d-464e-895b-061f018684b1"
      },
      "source": [
        "# 学習経過の可視化(大きさ)\n",
        "size_acc     = size_history.history['accuracy']\n",
        "size_val_acc = size_history.history['val_accuracy']\n",
        "\n",
        "nb_epoch = len(size_acc)\n",
        "plt.plot(range(nb_epoch), size_acc,     marker='.', label='size_acc')\n",
        "plt.plot(range(nb_epoch), size_val_acc, marker='.', label='size_val_acc')\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.show()"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgJO6RYR2V4z"
      },
      "source": [
        "## 拡張前のデータの学習状況と比較\n",
        "\n",
        "## CNN(大きさ)\n",
        "\n",
        "### modelの作成\n",
        "size_ne_model = Sequential()\n",
        "### 畳み込み層\n",
        "size_ne_model.add(Conv1D(32, 3, padding='same', activation='relu', input_shape=(50, 1)))\n",
        "### プーリング層\n",
        "size_ne_model.add(MaxPooling1D(2, padding='same'))\n",
        "### Flatten層\n",
        "size_ne_model.add(Flatten())\n",
        "### 全結合層\n",
        "size_ne_model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "### optimizer\n",
        "adam = keras.optimizers.Adam()\n",
        "\n",
        "###modelのコンパイル\n",
        "size_ne_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbN5gU_z2aqm",
        "outputId": "d6e45187-d76d-456f-b51e-c0df117c9a82"
      },
      "source": [
        "# 学習(大きさ)\n",
        "epochs = 500\n",
        "batch_size = 128\n",
        "size_ne_history = size_ne_model.fit(X_ne_ss_train, size_Y_ne_ss_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_ne_ss_test, size_Y_ne_ss_test))"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 1.6473 - accuracy: 0.2032 - val_loss: 1.4630 - val_accuracy: 0.1842\n",
            "Epoch 2/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.3844 - accuracy: 0.2772 - val_loss: 1.2445 - val_accuracy: 0.6208\n",
            "Epoch 3/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1495 - accuracy: 0.6788 - val_loss: 0.9731 - val_accuracy: 0.7558\n",
            "Epoch 4/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9138 - accuracy: 0.7855 - val_loss: 0.7955 - val_accuracy: 0.8683\n",
            "Epoch 5/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.7530 - accuracy: 0.8808 - val_loss: 0.6758 - val_accuracy: 0.8792\n",
            "Epoch 6/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.6425 - accuracy: 0.9036 - val_loss: 0.5894 - val_accuracy: 0.9025\n",
            "Epoch 7/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5582 - accuracy: 0.9134 - val_loss: 0.5130 - val_accuracy: 0.9075\n",
            "Epoch 8/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.9233 - val_loss: 0.4515 - val_accuracy: 0.9133\n",
            "Epoch 9/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.9213 - val_loss: 0.4045 - val_accuracy: 0.9200\n",
            "Epoch 10/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.9274 - val_loss: 0.3772 - val_accuracy: 0.9158\n",
            "Epoch 11/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3584 - accuracy: 0.9283 - val_loss: 0.3488 - val_accuracy: 0.9183\n",
            "Epoch 12/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3374 - accuracy: 0.9293 - val_loss: 0.3294 - val_accuracy: 0.9217\n",
            "Epoch 13/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3252 - accuracy: 0.9293 - val_loss: 0.3127 - val_accuracy: 0.9275\n",
            "Epoch 14/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3054 - accuracy: 0.9318 - val_loss: 0.2952 - val_accuracy: 0.9283\n",
            "Epoch 15/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.9318 - val_loss: 0.2820 - val_accuracy: 0.9283\n",
            "Epoch 16/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2608 - accuracy: 0.9360 - val_loss: 0.2815 - val_accuracy: 0.9267\n",
            "Epoch 17/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2679 - accuracy: 0.9394 - val_loss: 0.2714 - val_accuracy: 0.9258\n",
            "Epoch 18/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2530 - accuracy: 0.9398 - val_loss: 0.2661 - val_accuracy: 0.9283\n",
            "Epoch 19/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2383 - accuracy: 0.9379 - val_loss: 0.2567 - val_accuracy: 0.9292\n",
            "Epoch 20/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.9360 - val_loss: 0.2560 - val_accuracy: 0.9300\n",
            "Epoch 21/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2453 - accuracy: 0.9373 - val_loss: 0.2720 - val_accuracy: 0.9317\n",
            "Epoch 22/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2691 - accuracy: 0.9373 - val_loss: 0.2499 - val_accuracy: 0.9333\n",
            "Epoch 23/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2420 - accuracy: 0.9378 - val_loss: 0.2482 - val_accuracy: 0.9283\n",
            "Epoch 24/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2267 - accuracy: 0.9345 - val_loss: 0.2419 - val_accuracy: 0.9342\n",
            "Epoch 25/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2379 - accuracy: 0.9347 - val_loss: 0.2453 - val_accuracy: 0.9350\n",
            "Epoch 26/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2431 - accuracy: 0.9373 - val_loss: 0.2347 - val_accuracy: 0.9308\n",
            "Epoch 27/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2215 - accuracy: 0.9373 - val_loss: 0.2290 - val_accuracy: 0.9308\n",
            "Epoch 28/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2131 - accuracy: 0.9424 - val_loss: 0.2312 - val_accuracy: 0.9267\n",
            "Epoch 29/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2412 - accuracy: 0.9337 - val_loss: 0.2278 - val_accuracy: 0.9258\n",
            "Epoch 30/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2153 - accuracy: 0.9404 - val_loss: 0.2243 - val_accuracy: 0.9275\n",
            "Epoch 31/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2115 - accuracy: 0.9410 - val_loss: 0.2304 - val_accuracy: 0.9283\n",
            "Epoch 32/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2066 - accuracy: 0.9424 - val_loss: 0.2298 - val_accuracy: 0.9300\n",
            "Epoch 33/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2321 - accuracy: 0.9333 - val_loss: 0.2349 - val_accuracy: 0.9225\n",
            "Epoch 34/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2230 - accuracy: 0.9411 - val_loss: 0.2195 - val_accuracy: 0.9308\n",
            "Epoch 35/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2165 - accuracy: 0.9386 - val_loss: 0.2188 - val_accuracy: 0.9325\n",
            "Epoch 36/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2057 - accuracy: 0.9416 - val_loss: 0.2184 - val_accuracy: 0.9325\n",
            "Epoch 37/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1967 - accuracy: 0.9407 - val_loss: 0.2163 - val_accuracy: 0.9342\n",
            "Epoch 38/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2147 - accuracy: 0.9370 - val_loss: 0.2166 - val_accuracy: 0.9325\n",
            "Epoch 39/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2158 - accuracy: 0.9369 - val_loss: 0.2222 - val_accuracy: 0.9267\n",
            "Epoch 40/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2104 - accuracy: 0.9427 - val_loss: 0.2113 - val_accuracy: 0.9325\n",
            "Epoch 41/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1923 - accuracy: 0.9460 - val_loss: 0.2196 - val_accuracy: 0.9333\n",
            "Epoch 42/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2023 - accuracy: 0.9432 - val_loss: 0.2108 - val_accuracy: 0.9317\n",
            "Epoch 43/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1981 - accuracy: 0.9420 - val_loss: 0.2132 - val_accuracy: 0.9342\n",
            "Epoch 44/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2181 - accuracy: 0.9362 - val_loss: 0.2056 - val_accuracy: 0.9300\n",
            "Epoch 45/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1968 - accuracy: 0.9463 - val_loss: 0.2122 - val_accuracy: 0.9292\n",
            "Epoch 46/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2345 - accuracy: 0.9355 - val_loss: 0.2063 - val_accuracy: 0.9308\n",
            "Epoch 47/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.2078 - accuracy: 0.9360 - val_loss: 0.2077 - val_accuracy: 0.9317\n",
            "Epoch 48/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1861 - accuracy: 0.9509 - val_loss: 0.2068 - val_accuracy: 0.9325\n",
            "Epoch 49/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1890 - accuracy: 0.9426 - val_loss: 0.2025 - val_accuracy: 0.9325\n",
            "Epoch 50/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1958 - accuracy: 0.9451 - val_loss: 0.2082 - val_accuracy: 0.9308\n",
            "Epoch 51/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1931 - accuracy: 0.9459 - val_loss: 0.2094 - val_accuracy: 0.9283\n",
            "Epoch 52/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1873 - accuracy: 0.9442 - val_loss: 0.2027 - val_accuracy: 0.9350\n",
            "Epoch 53/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1861 - accuracy: 0.9460 - val_loss: 0.2053 - val_accuracy: 0.9317\n",
            "Epoch 54/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2115 - accuracy: 0.9418 - val_loss: 0.2006 - val_accuracy: 0.9342\n",
            "Epoch 55/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1996 - accuracy: 0.9378 - val_loss: 0.2068 - val_accuracy: 0.9333\n",
            "Epoch 56/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1733 - accuracy: 0.9473 - val_loss: 0.2130 - val_accuracy: 0.9325\n",
            "Epoch 57/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1944 - accuracy: 0.9448 - val_loss: 0.2048 - val_accuracy: 0.9317\n",
            "Epoch 58/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1643 - accuracy: 0.9520 - val_loss: 0.2040 - val_accuracy: 0.9367\n",
            "Epoch 59/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1887 - accuracy: 0.9435 - val_loss: 0.2070 - val_accuracy: 0.9333\n",
            "Epoch 60/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1907 - accuracy: 0.9441 - val_loss: 0.2020 - val_accuracy: 0.9325\n",
            "Epoch 61/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1952 - accuracy: 0.9427 - val_loss: 0.1979 - val_accuracy: 0.9317\n",
            "Epoch 62/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1726 - accuracy: 0.9515 - val_loss: 0.1986 - val_accuracy: 0.9342\n",
            "Epoch 63/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1907 - accuracy: 0.9420 - val_loss: 0.2069 - val_accuracy: 0.9317\n",
            "Epoch 64/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1682 - accuracy: 0.9521 - val_loss: 0.1931 - val_accuracy: 0.9358\n",
            "Epoch 65/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1997 - accuracy: 0.9365 - val_loss: 0.1978 - val_accuracy: 0.9300\n",
            "Epoch 66/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1833 - accuracy: 0.9468 - val_loss: 0.1937 - val_accuracy: 0.9325\n",
            "Epoch 67/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1793 - accuracy: 0.9470 - val_loss: 0.1953 - val_accuracy: 0.9283\n",
            "Epoch 68/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1626 - accuracy: 0.9512 - val_loss: 0.2005 - val_accuracy: 0.9308\n",
            "Epoch 69/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1943 - accuracy: 0.9445 - val_loss: 0.1976 - val_accuracy: 0.9325\n",
            "Epoch 70/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1778 - accuracy: 0.9448 - val_loss: 0.1887 - val_accuracy: 0.9358\n",
            "Epoch 71/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1647 - accuracy: 0.9503 - val_loss: 0.1865 - val_accuracy: 0.9375\n",
            "Epoch 72/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1597 - accuracy: 0.9507 - val_loss: 0.1998 - val_accuracy: 0.9283\n",
            "Epoch 73/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1623 - accuracy: 0.9527 - val_loss: 0.1856 - val_accuracy: 0.9325\n",
            "Epoch 74/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1668 - accuracy: 0.9501 - val_loss: 0.1873 - val_accuracy: 0.9358\n",
            "Epoch 75/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1833 - accuracy: 0.9433 - val_loss: 0.1948 - val_accuracy: 0.9383\n",
            "Epoch 76/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1603 - accuracy: 0.9510 - val_loss: 0.2046 - val_accuracy: 0.9367\n",
            "Epoch 77/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1676 - accuracy: 0.9501 - val_loss: 0.1925 - val_accuracy: 0.9317\n",
            "Epoch 78/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1679 - accuracy: 0.9498 - val_loss: 0.1855 - val_accuracy: 0.9375\n",
            "Epoch 79/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1699 - accuracy: 0.9471 - val_loss: 0.1877 - val_accuracy: 0.9358\n",
            "Epoch 80/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1708 - accuracy: 0.9433 - val_loss: 0.1938 - val_accuracy: 0.9350\n",
            "Epoch 81/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1780 - accuracy: 0.9473 - val_loss: 0.1863 - val_accuracy: 0.9367\n",
            "Epoch 82/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1558 - accuracy: 0.9538 - val_loss: 0.2074 - val_accuracy: 0.9333\n",
            "Epoch 83/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1649 - accuracy: 0.9447 - val_loss: 0.1886 - val_accuracy: 0.9333\n",
            "Epoch 84/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1752 - accuracy: 0.9496 - val_loss: 0.1838 - val_accuracy: 0.9342\n",
            "Epoch 85/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1552 - accuracy: 0.9473 - val_loss: 0.1843 - val_accuracy: 0.9392\n",
            "Epoch 86/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1527 - accuracy: 0.9511 - val_loss: 0.1897 - val_accuracy: 0.9342\n",
            "Epoch 87/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1543 - accuracy: 0.9503 - val_loss: 0.1819 - val_accuracy: 0.9383\n",
            "Epoch 88/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1564 - accuracy: 0.9483 - val_loss: 0.1815 - val_accuracy: 0.9375\n",
            "Epoch 89/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1535 - accuracy: 0.9524 - val_loss: 0.1800 - val_accuracy: 0.9383\n",
            "Epoch 90/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1515 - accuracy: 0.9490 - val_loss: 0.1861 - val_accuracy: 0.9375\n",
            "Epoch 91/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9525 - val_loss: 0.2126 - val_accuracy: 0.9325\n",
            "Epoch 92/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1647 - accuracy: 0.9471 - val_loss: 0.1898 - val_accuracy: 0.9317\n",
            "Epoch 93/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1587 - accuracy: 0.9548 - val_loss: 0.1835 - val_accuracy: 0.9333\n",
            "Epoch 94/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1626 - accuracy: 0.9503 - val_loss: 0.1760 - val_accuracy: 0.9367\n",
            "Epoch 95/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1473 - accuracy: 0.9534 - val_loss: 0.1858 - val_accuracy: 0.9375\n",
            "Epoch 96/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.9533 - val_loss: 0.1767 - val_accuracy: 0.9375\n",
            "Epoch 97/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1534 - accuracy: 0.9508 - val_loss: 0.1869 - val_accuracy: 0.9433\n",
            "Epoch 98/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1503 - accuracy: 0.9518 - val_loss: 0.1787 - val_accuracy: 0.9367\n",
            "Epoch 99/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1392 - accuracy: 0.9561 - val_loss: 0.1759 - val_accuracy: 0.9367\n",
            "Epoch 100/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.9532 - val_loss: 0.1696 - val_accuracy: 0.9392\n",
            "Epoch 101/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1552 - accuracy: 0.9478 - val_loss: 0.1727 - val_accuracy: 0.9375\n",
            "Epoch 102/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1499 - accuracy: 0.9541 - val_loss: 0.1740 - val_accuracy: 0.9400\n",
            "Epoch 103/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1369 - accuracy: 0.9543 - val_loss: 0.1774 - val_accuracy: 0.9392\n",
            "Epoch 104/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1468 - accuracy: 0.9527 - val_loss: 0.1728 - val_accuracy: 0.9400\n",
            "Epoch 105/500\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.1386 - accuracy: 0.9545 - val_loss: 0.1927 - val_accuracy: 0.9425\n",
            "Epoch 106/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1566 - accuracy: 0.9562 - val_loss: 0.1700 - val_accuracy: 0.9433\n",
            "Epoch 107/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1408 - accuracy: 0.9534 - val_loss: 0.1852 - val_accuracy: 0.9383\n",
            "Epoch 108/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1540 - accuracy: 0.9489 - val_loss: 0.1850 - val_accuracy: 0.9425\n",
            "Epoch 109/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1480 - accuracy: 0.9551 - val_loss: 0.1699 - val_accuracy: 0.9433\n",
            "Epoch 110/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1342 - accuracy: 0.9554 - val_loss: 0.1721 - val_accuracy: 0.9400\n",
            "Epoch 111/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1442 - accuracy: 0.9562 - val_loss: 0.1788 - val_accuracy: 0.9442\n",
            "Epoch 112/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.9530 - val_loss: 0.1659 - val_accuracy: 0.9408\n",
            "Epoch 113/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.9584 - val_loss: 0.1678 - val_accuracy: 0.9425\n",
            "Epoch 114/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1300 - accuracy: 0.9618 - val_loss: 0.1648 - val_accuracy: 0.9425\n",
            "Epoch 115/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1264 - accuracy: 0.9626 - val_loss: 0.1729 - val_accuracy: 0.9417\n",
            "Epoch 116/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1460 - accuracy: 0.9547 - val_loss: 0.1805 - val_accuracy: 0.9450\n",
            "Epoch 117/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1414 - accuracy: 0.9578 - val_loss: 0.1703 - val_accuracy: 0.9450\n",
            "Epoch 118/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1295 - accuracy: 0.9601 - val_loss: 0.1715 - val_accuracy: 0.9433\n",
            "Epoch 119/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1265 - accuracy: 0.9585 - val_loss: 0.1613 - val_accuracy: 0.9408\n",
            "Epoch 120/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1437 - accuracy: 0.9538 - val_loss: 0.1581 - val_accuracy: 0.9450\n",
            "Epoch 121/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1257 - accuracy: 0.9606 - val_loss: 0.1736 - val_accuracy: 0.9425\n",
            "Epoch 122/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1306 - accuracy: 0.9562 - val_loss: 0.1571 - val_accuracy: 0.9458\n",
            "Epoch 123/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1335 - accuracy: 0.9599 - val_loss: 0.1660 - val_accuracy: 0.9475\n",
            "Epoch 124/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1309 - accuracy: 0.9581 - val_loss: 0.1603 - val_accuracy: 0.9475\n",
            "Epoch 125/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1375 - accuracy: 0.9587 - val_loss: 0.1534 - val_accuracy: 0.9483\n",
            "Epoch 126/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1159 - accuracy: 0.9646 - val_loss: 0.1574 - val_accuracy: 0.9458\n",
            "Epoch 127/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1274 - accuracy: 0.9587 - val_loss: 0.1590 - val_accuracy: 0.9500\n",
            "Epoch 128/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1295 - accuracy: 0.9575 - val_loss: 0.1577 - val_accuracy: 0.9467\n",
            "Epoch 129/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1164 - accuracy: 0.9609 - val_loss: 0.1622 - val_accuracy: 0.9450\n",
            "Epoch 130/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1484 - accuracy: 0.9573 - val_loss: 0.1631 - val_accuracy: 0.9458\n",
            "Epoch 131/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1310 - accuracy: 0.9598 - val_loss: 0.1599 - val_accuracy: 0.9500\n",
            "Epoch 132/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1330 - accuracy: 0.9589 - val_loss: 0.1692 - val_accuracy: 0.9475\n",
            "Epoch 133/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1260 - accuracy: 0.9624 - val_loss: 0.1537 - val_accuracy: 0.9450\n",
            "Epoch 134/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1255 - accuracy: 0.9609 - val_loss: 0.1660 - val_accuracy: 0.9475\n",
            "Epoch 135/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1321 - accuracy: 0.9596 - val_loss: 0.1585 - val_accuracy: 0.9458\n",
            "Epoch 136/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1227 - accuracy: 0.9603 - val_loss: 0.1466 - val_accuracy: 0.9483\n",
            "Epoch 137/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1198 - accuracy: 0.9643 - val_loss: 0.1493 - val_accuracy: 0.9483\n",
            "Epoch 138/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1220 - accuracy: 0.9619 - val_loss: 0.1462 - val_accuracy: 0.9467\n",
            "Epoch 139/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1392 - accuracy: 0.9575 - val_loss: 0.1624 - val_accuracy: 0.9475\n",
            "Epoch 140/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1240 - accuracy: 0.9588 - val_loss: 0.1553 - val_accuracy: 0.9492\n",
            "Epoch 141/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1189 - accuracy: 0.9627 - val_loss: 0.1670 - val_accuracy: 0.9467\n",
            "Epoch 142/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1339 - accuracy: 0.9609 - val_loss: 0.1617 - val_accuracy: 0.9383\n",
            "Epoch 143/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1415 - accuracy: 0.9586 - val_loss: 0.1469 - val_accuracy: 0.9483\n",
            "Epoch 144/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1181 - accuracy: 0.9615 - val_loss: 0.1469 - val_accuracy: 0.9492\n",
            "Epoch 145/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1141 - accuracy: 0.9640 - val_loss: 0.1409 - val_accuracy: 0.9483\n",
            "Epoch 146/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1189 - accuracy: 0.9623 - val_loss: 0.1435 - val_accuracy: 0.9508\n",
            "Epoch 147/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1066 - accuracy: 0.9669 - val_loss: 0.1459 - val_accuracy: 0.9533\n",
            "Epoch 148/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1127 - accuracy: 0.9653 - val_loss: 0.1425 - val_accuracy: 0.9567\n",
            "Epoch 149/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1079 - accuracy: 0.9649 - val_loss: 0.1438 - val_accuracy: 0.9492\n",
            "Epoch 150/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1029 - accuracy: 0.9661 - val_loss: 0.1385 - val_accuracy: 0.9550\n",
            "Epoch 151/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1067 - accuracy: 0.9599 - val_loss: 0.1441 - val_accuracy: 0.9542\n",
            "Epoch 152/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1066 - accuracy: 0.9655 - val_loss: 0.1378 - val_accuracy: 0.9525\n",
            "Epoch 153/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1201 - accuracy: 0.9617 - val_loss: 0.1409 - val_accuracy: 0.9492\n",
            "Epoch 154/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1129 - accuracy: 0.9635 - val_loss: 0.1680 - val_accuracy: 0.9492\n",
            "Epoch 155/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1096 - accuracy: 0.9618 - val_loss: 0.1360 - val_accuracy: 0.9567\n",
            "Epoch 156/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1051 - accuracy: 0.9673 - val_loss: 0.1555 - val_accuracy: 0.9467\n",
            "Epoch 157/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1061 - accuracy: 0.9683 - val_loss: 0.1431 - val_accuracy: 0.9483\n",
            "Epoch 158/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1237 - accuracy: 0.9641 - val_loss: 0.1434 - val_accuracy: 0.9550\n",
            "Epoch 159/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1065 - accuracy: 0.9698 - val_loss: 0.1344 - val_accuracy: 0.9567\n",
            "Epoch 160/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1049 - accuracy: 0.9666 - val_loss: 0.1407 - val_accuracy: 0.9533\n",
            "Epoch 161/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1085 - accuracy: 0.9668 - val_loss: 0.1339 - val_accuracy: 0.9542\n",
            "Epoch 162/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0999 - accuracy: 0.9684 - val_loss: 0.1472 - val_accuracy: 0.9558\n",
            "Epoch 163/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1004 - accuracy: 0.9725 - val_loss: 0.1449 - val_accuracy: 0.9550\n",
            "Epoch 164/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1074 - accuracy: 0.9663 - val_loss: 0.1450 - val_accuracy: 0.9525\n",
            "Epoch 165/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1236 - accuracy: 0.9611 - val_loss: 0.1273 - val_accuracy: 0.9550\n",
            "Epoch 166/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1075 - accuracy: 0.9660 - val_loss: 0.1347 - val_accuracy: 0.9508\n",
            "Epoch 167/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0942 - accuracy: 0.9734 - val_loss: 0.1348 - val_accuracy: 0.9508\n",
            "Epoch 168/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0996 - accuracy: 0.9697 - val_loss: 0.1293 - val_accuracy: 0.9567\n",
            "Epoch 169/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0939 - accuracy: 0.9680 - val_loss: 0.1387 - val_accuracy: 0.9558\n",
            "Epoch 170/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0959 - accuracy: 0.9708 - val_loss: 0.1280 - val_accuracy: 0.9567\n",
            "Epoch 171/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1075 - accuracy: 0.9719 - val_loss: 0.1318 - val_accuracy: 0.9533\n",
            "Epoch 172/500\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.1050 - accuracy: 0.9678 - val_loss: 0.1292 - val_accuracy: 0.9600\n",
            "Epoch 173/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1004 - accuracy: 0.9670 - val_loss: 0.1311 - val_accuracy: 0.9542\n",
            "Epoch 174/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0948 - accuracy: 0.9724 - val_loss: 0.1322 - val_accuracy: 0.9583\n",
            "Epoch 175/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0968 - accuracy: 0.9690 - val_loss: 0.1399 - val_accuracy: 0.9592\n",
            "Epoch 176/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0917 - accuracy: 0.9738 - val_loss: 0.1344 - val_accuracy: 0.9550\n",
            "Epoch 177/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0891 - accuracy: 0.9698 - val_loss: 0.1267 - val_accuracy: 0.9550\n",
            "Epoch 178/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0847 - accuracy: 0.9753 - val_loss: 0.1324 - val_accuracy: 0.9567\n",
            "Epoch 179/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0982 - accuracy: 0.9721 - val_loss: 0.1267 - val_accuracy: 0.9575\n",
            "Epoch 180/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.9729 - val_loss: 0.1272 - val_accuracy: 0.9575\n",
            "Epoch 181/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0962 - accuracy: 0.9733 - val_loss: 0.1252 - val_accuracy: 0.9600\n",
            "Epoch 182/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0905 - accuracy: 0.9714 - val_loss: 0.1486 - val_accuracy: 0.9492\n",
            "Epoch 183/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9702 - val_loss: 0.1306 - val_accuracy: 0.9550\n",
            "Epoch 184/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1029 - accuracy: 0.9696 - val_loss: 0.1248 - val_accuracy: 0.9592\n",
            "Epoch 185/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.9708 - val_loss: 0.1369 - val_accuracy: 0.9608\n",
            "Epoch 186/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9749 - val_loss: 0.1283 - val_accuracy: 0.9558\n",
            "Epoch 187/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1049 - accuracy: 0.9722 - val_loss: 0.1377 - val_accuracy: 0.9550\n",
            "Epoch 188/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0849 - accuracy: 0.9742 - val_loss: 0.1259 - val_accuracy: 0.9600\n",
            "Epoch 189/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.9767 - val_loss: 0.1365 - val_accuracy: 0.9592\n",
            "Epoch 190/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0927 - accuracy: 0.9735 - val_loss: 0.1454 - val_accuracy: 0.9517\n",
            "Epoch 191/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0915 - accuracy: 0.9738 - val_loss: 0.1207 - val_accuracy: 0.9558\n",
            "Epoch 192/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9760 - val_loss: 0.1255 - val_accuracy: 0.9583\n",
            "Epoch 193/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0938 - accuracy: 0.9709 - val_loss: 0.1183 - val_accuracy: 0.9583\n",
            "Epoch 194/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9756 - val_loss: 0.1370 - val_accuracy: 0.9617\n",
            "Epoch 195/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0994 - accuracy: 0.9729 - val_loss: 0.1239 - val_accuracy: 0.9550\n",
            "Epoch 196/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0866 - accuracy: 0.9754 - val_loss: 0.1408 - val_accuracy: 0.9508\n",
            "Epoch 197/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0880 - accuracy: 0.9748 - val_loss: 0.1227 - val_accuracy: 0.9617\n",
            "Epoch 198/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0880 - accuracy: 0.9755 - val_loss: 0.1260 - val_accuracy: 0.9608\n",
            "Epoch 199/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0817 - accuracy: 0.9796 - val_loss: 0.1144 - val_accuracy: 0.9625\n",
            "Epoch 200/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0900 - accuracy: 0.9745 - val_loss: 0.1203 - val_accuracy: 0.9600\n",
            "Epoch 201/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0801 - accuracy: 0.9732 - val_loss: 0.1260 - val_accuracy: 0.9608\n",
            "Epoch 202/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0803 - accuracy: 0.9764 - val_loss: 0.1215 - val_accuracy: 0.9667\n",
            "Epoch 203/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0880 - accuracy: 0.9744 - val_loss: 0.1365 - val_accuracy: 0.9658\n",
            "Epoch 204/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0992 - accuracy: 0.9699 - val_loss: 0.1202 - val_accuracy: 0.9625\n",
            "Epoch 205/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9804 - val_loss: 0.1181 - val_accuracy: 0.9650\n",
            "Epoch 206/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0757 - accuracy: 0.9809 - val_loss: 0.1114 - val_accuracy: 0.9650\n",
            "Epoch 207/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0758 - accuracy: 0.9790 - val_loss: 0.1320 - val_accuracy: 0.9642\n",
            "Epoch 208/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0866 - accuracy: 0.9786 - val_loss: 0.1284 - val_accuracy: 0.9667\n",
            "Epoch 209/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0813 - accuracy: 0.9773 - val_loss: 0.1116 - val_accuracy: 0.9592\n",
            "Epoch 210/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0812 - accuracy: 0.9766 - val_loss: 0.1089 - val_accuracy: 0.9642\n",
            "Epoch 211/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0696 - accuracy: 0.9823 - val_loss: 0.1116 - val_accuracy: 0.9625\n",
            "Epoch 212/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0737 - accuracy: 0.9820 - val_loss: 0.1174 - val_accuracy: 0.9575\n",
            "Epoch 213/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0877 - accuracy: 0.9735 - val_loss: 0.1163 - val_accuracy: 0.9625\n",
            "Epoch 214/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0695 - accuracy: 0.9805 - val_loss: 0.1143 - val_accuracy: 0.9625\n",
            "Epoch 215/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0733 - accuracy: 0.9778 - val_loss: 0.1130 - val_accuracy: 0.9675\n",
            "Epoch 216/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0763 - accuracy: 0.9783 - val_loss: 0.1254 - val_accuracy: 0.9608\n",
            "Epoch 217/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0773 - accuracy: 0.9790 - val_loss: 0.1128 - val_accuracy: 0.9650\n",
            "Epoch 218/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0753 - accuracy: 0.9823 - val_loss: 0.1308 - val_accuracy: 0.9667\n",
            "Epoch 219/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0891 - accuracy: 0.9795 - val_loss: 0.1123 - val_accuracy: 0.9667\n",
            "Epoch 220/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0788 - accuracy: 0.9755 - val_loss: 0.1176 - val_accuracy: 0.9608\n",
            "Epoch 221/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9785 - val_loss: 0.1099 - val_accuracy: 0.9667\n",
            "Epoch 222/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0742 - accuracy: 0.9794 - val_loss: 0.1085 - val_accuracy: 0.9633\n",
            "Epoch 223/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0739 - accuracy: 0.9800 - val_loss: 0.1194 - val_accuracy: 0.9642\n",
            "Epoch 224/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0680 - accuracy: 0.9836 - val_loss: 0.1243 - val_accuracy: 0.9583\n",
            "Epoch 225/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0791 - accuracy: 0.9785 - val_loss: 0.1060 - val_accuracy: 0.9667\n",
            "Epoch 226/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.1133 - val_accuracy: 0.9633\n",
            "Epoch 227/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0680 - accuracy: 0.9811 - val_loss: 0.1178 - val_accuracy: 0.9625\n",
            "Epoch 228/500\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0748 - accuracy: 0.9804 - val_loss: 0.1010 - val_accuracy: 0.9642\n",
            "Epoch 229/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0658 - accuracy: 0.9837 - val_loss: 0.1057 - val_accuracy: 0.9675\n",
            "Epoch 230/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0734 - accuracy: 0.9817 - val_loss: 0.1130 - val_accuracy: 0.9700\n",
            "Epoch 231/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0649 - accuracy: 0.9812 - val_loss: 0.1065 - val_accuracy: 0.9692\n",
            "Epoch 232/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0668 - accuracy: 0.9833 - val_loss: 0.1010 - val_accuracy: 0.9658\n",
            "Epoch 233/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0637 - accuracy: 0.9847 - val_loss: 0.1017 - val_accuracy: 0.9692\n",
            "Epoch 234/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0626 - accuracy: 0.9851 - val_loss: 0.1272 - val_accuracy: 0.9658\n",
            "Epoch 235/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0754 - accuracy: 0.9783 - val_loss: 0.1048 - val_accuracy: 0.9675\n",
            "Epoch 236/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0673 - accuracy: 0.9843 - val_loss: 0.1003 - val_accuracy: 0.9667\n",
            "Epoch 237/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0613 - accuracy: 0.9854 - val_loss: 0.1021 - val_accuracy: 0.9692\n",
            "Epoch 238/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0577 - accuracy: 0.9853 - val_loss: 0.1073 - val_accuracy: 0.9683\n",
            "Epoch 239/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0629 - accuracy: 0.9856 - val_loss: 0.1024 - val_accuracy: 0.9717\n",
            "Epoch 240/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0635 - accuracy: 0.9867 - val_loss: 0.0966 - val_accuracy: 0.9708\n",
            "Epoch 241/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0622 - accuracy: 0.9863 - val_loss: 0.1111 - val_accuracy: 0.9742\n",
            "Epoch 242/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0656 - accuracy: 0.9837 - val_loss: 0.0976 - val_accuracy: 0.9700\n",
            "Epoch 243/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.9870 - val_loss: 0.1325 - val_accuracy: 0.9617\n",
            "Epoch 244/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0786 - accuracy: 0.9806 - val_loss: 0.1220 - val_accuracy: 0.9700\n",
            "Epoch 245/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0734 - accuracy: 0.9838 - val_loss: 0.1004 - val_accuracy: 0.9717\n",
            "Epoch 246/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0583 - accuracy: 0.9836 - val_loss: 0.1069 - val_accuracy: 0.9683\n",
            "Epoch 247/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0658 - accuracy: 0.9848 - val_loss: 0.1064 - val_accuracy: 0.9700\n",
            "Epoch 248/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0644 - accuracy: 0.9829 - val_loss: 0.1018 - val_accuracy: 0.9717\n",
            "Epoch 249/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0642 - accuracy: 0.9845 - val_loss: 0.1071 - val_accuracy: 0.9675\n",
            "Epoch 250/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0598 - accuracy: 0.9832 - val_loss: 0.1012 - val_accuracy: 0.9692\n",
            "Epoch 251/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0684 - accuracy: 0.9853 - val_loss: 0.1146 - val_accuracy: 0.9692\n",
            "Epoch 252/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0703 - accuracy: 0.9813 - val_loss: 0.1001 - val_accuracy: 0.9717\n",
            "Epoch 253/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0621 - accuracy: 0.9834 - val_loss: 0.1093 - val_accuracy: 0.9650\n",
            "Epoch 254/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0717 - accuracy: 0.9832 - val_loss: 0.0948 - val_accuracy: 0.9733\n",
            "Epoch 255/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.9826 - val_loss: 0.1006 - val_accuracy: 0.9725\n",
            "Epoch 256/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0641 - accuracy: 0.9848 - val_loss: 0.0998 - val_accuracy: 0.9692\n",
            "Epoch 257/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0618 - accuracy: 0.9871 - val_loss: 0.0959 - val_accuracy: 0.9692\n",
            "Epoch 258/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0559 - accuracy: 0.9867 - val_loss: 0.0975 - val_accuracy: 0.9733\n",
            "Epoch 259/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.9841 - val_loss: 0.0981 - val_accuracy: 0.9733\n",
            "Epoch 260/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9841 - val_loss: 0.0956 - val_accuracy: 0.9717\n",
            "Epoch 261/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0589 - accuracy: 0.9835 - val_loss: 0.0962 - val_accuracy: 0.9725\n",
            "Epoch 262/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 0.9899 - val_loss: 0.0956 - val_accuracy: 0.9683\n",
            "Epoch 263/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0536 - accuracy: 0.9863 - val_loss: 0.0903 - val_accuracy: 0.9750\n",
            "Epoch 264/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.0921 - val_accuracy: 0.9758\n",
            "Epoch 265/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0562 - accuracy: 0.9863 - val_loss: 0.0986 - val_accuracy: 0.9700\n",
            "Epoch 266/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9862 - val_loss: 0.0990 - val_accuracy: 0.9775\n",
            "Epoch 267/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0578 - accuracy: 0.9853 - val_loss: 0.0852 - val_accuracy: 0.9775\n",
            "Epoch 268/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9879 - val_loss: 0.0963 - val_accuracy: 0.9717\n",
            "Epoch 269/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0601 - accuracy: 0.9850 - val_loss: 0.1074 - val_accuracy: 0.9725\n",
            "Epoch 270/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0606 - accuracy: 0.9828 - val_loss: 0.1062 - val_accuracy: 0.9658\n",
            "Epoch 271/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0617 - accuracy: 0.9837 - val_loss: 0.0909 - val_accuracy: 0.9775\n",
            "Epoch 272/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0565 - accuracy: 0.9869 - val_loss: 0.0987 - val_accuracy: 0.9717\n",
            "Epoch 273/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0616 - accuracy: 0.9841 - val_loss: 0.0861 - val_accuracy: 0.9733\n",
            "Epoch 274/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0498 - accuracy: 0.9898 - val_loss: 0.0924 - val_accuracy: 0.9775\n",
            "Epoch 275/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0555 - accuracy: 0.9865 - val_loss: 0.0889 - val_accuracy: 0.9700\n",
            "Epoch 276/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0592 - accuracy: 0.9844 - val_loss: 0.1359 - val_accuracy: 0.9625\n",
            "Epoch 277/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0684 - accuracy: 0.9828 - val_loss: 0.0864 - val_accuracy: 0.9767\n",
            "Epoch 278/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0481 - accuracy: 0.9892 - val_loss: 0.0845 - val_accuracy: 0.9767\n",
            "Epoch 279/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0543 - accuracy: 0.9842 - val_loss: 0.1376 - val_accuracy: 0.9733\n",
            "Epoch 280/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0661 - accuracy: 0.9866 - val_loss: 0.0876 - val_accuracy: 0.9750\n",
            "Epoch 281/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0479 - accuracy: 0.9895 - val_loss: 0.0932 - val_accuracy: 0.9767\n",
            "Epoch 282/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0533 - accuracy: 0.9877 - val_loss: 0.0860 - val_accuracy: 0.9775\n",
            "Epoch 283/500\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.0502 - accuracy: 0.9873 - val_loss: 0.0859 - val_accuracy: 0.9742\n",
            "Epoch 284/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0509 - accuracy: 0.9888 - val_loss: 0.0832 - val_accuracy: 0.9800\n",
            "Epoch 285/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0461 - accuracy: 0.9891 - val_loss: 0.0853 - val_accuracy: 0.9767\n",
            "Epoch 286/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0514 - accuracy: 0.9865 - val_loss: 0.0878 - val_accuracy: 0.9742\n",
            "Epoch 287/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0482 - accuracy: 0.9893 - val_loss: 0.0987 - val_accuracy: 0.9750\n",
            "Epoch 288/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0515 - accuracy: 0.9868 - val_loss: 0.0869 - val_accuracy: 0.9758\n",
            "Epoch 289/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0510 - accuracy: 0.9857 - val_loss: 0.0847 - val_accuracy: 0.9792\n",
            "Epoch 290/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0473 - accuracy: 0.9881 - val_loss: 0.0869 - val_accuracy: 0.9725\n",
            "Epoch 291/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0552 - accuracy: 0.9857 - val_loss: 0.0927 - val_accuracy: 0.9700\n",
            "Epoch 292/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0517 - accuracy: 0.9861 - val_loss: 0.0966 - val_accuracy: 0.9783\n",
            "Epoch 293/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0469 - accuracy: 0.9863 - val_loss: 0.0814 - val_accuracy: 0.9775\n",
            "Epoch 294/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0465 - accuracy: 0.9893 - val_loss: 0.0891 - val_accuracy: 0.9800\n",
            "Epoch 295/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0527 - accuracy: 0.9853 - val_loss: 0.0822 - val_accuracy: 0.9808\n",
            "Epoch 296/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0465 - accuracy: 0.9888 - val_loss: 0.0809 - val_accuracy: 0.9792\n",
            "Epoch 297/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0439 - accuracy: 0.9903 - val_loss: 0.0910 - val_accuracy: 0.9767\n",
            "Epoch 298/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0517 - accuracy: 0.9871 - val_loss: 0.1041 - val_accuracy: 0.9750\n",
            "Epoch 299/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0516 - accuracy: 0.9872 - val_loss: 0.0784 - val_accuracy: 0.9775\n",
            "Epoch 300/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0471 - accuracy: 0.9886 - val_loss: 0.0837 - val_accuracy: 0.9808\n",
            "Epoch 301/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 0.9908 - val_loss: 0.0838 - val_accuracy: 0.9758\n",
            "Epoch 302/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0472 - accuracy: 0.9879 - val_loss: 0.0813 - val_accuracy: 0.9767\n",
            "Epoch 303/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0443 - accuracy: 0.9882 - val_loss: 0.0953 - val_accuracy: 0.9775\n",
            "Epoch 304/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9867 - val_loss: 0.0821 - val_accuracy: 0.9767\n",
            "Epoch 305/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0500 - accuracy: 0.9873 - val_loss: 0.0732 - val_accuracy: 0.9783\n",
            "Epoch 306/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0473 - accuracy: 0.9909 - val_loss: 0.0883 - val_accuracy: 0.9783\n",
            "Epoch 307/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0453 - accuracy: 0.9887 - val_loss: 0.0824 - val_accuracy: 0.9775\n",
            "Epoch 308/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0465 - accuracy: 0.9883 - val_loss: 0.1079 - val_accuracy: 0.9758\n",
            "Epoch 309/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0623 - accuracy: 0.9859 - val_loss: 0.0839 - val_accuracy: 0.9775\n",
            "Epoch 310/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9901 - val_loss: 0.1038 - val_accuracy: 0.9767\n",
            "Epoch 311/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0481 - accuracy: 0.9875 - val_loss: 0.0834 - val_accuracy: 0.9783\n",
            "Epoch 312/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0460 - accuracy: 0.9887 - val_loss: 0.0844 - val_accuracy: 0.9742\n",
            "Epoch 313/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 0.9900 - val_loss: 0.0886 - val_accuracy: 0.9767\n",
            "Epoch 314/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0492 - accuracy: 0.9875 - val_loss: 0.0769 - val_accuracy: 0.9817\n",
            "Epoch 315/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0471 - accuracy: 0.9884 - val_loss: 0.0847 - val_accuracy: 0.9792\n",
            "Epoch 316/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0406 - accuracy: 0.9904 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
            "Epoch 317/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9914 - val_loss: 0.0806 - val_accuracy: 0.9792\n",
            "Epoch 318/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0432 - accuracy: 0.9896 - val_loss: 0.0815 - val_accuracy: 0.9792\n",
            "Epoch 319/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9904 - val_loss: 0.0768 - val_accuracy: 0.9792\n",
            "Epoch 320/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0404 - accuracy: 0.9897 - val_loss: 0.0816 - val_accuracy: 0.9717\n",
            "Epoch 321/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0575 - accuracy: 0.9824 - val_loss: 0.0852 - val_accuracy: 0.9742\n",
            "Epoch 322/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0516 - accuracy: 0.9853 - val_loss: 0.0972 - val_accuracy: 0.9775\n",
            "Epoch 323/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0403 - accuracy: 0.9896 - val_loss: 0.0862 - val_accuracy: 0.9792\n",
            "Epoch 324/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9876 - val_loss: 0.0733 - val_accuracy: 0.9800\n",
            "Epoch 325/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0409 - accuracy: 0.9901 - val_loss: 0.0748 - val_accuracy: 0.9808\n",
            "Epoch 326/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0424 - accuracy: 0.9910 - val_loss: 0.0849 - val_accuracy: 0.9750\n",
            "Epoch 327/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9900 - val_loss: 0.0920 - val_accuracy: 0.9792\n",
            "Epoch 328/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0448 - accuracy: 0.9882 - val_loss: 0.0773 - val_accuracy: 0.9808\n",
            "Epoch 329/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9883 - val_loss: 0.1027 - val_accuracy: 0.9767\n",
            "Epoch 330/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0490 - accuracy: 0.9895 - val_loss: 0.0794 - val_accuracy: 0.9750\n",
            "Epoch 331/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0444 - accuracy: 0.9887 - val_loss: 0.0724 - val_accuracy: 0.9758\n",
            "Epoch 332/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0453 - accuracy: 0.9882 - val_loss: 0.0697 - val_accuracy: 0.9775\n",
            "Epoch 333/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0388 - accuracy: 0.9883 - val_loss: 0.0762 - val_accuracy: 0.9800\n",
            "Epoch 334/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9894 - val_loss: 0.0789 - val_accuracy: 0.9742\n",
            "Epoch 335/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0473 - accuracy: 0.9874 - val_loss: 0.0774 - val_accuracy: 0.9783\n",
            "Epoch 336/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0570 - accuracy: 0.9849 - val_loss: 0.0931 - val_accuracy: 0.9717\n",
            "Epoch 337/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0644 - accuracy: 0.9813 - val_loss: 0.0670 - val_accuracy: 0.9792\n",
            "Epoch 338/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0370 - accuracy: 0.9917 - val_loss: 0.0779 - val_accuracy: 0.9783\n",
            "Epoch 339/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0438 - accuracy: 0.9863 - val_loss: 0.0746 - val_accuracy: 0.9775\n",
            "Epoch 340/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9915 - val_loss: 0.0751 - val_accuracy: 0.9792\n",
            "Epoch 341/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0373 - accuracy: 0.9908 - val_loss: 0.0729 - val_accuracy: 0.9825\n",
            "Epoch 342/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9906 - val_loss: 0.0739 - val_accuracy: 0.9800\n",
            "Epoch 343/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9916 - val_loss: 0.0682 - val_accuracy: 0.9792\n",
            "Epoch 344/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0400 - accuracy: 0.9910 - val_loss: 0.0724 - val_accuracy: 0.9767\n",
            "Epoch 345/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0400 - accuracy: 0.9900 - val_loss: 0.0759 - val_accuracy: 0.9758\n",
            "Epoch 346/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 0.0738 - val_accuracy: 0.9800\n",
            "Epoch 347/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9896 - val_loss: 0.0698 - val_accuracy: 0.9792\n",
            "Epoch 348/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.0740 - val_accuracy: 0.9800\n",
            "Epoch 349/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9905 - val_loss: 0.0693 - val_accuracy: 0.9808\n",
            "Epoch 350/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9908 - val_loss: 0.0929 - val_accuracy: 0.9700\n",
            "Epoch 351/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0469 - accuracy: 0.9860 - val_loss: 0.0797 - val_accuracy: 0.9792\n",
            "Epoch 352/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.9901 - val_loss: 0.0726 - val_accuracy: 0.9808\n",
            "Epoch 353/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 0.9917 - val_loss: 0.0656 - val_accuracy: 0.9817\n",
            "Epoch 354/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0335 - accuracy: 0.9925 - val_loss: 0.0718 - val_accuracy: 0.9800\n",
            "Epoch 355/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9914 - val_loss: 0.0738 - val_accuracy: 0.9808\n",
            "Epoch 356/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9929 - val_loss: 0.0694 - val_accuracy: 0.9783\n",
            "Epoch 357/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0351 - accuracy: 0.9912 - val_loss: 0.0816 - val_accuracy: 0.9783\n",
            "Epoch 358/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0352 - accuracy: 0.9938 - val_loss: 0.0658 - val_accuracy: 0.9808\n",
            "Epoch 359/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 0.9907 - val_loss: 0.0648 - val_accuracy: 0.9800\n",
            "Epoch 360/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 0.0893 - val_accuracy: 0.9750\n",
            "Epoch 361/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0468 - accuracy: 0.9881 - val_loss: 0.0958 - val_accuracy: 0.9725\n",
            "Epoch 362/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9913 - val_loss: 0.0757 - val_accuracy: 0.9808\n",
            "Epoch 363/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9925 - val_loss: 0.0697 - val_accuracy: 0.9808\n",
            "Epoch 364/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0347 - accuracy: 0.9907 - val_loss: 0.0722 - val_accuracy: 0.9817\n",
            "Epoch 365/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 0.0696 - val_accuracy: 0.9825\n",
            "Epoch 366/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.9922 - val_loss: 0.0686 - val_accuracy: 0.9800\n",
            "Epoch 367/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0357 - accuracy: 0.9907 - val_loss: 0.0740 - val_accuracy: 0.9817\n",
            "Epoch 368/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 0.9902 - val_loss: 0.0695 - val_accuracy: 0.9800\n",
            "Epoch 369/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0380 - accuracy: 0.9898 - val_loss: 0.0743 - val_accuracy: 0.9767\n",
            "Epoch 370/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.0667 - val_accuracy: 0.9808\n",
            "Epoch 371/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 0.0681 - val_accuracy: 0.9775\n",
            "Epoch 372/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 0.0663 - val_accuracy: 0.9833\n",
            "Epoch 373/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0297 - accuracy: 0.9922 - val_loss: 0.0653 - val_accuracy: 0.9792\n",
            "Epoch 374/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0389 - accuracy: 0.9898 - val_loss: 0.1278 - val_accuracy: 0.9792\n",
            "Epoch 375/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0485 - accuracy: 0.9889 - val_loss: 0.0668 - val_accuracy: 0.9767\n",
            "Epoch 376/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0363 - accuracy: 0.9924 - val_loss: 0.0647 - val_accuracy: 0.9808\n",
            "Epoch 377/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9926 - val_loss: 0.0822 - val_accuracy: 0.9792\n",
            "Epoch 378/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 0.0822 - val_accuracy: 0.9792\n",
            "Epoch 379/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0355 - accuracy: 0.9919 - val_loss: 0.0714 - val_accuracy: 0.9792\n",
            "Epoch 380/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0372 - accuracy: 0.9905 - val_loss: 0.0692 - val_accuracy: 0.9817\n",
            "Epoch 381/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 0.9913 - val_loss: 0.0585 - val_accuracy: 0.9833\n",
            "Epoch 382/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9930 - val_loss: 0.0624 - val_accuracy: 0.9825\n",
            "Epoch 383/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0310 - accuracy: 0.9934 - val_loss: 0.0621 - val_accuracy: 0.9825\n",
            "Epoch 384/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0325 - accuracy: 0.9918 - val_loss: 0.0637 - val_accuracy: 0.9808\n",
            "Epoch 385/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0302 - accuracy: 0.9925 - val_loss: 0.0665 - val_accuracy: 0.9800\n",
            "Epoch 386/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0336 - accuracy: 0.9922 - val_loss: 0.0789 - val_accuracy: 0.9775\n",
            "Epoch 387/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.9915 - val_loss: 0.0659 - val_accuracy: 0.9817\n",
            "Epoch 388/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9907 - val_loss: 0.0720 - val_accuracy: 0.9783\n",
            "Epoch 389/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9908 - val_loss: 0.0676 - val_accuracy: 0.9783\n",
            "Epoch 390/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9921 - val_loss: 0.0613 - val_accuracy: 0.9842\n",
            "Epoch 391/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9914 - val_loss: 0.0633 - val_accuracy: 0.9825\n",
            "Epoch 392/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0356 - accuracy: 0.9901 - val_loss: 0.0652 - val_accuracy: 0.9825\n",
            "Epoch 393/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9911 - val_loss: 0.0809 - val_accuracy: 0.9775\n",
            "Epoch 394/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9888 - val_loss: 0.0717 - val_accuracy: 0.9783\n",
            "Epoch 395/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0374 - accuracy: 0.9896 - val_loss: 0.0647 - val_accuracy: 0.9808\n",
            "Epoch 396/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 0.0693 - val_accuracy: 0.9792\n",
            "Epoch 397/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 0.0620 - val_accuracy: 0.9833\n",
            "Epoch 398/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9926 - val_loss: 0.0607 - val_accuracy: 0.9833\n",
            "Epoch 399/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9924 - val_loss: 0.0597 - val_accuracy: 0.9817\n",
            "Epoch 400/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0353 - accuracy: 0.9922 - val_loss: 0.0661 - val_accuracy: 0.9833\n",
            "Epoch 401/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9901 - val_loss: 0.0636 - val_accuracy: 0.9817\n",
            "Epoch 402/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9909 - val_loss: 0.0646 - val_accuracy: 0.9850\n",
            "Epoch 403/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0347 - accuracy: 0.9934 - val_loss: 0.0678 - val_accuracy: 0.9850\n",
            "Epoch 404/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9940 - val_loss: 0.0613 - val_accuracy: 0.9825\n",
            "Epoch 405/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9930 - val_loss: 0.0646 - val_accuracy: 0.9808\n",
            "Epoch 406/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9935 - val_loss: 0.0714 - val_accuracy: 0.9808\n",
            "Epoch 407/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0389 - accuracy: 0.9906 - val_loss: 0.0750 - val_accuracy: 0.9833\n",
            "Epoch 408/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0366 - accuracy: 0.9918 - val_loss: 0.0760 - val_accuracy: 0.9808\n",
            "Epoch 409/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0377 - accuracy: 0.9912 - val_loss: 0.0645 - val_accuracy: 0.9842\n",
            "Epoch 410/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0296 - accuracy: 0.9918 - val_loss: 0.0595 - val_accuracy: 0.9825\n",
            "Epoch 411/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9922 - val_loss: 0.0802 - val_accuracy: 0.9750\n",
            "Epoch 412/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9903 - val_loss: 0.0699 - val_accuracy: 0.9792\n",
            "Epoch 413/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.9901 - val_loss: 0.0689 - val_accuracy: 0.9792\n",
            "Epoch 414/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.0626 - val_accuracy: 0.9833\n",
            "Epoch 415/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 0.0615 - val_accuracy: 0.9833\n",
            "Epoch 416/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.0674 - val_accuracy: 0.9800\n",
            "Epoch 417/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 0.9914 - val_loss: 0.0741 - val_accuracy: 0.9800\n",
            "Epoch 418/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9885 - val_loss: 0.0698 - val_accuracy: 0.9817\n",
            "Epoch 419/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.0749 - val_accuracy: 0.9817\n",
            "Epoch 420/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0642 - val_accuracy: 0.9850\n",
            "Epoch 421/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 0.9937 - val_loss: 0.0593 - val_accuracy: 0.9833\n",
            "Epoch 422/500\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.0686 - val_accuracy: 0.9775\n",
            "Epoch 423/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9919 - val_loss: 0.0716 - val_accuracy: 0.9775\n",
            "Epoch 424/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9910 - val_loss: 0.0599 - val_accuracy: 0.9833\n",
            "Epoch 425/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9918 - val_loss: 0.0615 - val_accuracy: 0.9850\n",
            "Epoch 426/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.0574 - val_accuracy: 0.9850\n",
            "Epoch 427/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.0561 - val_accuracy: 0.9833\n",
            "Epoch 428/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9939 - val_loss: 0.0610 - val_accuracy: 0.9833\n",
            "Epoch 429/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9938 - val_loss: 0.0671 - val_accuracy: 0.9817\n",
            "Epoch 430/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0366 - accuracy: 0.9910 - val_loss: 0.0640 - val_accuracy: 0.9833\n",
            "Epoch 431/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.9905 - val_loss: 0.0706 - val_accuracy: 0.9775\n",
            "Epoch 432/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9925 - val_loss: 0.0596 - val_accuracy: 0.9808\n",
            "Epoch 433/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9952 - val_loss: 0.0564 - val_accuracy: 0.9842\n",
            "Epoch 434/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0308 - accuracy: 0.9913 - val_loss: 0.0631 - val_accuracy: 0.9833\n",
            "Epoch 435/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 0.0650 - val_accuracy: 0.9833\n",
            "Epoch 436/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9949 - val_loss: 0.0671 - val_accuracy: 0.9825\n",
            "Epoch 437/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9937 - val_loss: 0.0562 - val_accuracy: 0.9833\n",
            "Epoch 438/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9954 - val_loss: 0.0652 - val_accuracy: 0.9792\n",
            "Epoch 439/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.0582 - val_accuracy: 0.9817\n",
            "Epoch 440/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9923 - val_loss: 0.0574 - val_accuracy: 0.9842\n",
            "Epoch 441/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9935 - val_loss: 0.0741 - val_accuracy: 0.9800\n",
            "Epoch 442/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0417 - accuracy: 0.9881 - val_loss: 0.0660 - val_accuracy: 0.9783\n",
            "Epoch 443/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9909 - val_loss: 0.0765 - val_accuracy: 0.9825\n",
            "Epoch 444/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9908 - val_loss: 0.0586 - val_accuracy: 0.9842\n",
            "Epoch 445/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9953 - val_loss: 0.0636 - val_accuracy: 0.9833\n",
            "Epoch 446/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9932 - val_loss: 0.0608 - val_accuracy: 0.9842\n",
            "Epoch 447/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 0.9909 - val_loss: 0.0634 - val_accuracy: 0.9842\n",
            "Epoch 448/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9938 - val_loss: 0.0620 - val_accuracy: 0.9825\n",
            "Epoch 449/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9935 - val_loss: 0.0646 - val_accuracy: 0.9842\n",
            "Epoch 450/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9915 - val_loss: 0.1437 - val_accuracy: 0.9725\n",
            "Epoch 451/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0789 - accuracy: 0.9865 - val_loss: 0.0744 - val_accuracy: 0.9800\n",
            "Epoch 452/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9914 - val_loss: 0.0622 - val_accuracy: 0.9808\n",
            "Epoch 453/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9935 - val_loss: 0.0574 - val_accuracy: 0.9825\n",
            "Epoch 454/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9937 - val_loss: 0.0687 - val_accuracy: 0.9842\n",
            "Epoch 455/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9943 - val_loss: 0.0560 - val_accuracy: 0.9858\n",
            "Epoch 456/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9932 - val_loss: 0.0647 - val_accuracy: 0.9808\n",
            "Epoch 457/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9942 - val_loss: 0.0691 - val_accuracy: 0.9817\n",
            "Epoch 458/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9919 - val_loss: 0.0537 - val_accuracy: 0.9858\n",
            "Epoch 459/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9930 - val_loss: 0.0691 - val_accuracy: 0.9767\n",
            "Epoch 460/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 0.9921 - val_loss: 0.0732 - val_accuracy: 0.9833\n",
            "Epoch 461/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0300 - accuracy: 0.9897 - val_loss: 0.0551 - val_accuracy: 0.9858\n",
            "Epoch 462/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9947 - val_loss: 0.0531 - val_accuracy: 0.9833\n",
            "Epoch 463/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9943 - val_loss: 0.0747 - val_accuracy: 0.9825\n",
            "Epoch 464/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9923 - val_loss: 0.0636 - val_accuracy: 0.9792\n",
            "Epoch 465/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0369 - accuracy: 0.9895 - val_loss: 0.0589 - val_accuracy: 0.9850\n",
            "Epoch 466/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9942 - val_loss: 0.0597 - val_accuracy: 0.9808\n",
            "Epoch 467/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 0.9935 - val_loss: 0.0556 - val_accuracy: 0.9867\n",
            "Epoch 468/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9936 - val_loss: 0.0577 - val_accuracy: 0.9850\n",
            "Epoch 469/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9945 - val_loss: 0.0789 - val_accuracy: 0.9792\n",
            "Epoch 470/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9922 - val_loss: 0.0757 - val_accuracy: 0.9825\n",
            "Epoch 471/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0439 - accuracy: 0.9901 - val_loss: 0.0573 - val_accuracy: 0.9850\n",
            "Epoch 472/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.0683 - val_accuracy: 0.9833\n",
            "Epoch 473/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0302 - accuracy: 0.9925 - val_loss: 0.0577 - val_accuracy: 0.9850\n",
            "Epoch 474/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9935 - val_loss: 0.0597 - val_accuracy: 0.9817\n",
            "Epoch 475/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9955 - val_loss: 0.0546 - val_accuracy: 0.9825\n",
            "Epoch 476/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.0551 - val_accuracy: 0.9842\n",
            "Epoch 477/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9937 - val_loss: 0.0621 - val_accuracy: 0.9850\n",
            "Epoch 478/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.0633 - val_accuracy: 0.9833\n",
            "Epoch 479/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9948 - val_loss: 0.0651 - val_accuracy: 0.9842\n",
            "Epoch 480/500\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0303 - accuracy: 0.9920 - val_loss: 0.0535 - val_accuracy: 0.9875\n",
            "Epoch 481/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9940 - val_loss: 0.0557 - val_accuracy: 0.9833\n",
            "Epoch 482/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.0530 - val_accuracy: 0.9858\n",
            "Epoch 483/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9939 - val_loss: 0.0564 - val_accuracy: 0.9842\n",
            "Epoch 484/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0545 - val_accuracy: 0.9817\n",
            "Epoch 485/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0285 - accuracy: 0.9922 - val_loss: 0.0529 - val_accuracy: 0.9842\n",
            "Epoch 486/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 0.0560 - val_accuracy: 0.9858\n",
            "Epoch 487/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.0579 - val_accuracy: 0.9850\n",
            "Epoch 488/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.0618 - val_accuracy: 0.9833\n",
            "Epoch 489/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9939 - val_loss: 0.0567 - val_accuracy: 0.9867\n",
            "Epoch 490/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9944 - val_loss: 0.0562 - val_accuracy: 0.9842\n",
            "Epoch 491/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9939 - val_loss: 0.0656 - val_accuracy: 0.9850\n",
            "Epoch 492/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9950 - val_loss: 0.0554 - val_accuracy: 0.9842\n",
            "Epoch 493/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9943 - val_loss: 0.0536 - val_accuracy: 0.9842\n",
            "Epoch 494/500\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.0211 - accuracy: 0.9953 - val_loss: 0.0653 - val_accuracy: 0.9792\n",
            "Epoch 495/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 0.9928 - val_loss: 0.0625 - val_accuracy: 0.9783\n",
            "Epoch 496/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9935 - val_loss: 0.0558 - val_accuracy: 0.9842\n",
            "Epoch 497/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.0574 - val_accuracy: 0.9817\n",
            "Epoch 498/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9952 - val_loss: 0.0579 - val_accuracy: 0.9842\n",
            "Epoch 499/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0553 - val_accuracy: 0.9867\n",
            "Epoch 500/500\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9941 - val_loss: 0.0550 - val_accuracy: 0.9858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyLZ-4WS6gQX",
        "outputId": "f08b6c4c-c73d-4ce0-c794-1963b119964e"
      },
      "source": [
        "# モデルの評価(大きさ)\n",
        "size_ne_score = size_ne_model.evaluate(X_ans_data, size_Y_ans_data, verbose=1)\n",
        "print('Test loss:', size_ne_score[0])\n",
        "print('Test accuracy:', size_ne_score[1])"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "317/317 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9886\n",
            "Test loss: 0.05134036764502525\n",
            "Test accuracy: 0.9886475801467896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "JO-nlQeD66Mm",
        "outputId": "ffa39a15-ccf7-4328-b87f-3fe9a0d78222"
      },
      "source": [
        "# 学習経過の可視化(大きさ)\n",
        "size_loss     = size_ne_history.history['loss']\n",
        "size_val_loss = size_ne_history.history['val_loss']\n",
        "\n",
        "nb_epoch = len(size_loss)\n",
        "plt.plot(range(nb_epoch), size_loss,     marker='.', label='size_loss')\n",
        "plt.plot(range(nb_epoch), size_val_loss, marker='.', label='size_val_loss')\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "74hzfx8l7DJq",
        "outputId": "6bf55cbe-a3ad-42d4-9514-5dbff38c9133"
      },
      "source": [
        "# 学習経過の可視化(大きさ)\n",
        "size_acc     = size_ne_history.history['accuracy']\n",
        "size_val_acc = size_ne_history.history['val_accuracy']\n",
        "\n",
        "nb_epoch = len(size_acc)\n",
        "plt.plot(range(nb_epoch), size_acc,     marker='.', label='size_acc')\n",
        "plt.plot(range(nb_epoch), size_val_acc, marker='.', label='size_val_acc')\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.show()"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzwlx4nk_SVW"
      },
      "source": [
        "## CNN(位置)\n",
        "\n",
        "### modelの作成\n",
        "position_model = Sequential()\n",
        "### 畳み込み層\n",
        "position_model.add(Conv1D(32, 3, padding='same', activation='relu', input_shape=(50, 1)))\n",
        "### プーリング層\n",
        "position_model.add(MaxPooling1D(2, padding='same'))\n",
        "### Flatten層\n",
        "position_model.add(Flatten())\n",
        "### 全結合層\n",
        "position_model.add(Dense(26, activation='softmax'))\n",
        "\n",
        "### optimizer\n",
        "adam = keras.optimizers.Adam()\n",
        "\n",
        "###modelのコンパイル\n",
        "position_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vMvOWwP_UxY",
        "outputId": "6de5a5ce-4a4d-45f5-f81d-7ae4cb0cc13d"
      },
      "source": [
        "# 学習(位置)\n",
        "epochs = 2000\n",
        "batch_size = 128\n",
        "position_history = position_model.fit(X_ss_train, position_Y_ss_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_ss_test, position_Y_ss_test))"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 3.1284 - accuracy: 0.0901 - val_loss: 2.7732 - val_accuracy: 0.2025\n",
            "Epoch 2/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 2.6913 - accuracy: 0.2706 - val_loss: 2.4554 - val_accuracy: 0.3175\n",
            "Epoch 3/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 2.4204 - accuracy: 0.3180 - val_loss: 2.2573 - val_accuracy: 0.3708\n",
            "Epoch 4/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 2.2289 - accuracy: 0.3536 - val_loss: 2.1219 - val_accuracy: 0.3650\n",
            "Epoch 5/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 2.1002 - accuracy: 0.3796 - val_loss: 2.0081 - val_accuracy: 0.4150\n",
            "Epoch 6/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.9935 - accuracy: 0.4236 - val_loss: 1.9200 - val_accuracy: 0.3983\n",
            "Epoch 7/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.9173 - accuracy: 0.4351 - val_loss: 1.8552 - val_accuracy: 0.4308\n",
            "Epoch 8/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.8501 - accuracy: 0.4584 - val_loss: 1.7762 - val_accuracy: 0.4675\n",
            "Epoch 9/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.7581 - accuracy: 0.4722 - val_loss: 1.7253 - val_accuracy: 0.4958\n",
            "Epoch 10/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.7014 - accuracy: 0.5005 - val_loss: 1.6788 - val_accuracy: 0.5142\n",
            "Epoch 11/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.6828 - accuracy: 0.4925 - val_loss: 1.6358 - val_accuracy: 0.4908\n",
            "Epoch 12/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.6438 - accuracy: 0.5073 - val_loss: 1.5985 - val_accuracy: 0.5317\n",
            "Epoch 13/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.6162 - accuracy: 0.5165 - val_loss: 1.5916 - val_accuracy: 0.4700\n",
            "Epoch 14/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.5791 - accuracy: 0.4964 - val_loss: 1.5395 - val_accuracy: 0.5217\n",
            "Epoch 15/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.5134 - accuracy: 0.5183 - val_loss: 1.5083 - val_accuracy: 0.5225\n",
            "Epoch 16/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.5227 - accuracy: 0.5383 - val_loss: 1.5005 - val_accuracy: 0.4975\n",
            "Epoch 17/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.4805 - accuracy: 0.5247 - val_loss: 1.4550 - val_accuracy: 0.5625\n",
            "Epoch 18/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.4661 - accuracy: 0.5532 - val_loss: 1.4605 - val_accuracy: 0.5467\n",
            "Epoch 19/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.4405 - accuracy: 0.5558 - val_loss: 1.4286 - val_accuracy: 0.5608\n",
            "Epoch 20/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.4244 - accuracy: 0.5638 - val_loss: 1.3943 - val_accuracy: 0.5750\n",
            "Epoch 21/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.4272 - accuracy: 0.5498 - val_loss: 1.3892 - val_accuracy: 0.5867\n",
            "Epoch 22/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.3847 - accuracy: 0.5591 - val_loss: 1.3708 - val_accuracy: 0.5700\n",
            "Epoch 23/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.3748 - accuracy: 0.5479 - val_loss: 1.3854 - val_accuracy: 0.5175\n",
            "Epoch 24/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.3316 - accuracy: 0.5591 - val_loss: 1.3403 - val_accuracy: 0.5608\n",
            "Epoch 25/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.3437 - accuracy: 0.5789 - val_loss: 1.3196 - val_accuracy: 0.5992\n",
            "Epoch 26/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.3094 - accuracy: 0.5853 - val_loss: 1.3094 - val_accuracy: 0.5692\n",
            "Epoch 27/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.2945 - accuracy: 0.5911 - val_loss: 1.3061 - val_accuracy: 0.5592\n",
            "Epoch 28/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2816 - accuracy: 0.5775 - val_loss: 1.2753 - val_accuracy: 0.6000\n",
            "Epoch 29/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.3006 - accuracy: 0.5927 - val_loss: 1.2719 - val_accuracy: 0.5942\n",
            "Epoch 30/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2613 - accuracy: 0.5998 - val_loss: 1.2807 - val_accuracy: 0.5517\n",
            "Epoch 31/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2671 - accuracy: 0.5923 - val_loss: 1.2696 - val_accuracy: 0.5883\n",
            "Epoch 32/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2370 - accuracy: 0.6046 - val_loss: 1.2304 - val_accuracy: 0.6083\n",
            "Epoch 33/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 1.2093 - accuracy: 0.6073 - val_loss: 1.2247 - val_accuracy: 0.6108\n",
            "Epoch 34/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2166 - accuracy: 0.5888 - val_loss: 1.2264 - val_accuracy: 0.6083\n",
            "Epoch 35/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2186 - accuracy: 0.5986 - val_loss: 1.2085 - val_accuracy: 0.6200\n",
            "Epoch 36/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2077 - accuracy: 0.6070 - val_loss: 1.2099 - val_accuracy: 0.6000\n",
            "Epoch 37/2000\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.2016 - accuracy: 0.5994 - val_loss: 1.1914 - val_accuracy: 0.6208\n",
            "Epoch 38/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1902 - accuracy: 0.6157 - val_loss: 1.2138 - val_accuracy: 0.5883\n",
            "Epoch 39/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1662 - accuracy: 0.6236 - val_loss: 1.1586 - val_accuracy: 0.6358\n",
            "Epoch 40/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1560 - accuracy: 0.6202 - val_loss: 1.1949 - val_accuracy: 0.5967\n",
            "Epoch 41/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1711 - accuracy: 0.6103 - val_loss: 1.1843 - val_accuracy: 0.5992\n",
            "Epoch 42/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1398 - accuracy: 0.6319 - val_loss: 1.1590 - val_accuracy: 0.6250\n",
            "Epoch 43/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1294 - accuracy: 0.6213 - val_loss: 1.1402 - val_accuracy: 0.6275\n",
            "Epoch 44/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.1477 - accuracy: 0.6170 - val_loss: 1.1427 - val_accuracy: 0.6083\n",
            "Epoch 45/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1314 - accuracy: 0.6304 - val_loss: 1.1501 - val_accuracy: 0.5858\n",
            "Epoch 46/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1292 - accuracy: 0.6129 - val_loss: 1.1154 - val_accuracy: 0.6367\n",
            "Epoch 47/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1184 - accuracy: 0.6337 - val_loss: 1.1426 - val_accuracy: 0.6092\n",
            "Epoch 48/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1002 - accuracy: 0.6311 - val_loss: 1.1067 - val_accuracy: 0.6225\n",
            "Epoch 49/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1075 - accuracy: 0.6439 - val_loss: 1.1248 - val_accuracy: 0.6125\n",
            "Epoch 50/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1152 - accuracy: 0.6248 - val_loss: 1.0862 - val_accuracy: 0.6258\n",
            "Epoch 51/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0886 - accuracy: 0.6338 - val_loss: 1.0970 - val_accuracy: 0.6208\n",
            "Epoch 52/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0967 - accuracy: 0.6177 - val_loss: 1.0994 - val_accuracy: 0.6258\n",
            "Epoch 53/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0741 - accuracy: 0.6335 - val_loss: 1.0898 - val_accuracy: 0.6167\n",
            "Epoch 54/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1196 - accuracy: 0.6186 - val_loss: 1.0559 - val_accuracy: 0.6375\n",
            "Epoch 55/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0687 - accuracy: 0.6319 - val_loss: 1.0752 - val_accuracy: 0.6258\n",
            "Epoch 56/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0519 - accuracy: 0.6423 - val_loss: 1.0622 - val_accuracy: 0.6317\n",
            "Epoch 57/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0526 - accuracy: 0.6313 - val_loss: 1.0817 - val_accuracy: 0.6292\n",
            "Epoch 58/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0683 - accuracy: 0.6256 - val_loss: 1.0922 - val_accuracy: 0.6200\n",
            "Epoch 59/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0666 - accuracy: 0.6281 - val_loss: 1.0667 - val_accuracy: 0.6350\n",
            "Epoch 60/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0741 - accuracy: 0.6405 - val_loss: 1.0601 - val_accuracy: 0.6225\n",
            "Epoch 61/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0345 - accuracy: 0.6442 - val_loss: 1.0489 - val_accuracy: 0.6342\n",
            "Epoch 62/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0271 - accuracy: 0.6324 - val_loss: 1.0507 - val_accuracy: 0.6233\n",
            "Epoch 63/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0571 - accuracy: 0.6340 - val_loss: 1.0243 - val_accuracy: 0.6450\n",
            "Epoch 64/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0275 - accuracy: 0.6506 - val_loss: 1.0577 - val_accuracy: 0.6333\n",
            "Epoch 65/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0536 - accuracy: 0.6302 - val_loss: 1.0481 - val_accuracy: 0.6183\n",
            "Epoch 66/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0152 - accuracy: 0.6580 - val_loss: 1.0502 - val_accuracy: 0.6275\n",
            "Epoch 67/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9994 - accuracy: 0.6466 - val_loss: 1.0386 - val_accuracy: 0.6375\n",
            "Epoch 68/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0058 - accuracy: 0.6539 - val_loss: 1.0287 - val_accuracy: 0.6408\n",
            "Epoch 69/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0135 - accuracy: 0.6426 - val_loss: 1.0543 - val_accuracy: 0.6433\n",
            "Epoch 70/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0145 - accuracy: 0.6414 - val_loss: 1.0127 - val_accuracy: 0.6525\n",
            "Epoch 71/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9943 - accuracy: 0.6564 - val_loss: 1.0158 - val_accuracy: 0.6400\n",
            "Epoch 72/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0085 - accuracy: 0.6447 - val_loss: 0.9953 - val_accuracy: 0.6642\n",
            "Epoch 73/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0142 - accuracy: 0.6512 - val_loss: 1.0183 - val_accuracy: 0.6392\n",
            "Epoch 74/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9733 - accuracy: 0.6637 - val_loss: 1.0142 - val_accuracy: 0.6425\n",
            "Epoch 75/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9970 - accuracy: 0.6457 - val_loss: 0.9969 - val_accuracy: 0.6550\n",
            "Epoch 76/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0072 - accuracy: 0.6478 - val_loss: 0.9787 - val_accuracy: 0.6600\n",
            "Epoch 77/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9809 - accuracy: 0.6535 - val_loss: 1.0038 - val_accuracy: 0.6408\n",
            "Epoch 78/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9919 - accuracy: 0.6566 - val_loss: 0.9849 - val_accuracy: 0.6483\n",
            "Epoch 79/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9802 - accuracy: 0.6508 - val_loss: 0.9921 - val_accuracy: 0.6508\n",
            "Epoch 80/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9538 - accuracy: 0.6771 - val_loss: 0.9955 - val_accuracy: 0.6508\n",
            "Epoch 81/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9927 - accuracy: 0.6466 - val_loss: 0.9948 - val_accuracy: 0.6592\n",
            "Epoch 82/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9801 - accuracy: 0.6662 - val_loss: 1.0234 - val_accuracy: 0.6308\n",
            "Epoch 83/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9833 - accuracy: 0.6483 - val_loss: 0.9790 - val_accuracy: 0.6483\n",
            "Epoch 84/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9568 - accuracy: 0.6637 - val_loss: 1.0101 - val_accuracy: 0.6175\n",
            "Epoch 85/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9687 - accuracy: 0.6639 - val_loss: 1.0030 - val_accuracy: 0.6467\n",
            "Epoch 86/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9773 - accuracy: 0.6517 - val_loss: 0.9757 - val_accuracy: 0.6742\n",
            "Epoch 87/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9584 - accuracy: 0.6753 - val_loss: 0.9750 - val_accuracy: 0.6567\n",
            "Epoch 88/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9516 - accuracy: 0.6646 - val_loss: 0.9973 - val_accuracy: 0.6558\n",
            "Epoch 89/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9805 - accuracy: 0.6588 - val_loss: 0.9586 - val_accuracy: 0.6550\n",
            "Epoch 90/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9363 - accuracy: 0.6696 - val_loss: 0.9909 - val_accuracy: 0.6333\n",
            "Epoch 91/2000\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.9565 - accuracy: 0.6713 - val_loss: 0.9918 - val_accuracy: 0.6442\n",
            "Epoch 92/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9501 - accuracy: 0.6644 - val_loss: 0.9511 - val_accuracy: 0.6758\n",
            "Epoch 93/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9254 - accuracy: 0.6733 - val_loss: 0.9895 - val_accuracy: 0.6642\n",
            "Epoch 94/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9560 - accuracy: 0.6666 - val_loss: 1.0039 - val_accuracy: 0.6358\n",
            "Epoch 95/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9708 - accuracy: 0.6620 - val_loss: 0.9607 - val_accuracy: 0.6475\n",
            "Epoch 96/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9291 - accuracy: 0.6673 - val_loss: 0.9748 - val_accuracy: 0.6433\n",
            "Epoch 97/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9417 - accuracy: 0.6714 - val_loss: 0.9403 - val_accuracy: 0.6667\n",
            "Epoch 98/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9169 - accuracy: 0.6732 - val_loss: 0.9446 - val_accuracy: 0.6775\n",
            "Epoch 99/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9508 - accuracy: 0.6665 - val_loss: 0.9568 - val_accuracy: 0.6492\n",
            "Epoch 100/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9285 - accuracy: 0.6678 - val_loss: 0.9828 - val_accuracy: 0.6492\n",
            "Epoch 101/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9497 - accuracy: 0.6657 - val_loss: 0.9495 - val_accuracy: 0.6558\n",
            "Epoch 102/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9412 - accuracy: 0.6561 - val_loss: 0.9534 - val_accuracy: 0.6633\n",
            "Epoch 103/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9462 - accuracy: 0.6665 - val_loss: 0.9359 - val_accuracy: 0.6683\n",
            "Epoch 104/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9192 - accuracy: 0.6734 - val_loss: 0.9696 - val_accuracy: 0.6508\n",
            "Epoch 105/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9375 - accuracy: 0.6668 - val_loss: 0.9404 - val_accuracy: 0.6375\n",
            "Epoch 106/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9272 - accuracy: 0.6598 - val_loss: 0.9260 - val_accuracy: 0.6708\n",
            "Epoch 107/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9349 - accuracy: 0.6625 - val_loss: 0.9461 - val_accuracy: 0.6750\n",
            "Epoch 108/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8962 - accuracy: 0.6770 - val_loss: 0.9398 - val_accuracy: 0.6608\n",
            "Epoch 109/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9223 - accuracy: 0.6759 - val_loss: 0.9439 - val_accuracy: 0.6442\n",
            "Epoch 110/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9236 - accuracy: 0.6774 - val_loss: 0.9202 - val_accuracy: 0.6717\n",
            "Epoch 111/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9226 - accuracy: 0.6677 - val_loss: 0.9521 - val_accuracy: 0.6525\n",
            "Epoch 112/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9494 - accuracy: 0.6556 - val_loss: 0.9593 - val_accuracy: 0.6500\n",
            "Epoch 113/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9139 - accuracy: 0.6749 - val_loss: 0.9859 - val_accuracy: 0.6442\n",
            "Epoch 114/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9087 - accuracy: 0.6657 - val_loss: 0.9159 - val_accuracy: 0.6950\n",
            "Epoch 115/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8907 - accuracy: 0.6845 - val_loss: 0.9385 - val_accuracy: 0.6808\n",
            "Epoch 116/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9163 - accuracy: 0.6684 - val_loss: 0.9227 - val_accuracy: 0.6808\n",
            "Epoch 117/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9039 - accuracy: 0.6752 - val_loss: 0.9374 - val_accuracy: 0.6608\n",
            "Epoch 118/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8991 - accuracy: 0.6874 - val_loss: 0.9234 - val_accuracy: 0.6650\n",
            "Epoch 119/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8962 - accuracy: 0.6752 - val_loss: 0.9246 - val_accuracy: 0.6742\n",
            "Epoch 120/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8951 - accuracy: 0.6804 - val_loss: 0.9380 - val_accuracy: 0.6800\n",
            "Epoch 121/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8994 - accuracy: 0.6774 - val_loss: 0.9134 - val_accuracy: 0.6658\n",
            "Epoch 122/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9029 - accuracy: 0.6757 - val_loss: 0.9088 - val_accuracy: 0.6733\n",
            "Epoch 123/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8917 - accuracy: 0.6821 - val_loss: 0.9068 - val_accuracy: 0.6692\n",
            "Epoch 124/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8779 - accuracy: 0.6891 - val_loss: 0.8985 - val_accuracy: 0.6775\n",
            "Epoch 125/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8698 - accuracy: 0.6993 - val_loss: 0.9056 - val_accuracy: 0.6733\n",
            "Epoch 126/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8946 - accuracy: 0.6739 - val_loss: 0.9027 - val_accuracy: 0.6867\n",
            "Epoch 127/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8934 - accuracy: 0.6805 - val_loss: 0.9198 - val_accuracy: 0.6800\n",
            "Epoch 128/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8866 - accuracy: 0.6820 - val_loss: 0.9851 - val_accuracy: 0.6542\n",
            "Epoch 129/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8970 - accuracy: 0.6916 - val_loss: 0.8977 - val_accuracy: 0.6867\n",
            "Epoch 130/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8594 - accuracy: 0.6983 - val_loss: 0.9047 - val_accuracy: 0.6825\n",
            "Epoch 131/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8983 - accuracy: 0.6832 - val_loss: 0.8795 - val_accuracy: 0.6867\n",
            "Epoch 132/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8932 - accuracy: 0.6838 - val_loss: 0.8964 - val_accuracy: 0.6825\n",
            "Epoch 133/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8709 - accuracy: 0.6954 - val_loss: 0.9164 - val_accuracy: 0.6733\n",
            "Epoch 134/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8497 - accuracy: 0.6970 - val_loss: 0.8967 - val_accuracy: 0.6850\n",
            "Epoch 135/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8707 - accuracy: 0.6873 - val_loss: 0.8896 - val_accuracy: 0.6908\n",
            "Epoch 136/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8742 - accuracy: 0.6928 - val_loss: 0.9139 - val_accuracy: 0.6833\n",
            "Epoch 137/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8650 - accuracy: 0.6945 - val_loss: 0.9160 - val_accuracy: 0.6850\n",
            "Epoch 138/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8820 - accuracy: 0.6899 - val_loss: 0.9121 - val_accuracy: 0.6792\n",
            "Epoch 139/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8668 - accuracy: 0.6979 - val_loss: 0.8999 - val_accuracy: 0.6767\n",
            "Epoch 140/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8752 - accuracy: 0.6803 - val_loss: 0.9056 - val_accuracy: 0.6683\n",
            "Epoch 141/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8774 - accuracy: 0.6820 - val_loss: 0.8733 - val_accuracy: 0.6842\n",
            "Epoch 142/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8600 - accuracy: 0.7018 - val_loss: 0.9019 - val_accuracy: 0.6675\n",
            "Epoch 143/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8763 - accuracy: 0.6768 - val_loss: 0.8840 - val_accuracy: 0.6850\n",
            "Epoch 144/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8740 - accuracy: 0.6785 - val_loss: 0.9129 - val_accuracy: 0.6658\n",
            "Epoch 145/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8573 - accuracy: 0.6939 - val_loss: 0.8905 - val_accuracy: 0.6700\n",
            "Epoch 146/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8141 - accuracy: 0.7086 - val_loss: 0.8915 - val_accuracy: 0.6908\n",
            "Epoch 147/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8722 - accuracy: 0.6940 - val_loss: 0.8891 - val_accuracy: 0.7025\n",
            "Epoch 148/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8666 - accuracy: 0.7028 - val_loss: 0.8652 - val_accuracy: 0.7017\n",
            "Epoch 149/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8528 - accuracy: 0.6875 - val_loss: 0.8949 - val_accuracy: 0.6850\n",
            "Epoch 150/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8352 - accuracy: 0.7033 - val_loss: 0.8829 - val_accuracy: 0.6858\n",
            "Epoch 151/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8492 - accuracy: 0.7031 - val_loss: 0.9234 - val_accuracy: 0.6625\n",
            "Epoch 152/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8938 - accuracy: 0.6682 - val_loss: 0.8715 - val_accuracy: 0.6992\n",
            "Epoch 153/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8546 - accuracy: 0.6977 - val_loss: 0.8816 - val_accuracy: 0.6767\n",
            "Epoch 154/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8565 - accuracy: 0.6900 - val_loss: 0.8979 - val_accuracy: 0.6825\n",
            "Epoch 155/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8528 - accuracy: 0.6987 - val_loss: 0.8850 - val_accuracy: 0.6875\n",
            "Epoch 156/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8468 - accuracy: 0.6866 - val_loss: 0.9043 - val_accuracy: 0.6833\n",
            "Epoch 157/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8510 - accuracy: 0.6893 - val_loss: 0.8926 - val_accuracy: 0.6892\n",
            "Epoch 158/2000\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.8602 - accuracy: 0.6978 - val_loss: 0.8559 - val_accuracy: 0.6992\n",
            "Epoch 159/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8544 - accuracy: 0.6907 - val_loss: 0.9373 - val_accuracy: 0.6825\n",
            "Epoch 160/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8516 - accuracy: 0.6982 - val_loss: 0.8704 - val_accuracy: 0.6833\n",
            "Epoch 161/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8195 - accuracy: 0.6961 - val_loss: 0.8656 - val_accuracy: 0.7025\n",
            "Epoch 162/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8226 - accuracy: 0.7169 - val_loss: 0.8800 - val_accuracy: 0.6817\n",
            "Epoch 163/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8576 - accuracy: 0.6929 - val_loss: 0.8711 - val_accuracy: 0.6892\n",
            "Epoch 164/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8657 - accuracy: 0.6897 - val_loss: 0.8726 - val_accuracy: 0.6875\n",
            "Epoch 165/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8418 - accuracy: 0.7021 - val_loss: 0.8661 - val_accuracy: 0.6983\n",
            "Epoch 166/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8579 - accuracy: 0.6864 - val_loss: 0.8928 - val_accuracy: 0.6783\n",
            "Epoch 167/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8663 - accuracy: 0.6776 - val_loss: 0.8912 - val_accuracy: 0.6850\n",
            "Epoch 168/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8277 - accuracy: 0.7158 - val_loss: 0.8567 - val_accuracy: 0.7008\n",
            "Epoch 169/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8278 - accuracy: 0.7107 - val_loss: 0.8583 - val_accuracy: 0.7025\n",
            "Epoch 170/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8301 - accuracy: 0.7072 - val_loss: 0.8419 - val_accuracy: 0.7000\n",
            "Epoch 171/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8460 - accuracy: 0.7058 - val_loss: 0.8712 - val_accuracy: 0.6817\n",
            "Epoch 172/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8450 - accuracy: 0.7008 - val_loss: 0.8858 - val_accuracy: 0.6967\n",
            "Epoch 173/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8336 - accuracy: 0.6948 - val_loss: 0.8573 - val_accuracy: 0.7033\n",
            "Epoch 174/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8407 - accuracy: 0.7104 - val_loss: 0.8671 - val_accuracy: 0.6933\n",
            "Epoch 175/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8349 - accuracy: 0.7055 - val_loss: 0.8402 - val_accuracy: 0.6975\n",
            "Epoch 176/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8025 - accuracy: 0.7170 - val_loss: 0.8387 - val_accuracy: 0.7133\n",
            "Epoch 177/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8227 - accuracy: 0.7039 - val_loss: 0.8530 - val_accuracy: 0.7075\n",
            "Epoch 178/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8363 - accuracy: 0.6994 - val_loss: 0.8686 - val_accuracy: 0.7067\n",
            "Epoch 179/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8485 - accuracy: 0.7066 - val_loss: 0.8603 - val_accuracy: 0.6967\n",
            "Epoch 180/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8009 - accuracy: 0.7192 - val_loss: 0.8536 - val_accuracy: 0.7092\n",
            "Epoch 181/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8289 - accuracy: 0.7065 - val_loss: 0.8663 - val_accuracy: 0.6858\n",
            "Epoch 182/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8146 - accuracy: 0.7162 - val_loss: 0.8724 - val_accuracy: 0.6867\n",
            "Epoch 183/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8546 - accuracy: 0.6976 - val_loss: 0.8484 - val_accuracy: 0.6917\n",
            "Epoch 184/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8790 - accuracy: 0.6831 - val_loss: 0.9066 - val_accuracy: 0.6883\n",
            "Epoch 185/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8449 - accuracy: 0.6966 - val_loss: 0.9044 - val_accuracy: 0.7092\n",
            "Epoch 186/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8579 - accuracy: 0.7020 - val_loss: 0.8706 - val_accuracy: 0.6942\n",
            "Epoch 187/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8143 - accuracy: 0.7047 - val_loss: 0.8410 - val_accuracy: 0.7017\n",
            "Epoch 188/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8164 - accuracy: 0.7108 - val_loss: 0.8600 - val_accuracy: 0.6925\n",
            "Epoch 189/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8383 - accuracy: 0.6990 - val_loss: 0.8637 - val_accuracy: 0.6833\n",
            "Epoch 190/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8355 - accuracy: 0.7066 - val_loss: 0.8756 - val_accuracy: 0.6850\n",
            "Epoch 191/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8380 - accuracy: 0.7008 - val_loss: 0.8642 - val_accuracy: 0.6808\n",
            "Epoch 192/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8290 - accuracy: 0.6994 - val_loss: 0.8712 - val_accuracy: 0.6958\n",
            "Epoch 193/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8292 - accuracy: 0.6986 - val_loss: 0.8736 - val_accuracy: 0.6975\n",
            "Epoch 194/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8323 - accuracy: 0.7100 - val_loss: 0.8421 - val_accuracy: 0.7008\n",
            "Epoch 195/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8061 - accuracy: 0.7043 - val_loss: 0.8458 - val_accuracy: 0.7100\n",
            "Epoch 196/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7992 - accuracy: 0.7186 - val_loss: 0.8515 - val_accuracy: 0.7067\n",
            "Epoch 197/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8308 - accuracy: 0.6898 - val_loss: 0.8637 - val_accuracy: 0.6992\n",
            "Epoch 198/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8142 - accuracy: 0.7178 - val_loss: 0.8320 - val_accuracy: 0.6975\n",
            "Epoch 199/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7969 - accuracy: 0.7268 - val_loss: 0.8348 - val_accuracy: 0.6925\n",
            "Epoch 200/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8110 - accuracy: 0.7154 - val_loss: 0.8661 - val_accuracy: 0.6892\n",
            "Epoch 201/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8554 - accuracy: 0.6972 - val_loss: 0.8860 - val_accuracy: 0.6850\n",
            "Epoch 202/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8345 - accuracy: 0.7033 - val_loss: 0.8541 - val_accuracy: 0.6900\n",
            "Epoch 203/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8119 - accuracy: 0.7153 - val_loss: 0.8608 - val_accuracy: 0.6942\n",
            "Epoch 204/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8176 - accuracy: 0.7098 - val_loss: 0.8016 - val_accuracy: 0.7358\n",
            "Epoch 205/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7984 - accuracy: 0.7180 - val_loss: 0.8728 - val_accuracy: 0.6875\n",
            "Epoch 206/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8238 - accuracy: 0.7054 - val_loss: 0.8430 - val_accuracy: 0.7150\n",
            "Epoch 207/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7840 - accuracy: 0.7226 - val_loss: 0.8307 - val_accuracy: 0.7158\n",
            "Epoch 208/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7775 - accuracy: 0.7249 - val_loss: 0.8413 - val_accuracy: 0.7025\n",
            "Epoch 209/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7868 - accuracy: 0.7101 - val_loss: 0.8311 - val_accuracy: 0.7017\n",
            "Epoch 210/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8088 - accuracy: 0.7087 - val_loss: 0.8560 - val_accuracy: 0.6842\n",
            "Epoch 211/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7980 - accuracy: 0.7056 - val_loss: 0.8526 - val_accuracy: 0.6942\n",
            "Epoch 212/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8228 - accuracy: 0.6988 - val_loss: 0.8285 - val_accuracy: 0.7133\n",
            "Epoch 213/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7743 - accuracy: 0.7107 - val_loss: 0.8351 - val_accuracy: 0.7275\n",
            "Epoch 214/2000\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.7994 - accuracy: 0.7172 - val_loss: 0.8376 - val_accuracy: 0.7075\n",
            "Epoch 215/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8170 - accuracy: 0.7099 - val_loss: 0.8554 - val_accuracy: 0.6933\n",
            "Epoch 216/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8352 - accuracy: 0.6936 - val_loss: 0.9026 - val_accuracy: 0.6925\n",
            "Epoch 217/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8311 - accuracy: 0.6972 - val_loss: 0.8659 - val_accuracy: 0.6933\n",
            "Epoch 218/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7862 - accuracy: 0.7240 - val_loss: 0.8977 - val_accuracy: 0.6883\n",
            "Epoch 219/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8135 - accuracy: 0.6961 - val_loss: 0.8197 - val_accuracy: 0.7242\n",
            "Epoch 220/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8018 - accuracy: 0.7134 - val_loss: 0.8681 - val_accuracy: 0.6875\n",
            "Epoch 221/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7961 - accuracy: 0.7091 - val_loss: 0.8233 - val_accuracy: 0.7075\n",
            "Epoch 222/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7904 - accuracy: 0.7249 - val_loss: 0.8173 - val_accuracy: 0.6942\n",
            "Epoch 223/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8100 - accuracy: 0.7171 - val_loss: 0.8375 - val_accuracy: 0.7033\n",
            "Epoch 224/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8081 - accuracy: 0.7172 - val_loss: 0.8450 - val_accuracy: 0.7067\n",
            "Epoch 225/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7977 - accuracy: 0.7222 - val_loss: 0.8552 - val_accuracy: 0.7033\n",
            "Epoch 226/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7728 - accuracy: 0.7140 - val_loss: 0.8430 - val_accuracy: 0.7025\n",
            "Epoch 227/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8049 - accuracy: 0.7117 - val_loss: 0.8193 - val_accuracy: 0.7242\n",
            "Epoch 228/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8024 - accuracy: 0.7214 - val_loss: 0.8506 - val_accuracy: 0.6908\n",
            "Epoch 229/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7797 - accuracy: 0.7261 - val_loss: 0.8372 - val_accuracy: 0.7033\n",
            "Epoch 230/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7910 - accuracy: 0.7193 - val_loss: 0.8342 - val_accuracy: 0.6983\n",
            "Epoch 231/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8097 - accuracy: 0.6993 - val_loss: 0.8130 - val_accuracy: 0.7058\n",
            "Epoch 232/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7820 - accuracy: 0.7335 - val_loss: 0.8387 - val_accuracy: 0.7075\n",
            "Epoch 233/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7644 - accuracy: 0.7313 - val_loss: 0.8157 - val_accuracy: 0.7183\n",
            "Epoch 234/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7978 - accuracy: 0.7198 - val_loss: 0.8040 - val_accuracy: 0.7267\n",
            "Epoch 235/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7932 - accuracy: 0.7236 - val_loss: 0.8413 - val_accuracy: 0.7225\n",
            "Epoch 236/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7993 - accuracy: 0.7193 - val_loss: 0.8259 - val_accuracy: 0.7092\n",
            "Epoch 237/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8042 - accuracy: 0.7159 - val_loss: 0.8730 - val_accuracy: 0.7067\n",
            "Epoch 238/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7871 - accuracy: 0.7192 - val_loss: 0.8286 - val_accuracy: 0.6975\n",
            "Epoch 239/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8001 - accuracy: 0.7099 - val_loss: 0.8151 - val_accuracy: 0.7142\n",
            "Epoch 240/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7781 - accuracy: 0.7321 - val_loss: 0.8108 - val_accuracy: 0.7150\n",
            "Epoch 241/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7707 - accuracy: 0.7190 - val_loss: 0.8478 - val_accuracy: 0.6942\n",
            "Epoch 242/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7757 - accuracy: 0.7140 - val_loss: 0.8068 - val_accuracy: 0.7167\n",
            "Epoch 243/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7581 - accuracy: 0.7334 - val_loss: 0.8336 - val_accuracy: 0.7242\n",
            "Epoch 244/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7858 - accuracy: 0.7129 - val_loss: 0.7898 - val_accuracy: 0.7242\n",
            "Epoch 245/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7447 - accuracy: 0.7428 - val_loss: 0.8110 - val_accuracy: 0.7217\n",
            "Epoch 246/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7556 - accuracy: 0.7421 - val_loss: 0.8045 - val_accuracy: 0.7225\n",
            "Epoch 247/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7792 - accuracy: 0.7111 - val_loss: 0.8301 - val_accuracy: 0.6933\n",
            "Epoch 248/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7709 - accuracy: 0.7307 - val_loss: 0.8107 - val_accuracy: 0.7042\n",
            "Epoch 249/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7810 - accuracy: 0.7193 - val_loss: 0.8299 - val_accuracy: 0.6950\n",
            "Epoch 250/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8126 - accuracy: 0.7018 - val_loss: 0.8415 - val_accuracy: 0.7075\n",
            "Epoch 251/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7625 - accuracy: 0.7286 - val_loss: 0.8105 - val_accuracy: 0.7325\n",
            "Epoch 252/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7514 - accuracy: 0.7386 - val_loss: 0.8085 - val_accuracy: 0.7217\n",
            "Epoch 253/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7671 - accuracy: 0.7212 - val_loss: 0.8462 - val_accuracy: 0.6933\n",
            "Epoch 254/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8040 - accuracy: 0.7196 - val_loss: 0.8310 - val_accuracy: 0.7050\n",
            "Epoch 255/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8055 - accuracy: 0.7038 - val_loss: 0.8075 - val_accuracy: 0.7150\n",
            "Epoch 256/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7671 - accuracy: 0.7245 - val_loss: 0.8190 - val_accuracy: 0.7267\n",
            "Epoch 257/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8230 - accuracy: 0.7114 - val_loss: 0.8554 - val_accuracy: 0.7008\n",
            "Epoch 258/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8071 - accuracy: 0.7185 - val_loss: 0.8436 - val_accuracy: 0.7142\n",
            "Epoch 259/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7651 - accuracy: 0.7161 - val_loss: 0.8381 - val_accuracy: 0.7075\n",
            "Epoch 260/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7799 - accuracy: 0.7225 - val_loss: 0.8136 - val_accuracy: 0.7183\n",
            "Epoch 261/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7705 - accuracy: 0.7172 - val_loss: 0.7836 - val_accuracy: 0.7417\n",
            "Epoch 262/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7528 - accuracy: 0.7416 - val_loss: 0.8339 - val_accuracy: 0.6950\n",
            "Epoch 263/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7821 - accuracy: 0.7178 - val_loss: 0.7878 - val_accuracy: 0.7300\n",
            "Epoch 264/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7723 - accuracy: 0.7159 - val_loss: 0.8210 - val_accuracy: 0.7108\n",
            "Epoch 265/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7713 - accuracy: 0.7267 - val_loss: 0.7963 - val_accuracy: 0.7125\n",
            "Epoch 266/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7863 - accuracy: 0.7217 - val_loss: 0.7740 - val_accuracy: 0.7267\n",
            "Epoch 267/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7593 - accuracy: 0.7353 - val_loss: 0.8227 - val_accuracy: 0.7175\n",
            "Epoch 268/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7687 - accuracy: 0.7155 - val_loss: 0.7842 - val_accuracy: 0.7333\n",
            "Epoch 269/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7636 - accuracy: 0.7305 - val_loss: 0.8195 - val_accuracy: 0.7017\n",
            "Epoch 270/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7525 - accuracy: 0.7289 - val_loss: 0.8439 - val_accuracy: 0.6925\n",
            "Epoch 271/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7724 - accuracy: 0.7255 - val_loss: 0.8567 - val_accuracy: 0.6933\n",
            "Epoch 272/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7856 - accuracy: 0.7190 - val_loss: 0.7980 - val_accuracy: 0.7100\n",
            "Epoch 273/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7467 - accuracy: 0.7269 - val_loss: 0.8449 - val_accuracy: 0.7058\n",
            "Epoch 274/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7886 - accuracy: 0.7122 - val_loss: 0.8095 - val_accuracy: 0.7267\n",
            "Epoch 275/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7733 - accuracy: 0.7354 - val_loss: 0.7979 - val_accuracy: 0.7150\n",
            "Epoch 276/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7509 - accuracy: 0.7424 - val_loss: 0.8204 - val_accuracy: 0.7175\n",
            "Epoch 277/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7720 - accuracy: 0.7279 - val_loss: 0.7814 - val_accuracy: 0.7200\n",
            "Epoch 278/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7569 - accuracy: 0.7338 - val_loss: 0.8134 - val_accuracy: 0.7075\n",
            "Epoch 279/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7884 - accuracy: 0.7125 - val_loss: 0.7945 - val_accuracy: 0.7233\n",
            "Epoch 280/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7543 - accuracy: 0.7312 - val_loss: 0.7910 - val_accuracy: 0.7075\n",
            "Epoch 281/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7408 - accuracy: 0.7366 - val_loss: 0.8009 - val_accuracy: 0.7167\n",
            "Epoch 282/2000\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.7502 - accuracy: 0.7405 - val_loss: 0.8260 - val_accuracy: 0.7200\n",
            "Epoch 283/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7614 - accuracy: 0.7332 - val_loss: 0.8356 - val_accuracy: 0.6967\n",
            "Epoch 284/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7770 - accuracy: 0.7182 - val_loss: 0.8005 - val_accuracy: 0.7092\n",
            "Epoch 285/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7456 - accuracy: 0.7339 - val_loss: 0.8144 - val_accuracy: 0.7142\n",
            "Epoch 286/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7577 - accuracy: 0.7269 - val_loss: 0.8066 - val_accuracy: 0.7150\n",
            "Epoch 287/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7565 - accuracy: 0.7283 - val_loss: 0.8494 - val_accuracy: 0.7158\n",
            "Epoch 288/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7516 - accuracy: 0.7254 - val_loss: 0.8483 - val_accuracy: 0.7083\n",
            "Epoch 289/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7721 - accuracy: 0.7271 - val_loss: 0.8404 - val_accuracy: 0.7017\n",
            "Epoch 290/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7530 - accuracy: 0.7281 - val_loss: 0.7726 - val_accuracy: 0.7242\n",
            "Epoch 291/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7488 - accuracy: 0.7278 - val_loss: 0.8077 - val_accuracy: 0.7075\n",
            "Epoch 292/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7337 - accuracy: 0.7412 - val_loss: 0.8342 - val_accuracy: 0.7025\n",
            "Epoch 293/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7534 - accuracy: 0.7349 - val_loss: 0.7873 - val_accuracy: 0.7350\n",
            "Epoch 294/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7335 - accuracy: 0.7417 - val_loss: 0.7932 - val_accuracy: 0.7200\n",
            "Epoch 295/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7608 - accuracy: 0.7234 - val_loss: 0.7937 - val_accuracy: 0.7142\n",
            "Epoch 296/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7511 - accuracy: 0.7279 - val_loss: 0.8088 - val_accuracy: 0.7092\n",
            "Epoch 297/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7547 - accuracy: 0.7264 - val_loss: 0.7998 - val_accuracy: 0.7300\n",
            "Epoch 298/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7476 - accuracy: 0.7327 - val_loss: 0.8049 - val_accuracy: 0.7367\n",
            "Epoch 299/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7522 - accuracy: 0.7370 - val_loss: 0.7698 - val_accuracy: 0.7283\n",
            "Epoch 300/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7123 - accuracy: 0.7538 - val_loss: 0.8094 - val_accuracy: 0.7167\n",
            "Epoch 301/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7440 - accuracy: 0.7401 - val_loss: 0.7907 - val_accuracy: 0.7333\n",
            "Epoch 302/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7410 - accuracy: 0.7382 - val_loss: 0.8266 - val_accuracy: 0.7058\n",
            "Epoch 303/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7582 - accuracy: 0.7267 - val_loss: 0.8455 - val_accuracy: 0.7283\n",
            "Epoch 304/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7518 - accuracy: 0.7296 - val_loss: 0.8136 - val_accuracy: 0.7267\n",
            "Epoch 305/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7815 - accuracy: 0.7148 - val_loss: 0.8341 - val_accuracy: 0.7200\n",
            "Epoch 306/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7533 - accuracy: 0.7332 - val_loss: 0.7814 - val_accuracy: 0.7350\n",
            "Epoch 307/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7333 - accuracy: 0.7478 - val_loss: 0.7785 - val_accuracy: 0.7308\n",
            "Epoch 308/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7129 - accuracy: 0.7457 - val_loss: 0.8119 - val_accuracy: 0.7100\n",
            "Epoch 309/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7342 - accuracy: 0.7377 - val_loss: 0.7806 - val_accuracy: 0.7250\n",
            "Epoch 310/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7476 - accuracy: 0.7354 - val_loss: 0.8098 - val_accuracy: 0.7283\n",
            "Epoch 311/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7100 - accuracy: 0.7437 - val_loss: 0.7886 - val_accuracy: 0.7150\n",
            "Epoch 312/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7317 - accuracy: 0.7365 - val_loss: 0.7909 - val_accuracy: 0.7250\n",
            "Epoch 313/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7323 - accuracy: 0.7436 - val_loss: 0.7941 - val_accuracy: 0.7267\n",
            "Epoch 314/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7631 - accuracy: 0.7246 - val_loss: 0.8061 - val_accuracy: 0.7175\n",
            "Epoch 315/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7534 - accuracy: 0.7241 - val_loss: 0.8257 - val_accuracy: 0.7092\n",
            "Epoch 316/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7459 - accuracy: 0.7367 - val_loss: 0.8021 - val_accuracy: 0.7250\n",
            "Epoch 317/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7330 - accuracy: 0.7489 - val_loss: 0.7668 - val_accuracy: 0.7425\n",
            "Epoch 318/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7628 - accuracy: 0.7175 - val_loss: 0.8236 - val_accuracy: 0.7167\n",
            "Epoch 319/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7136 - accuracy: 0.7538 - val_loss: 0.7690 - val_accuracy: 0.7408\n",
            "Epoch 320/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7181 - accuracy: 0.7470 - val_loss: 0.7959 - val_accuracy: 0.7142\n",
            "Epoch 321/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7578 - accuracy: 0.7325 - val_loss: 0.8186 - val_accuracy: 0.7408\n",
            "Epoch 322/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7335 - accuracy: 0.7411 - val_loss: 0.8173 - val_accuracy: 0.7192\n",
            "Epoch 323/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7507 - accuracy: 0.7431 - val_loss: 0.7742 - val_accuracy: 0.7275\n",
            "Epoch 324/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7224 - accuracy: 0.7441 - val_loss: 0.8033 - val_accuracy: 0.7392\n",
            "Epoch 325/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7518 - accuracy: 0.7296 - val_loss: 0.8252 - val_accuracy: 0.7192\n",
            "Epoch 326/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7455 - accuracy: 0.7331 - val_loss: 0.8112 - val_accuracy: 0.7158\n",
            "Epoch 327/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7250 - accuracy: 0.7371 - val_loss: 0.7814 - val_accuracy: 0.7283\n",
            "Epoch 328/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7151 - accuracy: 0.7511 - val_loss: 0.7989 - val_accuracy: 0.7258\n",
            "Epoch 329/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7022 - accuracy: 0.7527 - val_loss: 0.7869 - val_accuracy: 0.7408\n",
            "Epoch 330/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7415 - accuracy: 0.7498 - val_loss: 0.8151 - val_accuracy: 0.7208\n",
            "Epoch 331/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7768 - accuracy: 0.7141 - val_loss: 0.7958 - val_accuracy: 0.7200\n",
            "Epoch 332/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7765 - accuracy: 0.7160 - val_loss: 0.7970 - val_accuracy: 0.7450\n",
            "Epoch 333/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7224 - accuracy: 0.7451 - val_loss: 0.7942 - val_accuracy: 0.7208\n",
            "Epoch 334/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7395 - accuracy: 0.7431 - val_loss: 0.8208 - val_accuracy: 0.7158\n",
            "Epoch 335/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7610 - accuracy: 0.7356 - val_loss: 0.7758 - val_accuracy: 0.7458\n",
            "Epoch 336/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7164 - accuracy: 0.7512 - val_loss: 0.7662 - val_accuracy: 0.7308\n",
            "Epoch 337/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7076 - accuracy: 0.7488 - val_loss: 0.7774 - val_accuracy: 0.7242\n",
            "Epoch 338/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7221 - accuracy: 0.7387 - val_loss: 0.7696 - val_accuracy: 0.7283\n",
            "Epoch 339/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7412 - accuracy: 0.7339 - val_loss: 0.7632 - val_accuracy: 0.7417\n",
            "Epoch 340/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.7252 - accuracy: 0.7392 - val_loss: 0.7768 - val_accuracy: 0.7383\n",
            "Epoch 341/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7208 - accuracy: 0.7425 - val_loss: 0.7652 - val_accuracy: 0.7408\n",
            "Epoch 342/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7236 - accuracy: 0.7318 - val_loss: 0.7773 - val_accuracy: 0.7275\n",
            "Epoch 343/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7231 - accuracy: 0.7453 - val_loss: 0.8086 - val_accuracy: 0.7308\n",
            "Epoch 344/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7489 - accuracy: 0.7213 - val_loss: 0.7972 - val_accuracy: 0.7367\n",
            "Epoch 345/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7518 - accuracy: 0.7237 - val_loss: 0.8222 - val_accuracy: 0.7108\n",
            "Epoch 346/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7447 - accuracy: 0.7330 - val_loss: 0.7976 - val_accuracy: 0.7133\n",
            "Epoch 347/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7362 - accuracy: 0.7273 - val_loss: 0.8230 - val_accuracy: 0.7033\n",
            "Epoch 348/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7352 - accuracy: 0.7363 - val_loss: 0.7749 - val_accuracy: 0.7333\n",
            "Epoch 349/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7509 - accuracy: 0.7388 - val_loss: 0.8078 - val_accuracy: 0.7267\n",
            "Epoch 350/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7350 - accuracy: 0.7294 - val_loss: 0.7910 - val_accuracy: 0.7150\n",
            "Epoch 351/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7269 - accuracy: 0.7323 - val_loss: 0.7721 - val_accuracy: 0.7383\n",
            "Epoch 352/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7328 - accuracy: 0.7383 - val_loss: 0.7464 - val_accuracy: 0.7450\n",
            "Epoch 353/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7133 - accuracy: 0.7507 - val_loss: 0.7712 - val_accuracy: 0.7350\n",
            "Epoch 354/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7251 - accuracy: 0.7364 - val_loss: 0.7527 - val_accuracy: 0.7483\n",
            "Epoch 355/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7302 - accuracy: 0.7371 - val_loss: 0.7499 - val_accuracy: 0.7317\n",
            "Epoch 356/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6885 - accuracy: 0.7521 - val_loss: 0.8021 - val_accuracy: 0.7233\n",
            "Epoch 357/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7340 - accuracy: 0.7397 - val_loss: 0.7660 - val_accuracy: 0.7292\n",
            "Epoch 358/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7193 - accuracy: 0.7501 - val_loss: 0.8002 - val_accuracy: 0.7092\n",
            "Epoch 359/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7098 - accuracy: 0.7535 - val_loss: 0.7675 - val_accuracy: 0.7358\n",
            "Epoch 360/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7040 - accuracy: 0.7324 - val_loss: 0.7887 - val_accuracy: 0.7292\n",
            "Epoch 361/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7595 - accuracy: 0.7332 - val_loss: 0.7908 - val_accuracy: 0.7317\n",
            "Epoch 362/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7327 - accuracy: 0.7278 - val_loss: 0.7746 - val_accuracy: 0.7317\n",
            "Epoch 363/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7289 - accuracy: 0.7357 - val_loss: 0.7894 - val_accuracy: 0.7267\n",
            "Epoch 364/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7465 - accuracy: 0.7301 - val_loss: 0.7586 - val_accuracy: 0.7533\n",
            "Epoch 365/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7229 - accuracy: 0.7479 - val_loss: 0.7960 - val_accuracy: 0.7058\n",
            "Epoch 366/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7006 - accuracy: 0.7533 - val_loss: 0.7712 - val_accuracy: 0.7292\n",
            "Epoch 367/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7251 - accuracy: 0.7385 - val_loss: 0.7673 - val_accuracy: 0.7367\n",
            "Epoch 368/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7016 - accuracy: 0.7574 - val_loss: 0.7711 - val_accuracy: 0.7350\n",
            "Epoch 369/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7222 - accuracy: 0.7418 - val_loss: 0.8245 - val_accuracy: 0.7117\n",
            "Epoch 370/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7438 - accuracy: 0.7397 - val_loss: 0.7981 - val_accuracy: 0.7200\n",
            "Epoch 371/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7218 - accuracy: 0.7431 - val_loss: 0.7706 - val_accuracy: 0.7342\n",
            "Epoch 372/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7238 - accuracy: 0.7528 - val_loss: 0.8670 - val_accuracy: 0.6900\n",
            "Epoch 373/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7166 - accuracy: 0.7392 - val_loss: 0.7658 - val_accuracy: 0.7317\n",
            "Epoch 374/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7280 - accuracy: 0.7480 - val_loss: 0.7837 - val_accuracy: 0.7308\n",
            "Epoch 375/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6912 - accuracy: 0.7619 - val_loss: 0.8000 - val_accuracy: 0.7217\n",
            "Epoch 376/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7073 - accuracy: 0.7492 - val_loss: 0.8046 - val_accuracy: 0.7275\n",
            "Epoch 377/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7250 - accuracy: 0.7383 - val_loss: 0.7740 - val_accuracy: 0.7192\n",
            "Epoch 378/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7365 - accuracy: 0.7235 - val_loss: 0.7794 - val_accuracy: 0.7333\n",
            "Epoch 379/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7173 - accuracy: 0.7448 - val_loss: 0.7838 - val_accuracy: 0.7267\n",
            "Epoch 380/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7237 - accuracy: 0.7399 - val_loss: 0.8068 - val_accuracy: 0.7350\n",
            "Epoch 381/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7192 - accuracy: 0.7519 - val_loss: 0.7705 - val_accuracy: 0.7425\n",
            "Epoch 382/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7237 - accuracy: 0.7295 - val_loss: 0.7698 - val_accuracy: 0.7375\n",
            "Epoch 383/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7351 - accuracy: 0.7345 - val_loss: 0.7838 - val_accuracy: 0.7300\n",
            "Epoch 384/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7305 - accuracy: 0.7370 - val_loss: 0.7581 - val_accuracy: 0.7425\n",
            "Epoch 385/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7223 - accuracy: 0.7492 - val_loss: 0.7776 - val_accuracy: 0.7233\n",
            "Epoch 386/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6903 - accuracy: 0.7515 - val_loss: 0.7631 - val_accuracy: 0.7517\n",
            "Epoch 387/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7065 - accuracy: 0.7470 - val_loss: 0.7530 - val_accuracy: 0.7525\n",
            "Epoch 388/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7110 - accuracy: 0.7362 - val_loss: 0.7404 - val_accuracy: 0.7458\n",
            "Epoch 389/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7059 - accuracy: 0.7407 - val_loss: 0.7510 - val_accuracy: 0.7242\n",
            "Epoch 390/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7326 - accuracy: 0.7280 - val_loss: 0.7617 - val_accuracy: 0.7483\n",
            "Epoch 391/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6861 - accuracy: 0.7560 - val_loss: 0.8196 - val_accuracy: 0.7192\n",
            "Epoch 392/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7326 - accuracy: 0.7426 - val_loss: 0.7467 - val_accuracy: 0.7433\n",
            "Epoch 393/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7220 - accuracy: 0.7404 - val_loss: 0.8037 - val_accuracy: 0.7150\n",
            "Epoch 394/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7018 - accuracy: 0.7529 - val_loss: 0.7590 - val_accuracy: 0.7408\n",
            "Epoch 395/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6857 - accuracy: 0.7582 - val_loss: 0.7601 - val_accuracy: 0.7375\n",
            "Epoch 396/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6755 - accuracy: 0.7551 - val_loss: 0.7471 - val_accuracy: 0.7267\n",
            "Epoch 397/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7052 - accuracy: 0.7469 - val_loss: 0.7980 - val_accuracy: 0.7308\n",
            "Epoch 398/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7216 - accuracy: 0.7419 - val_loss: 0.7545 - val_accuracy: 0.7392\n",
            "Epoch 399/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7002 - accuracy: 0.7395 - val_loss: 0.7633 - val_accuracy: 0.7442\n",
            "Epoch 400/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6959 - accuracy: 0.7515 - val_loss: 0.7450 - val_accuracy: 0.7558\n",
            "Epoch 401/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6838 - accuracy: 0.7598 - val_loss: 0.7614 - val_accuracy: 0.7308\n",
            "Epoch 402/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6723 - accuracy: 0.7541 - val_loss: 0.7720 - val_accuracy: 0.7183\n",
            "Epoch 403/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7076 - accuracy: 0.7316 - val_loss: 0.7765 - val_accuracy: 0.7275\n",
            "Epoch 404/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7075 - accuracy: 0.7456 - val_loss: 0.8465 - val_accuracy: 0.7083\n",
            "Epoch 405/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7206 - accuracy: 0.7438 - val_loss: 0.7439 - val_accuracy: 0.7450\n",
            "Epoch 406/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6913 - accuracy: 0.7575 - val_loss: 0.7578 - val_accuracy: 0.7258\n",
            "Epoch 407/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6936 - accuracy: 0.7529 - val_loss: 0.7546 - val_accuracy: 0.7392\n",
            "Epoch 408/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.6969 - accuracy: 0.7522 - val_loss: 0.7628 - val_accuracy: 0.7383\n",
            "Epoch 409/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7050 - accuracy: 0.7377 - val_loss: 0.7825 - val_accuracy: 0.7208\n",
            "Epoch 410/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7451 - accuracy: 0.7374 - val_loss: 0.7451 - val_accuracy: 0.7208\n",
            "Epoch 411/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6852 - accuracy: 0.7541 - val_loss: 0.7568 - val_accuracy: 0.7300\n",
            "Epoch 412/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6998 - accuracy: 0.7512 - val_loss: 0.7652 - val_accuracy: 0.7458\n",
            "Epoch 413/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7292 - accuracy: 0.7460 - val_loss: 0.7299 - val_accuracy: 0.7425\n",
            "Epoch 414/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7025 - accuracy: 0.7501 - val_loss: 0.7912 - val_accuracy: 0.7192\n",
            "Epoch 415/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7222 - accuracy: 0.7352 - val_loss: 0.8196 - val_accuracy: 0.7183\n",
            "Epoch 416/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7080 - accuracy: 0.7494 - val_loss: 0.7866 - val_accuracy: 0.7375\n",
            "Epoch 417/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6879 - accuracy: 0.7523 - val_loss: 0.7325 - val_accuracy: 0.7417\n",
            "Epoch 418/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6954 - accuracy: 0.7554 - val_loss: 0.7735 - val_accuracy: 0.7292\n",
            "Epoch 419/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7040 - accuracy: 0.7560 - val_loss: 0.7737 - val_accuracy: 0.7483\n",
            "Epoch 420/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7346 - accuracy: 0.7447 - val_loss: 0.7998 - val_accuracy: 0.7192\n",
            "Epoch 421/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7289 - accuracy: 0.7381 - val_loss: 0.8636 - val_accuracy: 0.7092\n",
            "Epoch 422/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8034 - accuracy: 0.7265 - val_loss: 0.7970 - val_accuracy: 0.7242\n",
            "Epoch 423/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6852 - accuracy: 0.7587 - val_loss: 0.7615 - val_accuracy: 0.7283\n",
            "Epoch 424/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6996 - accuracy: 0.7446 - val_loss: 0.7795 - val_accuracy: 0.7442\n",
            "Epoch 425/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.7583 - val_loss: 0.7641 - val_accuracy: 0.7358\n",
            "Epoch 426/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7188 - accuracy: 0.7496 - val_loss: 0.7938 - val_accuracy: 0.7208\n",
            "Epoch 427/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7358 - accuracy: 0.7434 - val_loss: 0.7364 - val_accuracy: 0.7450\n",
            "Epoch 428/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6808 - accuracy: 0.7578 - val_loss: 0.7336 - val_accuracy: 0.7292\n",
            "Epoch 429/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6940 - accuracy: 0.7597 - val_loss: 0.7528 - val_accuracy: 0.7492\n",
            "Epoch 430/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7040 - accuracy: 0.7368 - val_loss: 0.7486 - val_accuracy: 0.7392\n",
            "Epoch 431/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.7489 - val_loss: 0.7714 - val_accuracy: 0.7283\n",
            "Epoch 432/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6920 - accuracy: 0.7456 - val_loss: 0.7426 - val_accuracy: 0.7367\n",
            "Epoch 433/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6630 - accuracy: 0.7619 - val_loss: 0.7514 - val_accuracy: 0.7350\n",
            "Epoch 434/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6832 - accuracy: 0.7294 - val_loss: 0.7422 - val_accuracy: 0.7533\n",
            "Epoch 435/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7072 - accuracy: 0.7397 - val_loss: 0.7489 - val_accuracy: 0.7358\n",
            "Epoch 436/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6900 - accuracy: 0.7658 - val_loss: 0.7450 - val_accuracy: 0.7458\n",
            "Epoch 437/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7004 - accuracy: 0.7548 - val_loss: 0.7601 - val_accuracy: 0.7367\n",
            "Epoch 438/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6671 - accuracy: 0.7574 - val_loss: 0.7343 - val_accuracy: 0.7292\n",
            "Epoch 439/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6755 - accuracy: 0.7554 - val_loss: 0.7439 - val_accuracy: 0.7483\n",
            "Epoch 440/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6853 - accuracy: 0.7557 - val_loss: 0.7696 - val_accuracy: 0.7400\n",
            "Epoch 441/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7035 - accuracy: 0.7511 - val_loss: 0.7689 - val_accuracy: 0.7467\n",
            "Epoch 442/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7248 - accuracy: 0.7376 - val_loss: 0.7582 - val_accuracy: 0.7283\n",
            "Epoch 443/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7246 - accuracy: 0.7292 - val_loss: 0.7637 - val_accuracy: 0.7417\n",
            "Epoch 444/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6876 - accuracy: 0.7458 - val_loss: 0.7800 - val_accuracy: 0.7375\n",
            "Epoch 445/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6880 - accuracy: 0.7488 - val_loss: 0.7269 - val_accuracy: 0.7492\n",
            "Epoch 446/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7063 - accuracy: 0.7488 - val_loss: 0.7693 - val_accuracy: 0.7325\n",
            "Epoch 447/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6871 - accuracy: 0.7547 - val_loss: 0.7204 - val_accuracy: 0.7467\n",
            "Epoch 448/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7156 - accuracy: 0.7373 - val_loss: 0.7591 - val_accuracy: 0.7417\n",
            "Epoch 449/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7272 - accuracy: 0.7316 - val_loss: 0.7526 - val_accuracy: 0.7442\n",
            "Epoch 450/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6579 - accuracy: 0.7671 - val_loss: 0.7380 - val_accuracy: 0.7408\n",
            "Epoch 451/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6831 - accuracy: 0.7564 - val_loss: 0.7486 - val_accuracy: 0.7250\n",
            "Epoch 452/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6801 - accuracy: 0.7596 - val_loss: 0.7517 - val_accuracy: 0.7408\n",
            "Epoch 453/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7107 - accuracy: 0.7493 - val_loss: 0.7574 - val_accuracy: 0.7150\n",
            "Epoch 454/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6880 - accuracy: 0.7539 - val_loss: 0.7458 - val_accuracy: 0.7225\n",
            "Epoch 455/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6871 - accuracy: 0.7593 - val_loss: 0.7960 - val_accuracy: 0.7208\n",
            "Epoch 456/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6983 - accuracy: 0.7531 - val_loss: 0.7177 - val_accuracy: 0.7592\n",
            "Epoch 457/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.7537 - val_loss: 0.7221 - val_accuracy: 0.7550\n",
            "Epoch 458/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6745 - accuracy: 0.7620 - val_loss: 0.7452 - val_accuracy: 0.7442\n",
            "Epoch 459/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6971 - accuracy: 0.7514 - val_loss: 0.7829 - val_accuracy: 0.7350\n",
            "Epoch 460/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7127 - accuracy: 0.7452 - val_loss: 0.7562 - val_accuracy: 0.7358\n",
            "Epoch 461/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6838 - accuracy: 0.7458 - val_loss: 0.7460 - val_accuracy: 0.7233\n",
            "Epoch 462/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6627 - accuracy: 0.7661 - val_loss: 0.7429 - val_accuracy: 0.7358\n",
            "Epoch 463/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6866 - accuracy: 0.7545 - val_loss: 0.7552 - val_accuracy: 0.7492\n",
            "Epoch 464/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6784 - accuracy: 0.7632 - val_loss: 0.7917 - val_accuracy: 0.7342\n",
            "Epoch 465/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6973 - accuracy: 0.7520 - val_loss: 0.7689 - val_accuracy: 0.7292\n",
            "Epoch 466/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.6955 - accuracy: 0.7626 - val_loss: 0.7553 - val_accuracy: 0.7392\n",
            "Epoch 467/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.7608 - val_loss: 0.7685 - val_accuracy: 0.7492\n",
            "Epoch 468/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6624 - accuracy: 0.7697 - val_loss: 0.7394 - val_accuracy: 0.7475\n",
            "Epoch 469/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6728 - accuracy: 0.7570 - val_loss: 0.7570 - val_accuracy: 0.7342\n",
            "Epoch 470/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6826 - accuracy: 0.7510 - val_loss: 0.7280 - val_accuracy: 0.7467\n",
            "Epoch 471/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7072 - accuracy: 0.7391 - val_loss: 0.7266 - val_accuracy: 0.7375\n",
            "Epoch 472/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6940 - accuracy: 0.7516 - val_loss: 0.7476 - val_accuracy: 0.7400\n",
            "Epoch 473/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6570 - accuracy: 0.7642 - val_loss: 0.7258 - val_accuracy: 0.7467\n",
            "Epoch 474/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6687 - accuracy: 0.7669 - val_loss: 0.7409 - val_accuracy: 0.7417\n",
            "Epoch 475/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6567 - accuracy: 0.7666 - val_loss: 0.7329 - val_accuracy: 0.7508\n",
            "Epoch 476/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6759 - accuracy: 0.7617 - val_loss: 0.7541 - val_accuracy: 0.7350\n",
            "Epoch 477/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6830 - accuracy: 0.7601 - val_loss: 0.7952 - val_accuracy: 0.7175\n",
            "Epoch 478/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6744 - accuracy: 0.7598 - val_loss: 0.7440 - val_accuracy: 0.7467\n",
            "Epoch 479/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6844 - accuracy: 0.7538 - val_loss: 0.7322 - val_accuracy: 0.7475\n",
            "Epoch 480/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6620 - accuracy: 0.7587 - val_loss: 0.7469 - val_accuracy: 0.7217\n",
            "Epoch 481/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6743 - accuracy: 0.7561 - val_loss: 0.7961 - val_accuracy: 0.7417\n",
            "Epoch 482/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6959 - accuracy: 0.7492 - val_loss: 0.7689 - val_accuracy: 0.7417\n",
            "Epoch 483/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6733 - accuracy: 0.7560 - val_loss: 0.7554 - val_accuracy: 0.7292\n",
            "Epoch 484/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6670 - accuracy: 0.7567 - val_loss: 0.7211 - val_accuracy: 0.7500\n",
            "Epoch 485/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6692 - accuracy: 0.7651 - val_loss: 0.7509 - val_accuracy: 0.7425\n",
            "Epoch 486/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6660 - accuracy: 0.7661 - val_loss: 0.7223 - val_accuracy: 0.7483\n",
            "Epoch 487/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6724 - accuracy: 0.7640 - val_loss: 0.7499 - val_accuracy: 0.7392\n",
            "Epoch 488/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6627 - accuracy: 0.7582 - val_loss: 0.7431 - val_accuracy: 0.7400\n",
            "Epoch 489/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6839 - accuracy: 0.7594 - val_loss: 0.7998 - val_accuracy: 0.7283\n",
            "Epoch 490/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6984 - accuracy: 0.7580 - val_loss: 0.7767 - val_accuracy: 0.7333\n",
            "Epoch 491/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7010 - accuracy: 0.7425 - val_loss: 0.7495 - val_accuracy: 0.7408\n",
            "Epoch 492/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7055 - accuracy: 0.7376 - val_loss: 0.7302 - val_accuracy: 0.7767\n",
            "Epoch 493/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6608 - accuracy: 0.7685 - val_loss: 0.7849 - val_accuracy: 0.7392\n",
            "Epoch 494/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6804 - accuracy: 0.7580 - val_loss: 0.7601 - val_accuracy: 0.7392\n",
            "Epoch 495/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7082 - accuracy: 0.7435 - val_loss: 0.7604 - val_accuracy: 0.7350\n",
            "Epoch 496/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6844 - accuracy: 0.7485 - val_loss: 0.7602 - val_accuracy: 0.7225\n",
            "Epoch 497/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6841 - accuracy: 0.7472 - val_loss: 0.7464 - val_accuracy: 0.7367\n",
            "Epoch 498/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.7511 - val_loss: 0.7435 - val_accuracy: 0.7483\n",
            "Epoch 499/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6484 - accuracy: 0.7688 - val_loss: 0.7588 - val_accuracy: 0.7558\n",
            "Epoch 500/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7131 - accuracy: 0.7424 - val_loss: 0.7702 - val_accuracy: 0.7167\n",
            "Epoch 501/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7165 - accuracy: 0.7378 - val_loss: 0.7467 - val_accuracy: 0.7367\n",
            "Epoch 502/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7085 - accuracy: 0.7466 - val_loss: 0.7364 - val_accuracy: 0.7408\n",
            "Epoch 503/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6682 - accuracy: 0.7591 - val_loss: 0.7402 - val_accuracy: 0.7475\n",
            "Epoch 504/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6830 - accuracy: 0.7586 - val_loss: 0.7424 - val_accuracy: 0.7325\n",
            "Epoch 505/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6885 - accuracy: 0.7508 - val_loss: 0.7418 - val_accuracy: 0.7367\n",
            "Epoch 506/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6491 - accuracy: 0.7684 - val_loss: 0.7320 - val_accuracy: 0.7400\n",
            "Epoch 507/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6536 - accuracy: 0.7650 - val_loss: 0.7514 - val_accuracy: 0.7367\n",
            "Epoch 508/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6511 - accuracy: 0.7666 - val_loss: 0.7502 - val_accuracy: 0.7517\n",
            "Epoch 509/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6653 - accuracy: 0.7721 - val_loss: 0.7448 - val_accuracy: 0.7342\n",
            "Epoch 510/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6739 - accuracy: 0.7507 - val_loss: 0.7234 - val_accuracy: 0.7542\n",
            "Epoch 511/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6509 - accuracy: 0.7743 - val_loss: 0.7156 - val_accuracy: 0.7433\n",
            "Epoch 512/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6497 - accuracy: 0.7667 - val_loss: 0.7543 - val_accuracy: 0.7350\n",
            "Epoch 513/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6960 - accuracy: 0.7446 - val_loss: 0.7479 - val_accuracy: 0.7458\n",
            "Epoch 514/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6719 - accuracy: 0.7606 - val_loss: 0.7485 - val_accuracy: 0.7333\n",
            "Epoch 515/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.7460 - val_loss: 0.7524 - val_accuracy: 0.7483\n",
            "Epoch 516/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6888 - accuracy: 0.7506 - val_loss: 0.7758 - val_accuracy: 0.7242\n",
            "Epoch 517/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6731 - accuracy: 0.7541 - val_loss: 0.7336 - val_accuracy: 0.7433\n",
            "Epoch 518/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6909 - accuracy: 0.7525 - val_loss: 0.7965 - val_accuracy: 0.7400\n",
            "Epoch 519/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6583 - accuracy: 0.7649 - val_loss: 0.7846 - val_accuracy: 0.7358\n",
            "Epoch 520/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6598 - accuracy: 0.7631 - val_loss: 0.7354 - val_accuracy: 0.7483\n",
            "Epoch 521/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7095 - accuracy: 0.7377 - val_loss: 0.7332 - val_accuracy: 0.7425\n",
            "Epoch 522/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6826 - accuracy: 0.7547 - val_loss: 0.7436 - val_accuracy: 0.7292\n",
            "Epoch 523/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6715 - accuracy: 0.7529 - val_loss: 0.7434 - val_accuracy: 0.7350\n",
            "Epoch 524/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6735 - accuracy: 0.7601 - val_loss: 0.7474 - val_accuracy: 0.7583\n",
            "Epoch 525/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6627 - accuracy: 0.7663 - val_loss: 0.7746 - val_accuracy: 0.7192\n",
            "Epoch 526/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6682 - accuracy: 0.7604 - val_loss: 0.7506 - val_accuracy: 0.7600\n",
            "Epoch 527/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6580 - accuracy: 0.7616 - val_loss: 0.7801 - val_accuracy: 0.7217\n",
            "Epoch 528/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6881 - accuracy: 0.7491 - val_loss: 0.7374 - val_accuracy: 0.7317\n",
            "Epoch 529/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6673 - accuracy: 0.7550 - val_loss: 0.7196 - val_accuracy: 0.7617\n",
            "Epoch 530/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6385 - accuracy: 0.7769 - val_loss: 0.7474 - val_accuracy: 0.7342\n",
            "Epoch 531/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6560 - accuracy: 0.7638 - val_loss: 0.7435 - val_accuracy: 0.7500\n",
            "Epoch 532/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6560 - accuracy: 0.7586 - val_loss: 0.7406 - val_accuracy: 0.7492\n",
            "Epoch 533/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.6580 - accuracy: 0.7668 - val_loss: 0.7172 - val_accuracy: 0.7542\n",
            "Epoch 534/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6728 - accuracy: 0.7554 - val_loss: 0.7121 - val_accuracy: 0.7583\n",
            "Epoch 535/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6540 - accuracy: 0.7702 - val_loss: 0.7610 - val_accuracy: 0.7450\n",
            "Epoch 536/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7166 - accuracy: 0.7435 - val_loss: 0.8986 - val_accuracy: 0.7283\n",
            "Epoch 537/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6980 - accuracy: 0.7503 - val_loss: 0.7537 - val_accuracy: 0.7483\n",
            "Epoch 538/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6779 - accuracy: 0.7594 - val_loss: 0.7822 - val_accuracy: 0.7358\n",
            "Epoch 539/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6730 - accuracy: 0.7596 - val_loss: 0.7267 - val_accuracy: 0.7542\n",
            "Epoch 540/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6448 - accuracy: 0.7702 - val_loss: 0.7185 - val_accuracy: 0.7558\n",
            "Epoch 541/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6649 - accuracy: 0.7616 - val_loss: 0.7952 - val_accuracy: 0.7350\n",
            "Epoch 542/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7050 - accuracy: 0.7413 - val_loss: 0.7147 - val_accuracy: 0.7517\n",
            "Epoch 543/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6659 - accuracy: 0.7655 - val_loss: 0.7759 - val_accuracy: 0.7558\n",
            "Epoch 544/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6848 - accuracy: 0.7533 - val_loss: 0.7265 - val_accuracy: 0.7400\n",
            "Epoch 545/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6759 - accuracy: 0.7654 - val_loss: 0.7178 - val_accuracy: 0.7475\n",
            "Epoch 546/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6629 - accuracy: 0.7578 - val_loss: 0.7170 - val_accuracy: 0.7600\n",
            "Epoch 547/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6624 - accuracy: 0.7618 - val_loss: 0.7144 - val_accuracy: 0.7600\n",
            "Epoch 548/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6290 - accuracy: 0.7759 - val_loss: 0.7257 - val_accuracy: 0.7408\n",
            "Epoch 549/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6594 - accuracy: 0.7768 - val_loss: 0.7955 - val_accuracy: 0.7433\n",
            "Epoch 550/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6888 - accuracy: 0.7531 - val_loss: 0.7710 - val_accuracy: 0.7567\n",
            "Epoch 551/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6840 - accuracy: 0.7582 - val_loss: 0.7811 - val_accuracy: 0.7383\n",
            "Epoch 552/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6364 - accuracy: 0.7674 - val_loss: 0.7439 - val_accuracy: 0.7367\n",
            "Epoch 553/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6777 - accuracy: 0.7589 - val_loss: 0.7645 - val_accuracy: 0.7275\n",
            "Epoch 554/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6864 - accuracy: 0.7549 - val_loss: 0.7168 - val_accuracy: 0.7358\n",
            "Epoch 555/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6490 - accuracy: 0.7655 - val_loss: 0.7338 - val_accuracy: 0.7558\n",
            "Epoch 556/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.7705 - val_loss: 0.7349 - val_accuracy: 0.7358\n",
            "Epoch 557/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6572 - accuracy: 0.7601 - val_loss: 0.7555 - val_accuracy: 0.7458\n",
            "Epoch 558/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6639 - accuracy: 0.7581 - val_loss: 0.7924 - val_accuracy: 0.7133\n",
            "Epoch 559/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6652 - accuracy: 0.7602 - val_loss: 0.7282 - val_accuracy: 0.7550\n",
            "Epoch 560/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6426 - accuracy: 0.7658 - val_loss: 0.7232 - val_accuracy: 0.7567\n",
            "Epoch 561/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6559 - accuracy: 0.7691 - val_loss: 0.7028 - val_accuracy: 0.7558\n",
            "Epoch 562/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6352 - accuracy: 0.7712 - val_loss: 0.7323 - val_accuracy: 0.7467\n",
            "Epoch 563/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6826 - accuracy: 0.7483 - val_loss: 0.7493 - val_accuracy: 0.7392\n",
            "Epoch 564/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6764 - accuracy: 0.7622 - val_loss: 0.7191 - val_accuracy: 0.7333\n",
            "Epoch 565/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6294 - accuracy: 0.7738 - val_loss: 0.7324 - val_accuracy: 0.7458\n",
            "Epoch 566/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6342 - accuracy: 0.7749 - val_loss: 0.7571 - val_accuracy: 0.7383\n",
            "Epoch 567/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6510 - accuracy: 0.7597 - val_loss: 0.7404 - val_accuracy: 0.7467\n",
            "Epoch 568/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6473 - accuracy: 0.7699 - val_loss: 0.7028 - val_accuracy: 0.7575\n",
            "Epoch 569/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6577 - accuracy: 0.7608 - val_loss: 0.7166 - val_accuracy: 0.7517\n",
            "Epoch 570/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6572 - accuracy: 0.7657 - val_loss: 0.7166 - val_accuracy: 0.7692\n",
            "Epoch 571/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6391 - accuracy: 0.7719 - val_loss: 0.7200 - val_accuracy: 0.7500\n",
            "Epoch 572/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6449 - accuracy: 0.7643 - val_loss: 0.7473 - val_accuracy: 0.7250\n",
            "Epoch 573/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6819 - accuracy: 0.7640 - val_loss: 0.7679 - val_accuracy: 0.7333\n",
            "Epoch 574/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6654 - accuracy: 0.7721 - val_loss: 0.7140 - val_accuracy: 0.7550\n",
            "Epoch 575/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6696 - accuracy: 0.7608 - val_loss: 0.7203 - val_accuracy: 0.7517\n",
            "Epoch 576/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6684 - accuracy: 0.7653 - val_loss: 0.7532 - val_accuracy: 0.7425\n",
            "Epoch 577/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6500 - accuracy: 0.7583 - val_loss: 0.7319 - val_accuracy: 0.7475\n",
            "Epoch 578/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6914 - accuracy: 0.7482 - val_loss: 0.7485 - val_accuracy: 0.7317\n",
            "Epoch 579/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6606 - accuracy: 0.7727 - val_loss: 0.7318 - val_accuracy: 0.7617\n",
            "Epoch 580/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6588 - accuracy: 0.7654 - val_loss: 0.6922 - val_accuracy: 0.7533\n",
            "Epoch 581/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6485 - accuracy: 0.7639 - val_loss: 0.7501 - val_accuracy: 0.7200\n",
            "Epoch 582/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6690 - accuracy: 0.7562 - val_loss: 0.7503 - val_accuracy: 0.7525\n",
            "Epoch 583/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6592 - accuracy: 0.7651 - val_loss: 0.7207 - val_accuracy: 0.7592\n",
            "Epoch 584/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6723 - accuracy: 0.7648 - val_loss: 0.7196 - val_accuracy: 0.7425\n",
            "Epoch 585/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6364 - accuracy: 0.7669 - val_loss: 0.7316 - val_accuracy: 0.7533\n",
            "Epoch 586/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6559 - accuracy: 0.7707 - val_loss: 0.7118 - val_accuracy: 0.7567\n",
            "Epoch 587/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6680 - accuracy: 0.7540 - val_loss: 0.7122 - val_accuracy: 0.7467\n",
            "Epoch 588/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6304 - accuracy: 0.7728 - val_loss: 0.7301 - val_accuracy: 0.7525\n",
            "Epoch 589/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.6904 - accuracy: 0.7491 - val_loss: 0.7267 - val_accuracy: 0.7392\n",
            "Epoch 590/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6572 - accuracy: 0.7729 - val_loss: 0.7459 - val_accuracy: 0.7500\n",
            "Epoch 591/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6738 - accuracy: 0.7618 - val_loss: 0.7388 - val_accuracy: 0.7517\n",
            "Epoch 592/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6583 - accuracy: 0.7699 - val_loss: 0.7340 - val_accuracy: 0.7483\n",
            "Epoch 593/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6462 - accuracy: 0.7705 - val_loss: 0.7425 - val_accuracy: 0.7342\n",
            "Epoch 594/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6506 - accuracy: 0.7691 - val_loss: 0.7336 - val_accuracy: 0.7542\n",
            "Epoch 595/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6364 - accuracy: 0.7705 - val_loss: 0.7143 - val_accuracy: 0.7542\n",
            "Epoch 596/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6512 - accuracy: 0.7653 - val_loss: 0.7130 - val_accuracy: 0.7267\n",
            "Epoch 597/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6829 - accuracy: 0.7447 - val_loss: 0.7359 - val_accuracy: 0.7375\n",
            "Epoch 598/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6374 - accuracy: 0.7693 - val_loss: 0.7075 - val_accuracy: 0.7550\n",
            "Epoch 599/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6465 - accuracy: 0.7741 - val_loss: 0.7142 - val_accuracy: 0.7533\n",
            "Epoch 600/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6668 - accuracy: 0.7603 - val_loss: 0.7205 - val_accuracy: 0.7642\n",
            "Epoch 601/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6417 - accuracy: 0.7742 - val_loss: 0.7153 - val_accuracy: 0.7575\n",
            "Epoch 602/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6177 - accuracy: 0.7830 - val_loss: 0.7419 - val_accuracy: 0.7442\n",
            "Epoch 603/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6700 - accuracy: 0.7637 - val_loss: 0.7369 - val_accuracy: 0.7525\n",
            "Epoch 604/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6561 - accuracy: 0.7741 - val_loss: 0.7230 - val_accuracy: 0.7542\n",
            "Epoch 605/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6437 - accuracy: 0.7628 - val_loss: 0.7236 - val_accuracy: 0.7442\n",
            "Epoch 606/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6550 - accuracy: 0.7638 - val_loss: 0.7111 - val_accuracy: 0.7492\n",
            "Epoch 607/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6270 - accuracy: 0.7821 - val_loss: 0.7457 - val_accuracy: 0.7483\n",
            "Epoch 608/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6552 - accuracy: 0.7692 - val_loss: 0.7278 - val_accuracy: 0.7392\n",
            "Epoch 609/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6483 - accuracy: 0.7739 - val_loss: 0.7113 - val_accuracy: 0.7575\n",
            "Epoch 610/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6474 - accuracy: 0.7675 - val_loss: 0.7257 - val_accuracy: 0.7483\n",
            "Epoch 611/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6624 - accuracy: 0.7692 - val_loss: 0.7043 - val_accuracy: 0.7683\n",
            "Epoch 612/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6602 - accuracy: 0.7640 - val_loss: 0.7077 - val_accuracy: 0.7483\n",
            "Epoch 613/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6484 - accuracy: 0.7571 - val_loss: 0.7449 - val_accuracy: 0.7567\n",
            "Epoch 614/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6325 - accuracy: 0.7786 - val_loss: 0.7563 - val_accuracy: 0.7400\n",
            "Epoch 615/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6544 - accuracy: 0.7614 - val_loss: 0.7079 - val_accuracy: 0.7375\n",
            "Epoch 616/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6377 - accuracy: 0.7717 - val_loss: 0.7186 - val_accuracy: 0.7350\n",
            "Epoch 617/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6246 - accuracy: 0.7745 - val_loss: 0.7230 - val_accuracy: 0.7533\n",
            "Epoch 618/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6488 - accuracy: 0.7706 - val_loss: 0.7143 - val_accuracy: 0.7592\n",
            "Epoch 619/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6646 - accuracy: 0.7698 - val_loss: 0.7226 - val_accuracy: 0.7425\n",
            "Epoch 620/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6368 - accuracy: 0.7676 - val_loss: 0.7521 - val_accuracy: 0.7483\n",
            "Epoch 621/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6373 - accuracy: 0.7707 - val_loss: 0.7516 - val_accuracy: 0.7325\n",
            "Epoch 622/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6535 - accuracy: 0.7552 - val_loss: 0.7308 - val_accuracy: 0.7558\n",
            "Epoch 623/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6468 - accuracy: 0.7675 - val_loss: 0.7109 - val_accuracy: 0.7517\n",
            "Epoch 624/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6579 - accuracy: 0.7586 - val_loss: 0.7654 - val_accuracy: 0.7300\n",
            "Epoch 625/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6587 - accuracy: 0.7527 - val_loss: 0.7235 - val_accuracy: 0.7500\n",
            "Epoch 626/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6173 - accuracy: 0.7863 - val_loss: 0.6712 - val_accuracy: 0.7575\n",
            "Epoch 627/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6360 - accuracy: 0.7728 - val_loss: 0.7427 - val_accuracy: 0.7500\n",
            "Epoch 628/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6422 - accuracy: 0.7677 - val_loss: 0.7115 - val_accuracy: 0.7467\n",
            "Epoch 629/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6556 - accuracy: 0.7680 - val_loss: 0.7232 - val_accuracy: 0.7458\n",
            "Epoch 630/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6682 - accuracy: 0.7633 - val_loss: 0.6874 - val_accuracy: 0.7625\n",
            "Epoch 631/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6481 - accuracy: 0.7604 - val_loss: 0.7602 - val_accuracy: 0.7292\n",
            "Epoch 632/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6463 - accuracy: 0.7610 - val_loss: 0.7085 - val_accuracy: 0.7483\n",
            "Epoch 633/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6576 - accuracy: 0.7693 - val_loss: 0.7288 - val_accuracy: 0.7517\n",
            "Epoch 634/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6257 - accuracy: 0.7697 - val_loss: 0.7069 - val_accuracy: 0.7600\n",
            "Epoch 635/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6636 - accuracy: 0.7617 - val_loss: 0.7437 - val_accuracy: 0.7217\n",
            "Epoch 636/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6677 - accuracy: 0.7665 - val_loss: 0.7678 - val_accuracy: 0.7592\n",
            "Epoch 637/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6619 - accuracy: 0.7727 - val_loss: 0.6988 - val_accuracy: 0.7642\n",
            "Epoch 638/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6591 - accuracy: 0.7839 - val_loss: 0.7579 - val_accuracy: 0.7475\n",
            "Epoch 639/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6447 - accuracy: 0.7614 - val_loss: 0.7135 - val_accuracy: 0.7525\n",
            "Epoch 640/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6327 - accuracy: 0.7734 - val_loss: 0.7205 - val_accuracy: 0.7425\n",
            "Epoch 641/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6385 - accuracy: 0.7668 - val_loss: 0.7197 - val_accuracy: 0.7533\n",
            "Epoch 642/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6599 - accuracy: 0.7703 - val_loss: 0.7289 - val_accuracy: 0.7383\n",
            "Epoch 643/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6425 - accuracy: 0.7668 - val_loss: 0.7035 - val_accuracy: 0.7758\n",
            "Epoch 644/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6530 - accuracy: 0.7543 - val_loss: 0.7357 - val_accuracy: 0.7350\n",
            "Epoch 645/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6656 - accuracy: 0.7585 - val_loss: 0.6970 - val_accuracy: 0.7483\n",
            "Epoch 646/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6471 - accuracy: 0.7740 - val_loss: 0.7137 - val_accuracy: 0.7642\n",
            "Epoch 647/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6592 - accuracy: 0.7578 - val_loss: 0.7470 - val_accuracy: 0.7400\n",
            "Epoch 648/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6311 - accuracy: 0.7699 - val_loss: 0.7189 - val_accuracy: 0.7492\n",
            "Epoch 649/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6212 - accuracy: 0.7757 - val_loss: 0.7051 - val_accuracy: 0.7508\n",
            "Epoch 650/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6531 - accuracy: 0.7601 - val_loss: 0.7056 - val_accuracy: 0.7625\n",
            "Epoch 651/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6386 - accuracy: 0.7788 - val_loss: 0.7438 - val_accuracy: 0.7542\n",
            "Epoch 652/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6554 - accuracy: 0.7612 - val_loss: 0.7268 - val_accuracy: 0.7242\n",
            "Epoch 653/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6230 - accuracy: 0.7677 - val_loss: 0.7547 - val_accuracy: 0.7325\n",
            "Epoch 654/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6680 - accuracy: 0.7598 - val_loss: 0.6900 - val_accuracy: 0.7667\n",
            "Epoch 655/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6438 - accuracy: 0.7637 - val_loss: 0.6892 - val_accuracy: 0.7600\n",
            "Epoch 656/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6275 - accuracy: 0.7741 - val_loss: 0.7359 - val_accuracy: 0.7383\n",
            "Epoch 657/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.6604 - accuracy: 0.7656 - val_loss: 0.7227 - val_accuracy: 0.7517\n",
            "Epoch 658/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6414 - accuracy: 0.7681 - val_loss: 0.7225 - val_accuracy: 0.7483\n",
            "Epoch 659/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6588 - accuracy: 0.7572 - val_loss: 0.7084 - val_accuracy: 0.7667\n",
            "Epoch 660/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6359 - accuracy: 0.7783 - val_loss: 0.6994 - val_accuracy: 0.7583\n",
            "Epoch 661/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6359 - accuracy: 0.7820 - val_loss: 0.7325 - val_accuracy: 0.7300\n",
            "Epoch 662/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6626 - accuracy: 0.7665 - val_loss: 0.7169 - val_accuracy: 0.7592\n",
            "Epoch 663/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6276 - accuracy: 0.7869 - val_loss: 0.7579 - val_accuracy: 0.7450\n",
            "Epoch 664/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6521 - accuracy: 0.7711 - val_loss: 0.7261 - val_accuracy: 0.7517\n",
            "Epoch 665/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6432 - accuracy: 0.7707 - val_loss: 0.7391 - val_accuracy: 0.7483\n",
            "Epoch 666/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6371 - accuracy: 0.7678 - val_loss: 0.7710 - val_accuracy: 0.7417\n",
            "Epoch 667/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6506 - accuracy: 0.7632 - val_loss: 0.7285 - val_accuracy: 0.7558\n",
            "Epoch 668/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6335 - accuracy: 0.7666 - val_loss: 0.7236 - val_accuracy: 0.7325\n",
            "Epoch 669/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6569 - accuracy: 0.7629 - val_loss: 0.7306 - val_accuracy: 0.7525\n",
            "Epoch 670/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6104 - accuracy: 0.7758 - val_loss: 0.7521 - val_accuracy: 0.7333\n",
            "Epoch 671/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6296 - accuracy: 0.7760 - val_loss: 0.7013 - val_accuracy: 0.7625\n",
            "Epoch 672/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6324 - accuracy: 0.7745 - val_loss: 0.6832 - val_accuracy: 0.7600\n",
            "Epoch 673/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6476 - accuracy: 0.7638 - val_loss: 0.7289 - val_accuracy: 0.7492\n",
            "Epoch 674/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6262 - accuracy: 0.7724 - val_loss: 0.7029 - val_accuracy: 0.7567\n",
            "Epoch 675/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6423 - accuracy: 0.7720 - val_loss: 0.7458 - val_accuracy: 0.7558\n",
            "Epoch 676/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6335 - accuracy: 0.7624 - val_loss: 0.7162 - val_accuracy: 0.7592\n",
            "Epoch 677/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6298 - accuracy: 0.7787 - val_loss: 0.7887 - val_accuracy: 0.7442\n",
            "Epoch 678/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6480 - accuracy: 0.7771 - val_loss: 0.7328 - val_accuracy: 0.7525\n",
            "Epoch 679/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6017 - accuracy: 0.7900 - val_loss: 0.7224 - val_accuracy: 0.7617\n",
            "Epoch 680/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6322 - accuracy: 0.7652 - val_loss: 0.6900 - val_accuracy: 0.7658\n",
            "Epoch 681/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6353 - accuracy: 0.7714 - val_loss: 0.7047 - val_accuracy: 0.7542\n",
            "Epoch 682/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6653 - accuracy: 0.7664 - val_loss: 0.7041 - val_accuracy: 0.7542\n",
            "Epoch 683/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6323 - accuracy: 0.7734 - val_loss: 0.7056 - val_accuracy: 0.7450\n",
            "Epoch 684/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6322 - accuracy: 0.7699 - val_loss: 0.7040 - val_accuracy: 0.7592\n",
            "Epoch 685/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6360 - accuracy: 0.7721 - val_loss: 0.7305 - val_accuracy: 0.7483\n",
            "Epoch 686/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6247 - accuracy: 0.7741 - val_loss: 0.7032 - val_accuracy: 0.7617\n",
            "Epoch 687/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6295 - accuracy: 0.7752 - val_loss: 0.6925 - val_accuracy: 0.7608\n",
            "Epoch 688/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6159 - accuracy: 0.7727 - val_loss: 0.7221 - val_accuracy: 0.7517\n",
            "Epoch 689/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6394 - accuracy: 0.7676 - val_loss: 0.7381 - val_accuracy: 0.7333\n",
            "Epoch 690/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6275 - accuracy: 0.7649 - val_loss: 0.7174 - val_accuracy: 0.7600\n",
            "Epoch 691/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6469 - accuracy: 0.7684 - val_loss: 0.7093 - val_accuracy: 0.7608\n",
            "Epoch 692/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6287 - accuracy: 0.7716 - val_loss: 0.7354 - val_accuracy: 0.7417\n",
            "Epoch 693/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6538 - accuracy: 0.7585 - val_loss: 0.6882 - val_accuracy: 0.7592\n",
            "Epoch 694/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6215 - accuracy: 0.7797 - val_loss: 0.7770 - val_accuracy: 0.7350\n",
            "Epoch 695/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6430 - accuracy: 0.7759 - val_loss: 0.7128 - val_accuracy: 0.7525\n",
            "Epoch 696/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6330 - accuracy: 0.7658 - val_loss: 0.7234 - val_accuracy: 0.7633\n",
            "Epoch 697/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6440 - accuracy: 0.7718 - val_loss: 0.6879 - val_accuracy: 0.7742\n",
            "Epoch 698/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6422 - accuracy: 0.7736 - val_loss: 0.7108 - val_accuracy: 0.7692\n",
            "Epoch 699/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6390 - accuracy: 0.7697 - val_loss: 0.7607 - val_accuracy: 0.7383\n",
            "Epoch 700/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6253 - accuracy: 0.7792 - val_loss: 0.7425 - val_accuracy: 0.7542\n",
            "Epoch 701/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6287 - accuracy: 0.7743 - val_loss: 0.7407 - val_accuracy: 0.7417\n",
            "Epoch 702/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6204 - accuracy: 0.7668 - val_loss: 0.7185 - val_accuracy: 0.7383\n",
            "Epoch 703/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6073 - accuracy: 0.7890 - val_loss: 0.6935 - val_accuracy: 0.7558\n",
            "Epoch 704/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6435 - accuracy: 0.7576 - val_loss: 0.7296 - val_accuracy: 0.7400\n",
            "Epoch 705/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6390 - accuracy: 0.7719 - val_loss: 0.7382 - val_accuracy: 0.7317\n",
            "Epoch 706/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6476 - accuracy: 0.7711 - val_loss: 0.7059 - val_accuracy: 0.7625\n",
            "Epoch 707/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6393 - accuracy: 0.7624 - val_loss: 0.7397 - val_accuracy: 0.7383\n",
            "Epoch 708/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6123 - accuracy: 0.7807 - val_loss: 0.7013 - val_accuracy: 0.7692\n",
            "Epoch 709/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6454 - accuracy: 0.7732 - val_loss: 0.7447 - val_accuracy: 0.7425\n",
            "Epoch 710/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6349 - accuracy: 0.7696 - val_loss: 0.7372 - val_accuracy: 0.7592\n",
            "Epoch 711/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6390 - accuracy: 0.7609 - val_loss: 0.6841 - val_accuracy: 0.7675\n",
            "Epoch 712/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6018 - accuracy: 0.7840 - val_loss: 0.7116 - val_accuracy: 0.7567\n",
            "Epoch 713/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6256 - accuracy: 0.7774 - val_loss: 0.7558 - val_accuracy: 0.7442\n",
            "Epoch 714/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6831 - accuracy: 0.7467 - val_loss: 0.7140 - val_accuracy: 0.7467\n",
            "Epoch 715/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.6573 - accuracy: 0.7582 - val_loss: 0.7441 - val_accuracy: 0.7400\n",
            "Epoch 716/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6418 - accuracy: 0.7793 - val_loss: 0.7202 - val_accuracy: 0.7500\n",
            "Epoch 717/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6290 - accuracy: 0.7710 - val_loss: 0.7436 - val_accuracy: 0.7617\n",
            "Epoch 718/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6638 - accuracy: 0.7615 - val_loss: 0.6927 - val_accuracy: 0.7617\n",
            "Epoch 719/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6169 - accuracy: 0.7819 - val_loss: 0.7064 - val_accuracy: 0.7633\n",
            "Epoch 720/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6131 - accuracy: 0.7786 - val_loss: 0.7278 - val_accuracy: 0.7458\n",
            "Epoch 721/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6195 - accuracy: 0.7812 - val_loss: 0.7024 - val_accuracy: 0.7683\n",
            "Epoch 722/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6240 - accuracy: 0.7817 - val_loss: 0.7319 - val_accuracy: 0.7600\n",
            "Epoch 723/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6472 - accuracy: 0.7644 - val_loss: 0.7481 - val_accuracy: 0.7358\n",
            "Epoch 724/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6452 - accuracy: 0.7617 - val_loss: 0.6796 - val_accuracy: 0.7675\n",
            "Epoch 725/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6302 - accuracy: 0.7734 - val_loss: 0.7097 - val_accuracy: 0.7575\n",
            "Epoch 726/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5891 - accuracy: 0.7872 - val_loss: 0.7159 - val_accuracy: 0.7492\n",
            "Epoch 727/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6229 - accuracy: 0.7654 - val_loss: 0.7251 - val_accuracy: 0.7492\n",
            "Epoch 728/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6371 - accuracy: 0.7858 - val_loss: 0.6987 - val_accuracy: 0.7442\n",
            "Epoch 729/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6298 - accuracy: 0.7699 - val_loss: 0.7218 - val_accuracy: 0.7508\n",
            "Epoch 730/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6267 - accuracy: 0.7842 - val_loss: 0.6858 - val_accuracy: 0.7742\n",
            "Epoch 731/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6051 - accuracy: 0.7832 - val_loss: 0.7067 - val_accuracy: 0.7517\n",
            "Epoch 732/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6240 - accuracy: 0.7785 - val_loss: 0.7305 - val_accuracy: 0.7433\n",
            "Epoch 733/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6340 - accuracy: 0.7703 - val_loss: 0.7528 - val_accuracy: 0.7283\n",
            "Epoch 734/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6131 - accuracy: 0.7784 - val_loss: 0.6880 - val_accuracy: 0.7617\n",
            "Epoch 735/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6096 - accuracy: 0.7841 - val_loss: 0.7330 - val_accuracy: 0.7492\n",
            "Epoch 736/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6393 - accuracy: 0.7763 - val_loss: 0.7173 - val_accuracy: 0.7658\n",
            "Epoch 737/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6159 - accuracy: 0.7875 - val_loss: 0.7414 - val_accuracy: 0.7283\n",
            "Epoch 738/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6409 - accuracy: 0.7771 - val_loss: 0.7600 - val_accuracy: 0.7417\n",
            "Epoch 739/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6545 - accuracy: 0.7660 - val_loss: 0.7194 - val_accuracy: 0.7517\n",
            "Epoch 740/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6326 - accuracy: 0.7702 - val_loss: 0.7285 - val_accuracy: 0.7342\n",
            "Epoch 741/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6102 - accuracy: 0.7771 - val_loss: 0.7180 - val_accuracy: 0.7467\n",
            "Epoch 742/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6362 - accuracy: 0.7634 - val_loss: 0.7373 - val_accuracy: 0.7533\n",
            "Epoch 743/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6306 - accuracy: 0.7736 - val_loss: 0.7065 - val_accuracy: 0.7542\n",
            "Epoch 744/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6412 - accuracy: 0.7629 - val_loss: 0.7254 - val_accuracy: 0.7358\n",
            "Epoch 745/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6132 - accuracy: 0.7718 - val_loss: 0.7017 - val_accuracy: 0.7542\n",
            "Epoch 746/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5849 - accuracy: 0.7927 - val_loss: 0.7418 - val_accuracy: 0.7392\n",
            "Epoch 747/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6097 - accuracy: 0.7801 - val_loss: 0.7395 - val_accuracy: 0.7417\n",
            "Epoch 748/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6177 - accuracy: 0.7762 - val_loss: 0.7025 - val_accuracy: 0.7525\n",
            "Epoch 749/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6311 - accuracy: 0.7739 - val_loss: 0.7341 - val_accuracy: 0.7417\n",
            "Epoch 750/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6161 - accuracy: 0.7733 - val_loss: 0.7584 - val_accuracy: 0.7417\n",
            "Epoch 751/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6429 - accuracy: 0.7658 - val_loss: 0.7137 - val_accuracy: 0.7475\n",
            "Epoch 752/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6251 - accuracy: 0.7718 - val_loss: 0.7459 - val_accuracy: 0.7467\n",
            "Epoch 753/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6318 - accuracy: 0.7681 - val_loss: 0.7123 - val_accuracy: 0.7550\n",
            "Epoch 754/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6080 - accuracy: 0.7847 - val_loss: 0.7139 - val_accuracy: 0.7508\n",
            "Epoch 755/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6298 - accuracy: 0.7641 - val_loss: 0.7116 - val_accuracy: 0.7633\n",
            "Epoch 756/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6159 - accuracy: 0.7721 - val_loss: 0.7316 - val_accuracy: 0.7600\n",
            "Epoch 757/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6235 - accuracy: 0.7625 - val_loss: 0.7255 - val_accuracy: 0.7567\n",
            "Epoch 758/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6256 - accuracy: 0.7724 - val_loss: 0.7040 - val_accuracy: 0.7600\n",
            "Epoch 759/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6237 - accuracy: 0.7736 - val_loss: 0.7761 - val_accuracy: 0.7542\n",
            "Epoch 760/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6291 - accuracy: 0.7764 - val_loss: 0.7122 - val_accuracy: 0.7467\n",
            "Epoch 761/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6099 - accuracy: 0.7789 - val_loss: 0.7071 - val_accuracy: 0.7683\n",
            "Epoch 762/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6338 - accuracy: 0.7794 - val_loss: 0.7370 - val_accuracy: 0.7467\n",
            "Epoch 763/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6273 - accuracy: 0.7718 - val_loss: 0.7122 - val_accuracy: 0.7633\n",
            "Epoch 764/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6337 - accuracy: 0.7827 - val_loss: 0.7318 - val_accuracy: 0.7425\n",
            "Epoch 765/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6182 - accuracy: 0.7761 - val_loss: 0.7030 - val_accuracy: 0.7592\n",
            "Epoch 766/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6110 - accuracy: 0.7843 - val_loss: 0.7094 - val_accuracy: 0.7608\n",
            "Epoch 767/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6291 - accuracy: 0.7756 - val_loss: 0.7142 - val_accuracy: 0.7717\n",
            "Epoch 768/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6368 - accuracy: 0.7699 - val_loss: 0.6970 - val_accuracy: 0.7625\n",
            "Epoch 769/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6106 - accuracy: 0.7859 - val_loss: 0.7757 - val_accuracy: 0.7425\n",
            "Epoch 770/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6528 - accuracy: 0.7625 - val_loss: 0.6949 - val_accuracy: 0.7658\n",
            "Epoch 771/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5924 - accuracy: 0.7842 - val_loss: 0.7236 - val_accuracy: 0.7592\n",
            "Epoch 772/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6622 - accuracy: 0.7677 - val_loss: 0.7179 - val_accuracy: 0.7658\n",
            "Epoch 773/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6189 - accuracy: 0.7753 - val_loss: 0.7729 - val_accuracy: 0.7625\n",
            "Epoch 774/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6310 - accuracy: 0.7727 - val_loss: 0.7928 - val_accuracy: 0.7275\n",
            "Epoch 775/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6376 - accuracy: 0.7570 - val_loss: 0.6836 - val_accuracy: 0.7783\n",
            "Epoch 776/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6142 - accuracy: 0.7837 - val_loss: 0.7018 - val_accuracy: 0.7508\n",
            "Epoch 777/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5850 - accuracy: 0.7937 - val_loss: 0.7136 - val_accuracy: 0.7400\n",
            "Epoch 778/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6300 - accuracy: 0.7691 - val_loss: 0.6944 - val_accuracy: 0.7742\n",
            "Epoch 779/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6274 - accuracy: 0.7743 - val_loss: 0.6953 - val_accuracy: 0.7708\n",
            "Epoch 780/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6234 - accuracy: 0.7727 - val_loss: 0.6979 - val_accuracy: 0.7642\n",
            "Epoch 781/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6222 - accuracy: 0.7772 - val_loss: 0.7426 - val_accuracy: 0.7342\n",
            "Epoch 782/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6244 - accuracy: 0.7765 - val_loss: 0.7295 - val_accuracy: 0.7492\n",
            "Epoch 783/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.6358 - accuracy: 0.7686 - val_loss: 0.7001 - val_accuracy: 0.7625\n",
            "Epoch 784/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6410 - accuracy: 0.7633 - val_loss: 0.7227 - val_accuracy: 0.7625\n",
            "Epoch 785/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6283 - accuracy: 0.7671 - val_loss: 0.7482 - val_accuracy: 0.7350\n",
            "Epoch 786/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6401 - accuracy: 0.7721 - val_loss: 0.7137 - val_accuracy: 0.7675\n",
            "Epoch 787/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6426 - accuracy: 0.7601 - val_loss: 0.7173 - val_accuracy: 0.7558\n",
            "Epoch 788/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6307 - accuracy: 0.7630 - val_loss: 0.7140 - val_accuracy: 0.7508\n",
            "Epoch 789/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6420 - accuracy: 0.7646 - val_loss: 0.7076 - val_accuracy: 0.7475\n",
            "Epoch 790/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5915 - accuracy: 0.7805 - val_loss: 0.6953 - val_accuracy: 0.7758\n",
            "Epoch 791/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6116 - accuracy: 0.7838 - val_loss: 0.6940 - val_accuracy: 0.7558\n",
            "Epoch 792/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5996 - accuracy: 0.7768 - val_loss: 0.6878 - val_accuracy: 0.7667\n",
            "Epoch 793/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6109 - accuracy: 0.7870 - val_loss: 0.7428 - val_accuracy: 0.7350\n",
            "Epoch 794/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6147 - accuracy: 0.7877 - val_loss: 0.7646 - val_accuracy: 0.7450\n",
            "Epoch 795/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6303 - accuracy: 0.7778 - val_loss: 0.7078 - val_accuracy: 0.7583\n",
            "Epoch 796/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6593 - accuracy: 0.7656 - val_loss: 0.7425 - val_accuracy: 0.7375\n",
            "Epoch 797/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6325 - accuracy: 0.7748 - val_loss: 0.6966 - val_accuracy: 0.7608\n",
            "Epoch 798/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6164 - accuracy: 0.7805 - val_loss: 0.6933 - val_accuracy: 0.7575\n",
            "Epoch 799/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6170 - accuracy: 0.7694 - val_loss: 0.7450 - val_accuracy: 0.7508\n",
            "Epoch 800/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6088 - accuracy: 0.7851 - val_loss: 0.7130 - val_accuracy: 0.7433\n",
            "Epoch 801/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6114 - accuracy: 0.7819 - val_loss: 0.6880 - val_accuracy: 0.7733\n",
            "Epoch 802/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6058 - accuracy: 0.7775 - val_loss: 0.6988 - val_accuracy: 0.7525\n",
            "Epoch 803/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6179 - accuracy: 0.7773 - val_loss: 0.7054 - val_accuracy: 0.7483\n",
            "Epoch 804/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6080 - accuracy: 0.7769 - val_loss: 0.7026 - val_accuracy: 0.7458\n",
            "Epoch 805/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.6229 - accuracy: 0.7649 - val_loss: 0.6949 - val_accuracy: 0.7708\n",
            "Epoch 806/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6150 - accuracy: 0.7691 - val_loss: 0.7221 - val_accuracy: 0.7558\n",
            "Epoch 807/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6336 - accuracy: 0.7750 - val_loss: 0.7085 - val_accuracy: 0.7700\n",
            "Epoch 808/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5931 - accuracy: 0.7830 - val_loss: 0.6959 - val_accuracy: 0.7633\n",
            "Epoch 809/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6075 - accuracy: 0.7780 - val_loss: 0.7075 - val_accuracy: 0.7642\n",
            "Epoch 810/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6083 - accuracy: 0.7865 - val_loss: 0.7201 - val_accuracy: 0.7300\n",
            "Epoch 811/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6015 - accuracy: 0.7767 - val_loss: 0.7024 - val_accuracy: 0.7508\n",
            "Epoch 812/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5835 - accuracy: 0.7953 - val_loss: 0.7006 - val_accuracy: 0.7633\n",
            "Epoch 813/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6080 - accuracy: 0.7799 - val_loss: 0.7261 - val_accuracy: 0.7542\n",
            "Epoch 814/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6177 - accuracy: 0.7812 - val_loss: 0.6990 - val_accuracy: 0.7608\n",
            "Epoch 815/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6035 - accuracy: 0.7870 - val_loss: 0.7024 - val_accuracy: 0.7608\n",
            "Epoch 816/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6080 - accuracy: 0.7821 - val_loss: 0.7042 - val_accuracy: 0.7575\n",
            "Epoch 817/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6437 - accuracy: 0.7635 - val_loss: 0.6935 - val_accuracy: 0.7483\n",
            "Epoch 818/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5996 - accuracy: 0.7824 - val_loss: 0.6996 - val_accuracy: 0.7642\n",
            "Epoch 819/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6068 - accuracy: 0.7667 - val_loss: 0.7204 - val_accuracy: 0.7475\n",
            "Epoch 820/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6278 - accuracy: 0.7715 - val_loss: 0.7579 - val_accuracy: 0.7317\n",
            "Epoch 821/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6424 - accuracy: 0.7720 - val_loss: 0.7036 - val_accuracy: 0.7575\n",
            "Epoch 822/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6089 - accuracy: 0.7772 - val_loss: 0.7112 - val_accuracy: 0.7525\n",
            "Epoch 823/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6085 - accuracy: 0.7795 - val_loss: 0.7142 - val_accuracy: 0.7500\n",
            "Epoch 824/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6292 - accuracy: 0.7732 - val_loss: 0.7196 - val_accuracy: 0.7708\n",
            "Epoch 825/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6106 - accuracy: 0.7866 - val_loss: 0.7955 - val_accuracy: 0.7575\n",
            "Epoch 826/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6917 - accuracy: 0.7773 - val_loss: 0.8215 - val_accuracy: 0.7283\n",
            "Epoch 827/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6193 - accuracy: 0.7834 - val_loss: 0.7367 - val_accuracy: 0.7667\n",
            "Epoch 828/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6129 - accuracy: 0.7663 - val_loss: 0.7185 - val_accuracy: 0.7558\n",
            "Epoch 829/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6065 - accuracy: 0.7824 - val_loss: 0.7060 - val_accuracy: 0.7600\n",
            "Epoch 830/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6015 - accuracy: 0.7823 - val_loss: 0.7142 - val_accuracy: 0.7542\n",
            "Epoch 831/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6505 - accuracy: 0.7627 - val_loss: 0.7423 - val_accuracy: 0.7400\n",
            "Epoch 832/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6311 - accuracy: 0.7692 - val_loss: 0.7143 - val_accuracy: 0.7533\n",
            "Epoch 833/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5925 - accuracy: 0.7844 - val_loss: 0.7385 - val_accuracy: 0.7317\n",
            "Epoch 834/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6037 - accuracy: 0.7765 - val_loss: 0.7208 - val_accuracy: 0.7642\n",
            "Epoch 835/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5930 - accuracy: 0.7869 - val_loss: 0.7166 - val_accuracy: 0.7617\n",
            "Epoch 836/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6360 - accuracy: 0.7713 - val_loss: 0.6990 - val_accuracy: 0.7625\n",
            "Epoch 837/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6324 - accuracy: 0.7617 - val_loss: 0.7259 - val_accuracy: 0.7550\n",
            "Epoch 838/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5986 - accuracy: 0.7862 - val_loss: 0.7179 - val_accuracy: 0.7550\n",
            "Epoch 839/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5967 - accuracy: 0.7881 - val_loss: 0.7441 - val_accuracy: 0.7608\n",
            "Epoch 840/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5980 - accuracy: 0.7824 - val_loss: 0.7005 - val_accuracy: 0.7733\n",
            "Epoch 841/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.5838 - accuracy: 0.7892 - val_loss: 0.6917 - val_accuracy: 0.7783\n",
            "Epoch 842/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5975 - accuracy: 0.7760 - val_loss: 0.6922 - val_accuracy: 0.7508\n",
            "Epoch 843/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6060 - accuracy: 0.7783 - val_loss: 0.7003 - val_accuracy: 0.7508\n",
            "Epoch 844/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5981 - accuracy: 0.7813 - val_loss: 0.7054 - val_accuracy: 0.7758\n",
            "Epoch 845/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5925 - accuracy: 0.7968 - val_loss: 0.6957 - val_accuracy: 0.7667\n",
            "Epoch 846/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5945 - accuracy: 0.7844 - val_loss: 0.7060 - val_accuracy: 0.7492\n",
            "Epoch 847/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6345 - accuracy: 0.7731 - val_loss: 0.7106 - val_accuracy: 0.7625\n",
            "Epoch 848/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6209 - accuracy: 0.7769 - val_loss: 0.7045 - val_accuracy: 0.7733\n",
            "Epoch 849/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6084 - accuracy: 0.7900 - val_loss: 0.6916 - val_accuracy: 0.7642\n",
            "Epoch 850/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5967 - accuracy: 0.7836 - val_loss: 0.7056 - val_accuracy: 0.7567\n",
            "Epoch 851/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6258 - accuracy: 0.7720 - val_loss: 0.7070 - val_accuracy: 0.7600\n",
            "Epoch 852/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6189 - accuracy: 0.7850 - val_loss: 0.7292 - val_accuracy: 0.7517\n",
            "Epoch 853/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6578 - accuracy: 0.7722 - val_loss: 0.7452 - val_accuracy: 0.7458\n",
            "Epoch 854/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6240 - accuracy: 0.7752 - val_loss: 0.7017 - val_accuracy: 0.7592\n",
            "Epoch 855/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6200 - accuracy: 0.7663 - val_loss: 0.7507 - val_accuracy: 0.7383\n",
            "Epoch 856/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5996 - accuracy: 0.7829 - val_loss: 0.6949 - val_accuracy: 0.7792\n",
            "Epoch 857/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5767 - accuracy: 0.7881 - val_loss: 0.7752 - val_accuracy: 0.7350\n",
            "Epoch 858/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6313 - accuracy: 0.7733 - val_loss: 0.7441 - val_accuracy: 0.7367\n",
            "Epoch 859/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6280 - accuracy: 0.7811 - val_loss: 0.6882 - val_accuracy: 0.7608\n",
            "Epoch 860/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6168 - accuracy: 0.7752 - val_loss: 0.7486 - val_accuracy: 0.7467\n",
            "Epoch 861/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6177 - accuracy: 0.7846 - val_loss: 0.7053 - val_accuracy: 0.7550\n",
            "Epoch 862/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6190 - accuracy: 0.7742 - val_loss: 0.6781 - val_accuracy: 0.7758\n",
            "Epoch 863/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6028 - accuracy: 0.7924 - val_loss: 0.7099 - val_accuracy: 0.7700\n",
            "Epoch 864/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6039 - accuracy: 0.7835 - val_loss: 0.6864 - val_accuracy: 0.7633\n",
            "Epoch 865/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6020 - accuracy: 0.7850 - val_loss: 0.7353 - val_accuracy: 0.7433\n",
            "Epoch 866/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5978 - accuracy: 0.7811 - val_loss: 0.7036 - val_accuracy: 0.7617\n",
            "Epoch 867/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6040 - accuracy: 0.7803 - val_loss: 0.6889 - val_accuracy: 0.7617\n",
            "Epoch 868/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6153 - accuracy: 0.7763 - val_loss: 0.7080 - val_accuracy: 0.7725\n",
            "Epoch 869/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6357 - accuracy: 0.7655 - val_loss: 0.7475 - val_accuracy: 0.7450\n",
            "Epoch 870/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6043 - accuracy: 0.7768 - val_loss: 0.7058 - val_accuracy: 0.7708\n",
            "Epoch 871/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6008 - accuracy: 0.7861 - val_loss: 0.7060 - val_accuracy: 0.7517\n",
            "Epoch 872/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6244 - accuracy: 0.7796 - val_loss: 0.6810 - val_accuracy: 0.7633\n",
            "Epoch 873/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5923 - accuracy: 0.7926 - val_loss: 0.7284 - val_accuracy: 0.7650\n",
            "Epoch 874/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6576 - accuracy: 0.7744 - val_loss: 0.7766 - val_accuracy: 0.7692\n",
            "Epoch 875/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6380 - accuracy: 0.7837 - val_loss: 0.7082 - val_accuracy: 0.7617\n",
            "Epoch 876/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6266 - accuracy: 0.7716 - val_loss: 0.6927 - val_accuracy: 0.7742\n",
            "Epoch 877/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6062 - accuracy: 0.7826 - val_loss: 0.7000 - val_accuracy: 0.7692\n",
            "Epoch 878/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6178 - accuracy: 0.7793 - val_loss: 0.7257 - val_accuracy: 0.7608\n",
            "Epoch 879/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6081 - accuracy: 0.7811 - val_loss: 0.7224 - val_accuracy: 0.7525\n",
            "Epoch 880/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5899 - accuracy: 0.7845 - val_loss: 0.6818 - val_accuracy: 0.7667\n",
            "Epoch 881/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5949 - accuracy: 0.7892 - val_loss: 0.7188 - val_accuracy: 0.7575\n",
            "Epoch 882/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5938 - accuracy: 0.7834 - val_loss: 0.7177 - val_accuracy: 0.7492\n",
            "Epoch 883/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5979 - accuracy: 0.7812 - val_loss: 0.7049 - val_accuracy: 0.7475\n",
            "Epoch 884/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5932 - accuracy: 0.7826 - val_loss: 0.7082 - val_accuracy: 0.7575\n",
            "Epoch 885/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6078 - accuracy: 0.7839 - val_loss: 0.7289 - val_accuracy: 0.7483\n",
            "Epoch 886/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6203 - accuracy: 0.7761 - val_loss: 0.6873 - val_accuracy: 0.7617\n",
            "Epoch 887/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6221 - accuracy: 0.7755 - val_loss: 0.7004 - val_accuracy: 0.7533\n",
            "Epoch 888/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5835 - accuracy: 0.7840 - val_loss: 0.7322 - val_accuracy: 0.7392\n",
            "Epoch 889/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6427 - accuracy: 0.7573 - val_loss: 0.7106 - val_accuracy: 0.7558\n",
            "Epoch 890/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6107 - accuracy: 0.7735 - val_loss: 0.7291 - val_accuracy: 0.7617\n",
            "Epoch 891/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6046 - accuracy: 0.7812 - val_loss: 0.7131 - val_accuracy: 0.7667\n",
            "Epoch 892/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5995 - accuracy: 0.7787 - val_loss: 0.7193 - val_accuracy: 0.7567\n",
            "Epoch 893/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6240 - accuracy: 0.7675 - val_loss: 0.6964 - val_accuracy: 0.7642\n",
            "Epoch 894/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6017 - accuracy: 0.7808 - val_loss: 0.6972 - val_accuracy: 0.7508\n",
            "Epoch 895/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5982 - accuracy: 0.7804 - val_loss: 0.6875 - val_accuracy: 0.7675\n",
            "Epoch 896/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5918 - accuracy: 0.7925 - val_loss: 0.6722 - val_accuracy: 0.7642\n",
            "Epoch 897/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6015 - accuracy: 0.7805 - val_loss: 0.7274 - val_accuracy: 0.7442\n",
            "Epoch 898/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6039 - accuracy: 0.7828 - val_loss: 0.7058 - val_accuracy: 0.7458\n",
            "Epoch 899/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6207 - accuracy: 0.7720 - val_loss: 0.7245 - val_accuracy: 0.7508\n",
            "Epoch 900/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6178 - accuracy: 0.7730 - val_loss: 0.7155 - val_accuracy: 0.7550\n",
            "Epoch 901/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6061 - accuracy: 0.7754 - val_loss: 0.7115 - val_accuracy: 0.7675\n",
            "Epoch 902/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6421 - accuracy: 0.7811 - val_loss: 0.7896 - val_accuracy: 0.7375\n",
            "Epoch 903/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6197 - accuracy: 0.7800 - val_loss: 0.6748 - val_accuracy: 0.7767\n",
            "Epoch 904/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6005 - accuracy: 0.7765 - val_loss: 0.7516 - val_accuracy: 0.7358\n",
            "Epoch 905/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6082 - accuracy: 0.7794 - val_loss: 0.6903 - val_accuracy: 0.7750\n",
            "Epoch 906/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6024 - accuracy: 0.7781 - val_loss: 0.7723 - val_accuracy: 0.7408\n",
            "Epoch 907/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6217 - accuracy: 0.7715 - val_loss: 0.7117 - val_accuracy: 0.7667\n",
            "Epoch 908/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.6075 - accuracy: 0.7781 - val_loss: 0.7321 - val_accuracy: 0.7625\n",
            "Epoch 909/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5975 - accuracy: 0.7853 - val_loss: 0.7974 - val_accuracy: 0.7417\n",
            "Epoch 910/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6072 - accuracy: 0.7699 - val_loss: 0.6940 - val_accuracy: 0.7650\n",
            "Epoch 911/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6054 - accuracy: 0.7743 - val_loss: 0.6882 - val_accuracy: 0.7683\n",
            "Epoch 912/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5905 - accuracy: 0.7898 - val_loss: 0.6826 - val_accuracy: 0.7767\n",
            "Epoch 913/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5708 - accuracy: 0.7882 - val_loss: 0.7149 - val_accuracy: 0.7558\n",
            "Epoch 914/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6005 - accuracy: 0.7872 - val_loss: 0.7188 - val_accuracy: 0.7558\n",
            "Epoch 915/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5923 - accuracy: 0.7786 - val_loss: 0.7188 - val_accuracy: 0.7550\n",
            "Epoch 916/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6006 - accuracy: 0.7843 - val_loss: 0.7001 - val_accuracy: 0.7742\n",
            "Epoch 917/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6187 - accuracy: 0.7776 - val_loss: 0.7274 - val_accuracy: 0.7392\n",
            "Epoch 918/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6226 - accuracy: 0.7694 - val_loss: 0.7775 - val_accuracy: 0.7225\n",
            "Epoch 919/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6375 - accuracy: 0.7731 - val_loss: 0.7203 - val_accuracy: 0.7450\n",
            "Epoch 920/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6082 - accuracy: 0.7815 - val_loss: 0.6856 - val_accuracy: 0.7767\n",
            "Epoch 921/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6024 - accuracy: 0.7880 - val_loss: 0.7132 - val_accuracy: 0.7608\n",
            "Epoch 922/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6099 - accuracy: 0.7898 - val_loss: 0.7315 - val_accuracy: 0.7625\n",
            "Epoch 923/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6203 - accuracy: 0.7761 - val_loss: 0.6997 - val_accuracy: 0.7658\n",
            "Epoch 924/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5845 - accuracy: 0.7839 - val_loss: 0.7273 - val_accuracy: 0.7617\n",
            "Epoch 925/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6133 - accuracy: 0.7715 - val_loss: 0.7215 - val_accuracy: 0.7533\n",
            "Epoch 926/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6143 - accuracy: 0.7795 - val_loss: 0.7210 - val_accuracy: 0.7475\n",
            "Epoch 927/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5915 - accuracy: 0.7926 - val_loss: 0.7006 - val_accuracy: 0.7625\n",
            "Epoch 928/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6070 - accuracy: 0.7732 - val_loss: 0.6834 - val_accuracy: 0.7683\n",
            "Epoch 929/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6043 - accuracy: 0.7816 - val_loss: 0.6750 - val_accuracy: 0.7675\n",
            "Epoch 930/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5870 - accuracy: 0.7801 - val_loss: 0.7044 - val_accuracy: 0.7442\n",
            "Epoch 931/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6042 - accuracy: 0.7774 - val_loss: 0.7179 - val_accuracy: 0.7500\n",
            "Epoch 932/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6227 - accuracy: 0.7689 - val_loss: 0.7293 - val_accuracy: 0.7342\n",
            "Epoch 933/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6486 - accuracy: 0.7551 - val_loss: 0.7197 - val_accuracy: 0.7642\n",
            "Epoch 934/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6055 - accuracy: 0.7763 - val_loss: 0.6977 - val_accuracy: 0.7575\n",
            "Epoch 935/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6229 - accuracy: 0.7768 - val_loss: 0.7241 - val_accuracy: 0.7550\n",
            "Epoch 936/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6214 - accuracy: 0.7822 - val_loss: 0.6976 - val_accuracy: 0.7717\n",
            "Epoch 937/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5979 - accuracy: 0.7818 - val_loss: 0.7121 - val_accuracy: 0.7567\n",
            "Epoch 938/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6195 - accuracy: 0.7806 - val_loss: 0.7463 - val_accuracy: 0.7383\n",
            "Epoch 939/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5844 - accuracy: 0.7888 - val_loss: 0.6901 - val_accuracy: 0.7675\n",
            "Epoch 940/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6084 - accuracy: 0.7839 - val_loss: 0.6960 - val_accuracy: 0.7542\n",
            "Epoch 941/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5760 - accuracy: 0.7909 - val_loss: 0.7285 - val_accuracy: 0.7458\n",
            "Epoch 942/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5731 - accuracy: 0.7920 - val_loss: 0.7428 - val_accuracy: 0.7592\n",
            "Epoch 943/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6107 - accuracy: 0.7809 - val_loss: 0.7508 - val_accuracy: 0.7467\n",
            "Epoch 944/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5833 - accuracy: 0.7921 - val_loss: 0.7038 - val_accuracy: 0.7692\n",
            "Epoch 945/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5964 - accuracy: 0.7911 - val_loss: 0.6873 - val_accuracy: 0.7792\n",
            "Epoch 946/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5993 - accuracy: 0.7912 - val_loss: 0.7151 - val_accuracy: 0.7367\n",
            "Epoch 947/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6164 - accuracy: 0.7657 - val_loss: 0.7224 - val_accuracy: 0.7525\n",
            "Epoch 948/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5903 - accuracy: 0.7943 - val_loss: 0.6965 - val_accuracy: 0.7775\n",
            "Epoch 949/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6093 - accuracy: 0.7836 - val_loss: 0.6899 - val_accuracy: 0.7692\n",
            "Epoch 950/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6030 - accuracy: 0.7850 - val_loss: 0.6918 - val_accuracy: 0.7667\n",
            "Epoch 951/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6042 - accuracy: 0.7826 - val_loss: 0.7378 - val_accuracy: 0.7583\n",
            "Epoch 952/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6025 - accuracy: 0.7785 - val_loss: 0.6973 - val_accuracy: 0.7650\n",
            "Epoch 953/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5913 - accuracy: 0.7842 - val_loss: 0.6974 - val_accuracy: 0.7567\n",
            "Epoch 954/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5936 - accuracy: 0.7925 - val_loss: 0.6869 - val_accuracy: 0.7692\n",
            "Epoch 955/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5967 - accuracy: 0.7848 - val_loss: 0.7335 - val_accuracy: 0.7608\n",
            "Epoch 956/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5970 - accuracy: 0.7840 - val_loss: 0.7304 - val_accuracy: 0.7542\n",
            "Epoch 957/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5967 - accuracy: 0.7824 - val_loss: 0.7280 - val_accuracy: 0.7600\n",
            "Epoch 958/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6112 - accuracy: 0.7800 - val_loss: 0.6925 - val_accuracy: 0.7542\n",
            "Epoch 959/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6073 - accuracy: 0.7692 - val_loss: 0.7015 - val_accuracy: 0.7592\n",
            "Epoch 960/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5821 - accuracy: 0.7923 - val_loss: 0.7024 - val_accuracy: 0.7708\n",
            "Epoch 961/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5772 - accuracy: 0.7986 - val_loss: 0.7026 - val_accuracy: 0.7617\n",
            "Epoch 962/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5835 - accuracy: 0.8014 - val_loss: 0.7035 - val_accuracy: 0.7558\n",
            "Epoch 963/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6023 - accuracy: 0.7932 - val_loss: 0.6901 - val_accuracy: 0.7758\n",
            "Epoch 964/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5962 - accuracy: 0.7897 - val_loss: 0.7103 - val_accuracy: 0.7467\n",
            "Epoch 965/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5835 - accuracy: 0.7835 - val_loss: 0.7356 - val_accuracy: 0.7600\n",
            "Epoch 966/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6136 - accuracy: 0.7733 - val_loss: 0.7410 - val_accuracy: 0.7533\n",
            "Epoch 967/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6394 - accuracy: 0.7742 - val_loss: 0.7238 - val_accuracy: 0.7442\n",
            "Epoch 968/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5976 - accuracy: 0.7841 - val_loss: 0.7510 - val_accuracy: 0.7550\n",
            "Epoch 969/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6328 - accuracy: 0.7714 - val_loss: 0.7211 - val_accuracy: 0.7633\n",
            "Epoch 970/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6002 - accuracy: 0.7782 - val_loss: 0.7086 - val_accuracy: 0.7542\n",
            "Epoch 971/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6080 - accuracy: 0.7858 - val_loss: 0.7156 - val_accuracy: 0.7617\n",
            "Epoch 972/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5944 - accuracy: 0.7830 - val_loss: 0.7204 - val_accuracy: 0.7500\n",
            "Epoch 973/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6046 - accuracy: 0.7725 - val_loss: 0.7153 - val_accuracy: 0.7467\n",
            "Epoch 974/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6038 - accuracy: 0.7839 - val_loss: 0.6913 - val_accuracy: 0.7608\n",
            "Epoch 975/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5904 - accuracy: 0.7926 - val_loss: 0.7050 - val_accuracy: 0.7650\n",
            "Epoch 976/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6149 - accuracy: 0.7794 - val_loss: 0.7501 - val_accuracy: 0.7425\n",
            "Epoch 977/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6133 - accuracy: 0.7684 - val_loss: 0.6660 - val_accuracy: 0.7817\n",
            "Epoch 978/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5692 - accuracy: 0.8000 - val_loss: 0.7032 - val_accuracy: 0.7542\n",
            "Epoch 979/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5916 - accuracy: 0.7793 - val_loss: 0.7425 - val_accuracy: 0.7567\n",
            "Epoch 980/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6407 - accuracy: 0.7766 - val_loss: 0.7262 - val_accuracy: 0.7683\n",
            "Epoch 981/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6354 - accuracy: 0.7827 - val_loss: 0.7588 - val_accuracy: 0.7550\n",
            "Epoch 982/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5842 - accuracy: 0.7875 - val_loss: 0.7008 - val_accuracy: 0.7542\n",
            "Epoch 983/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5916 - accuracy: 0.7797 - val_loss: 0.7010 - val_accuracy: 0.7700\n",
            "Epoch 984/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5790 - accuracy: 0.7949 - val_loss: 0.7548 - val_accuracy: 0.7425\n",
            "Epoch 985/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5723 - accuracy: 0.7902 - val_loss: 0.7179 - val_accuracy: 0.7433\n",
            "Epoch 986/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5784 - accuracy: 0.7909 - val_loss: 0.6995 - val_accuracy: 0.7533\n",
            "Epoch 987/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6167 - accuracy: 0.7697 - val_loss: 0.7150 - val_accuracy: 0.7517\n",
            "Epoch 988/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5759 - accuracy: 0.7989 - val_loss: 0.7073 - val_accuracy: 0.7633\n",
            "Epoch 989/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5941 - accuracy: 0.7921 - val_loss: 0.7166 - val_accuracy: 0.7525\n",
            "Epoch 990/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5821 - accuracy: 0.7928 - val_loss: 0.7409 - val_accuracy: 0.7308\n",
            "Epoch 991/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6158 - accuracy: 0.7789 - val_loss: 0.7175 - val_accuracy: 0.7542\n",
            "Epoch 992/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6056 - accuracy: 0.7892 - val_loss: 0.7049 - val_accuracy: 0.7683\n",
            "Epoch 993/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5840 - accuracy: 0.7846 - val_loss: 0.7175 - val_accuracy: 0.7592\n",
            "Epoch 994/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5890 - accuracy: 0.7863 - val_loss: 0.6899 - val_accuracy: 0.7767\n",
            "Epoch 995/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6027 - accuracy: 0.7886 - val_loss: 0.6911 - val_accuracy: 0.7633\n",
            "Epoch 996/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5880 - accuracy: 0.7813 - val_loss: 0.7368 - val_accuracy: 0.7450\n",
            "Epoch 997/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5933 - accuracy: 0.7906 - val_loss: 0.6994 - val_accuracy: 0.7692\n",
            "Epoch 998/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5805 - accuracy: 0.7883 - val_loss: 0.7475 - val_accuracy: 0.7650\n",
            "Epoch 999/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6146 - accuracy: 0.7862 - val_loss: 0.7117 - val_accuracy: 0.7475\n",
            "Epoch 1000/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5590 - accuracy: 0.7964 - val_loss: 0.7151 - val_accuracy: 0.7550\n",
            "Epoch 1001/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6023 - accuracy: 0.7778 - val_loss: 0.7409 - val_accuracy: 0.7425\n",
            "Epoch 1002/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5983 - accuracy: 0.7866 - val_loss: 0.6914 - val_accuracy: 0.7575\n",
            "Epoch 1003/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5704 - accuracy: 0.7968 - val_loss: 0.7265 - val_accuracy: 0.7483\n",
            "Epoch 1004/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5674 - accuracy: 0.8015 - val_loss: 0.7825 - val_accuracy: 0.7517\n",
            "Epoch 1005/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6004 - accuracy: 0.7731 - val_loss: 0.7177 - val_accuracy: 0.7442\n",
            "Epoch 1006/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5916 - accuracy: 0.7808 - val_loss: 0.7243 - val_accuracy: 0.7658\n",
            "Epoch 1007/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5900 - accuracy: 0.7876 - val_loss: 0.7148 - val_accuracy: 0.7508\n",
            "Epoch 1008/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6105 - accuracy: 0.7830 - val_loss: 0.7451 - val_accuracy: 0.7583\n",
            "Epoch 1009/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5722 - accuracy: 0.7960 - val_loss: 0.6858 - val_accuracy: 0.7667\n",
            "Epoch 1010/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6174 - accuracy: 0.7809 - val_loss: 0.7933 - val_accuracy: 0.7417\n",
            "Epoch 1011/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5924 - accuracy: 0.7873 - val_loss: 0.7043 - val_accuracy: 0.7592\n",
            "Epoch 1012/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5925 - accuracy: 0.7826 - val_loss: 0.7123 - val_accuracy: 0.7650\n",
            "Epoch 1013/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5746 - accuracy: 0.7902 - val_loss: 0.7199 - val_accuracy: 0.7642\n",
            "Epoch 1014/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5928 - accuracy: 0.7894 - val_loss: 0.6924 - val_accuracy: 0.7675\n",
            "Epoch 1015/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5912 - accuracy: 0.7876 - val_loss: 0.7226 - val_accuracy: 0.7667\n",
            "Epoch 1016/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6007 - accuracy: 0.7859 - val_loss: 0.6736 - val_accuracy: 0.7633\n",
            "Epoch 1017/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5998 - accuracy: 0.7834 - val_loss: 0.7468 - val_accuracy: 0.7333\n",
            "Epoch 1018/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6315 - accuracy: 0.7700 - val_loss: 0.7148 - val_accuracy: 0.7567\n",
            "Epoch 1019/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6160 - accuracy: 0.7735 - val_loss: 0.7113 - val_accuracy: 0.7683\n",
            "Epoch 1020/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5917 - accuracy: 0.7888 - val_loss: 0.7098 - val_accuracy: 0.7408\n",
            "Epoch 1021/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5937 - accuracy: 0.7884 - val_loss: 0.6983 - val_accuracy: 0.7575\n",
            "Epoch 1022/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5660 - accuracy: 0.7996 - val_loss: 0.7202 - val_accuracy: 0.7717\n",
            "Epoch 1023/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6243 - accuracy: 0.7801 - val_loss: 0.7231 - val_accuracy: 0.7492\n",
            "Epoch 1024/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5919 - accuracy: 0.7868 - val_loss: 0.7473 - val_accuracy: 0.7642\n",
            "Epoch 1025/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5969 - accuracy: 0.7763 - val_loss: 0.7378 - val_accuracy: 0.7692\n",
            "Epoch 1026/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5961 - accuracy: 0.7842 - val_loss: 0.7779 - val_accuracy: 0.7533\n",
            "Epoch 1027/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6146 - accuracy: 0.7857 - val_loss: 0.7314 - val_accuracy: 0.7467\n",
            "Epoch 1028/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6032 - accuracy: 0.7873 - val_loss: 0.7335 - val_accuracy: 0.7500\n",
            "Epoch 1029/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5804 - accuracy: 0.7884 - val_loss: 0.7650 - val_accuracy: 0.7450\n",
            "Epoch 1030/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6171 - accuracy: 0.7782 - val_loss: 0.7385 - val_accuracy: 0.7617\n",
            "Epoch 1031/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6124 - accuracy: 0.7778 - val_loss: 0.7114 - val_accuracy: 0.7617\n",
            "Epoch 1032/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.5645 - accuracy: 0.7928 - val_loss: 0.7190 - val_accuracy: 0.7617\n",
            "Epoch 1033/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5722 - accuracy: 0.7937 - val_loss: 0.7291 - val_accuracy: 0.7650\n",
            "Epoch 1034/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5756 - accuracy: 0.7923 - val_loss: 0.7821 - val_accuracy: 0.7392\n",
            "Epoch 1035/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6135 - accuracy: 0.7728 - val_loss: 0.7236 - val_accuracy: 0.7508\n",
            "Epoch 1036/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5723 - accuracy: 0.7907 - val_loss: 0.7030 - val_accuracy: 0.7717\n",
            "Epoch 1037/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5822 - accuracy: 0.7895 - val_loss: 0.6812 - val_accuracy: 0.7725\n",
            "Epoch 1038/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5838 - accuracy: 0.7885 - val_loss: 0.6935 - val_accuracy: 0.7683\n",
            "Epoch 1039/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5849 - accuracy: 0.7806 - val_loss: 0.6794 - val_accuracy: 0.7783\n",
            "Epoch 1040/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5773 - accuracy: 0.7787 - val_loss: 0.7312 - val_accuracy: 0.7675\n",
            "Epoch 1041/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5978 - accuracy: 0.7896 - val_loss: 0.6921 - val_accuracy: 0.7717\n",
            "Epoch 1042/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5899 - accuracy: 0.7877 - val_loss: 0.7082 - val_accuracy: 0.7542\n",
            "Epoch 1043/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5868 - accuracy: 0.7865 - val_loss: 0.7037 - val_accuracy: 0.7567\n",
            "Epoch 1044/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5984 - accuracy: 0.7807 - val_loss: 0.7427 - val_accuracy: 0.7608\n",
            "Epoch 1045/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5869 - accuracy: 0.7856 - val_loss: 0.7523 - val_accuracy: 0.7442\n",
            "Epoch 1046/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5865 - accuracy: 0.7799 - val_loss: 0.7127 - val_accuracy: 0.7567\n",
            "Epoch 1047/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5859 - accuracy: 0.7800 - val_loss: 0.7019 - val_accuracy: 0.7708\n",
            "Epoch 1048/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6076 - accuracy: 0.7754 - val_loss: 0.7105 - val_accuracy: 0.7483\n",
            "Epoch 1049/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6126 - accuracy: 0.7796 - val_loss: 0.7178 - val_accuracy: 0.7458\n",
            "Epoch 1050/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5761 - accuracy: 0.7876 - val_loss: 0.7258 - val_accuracy: 0.7525\n",
            "Epoch 1051/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5995 - accuracy: 0.7839 - val_loss: 0.7198 - val_accuracy: 0.7600\n",
            "Epoch 1052/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6008 - accuracy: 0.7698 - val_loss: 0.6983 - val_accuracy: 0.7642\n",
            "Epoch 1053/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5660 - accuracy: 0.7930 - val_loss: 0.7184 - val_accuracy: 0.7742\n",
            "Epoch 1054/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5783 - accuracy: 0.7891 - val_loss: 0.6971 - val_accuracy: 0.7675\n",
            "Epoch 1055/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6086 - accuracy: 0.7792 - val_loss: 0.7189 - val_accuracy: 0.7608\n",
            "Epoch 1056/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5765 - accuracy: 0.7902 - val_loss: 0.6949 - val_accuracy: 0.7675\n",
            "Epoch 1057/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5877 - accuracy: 0.7872 - val_loss: 0.7144 - val_accuracy: 0.7542\n",
            "Epoch 1058/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5936 - accuracy: 0.7768 - val_loss: 0.7145 - val_accuracy: 0.7633\n",
            "Epoch 1059/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6513 - accuracy: 0.7812 - val_loss: 0.7181 - val_accuracy: 0.7683\n",
            "Epoch 1060/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5946 - accuracy: 0.7768 - val_loss: 0.7556 - val_accuracy: 0.7650\n",
            "Epoch 1061/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5871 - accuracy: 0.7878 - val_loss: 0.6921 - val_accuracy: 0.7558\n",
            "Epoch 1062/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5838 - accuracy: 0.7873 - val_loss: 0.7092 - val_accuracy: 0.7683\n",
            "Epoch 1063/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5806 - accuracy: 0.7795 - val_loss: 0.7261 - val_accuracy: 0.7442\n",
            "Epoch 1064/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6021 - accuracy: 0.7701 - val_loss: 0.7293 - val_accuracy: 0.7633\n",
            "Epoch 1065/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6273 - accuracy: 0.7672 - val_loss: 0.6706 - val_accuracy: 0.7700\n",
            "Epoch 1066/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5756 - accuracy: 0.7985 - val_loss: 0.7351 - val_accuracy: 0.7667\n",
            "Epoch 1067/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6162 - accuracy: 0.7744 - val_loss: 0.7010 - val_accuracy: 0.7558\n",
            "Epoch 1068/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5730 - accuracy: 0.7840 - val_loss: 0.7204 - val_accuracy: 0.7575\n",
            "Epoch 1069/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5996 - accuracy: 0.7769 - val_loss: 0.7022 - val_accuracy: 0.7517\n",
            "Epoch 1070/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5810 - accuracy: 0.7858 - val_loss: 0.7022 - val_accuracy: 0.7667\n",
            "Epoch 1071/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5911 - accuracy: 0.7787 - val_loss: 0.7012 - val_accuracy: 0.7633\n",
            "Epoch 1072/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6060 - accuracy: 0.7842 - val_loss: 0.7092 - val_accuracy: 0.7658\n",
            "Epoch 1073/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5963 - accuracy: 0.7833 - val_loss: 0.7304 - val_accuracy: 0.7625\n",
            "Epoch 1074/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5877 - accuracy: 0.7863 - val_loss: 0.7698 - val_accuracy: 0.7533\n",
            "Epoch 1075/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5913 - accuracy: 0.7838 - val_loss: 0.6951 - val_accuracy: 0.7600\n",
            "Epoch 1076/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6175 - accuracy: 0.7732 - val_loss: 0.6989 - val_accuracy: 0.7667\n",
            "Epoch 1077/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5792 - accuracy: 0.7938 - val_loss: 0.7153 - val_accuracy: 0.7567\n",
            "Epoch 1078/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5779 - accuracy: 0.7867 - val_loss: 0.7436 - val_accuracy: 0.7517\n",
            "Epoch 1079/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5632 - accuracy: 0.7963 - val_loss: 0.7047 - val_accuracy: 0.7642\n",
            "Epoch 1080/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5766 - accuracy: 0.7931 - val_loss: 0.7303 - val_accuracy: 0.7517\n",
            "Epoch 1081/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5881 - accuracy: 0.7855 - val_loss: 0.7181 - val_accuracy: 0.7667\n",
            "Epoch 1082/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6023 - accuracy: 0.7901 - val_loss: 0.7314 - val_accuracy: 0.7483\n",
            "Epoch 1083/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5795 - accuracy: 0.7949 - val_loss: 0.7134 - val_accuracy: 0.7617\n",
            "Epoch 1084/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5815 - accuracy: 0.7863 - val_loss: 0.7210 - val_accuracy: 0.7633\n",
            "Epoch 1085/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6105 - accuracy: 0.7798 - val_loss: 0.7370 - val_accuracy: 0.7542\n",
            "Epoch 1086/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5926 - accuracy: 0.7845 - val_loss: 0.7480 - val_accuracy: 0.7592\n",
            "Epoch 1087/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6059 - accuracy: 0.7772 - val_loss: 0.7261 - val_accuracy: 0.7583\n",
            "Epoch 1088/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5605 - accuracy: 0.7938 - val_loss: 0.7209 - val_accuracy: 0.7558\n",
            "Epoch 1089/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5964 - accuracy: 0.7708 - val_loss: 0.7093 - val_accuracy: 0.7675\n",
            "Epoch 1090/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5883 - accuracy: 0.7849 - val_loss: 0.7292 - val_accuracy: 0.7575\n",
            "Epoch 1091/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5798 - accuracy: 0.7858 - val_loss: 0.7263 - val_accuracy: 0.7658\n",
            "Epoch 1092/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5693 - accuracy: 0.7995 - val_loss: 0.7139 - val_accuracy: 0.7650\n",
            "Epoch 1093/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5852 - accuracy: 0.7928 - val_loss: 0.7025 - val_accuracy: 0.7692\n",
            "Epoch 1094/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5821 - accuracy: 0.7874 - val_loss: 0.7258 - val_accuracy: 0.7683\n",
            "Epoch 1095/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5763 - accuracy: 0.7945 - val_loss: 0.7231 - val_accuracy: 0.7625\n",
            "Epoch 1096/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5785 - accuracy: 0.7922 - val_loss: 0.7204 - val_accuracy: 0.7542\n",
            "Epoch 1097/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5962 - accuracy: 0.7803 - val_loss: 0.8226 - val_accuracy: 0.7392\n",
            "Epoch 1098/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5719 - accuracy: 0.7952 - val_loss: 0.7301 - val_accuracy: 0.7700\n",
            "Epoch 1099/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5694 - accuracy: 0.7961 - val_loss: 0.7088 - val_accuracy: 0.7750\n",
            "Epoch 1100/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5970 - accuracy: 0.7809 - val_loss: 0.7276 - val_accuracy: 0.7608\n",
            "Epoch 1101/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5981 - accuracy: 0.7849 - val_loss: 0.7256 - val_accuracy: 0.7567\n",
            "Epoch 1102/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5670 - accuracy: 0.7875 - val_loss: 0.7219 - val_accuracy: 0.7658\n",
            "Epoch 1103/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6115 - accuracy: 0.7723 - val_loss: 0.7477 - val_accuracy: 0.7517\n",
            "Epoch 1104/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5775 - accuracy: 0.7890 - val_loss: 0.7339 - val_accuracy: 0.7633\n",
            "Epoch 1105/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5889 - accuracy: 0.7806 - val_loss: 0.6919 - val_accuracy: 0.7733\n",
            "Epoch 1106/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5572 - accuracy: 0.7925 - val_loss: 0.6821 - val_accuracy: 0.7633\n",
            "Epoch 1107/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5822 - accuracy: 0.7807 - val_loss: 0.7555 - val_accuracy: 0.7583\n",
            "Epoch 1108/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5787 - accuracy: 0.7928 - val_loss: 0.7387 - val_accuracy: 0.7483\n",
            "Epoch 1109/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6095 - accuracy: 0.7735 - val_loss: 0.7252 - val_accuracy: 0.7367\n",
            "Epoch 1110/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6006 - accuracy: 0.7777 - val_loss: 0.7320 - val_accuracy: 0.7558\n",
            "Epoch 1111/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5813 - accuracy: 0.7874 - val_loss: 0.7448 - val_accuracy: 0.7642\n",
            "Epoch 1112/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5652 - accuracy: 0.7997 - val_loss: 0.7204 - val_accuracy: 0.7642\n",
            "Epoch 1113/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6049 - accuracy: 0.7807 - val_loss: 0.7471 - val_accuracy: 0.7650\n",
            "Epoch 1114/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5993 - accuracy: 0.7932 - val_loss: 0.7906 - val_accuracy: 0.7408\n",
            "Epoch 1115/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6127 - accuracy: 0.7855 - val_loss: 0.7320 - val_accuracy: 0.7683\n",
            "Epoch 1116/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5970 - accuracy: 0.7876 - val_loss: 0.7051 - val_accuracy: 0.7650\n",
            "Epoch 1117/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5928 - accuracy: 0.7945 - val_loss: 0.7085 - val_accuracy: 0.7625\n",
            "Epoch 1118/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5839 - accuracy: 0.7867 - val_loss: 0.7373 - val_accuracy: 0.7625\n",
            "Epoch 1119/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6161 - accuracy: 0.7676 - val_loss: 0.7522 - val_accuracy: 0.7458\n",
            "Epoch 1120/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6033 - accuracy: 0.7749 - val_loss: 0.6952 - val_accuracy: 0.7608\n",
            "Epoch 1121/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5742 - accuracy: 0.7808 - val_loss: 0.7087 - val_accuracy: 0.7700\n",
            "Epoch 1122/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5733 - accuracy: 0.8002 - val_loss: 0.7159 - val_accuracy: 0.7575\n",
            "Epoch 1123/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5591 - accuracy: 0.7999 - val_loss: 0.7144 - val_accuracy: 0.7617\n",
            "Epoch 1124/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5654 - accuracy: 0.7880 - val_loss: 0.6825 - val_accuracy: 0.7817\n",
            "Epoch 1125/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5881 - accuracy: 0.7992 - val_loss: 0.7690 - val_accuracy: 0.7400\n",
            "Epoch 1126/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5863 - accuracy: 0.7927 - val_loss: 0.7165 - val_accuracy: 0.7633\n",
            "Epoch 1127/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5803 - accuracy: 0.7930 - val_loss: 0.7045 - val_accuracy: 0.7567\n",
            "Epoch 1128/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5697 - accuracy: 0.7868 - val_loss: 0.7045 - val_accuracy: 0.7783\n",
            "Epoch 1129/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5665 - accuracy: 0.7971 - val_loss: 0.7134 - val_accuracy: 0.7683\n",
            "Epoch 1130/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5666 - accuracy: 0.7878 - val_loss: 0.7183 - val_accuracy: 0.7675\n",
            "Epoch 1131/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5770 - accuracy: 0.7942 - val_loss: 0.6813 - val_accuracy: 0.7750\n",
            "Epoch 1132/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5588 - accuracy: 0.7806 - val_loss: 0.7236 - val_accuracy: 0.7617\n",
            "Epoch 1133/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5714 - accuracy: 0.7852 - val_loss: 0.7116 - val_accuracy: 0.7642\n",
            "Epoch 1134/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5601 - accuracy: 0.8004 - val_loss: 0.7184 - val_accuracy: 0.7725\n",
            "Epoch 1135/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5847 - accuracy: 0.7940 - val_loss: 0.7106 - val_accuracy: 0.7633\n",
            "Epoch 1136/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6043 - accuracy: 0.7780 - val_loss: 0.7278 - val_accuracy: 0.7608\n",
            "Epoch 1137/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5678 - accuracy: 0.7872 - val_loss: 0.7080 - val_accuracy: 0.7567\n",
            "Epoch 1138/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5660 - accuracy: 0.7962 - val_loss: 0.7411 - val_accuracy: 0.7667\n",
            "Epoch 1139/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5817 - accuracy: 0.7798 - val_loss: 0.7047 - val_accuracy: 0.7750\n",
            "Epoch 1140/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5680 - accuracy: 0.7975 - val_loss: 0.7348 - val_accuracy: 0.7550\n",
            "Epoch 1141/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5891 - accuracy: 0.7820 - val_loss: 0.7272 - val_accuracy: 0.7667\n",
            "Epoch 1142/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5882 - accuracy: 0.7918 - val_loss: 0.7244 - val_accuracy: 0.7592\n",
            "Epoch 1143/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5801 - accuracy: 0.7831 - val_loss: 0.7211 - val_accuracy: 0.7558\n",
            "Epoch 1144/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5536 - accuracy: 0.8052 - val_loss: 0.7287 - val_accuracy: 0.7542\n",
            "Epoch 1145/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5729 - accuracy: 0.7969 - val_loss: 0.7336 - val_accuracy: 0.7650\n",
            "Epoch 1146/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6197 - accuracy: 0.7864 - val_loss: 0.7387 - val_accuracy: 0.7617\n",
            "Epoch 1147/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5736 - accuracy: 0.7942 - val_loss: 0.6700 - val_accuracy: 0.7792\n",
            "Epoch 1148/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5916 - accuracy: 0.7823 - val_loss: 0.7414 - val_accuracy: 0.7508\n",
            "Epoch 1149/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5823 - accuracy: 0.7830 - val_loss: 0.7391 - val_accuracy: 0.7683\n",
            "Epoch 1150/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5902 - accuracy: 0.7823 - val_loss: 0.7314 - val_accuracy: 0.7550\n",
            "Epoch 1151/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5819 - accuracy: 0.7817 - val_loss: 0.7264 - val_accuracy: 0.7567\n",
            "Epoch 1152/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5971 - accuracy: 0.7771 - val_loss: 0.7534 - val_accuracy: 0.7675\n",
            "Epoch 1153/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5814 - accuracy: 0.7972 - val_loss: 0.7223 - val_accuracy: 0.7550\n",
            "Epoch 1154/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5692 - accuracy: 0.7918 - val_loss: 0.7263 - val_accuracy: 0.7700\n",
            "Epoch 1155/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5838 - accuracy: 0.7803 - val_loss: 0.7241 - val_accuracy: 0.7567\n",
            "Epoch 1156/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5746 - accuracy: 0.7892 - val_loss: 0.7130 - val_accuracy: 0.7617\n",
            "Epoch 1157/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5848 - accuracy: 0.7902 - val_loss: 0.7187 - val_accuracy: 0.7617\n",
            "Epoch 1158/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.5766 - accuracy: 0.7964 - val_loss: 0.7350 - val_accuracy: 0.7550\n",
            "Epoch 1159/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5995 - accuracy: 0.7766 - val_loss: 0.7363 - val_accuracy: 0.7608\n",
            "Epoch 1160/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5822 - accuracy: 0.7987 - val_loss: 0.7268 - val_accuracy: 0.7758\n",
            "Epoch 1161/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5868 - accuracy: 0.7799 - val_loss: 0.7708 - val_accuracy: 0.7633\n",
            "Epoch 1162/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6181 - accuracy: 0.7919 - val_loss: 0.7060 - val_accuracy: 0.7658\n",
            "Epoch 1163/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6088 - accuracy: 0.7690 - val_loss: 0.7816 - val_accuracy: 0.7375\n",
            "Epoch 1164/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6023 - accuracy: 0.7779 - val_loss: 0.7043 - val_accuracy: 0.7575\n",
            "Epoch 1165/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5570 - accuracy: 0.7991 - val_loss: 0.7265 - val_accuracy: 0.7600\n",
            "Epoch 1166/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5909 - accuracy: 0.7849 - val_loss: 0.7201 - val_accuracy: 0.7833\n",
            "Epoch 1167/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5588 - accuracy: 0.7882 - val_loss: 0.7010 - val_accuracy: 0.7700\n",
            "Epoch 1168/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5504 - accuracy: 0.7990 - val_loss: 0.6943 - val_accuracy: 0.7942\n",
            "Epoch 1169/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5492 - accuracy: 0.8009 - val_loss: 0.7269 - val_accuracy: 0.7717\n",
            "Epoch 1170/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5710 - accuracy: 0.7915 - val_loss: 0.7330 - val_accuracy: 0.7542\n",
            "Epoch 1171/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5531 - accuracy: 0.8003 - val_loss: 0.7113 - val_accuracy: 0.7667\n",
            "Epoch 1172/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5654 - accuracy: 0.7922 - val_loss: 0.7041 - val_accuracy: 0.7492\n",
            "Epoch 1173/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5717 - accuracy: 0.7907 - val_loss: 0.7218 - val_accuracy: 0.7583\n",
            "Epoch 1174/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6029 - accuracy: 0.7828 - val_loss: 0.7640 - val_accuracy: 0.7550\n",
            "Epoch 1175/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5908 - accuracy: 0.7822 - val_loss: 0.7994 - val_accuracy: 0.7442\n",
            "Epoch 1176/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6154 - accuracy: 0.7714 - val_loss: 0.7505 - val_accuracy: 0.7708\n",
            "Epoch 1177/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5751 - accuracy: 0.7823 - val_loss: 0.7156 - val_accuracy: 0.7583\n",
            "Epoch 1178/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5661 - accuracy: 0.7988 - val_loss: 0.7519 - val_accuracy: 0.7550\n",
            "Epoch 1179/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5775 - accuracy: 0.7895 - val_loss: 0.7143 - val_accuracy: 0.7642\n",
            "Epoch 1180/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5783 - accuracy: 0.7871 - val_loss: 0.7358 - val_accuracy: 0.7450\n",
            "Epoch 1181/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5564 - accuracy: 0.8002 - val_loss: 0.7369 - val_accuracy: 0.7475\n",
            "Epoch 1182/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5798 - accuracy: 0.7724 - val_loss: 0.7079 - val_accuracy: 0.7558\n",
            "Epoch 1183/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5861 - accuracy: 0.7824 - val_loss: 0.7349 - val_accuracy: 0.7550\n",
            "Epoch 1184/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5830 - accuracy: 0.7851 - val_loss: 0.8282 - val_accuracy: 0.7425\n",
            "Epoch 1185/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6048 - accuracy: 0.7825 - val_loss: 0.7465 - val_accuracy: 0.7608\n",
            "Epoch 1186/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5884 - accuracy: 0.7759 - val_loss: 0.7622 - val_accuracy: 0.7600\n",
            "Epoch 1187/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5883 - accuracy: 0.7893 - val_loss: 0.7040 - val_accuracy: 0.7633\n",
            "Epoch 1188/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5662 - accuracy: 0.7861 - val_loss: 0.7904 - val_accuracy: 0.7417\n",
            "Epoch 1189/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5936 - accuracy: 0.7871 - val_loss: 0.7937 - val_accuracy: 0.7467\n",
            "Epoch 1190/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6212 - accuracy: 0.7696 - val_loss: 0.7939 - val_accuracy: 0.7633\n",
            "Epoch 1191/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6927 - accuracy: 0.7761 - val_loss: 0.7987 - val_accuracy: 0.7658\n",
            "Epoch 1192/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5874 - accuracy: 0.7922 - val_loss: 0.7214 - val_accuracy: 0.7792\n",
            "Epoch 1193/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5754 - accuracy: 0.7907 - val_loss: 0.7138 - val_accuracy: 0.7667\n",
            "Epoch 1194/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5688 - accuracy: 0.7922 - val_loss: 0.7252 - val_accuracy: 0.7817\n",
            "Epoch 1195/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5934 - accuracy: 0.7819 - val_loss: 0.7238 - val_accuracy: 0.7675\n",
            "Epoch 1196/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5738 - accuracy: 0.7858 - val_loss: 0.7288 - val_accuracy: 0.7642\n",
            "Epoch 1197/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5725 - accuracy: 0.7912 - val_loss: 0.7120 - val_accuracy: 0.7658\n",
            "Epoch 1198/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5710 - accuracy: 0.7986 - val_loss: 0.7102 - val_accuracy: 0.7750\n",
            "Epoch 1199/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6147 - accuracy: 0.7771 - val_loss: 0.7011 - val_accuracy: 0.7700\n",
            "Epoch 1200/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5714 - accuracy: 0.7885 - val_loss: 0.7247 - val_accuracy: 0.7675\n",
            "Epoch 1201/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6146 - accuracy: 0.7842 - val_loss: 0.7177 - val_accuracy: 0.7700\n",
            "Epoch 1202/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5774 - accuracy: 0.7954 - val_loss: 0.7612 - val_accuracy: 0.7467\n",
            "Epoch 1203/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5419 - accuracy: 0.7985 - val_loss: 0.6913 - val_accuracy: 0.7767\n",
            "Epoch 1204/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5684 - accuracy: 0.7888 - val_loss: 0.7406 - val_accuracy: 0.7625\n",
            "Epoch 1205/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5767 - accuracy: 0.7960 - val_loss: 0.7837 - val_accuracy: 0.7575\n",
            "Epoch 1206/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6209 - accuracy: 0.7849 - val_loss: 0.7152 - val_accuracy: 0.7633\n",
            "Epoch 1207/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5650 - accuracy: 0.7950 - val_loss: 0.6949 - val_accuracy: 0.7808\n",
            "Epoch 1208/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5788 - accuracy: 0.7861 - val_loss: 0.7233 - val_accuracy: 0.7667\n",
            "Epoch 1209/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5563 - accuracy: 0.8039 - val_loss: 0.6857 - val_accuracy: 0.7683\n",
            "Epoch 1210/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5692 - accuracy: 0.7884 - val_loss: 0.7234 - val_accuracy: 0.7592\n",
            "Epoch 1211/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5895 - accuracy: 0.7865 - val_loss: 0.7250 - val_accuracy: 0.7650\n",
            "Epoch 1212/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5912 - accuracy: 0.7939 - val_loss: 0.7596 - val_accuracy: 0.7575\n",
            "Epoch 1213/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5515 - accuracy: 0.8050 - val_loss: 0.7826 - val_accuracy: 0.7508\n",
            "Epoch 1214/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5743 - accuracy: 0.7948 - val_loss: 0.7569 - val_accuracy: 0.7592\n",
            "Epoch 1215/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5692 - accuracy: 0.7884 - val_loss: 0.7379 - val_accuracy: 0.7600\n",
            "Epoch 1216/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5776 - accuracy: 0.7852 - val_loss: 0.7419 - val_accuracy: 0.7508\n",
            "Epoch 1217/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6098 - accuracy: 0.7747 - val_loss: 0.8356 - val_accuracy: 0.7350\n",
            "Epoch 1218/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5958 - accuracy: 0.7876 - val_loss: 0.7426 - val_accuracy: 0.7458\n",
            "Epoch 1219/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6111 - accuracy: 0.7856 - val_loss: 0.6953 - val_accuracy: 0.7692\n",
            "Epoch 1220/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5674 - accuracy: 0.7938 - val_loss: 0.7234 - val_accuracy: 0.7608\n",
            "Epoch 1221/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5939 - accuracy: 0.7786 - val_loss: 0.7073 - val_accuracy: 0.7650\n",
            "Epoch 1222/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5726 - accuracy: 0.7926 - val_loss: 0.7485 - val_accuracy: 0.7517\n",
            "Epoch 1223/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5682 - accuracy: 0.7955 - val_loss: 0.8041 - val_accuracy: 0.7550\n",
            "Epoch 1224/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5786 - accuracy: 0.7868 - val_loss: 0.7095 - val_accuracy: 0.7675\n",
            "Epoch 1225/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5639 - accuracy: 0.7937 - val_loss: 0.7344 - val_accuracy: 0.7692\n",
            "Epoch 1226/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5604 - accuracy: 0.7982 - val_loss: 0.7260 - val_accuracy: 0.7475\n",
            "Epoch 1227/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5925 - accuracy: 0.7811 - val_loss: 0.7414 - val_accuracy: 0.7550\n",
            "Epoch 1228/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5629 - accuracy: 0.7937 - val_loss: 0.7240 - val_accuracy: 0.7642\n",
            "Epoch 1229/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5684 - accuracy: 0.7846 - val_loss: 0.7451 - val_accuracy: 0.7608\n",
            "Epoch 1230/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6011 - accuracy: 0.7754 - val_loss: 0.8881 - val_accuracy: 0.7450\n",
            "Epoch 1231/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6530 - accuracy: 0.7773 - val_loss: 0.7573 - val_accuracy: 0.7483\n",
            "Epoch 1232/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5876 - accuracy: 0.7785 - val_loss: 0.7082 - val_accuracy: 0.7642\n",
            "Epoch 1233/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5884 - accuracy: 0.7948 - val_loss: 0.7210 - val_accuracy: 0.7783\n",
            "Epoch 1234/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5786 - accuracy: 0.7925 - val_loss: 0.7048 - val_accuracy: 0.7667\n",
            "Epoch 1235/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5491 - accuracy: 0.8009 - val_loss: 0.7021 - val_accuracy: 0.7708\n",
            "Epoch 1236/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5405 - accuracy: 0.7956 - val_loss: 0.7022 - val_accuracy: 0.7750\n",
            "Epoch 1237/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5726 - accuracy: 0.7850 - val_loss: 0.7417 - val_accuracy: 0.7583\n",
            "Epoch 1238/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5590 - accuracy: 0.7961 - val_loss: 0.7129 - val_accuracy: 0.7633\n",
            "Epoch 1239/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5521 - accuracy: 0.7994 - val_loss: 0.6979 - val_accuracy: 0.7658\n",
            "Epoch 1240/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5529 - accuracy: 0.8028 - val_loss: 0.7236 - val_accuracy: 0.7592\n",
            "Epoch 1241/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5894 - accuracy: 0.7829 - val_loss: 0.7457 - val_accuracy: 0.7617\n",
            "Epoch 1242/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5693 - accuracy: 0.7942 - val_loss: 0.7148 - val_accuracy: 0.7650\n",
            "Epoch 1243/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5661 - accuracy: 0.7856 - val_loss: 0.7331 - val_accuracy: 0.7683\n",
            "Epoch 1244/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5714 - accuracy: 0.7845 - val_loss: 0.7270 - val_accuracy: 0.7667\n",
            "Epoch 1245/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5656 - accuracy: 0.7885 - val_loss: 0.7864 - val_accuracy: 0.7500\n",
            "Epoch 1246/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5724 - accuracy: 0.7906 - val_loss: 0.7288 - val_accuracy: 0.7708\n",
            "Epoch 1247/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5674 - accuracy: 0.7843 - val_loss: 0.7354 - val_accuracy: 0.7608\n",
            "Epoch 1248/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5524 - accuracy: 0.7948 - val_loss: 0.7295 - val_accuracy: 0.7675\n",
            "Epoch 1249/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5540 - accuracy: 0.7857 - val_loss: 0.7023 - val_accuracy: 0.7800\n",
            "Epoch 1250/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5661 - accuracy: 0.7866 - val_loss: 0.7333 - val_accuracy: 0.7583\n",
            "Epoch 1251/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5677 - accuracy: 0.7938 - val_loss: 0.7753 - val_accuracy: 0.7392\n",
            "Epoch 1252/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5868 - accuracy: 0.7799 - val_loss: 0.7442 - val_accuracy: 0.7508\n",
            "Epoch 1253/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5928 - accuracy: 0.7752 - val_loss: 0.7293 - val_accuracy: 0.7442\n",
            "Epoch 1254/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5483 - accuracy: 0.8031 - val_loss: 0.7367 - val_accuracy: 0.7675\n",
            "Epoch 1255/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5674 - accuracy: 0.7950 - val_loss: 0.7482 - val_accuracy: 0.7542\n",
            "Epoch 1256/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5623 - accuracy: 0.7902 - val_loss: 0.7119 - val_accuracy: 0.7692\n",
            "Epoch 1257/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5864 - accuracy: 0.7877 - val_loss: 0.7008 - val_accuracy: 0.7725\n",
            "Epoch 1258/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5441 - accuracy: 0.7979 - val_loss: 0.7283 - val_accuracy: 0.7767\n",
            "Epoch 1259/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5845 - accuracy: 0.7826 - val_loss: 0.7356 - val_accuracy: 0.7700\n",
            "Epoch 1260/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5918 - accuracy: 0.7816 - val_loss: 0.7310 - val_accuracy: 0.7608\n",
            "Epoch 1261/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5484 - accuracy: 0.7998 - val_loss: 0.7672 - val_accuracy: 0.7692\n",
            "Epoch 1262/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5955 - accuracy: 0.7807 - val_loss: 0.7225 - val_accuracy: 0.7717\n",
            "Epoch 1263/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5740 - accuracy: 0.7963 - val_loss: 0.7010 - val_accuracy: 0.7708\n",
            "Epoch 1264/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5623 - accuracy: 0.7973 - val_loss: 0.7614 - val_accuracy: 0.7542\n",
            "Epoch 1265/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5630 - accuracy: 0.7963 - val_loss: 0.6986 - val_accuracy: 0.7817\n",
            "Epoch 1266/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5622 - accuracy: 0.7977 - val_loss: 0.7419 - val_accuracy: 0.7550\n",
            "Epoch 1267/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6101 - accuracy: 0.7752 - val_loss: 0.7061 - val_accuracy: 0.7800\n",
            "Epoch 1268/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5725 - accuracy: 0.7948 - val_loss: 0.7609 - val_accuracy: 0.7783\n",
            "Epoch 1269/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6157 - accuracy: 0.7754 - val_loss: 0.7403 - val_accuracy: 0.7625\n",
            "Epoch 1270/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5795 - accuracy: 0.7820 - val_loss: 0.7562 - val_accuracy: 0.7592\n",
            "Epoch 1271/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5496 - accuracy: 0.7964 - val_loss: 0.7311 - val_accuracy: 0.7767\n",
            "Epoch 1272/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5709 - accuracy: 0.7941 - val_loss: 0.7004 - val_accuracy: 0.7733\n",
            "Epoch 1273/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5567 - accuracy: 0.8024 - val_loss: 0.7344 - val_accuracy: 0.7767\n",
            "Epoch 1274/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5901 - accuracy: 0.7852 - val_loss: 0.7412 - val_accuracy: 0.7692\n",
            "Epoch 1275/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5691 - accuracy: 0.7850 - val_loss: 0.7176 - val_accuracy: 0.7675\n",
            "Epoch 1276/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5721 - accuracy: 0.7907 - val_loss: 0.7157 - val_accuracy: 0.7633\n",
            "Epoch 1277/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5729 - accuracy: 0.7911 - val_loss: 0.7239 - val_accuracy: 0.7792\n",
            "Epoch 1278/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6135 - accuracy: 0.7758 - val_loss: 0.6929 - val_accuracy: 0.7700\n",
            "Epoch 1279/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5543 - accuracy: 0.7939 - val_loss: 0.7530 - val_accuracy: 0.7542\n",
            "Epoch 1280/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6016 - accuracy: 0.7883 - val_loss: 0.7126 - val_accuracy: 0.7817\n",
            "Epoch 1281/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5735 - accuracy: 0.7900 - val_loss: 0.7330 - val_accuracy: 0.7667\n",
            "Epoch 1282/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5969 - accuracy: 0.7783 - val_loss: 0.7011 - val_accuracy: 0.7692\n",
            "Epoch 1283/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5702 - accuracy: 0.7864 - val_loss: 0.7378 - val_accuracy: 0.7708\n",
            "Epoch 1284/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5690 - accuracy: 0.7894 - val_loss: 0.7364 - val_accuracy: 0.7667\n",
            "Epoch 1285/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5472 - accuracy: 0.8003 - val_loss: 0.7316 - val_accuracy: 0.7650\n",
            "Epoch 1286/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6050 - accuracy: 0.7800 - val_loss: 0.7129 - val_accuracy: 0.7808\n",
            "Epoch 1287/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5497 - accuracy: 0.8000 - val_loss: 0.6957 - val_accuracy: 0.7692\n",
            "Epoch 1288/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5393 - accuracy: 0.8117 - val_loss: 0.7604 - val_accuracy: 0.7533\n",
            "Epoch 1289/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5691 - accuracy: 0.7919 - val_loss: 0.7698 - val_accuracy: 0.7575\n",
            "Epoch 1290/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5637 - accuracy: 0.7937 - val_loss: 0.7346 - val_accuracy: 0.7750\n",
            "Epoch 1291/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5684 - accuracy: 0.7863 - val_loss: 0.7277 - val_accuracy: 0.7492\n",
            "Epoch 1292/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5439 - accuracy: 0.8013 - val_loss: 0.7357 - val_accuracy: 0.7592\n",
            "Epoch 1293/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5732 - accuracy: 0.7919 - val_loss: 0.7303 - val_accuracy: 0.7708\n",
            "Epoch 1294/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5902 - accuracy: 0.7922 - val_loss: 0.7468 - val_accuracy: 0.7575\n",
            "Epoch 1295/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5612 - accuracy: 0.7878 - val_loss: 0.7499 - val_accuracy: 0.7708\n",
            "Epoch 1296/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5710 - accuracy: 0.7901 - val_loss: 0.7347 - val_accuracy: 0.7650\n",
            "Epoch 1297/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5470 - accuracy: 0.7891 - val_loss: 0.7722 - val_accuracy: 0.7575\n",
            "Epoch 1298/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5786 - accuracy: 0.7902 - val_loss: 0.7215 - val_accuracy: 0.7667\n",
            "Epoch 1299/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5817 - accuracy: 0.7853 - val_loss: 0.7286 - val_accuracy: 0.7608\n",
            "Epoch 1300/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5570 - accuracy: 0.7838 - val_loss: 0.7554 - val_accuracy: 0.7642\n",
            "Epoch 1301/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5691 - accuracy: 0.7940 - val_loss: 0.7325 - val_accuracy: 0.7667\n",
            "Epoch 1302/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5491 - accuracy: 0.8030 - val_loss: 0.7564 - val_accuracy: 0.7525\n",
            "Epoch 1303/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5694 - accuracy: 0.7894 - val_loss: 0.7258 - val_accuracy: 0.7617\n",
            "Epoch 1304/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5675 - accuracy: 0.7952 - val_loss: 0.7524 - val_accuracy: 0.7625\n",
            "Epoch 1305/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5944 - accuracy: 0.7768 - val_loss: 0.7342 - val_accuracy: 0.7692\n",
            "Epoch 1306/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5754 - accuracy: 0.7910 - val_loss: 0.7726 - val_accuracy: 0.7617\n",
            "Epoch 1307/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5726 - accuracy: 0.7941 - val_loss: 0.7674 - val_accuracy: 0.7517\n",
            "Epoch 1308/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5521 - accuracy: 0.8006 - val_loss: 0.7270 - val_accuracy: 0.7825\n",
            "Epoch 1309/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5521 - accuracy: 0.7917 - val_loss: 0.7597 - val_accuracy: 0.7617\n",
            "Epoch 1310/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5702 - accuracy: 0.7889 - val_loss: 0.7208 - val_accuracy: 0.7608\n",
            "Epoch 1311/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5731 - accuracy: 0.7931 - val_loss: 0.7415 - val_accuracy: 0.7600\n",
            "Epoch 1312/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5469 - accuracy: 0.7999 - val_loss: 0.7487 - val_accuracy: 0.7658\n",
            "Epoch 1313/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5492 - accuracy: 0.8039 - val_loss: 0.7541 - val_accuracy: 0.7583\n",
            "Epoch 1314/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5615 - accuracy: 0.7987 - val_loss: 0.7520 - val_accuracy: 0.7558\n",
            "Epoch 1315/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5565 - accuracy: 0.7930 - val_loss: 0.7521 - val_accuracy: 0.7625\n",
            "Epoch 1316/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5840 - accuracy: 0.7885 - val_loss: 0.7376 - val_accuracy: 0.7742\n",
            "Epoch 1317/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5639 - accuracy: 0.8002 - val_loss: 0.7606 - val_accuracy: 0.7608\n",
            "Epoch 1318/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5987 - accuracy: 0.7752 - val_loss: 0.7578 - val_accuracy: 0.7642\n",
            "Epoch 1319/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5731 - accuracy: 0.7937 - val_loss: 0.7169 - val_accuracy: 0.7758\n",
            "Epoch 1320/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5691 - accuracy: 0.7950 - val_loss: 0.7329 - val_accuracy: 0.7758\n",
            "Epoch 1321/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5488 - accuracy: 0.8063 - val_loss: 0.7528 - val_accuracy: 0.7617\n",
            "Epoch 1322/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5534 - accuracy: 0.8048 - val_loss: 0.7427 - val_accuracy: 0.7583\n",
            "Epoch 1323/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5656 - accuracy: 0.7887 - val_loss: 0.7469 - val_accuracy: 0.7550\n",
            "Epoch 1324/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5623 - accuracy: 0.8025 - val_loss: 0.7117 - val_accuracy: 0.7775\n",
            "Epoch 1325/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5862 - accuracy: 0.7906 - val_loss: 0.7456 - val_accuracy: 0.7775\n",
            "Epoch 1326/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5859 - accuracy: 0.7718 - val_loss: 0.7108 - val_accuracy: 0.7783\n",
            "Epoch 1327/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5449 - accuracy: 0.8033 - val_loss: 0.7654 - val_accuracy: 0.7458\n",
            "Epoch 1328/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5802 - accuracy: 0.7827 - val_loss: 0.7677 - val_accuracy: 0.7425\n",
            "Epoch 1329/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5785 - accuracy: 0.7803 - val_loss: 0.7527 - val_accuracy: 0.7617\n",
            "Epoch 1330/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5446 - accuracy: 0.8004 - val_loss: 0.7168 - val_accuracy: 0.7858\n",
            "Epoch 1331/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5451 - accuracy: 0.8023 - val_loss: 0.7169 - val_accuracy: 0.7667\n",
            "Epoch 1332/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5495 - accuracy: 0.8011 - val_loss: 0.7402 - val_accuracy: 0.7600\n",
            "Epoch 1333/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5623 - accuracy: 0.7936 - val_loss: 0.7101 - val_accuracy: 0.7800\n",
            "Epoch 1334/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5437 - accuracy: 0.8069 - val_loss: 0.7188 - val_accuracy: 0.7758\n",
            "Epoch 1335/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5435 - accuracy: 0.7996 - val_loss: 0.7891 - val_accuracy: 0.7408\n",
            "Epoch 1336/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5781 - accuracy: 0.7933 - val_loss: 0.7121 - val_accuracy: 0.7775\n",
            "Epoch 1337/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5817 - accuracy: 0.7819 - val_loss: 0.7192 - val_accuracy: 0.7808\n",
            "Epoch 1338/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5512 - accuracy: 0.7995 - val_loss: 0.7366 - val_accuracy: 0.7750\n",
            "Epoch 1339/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.5524 - accuracy: 0.7947 - val_loss: 0.7528 - val_accuracy: 0.7792\n",
            "Epoch 1340/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5665 - accuracy: 0.7988 - val_loss: 0.8105 - val_accuracy: 0.7692\n",
            "Epoch 1341/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7128 - accuracy: 0.7865 - val_loss: 0.7407 - val_accuracy: 0.7683\n",
            "Epoch 1342/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5855 - accuracy: 0.7905 - val_loss: 0.7109 - val_accuracy: 0.7608\n",
            "Epoch 1343/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5318 - accuracy: 0.8051 - val_loss: 0.7346 - val_accuracy: 0.7500\n",
            "Epoch 1344/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5587 - accuracy: 0.7930 - val_loss: 0.7484 - val_accuracy: 0.7550\n",
            "Epoch 1345/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5799 - accuracy: 0.7881 - val_loss: 0.7146 - val_accuracy: 0.7725\n",
            "Epoch 1346/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5640 - accuracy: 0.7936 - val_loss: 0.7261 - val_accuracy: 0.7633\n",
            "Epoch 1347/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5731 - accuracy: 0.7939 - val_loss: 0.7321 - val_accuracy: 0.7717\n",
            "Epoch 1348/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5836 - accuracy: 0.7819 - val_loss: 0.7432 - val_accuracy: 0.7617\n",
            "Epoch 1349/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5883 - accuracy: 0.7816 - val_loss: 0.7282 - val_accuracy: 0.7725\n",
            "Epoch 1350/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5593 - accuracy: 0.7979 - val_loss: 0.7376 - val_accuracy: 0.7708\n",
            "Epoch 1351/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5845 - accuracy: 0.7894 - val_loss: 0.7375 - val_accuracy: 0.7717\n",
            "Epoch 1352/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5542 - accuracy: 0.7967 - val_loss: 0.7311 - val_accuracy: 0.7592\n",
            "Epoch 1353/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5657 - accuracy: 0.7952 - val_loss: 0.7225 - val_accuracy: 0.7808\n",
            "Epoch 1354/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5395 - accuracy: 0.7992 - val_loss: 0.7388 - val_accuracy: 0.7575\n",
            "Epoch 1355/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5532 - accuracy: 0.7995 - val_loss: 0.7360 - val_accuracy: 0.7617\n",
            "Epoch 1356/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5693 - accuracy: 0.7945 - val_loss: 0.7320 - val_accuracy: 0.7692\n",
            "Epoch 1357/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5694 - accuracy: 0.7863 - val_loss: 0.7799 - val_accuracy: 0.7425\n",
            "Epoch 1358/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5582 - accuracy: 0.7911 - val_loss: 0.7223 - val_accuracy: 0.7608\n",
            "Epoch 1359/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5423 - accuracy: 0.7981 - val_loss: 0.7364 - val_accuracy: 0.7767\n",
            "Epoch 1360/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5693 - accuracy: 0.7922 - val_loss: 0.7294 - val_accuracy: 0.7592\n",
            "Epoch 1361/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5494 - accuracy: 0.8017 - val_loss: 0.7262 - val_accuracy: 0.7725\n",
            "Epoch 1362/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5475 - accuracy: 0.8043 - val_loss: 0.7081 - val_accuracy: 0.7733\n",
            "Epoch 1363/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5631 - accuracy: 0.7829 - val_loss: 0.7144 - val_accuracy: 0.7742\n",
            "Epoch 1364/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5380 - accuracy: 0.7997 - val_loss: 0.7198 - val_accuracy: 0.7633\n",
            "Epoch 1365/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5545 - accuracy: 0.8027 - val_loss: 0.7194 - val_accuracy: 0.7667\n",
            "Epoch 1366/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5573 - accuracy: 0.7956 - val_loss: 0.7456 - val_accuracy: 0.7617\n",
            "Epoch 1367/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6156 - accuracy: 0.7820 - val_loss: 0.8086 - val_accuracy: 0.7583\n",
            "Epoch 1368/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5691 - accuracy: 0.7881 - val_loss: 0.7546 - val_accuracy: 0.7775\n",
            "Epoch 1369/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5825 - accuracy: 0.7918 - val_loss: 0.7515 - val_accuracy: 0.7600\n",
            "Epoch 1370/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5993 - accuracy: 0.7822 - val_loss: 0.7642 - val_accuracy: 0.7525\n",
            "Epoch 1371/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5849 - accuracy: 0.7832 - val_loss: 0.7395 - val_accuracy: 0.7850\n",
            "Epoch 1372/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5604 - accuracy: 0.7924 - val_loss: 0.7456 - val_accuracy: 0.7600\n",
            "Epoch 1373/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5701 - accuracy: 0.7903 - val_loss: 0.7418 - val_accuracy: 0.7658\n",
            "Epoch 1374/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5641 - accuracy: 0.7960 - val_loss: 0.7341 - val_accuracy: 0.7758\n",
            "Epoch 1375/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5313 - accuracy: 0.8084 - val_loss: 0.7339 - val_accuracy: 0.7692\n",
            "Epoch 1376/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5514 - accuracy: 0.7965 - val_loss: 0.7031 - val_accuracy: 0.7867\n",
            "Epoch 1377/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5515 - accuracy: 0.7973 - val_loss: 0.7695 - val_accuracy: 0.7558\n",
            "Epoch 1378/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5634 - accuracy: 0.7945 - val_loss: 0.7107 - val_accuracy: 0.7717\n",
            "Epoch 1379/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5673 - accuracy: 0.7919 - val_loss: 0.7199 - val_accuracy: 0.7642\n",
            "Epoch 1380/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5625 - accuracy: 0.7916 - val_loss: 0.7642 - val_accuracy: 0.7567\n",
            "Epoch 1381/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5665 - accuracy: 0.7940 - val_loss: 0.7345 - val_accuracy: 0.7567\n",
            "Epoch 1382/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5235 - accuracy: 0.8142 - val_loss: 0.7549 - val_accuracy: 0.7658\n",
            "Epoch 1383/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5466 - accuracy: 0.8052 - val_loss: 0.7547 - val_accuracy: 0.7683\n",
            "Epoch 1384/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5682 - accuracy: 0.7986 - val_loss: 0.7737 - val_accuracy: 0.7625\n",
            "Epoch 1385/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5490 - accuracy: 0.8020 - val_loss: 0.7351 - val_accuracy: 0.7650\n",
            "Epoch 1386/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5843 - accuracy: 0.7813 - val_loss: 0.7224 - val_accuracy: 0.7692\n",
            "Epoch 1387/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5498 - accuracy: 0.7979 - val_loss: 0.7411 - val_accuracy: 0.7550\n",
            "Epoch 1388/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5728 - accuracy: 0.7876 - val_loss: 0.7779 - val_accuracy: 0.7508\n",
            "Epoch 1389/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5834 - accuracy: 0.7778 - val_loss: 0.7509 - val_accuracy: 0.7625\n",
            "Epoch 1390/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5701 - accuracy: 0.7782 - val_loss: 0.7259 - val_accuracy: 0.7642\n",
            "Epoch 1391/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5568 - accuracy: 0.7955 - val_loss: 0.7049 - val_accuracy: 0.7617\n",
            "Epoch 1392/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5461 - accuracy: 0.7980 - val_loss: 0.7201 - val_accuracy: 0.7758\n",
            "Epoch 1393/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5425 - accuracy: 0.8031 - val_loss: 0.7496 - val_accuracy: 0.7567\n",
            "Epoch 1394/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5794 - accuracy: 0.7898 - val_loss: 0.7410 - val_accuracy: 0.7625\n",
            "Epoch 1395/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5800 - accuracy: 0.7814 - val_loss: 0.7706 - val_accuracy: 0.7642\n",
            "Epoch 1396/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5845 - accuracy: 0.7824 - val_loss: 0.7651 - val_accuracy: 0.7542\n",
            "Epoch 1397/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5695 - accuracy: 0.8032 - val_loss: 0.7384 - val_accuracy: 0.7692\n",
            "Epoch 1398/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5776 - accuracy: 0.7865 - val_loss: 0.7645 - val_accuracy: 0.7608\n",
            "Epoch 1399/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5532 - accuracy: 0.7976 - val_loss: 0.7619 - val_accuracy: 0.7617\n",
            "Epoch 1400/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5544 - accuracy: 0.7981 - val_loss: 0.7220 - val_accuracy: 0.7633\n",
            "Epoch 1401/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5412 - accuracy: 0.8025 - val_loss: 0.7660 - val_accuracy: 0.7567\n",
            "Epoch 1402/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5577 - accuracy: 0.7958 - val_loss: 0.7269 - val_accuracy: 0.7692\n",
            "Epoch 1403/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5350 - accuracy: 0.8036 - val_loss: 0.7422 - val_accuracy: 0.7642\n",
            "Epoch 1404/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5439 - accuracy: 0.8044 - val_loss: 0.7207 - val_accuracy: 0.7650\n",
            "Epoch 1405/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5473 - accuracy: 0.7962 - val_loss: 0.7234 - val_accuracy: 0.7925\n",
            "Epoch 1406/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5492 - accuracy: 0.8005 - val_loss: 0.7540 - val_accuracy: 0.7692\n",
            "Epoch 1407/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.5785 - accuracy: 0.7918 - val_loss: 0.7450 - val_accuracy: 0.7775\n",
            "Epoch 1408/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5570 - accuracy: 0.8000 - val_loss: 0.7923 - val_accuracy: 0.7633\n",
            "Epoch 1409/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6116 - accuracy: 0.7878 - val_loss: 0.7837 - val_accuracy: 0.7508\n",
            "Epoch 1410/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5646 - accuracy: 0.7933 - val_loss: 0.7779 - val_accuracy: 0.7617\n",
            "Epoch 1411/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5771 - accuracy: 0.7921 - val_loss: 0.7280 - val_accuracy: 0.7692\n",
            "Epoch 1412/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5644 - accuracy: 0.7968 - val_loss: 0.7430 - val_accuracy: 0.7642\n",
            "Epoch 1413/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5838 - accuracy: 0.7963 - val_loss: 0.7559 - val_accuracy: 0.7725\n",
            "Epoch 1414/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5906 - accuracy: 0.7885 - val_loss: 0.7197 - val_accuracy: 0.7675\n",
            "Epoch 1415/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5304 - accuracy: 0.8063 - val_loss: 0.7536 - val_accuracy: 0.7625\n",
            "Epoch 1416/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5582 - accuracy: 0.7990 - val_loss: 0.7818 - val_accuracy: 0.7617\n",
            "Epoch 1417/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5511 - accuracy: 0.7985 - val_loss: 0.7444 - val_accuracy: 0.7700\n",
            "Epoch 1418/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5438 - accuracy: 0.7944 - val_loss: 0.7388 - val_accuracy: 0.7800\n",
            "Epoch 1419/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5468 - accuracy: 0.8071 - val_loss: 0.7298 - val_accuracy: 0.7700\n",
            "Epoch 1420/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5627 - accuracy: 0.7889 - val_loss: 0.7433 - val_accuracy: 0.7675\n",
            "Epoch 1421/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5398 - accuracy: 0.8026 - val_loss: 0.7315 - val_accuracy: 0.7775\n",
            "Epoch 1422/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5388 - accuracy: 0.8108 - val_loss: 0.7269 - val_accuracy: 0.7717\n",
            "Epoch 1423/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5468 - accuracy: 0.7979 - val_loss: 0.7159 - val_accuracy: 0.7783\n",
            "Epoch 1424/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5864 - accuracy: 0.7896 - val_loss: 0.7438 - val_accuracy: 0.7667\n",
            "Epoch 1425/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5607 - accuracy: 0.8000 - val_loss: 0.7192 - val_accuracy: 0.7750\n",
            "Epoch 1426/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5750 - accuracy: 0.7901 - val_loss: 0.7308 - val_accuracy: 0.7717\n",
            "Epoch 1427/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5390 - accuracy: 0.8001 - val_loss: 0.7325 - val_accuracy: 0.7675\n",
            "Epoch 1428/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5425 - accuracy: 0.8039 - val_loss: 0.7455 - val_accuracy: 0.7767\n",
            "Epoch 1429/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5679 - accuracy: 0.7956 - val_loss: 0.7107 - val_accuracy: 0.7733\n",
            "Epoch 1430/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5566 - accuracy: 0.7840 - val_loss: 0.7599 - val_accuracy: 0.7708\n",
            "Epoch 1431/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5443 - accuracy: 0.7977 - val_loss: 0.7724 - val_accuracy: 0.7583\n",
            "Epoch 1432/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5790 - accuracy: 0.7804 - val_loss: 0.7537 - val_accuracy: 0.7567\n",
            "Epoch 1433/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5561 - accuracy: 0.7967 - val_loss: 0.7597 - val_accuracy: 0.7567\n",
            "Epoch 1434/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5761 - accuracy: 0.7805 - val_loss: 0.7631 - val_accuracy: 0.7633\n",
            "Epoch 1435/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5619 - accuracy: 0.7899 - val_loss: 0.7241 - val_accuracy: 0.7708\n",
            "Epoch 1436/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5727 - accuracy: 0.7923 - val_loss: 0.7310 - val_accuracy: 0.7708\n",
            "Epoch 1437/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.5676 - accuracy: 0.7988 - val_loss: 0.7608 - val_accuracy: 0.7750\n",
            "Epoch 1438/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5674 - accuracy: 0.7844 - val_loss: 0.7975 - val_accuracy: 0.7508\n",
            "Epoch 1439/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5903 - accuracy: 0.7850 - val_loss: 0.7793 - val_accuracy: 0.7650\n",
            "Epoch 1440/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5531 - accuracy: 0.7915 - val_loss: 0.7350 - val_accuracy: 0.7608\n",
            "Epoch 1441/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5376 - accuracy: 0.8003 - val_loss: 0.7609 - val_accuracy: 0.7675\n",
            "Epoch 1442/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5633 - accuracy: 0.7900 - val_loss: 0.7386 - val_accuracy: 0.7925\n",
            "Epoch 1443/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5866 - accuracy: 0.7825 - val_loss: 0.7255 - val_accuracy: 0.7892\n",
            "Epoch 1444/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5427 - accuracy: 0.8094 - val_loss: 0.7809 - val_accuracy: 0.7483\n",
            "Epoch 1445/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5594 - accuracy: 0.7945 - val_loss: 0.7758 - val_accuracy: 0.7633\n",
            "Epoch 1446/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5496 - accuracy: 0.7925 - val_loss: 0.7699 - val_accuracy: 0.7542\n",
            "Epoch 1447/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5772 - accuracy: 0.7872 - val_loss: 0.7359 - val_accuracy: 0.7667\n",
            "Epoch 1448/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5514 - accuracy: 0.7990 - val_loss: 0.7662 - val_accuracy: 0.7558\n",
            "Epoch 1449/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5467 - accuracy: 0.7992 - val_loss: 0.7512 - val_accuracy: 0.7683\n",
            "Epoch 1450/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5386 - accuracy: 0.8059 - val_loss: 0.7467 - val_accuracy: 0.7667\n",
            "Epoch 1451/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5447 - accuracy: 0.8045 - val_loss: 0.7295 - val_accuracy: 0.7692\n",
            "Epoch 1452/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5753 - accuracy: 0.7913 - val_loss: 0.7968 - val_accuracy: 0.7508\n",
            "Epoch 1453/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5729 - accuracy: 0.7883 - val_loss: 0.7603 - val_accuracy: 0.7650\n",
            "Epoch 1454/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5459 - accuracy: 0.8030 - val_loss: 0.7427 - val_accuracy: 0.7742\n",
            "Epoch 1455/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5884 - accuracy: 0.7796 - val_loss: 0.7559 - val_accuracy: 0.7733\n",
            "Epoch 1456/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5684 - accuracy: 0.7913 - val_loss: 0.7407 - val_accuracy: 0.7792\n",
            "Epoch 1457/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5515 - accuracy: 0.7944 - val_loss: 0.7614 - val_accuracy: 0.7683\n",
            "Epoch 1458/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5419 - accuracy: 0.7977 - val_loss: 0.7988 - val_accuracy: 0.7475\n",
            "Epoch 1459/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5935 - accuracy: 0.7831 - val_loss: 0.7613 - val_accuracy: 0.7658\n",
            "Epoch 1460/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5651 - accuracy: 0.7871 - val_loss: 0.7529 - val_accuracy: 0.7717\n",
            "Epoch 1461/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5634 - accuracy: 0.7883 - val_loss: 0.7347 - val_accuracy: 0.7767\n",
            "Epoch 1462/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5694 - accuracy: 0.7831 - val_loss: 0.7448 - val_accuracy: 0.7775\n",
            "Epoch 1463/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5450 - accuracy: 0.8026 - val_loss: 0.7258 - val_accuracy: 0.7767\n",
            "Epoch 1464/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5409 - accuracy: 0.8007 - val_loss: 0.7250 - val_accuracy: 0.7650\n",
            "Epoch 1465/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.5231 - accuracy: 0.8150 - val_loss: 0.7557 - val_accuracy: 0.7725\n",
            "Epoch 1466/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5717 - accuracy: 0.7917 - val_loss: 0.7854 - val_accuracy: 0.7425\n",
            "Epoch 1467/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5887 - accuracy: 0.7803 - val_loss: 0.7982 - val_accuracy: 0.7483\n",
            "Epoch 1468/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5561 - accuracy: 0.7907 - val_loss: 0.7204 - val_accuracy: 0.7783\n",
            "Epoch 1469/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5284 - accuracy: 0.8050 - val_loss: 0.7499 - val_accuracy: 0.7725\n",
            "Epoch 1470/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5499 - accuracy: 0.8027 - val_loss: 0.7630 - val_accuracy: 0.7675\n",
            "Epoch 1471/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5696 - accuracy: 0.7904 - val_loss: 0.7686 - val_accuracy: 0.7650\n",
            "Epoch 1472/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5404 - accuracy: 0.8064 - val_loss: 0.7893 - val_accuracy: 0.7542\n",
            "Epoch 1473/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5731 - accuracy: 0.7831 - val_loss: 0.7106 - val_accuracy: 0.7833\n",
            "Epoch 1474/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5540 - accuracy: 0.7890 - val_loss: 0.7863 - val_accuracy: 0.7592\n",
            "Epoch 1475/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5862 - accuracy: 0.7818 - val_loss: 0.7438 - val_accuracy: 0.7617\n",
            "Epoch 1476/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5822 - accuracy: 0.7881 - val_loss: 0.7702 - val_accuracy: 0.7500\n",
            "Epoch 1477/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5475 - accuracy: 0.7913 - val_loss: 0.7316 - val_accuracy: 0.7683\n",
            "Epoch 1478/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5713 - accuracy: 0.7854 - val_loss: 0.7531 - val_accuracy: 0.7800\n",
            "Epoch 1479/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5684 - accuracy: 0.7878 - val_loss: 0.7880 - val_accuracy: 0.7450\n",
            "Epoch 1480/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5662 - accuracy: 0.7808 - val_loss: 0.7850 - val_accuracy: 0.7683\n",
            "Epoch 1481/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5550 - accuracy: 0.7959 - val_loss: 0.7469 - val_accuracy: 0.7750\n",
            "Epoch 1482/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5341 - accuracy: 0.8106 - val_loss: 0.7641 - val_accuracy: 0.7625\n",
            "Epoch 1483/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5446 - accuracy: 0.7976 - val_loss: 0.7364 - val_accuracy: 0.7833\n",
            "Epoch 1484/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5467 - accuracy: 0.7977 - val_loss: 0.7801 - val_accuracy: 0.7608\n",
            "Epoch 1485/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5458 - accuracy: 0.7994 - val_loss: 0.7500 - val_accuracy: 0.7717\n",
            "Epoch 1486/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5685 - accuracy: 0.7840 - val_loss: 0.7703 - val_accuracy: 0.7758\n",
            "Epoch 1487/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5772 - accuracy: 0.7909 - val_loss: 0.7357 - val_accuracy: 0.7708\n",
            "Epoch 1488/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5730 - accuracy: 0.7903 - val_loss: 0.7637 - val_accuracy: 0.7650\n",
            "Epoch 1489/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5709 - accuracy: 0.7963 - val_loss: 0.7683 - val_accuracy: 0.7658\n",
            "Epoch 1490/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5673 - accuracy: 0.7917 - val_loss: 0.7361 - val_accuracy: 0.7642\n",
            "Epoch 1491/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5396 - accuracy: 0.8023 - val_loss: 0.7360 - val_accuracy: 0.7633\n",
            "Epoch 1492/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5573 - accuracy: 0.7942 - val_loss: 0.7764 - val_accuracy: 0.7567\n",
            "Epoch 1493/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5717 - accuracy: 0.7902 - val_loss: 0.7571 - val_accuracy: 0.7717\n",
            "Epoch 1494/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5599 - accuracy: 0.7985 - val_loss: 0.7390 - val_accuracy: 0.7858\n",
            "Epoch 1495/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5317 - accuracy: 0.8035 - val_loss: 0.7958 - val_accuracy: 0.7483\n",
            "Epoch 1496/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5491 - accuracy: 0.7972 - val_loss: 0.7630 - val_accuracy: 0.7667\n",
            "Epoch 1497/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5513 - accuracy: 0.8053 - val_loss: 0.7503 - val_accuracy: 0.7775\n",
            "Epoch 1498/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5502 - accuracy: 0.7948 - val_loss: 0.7967 - val_accuracy: 0.7583\n",
            "Epoch 1499/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5915 - accuracy: 0.7903 - val_loss: 0.7665 - val_accuracy: 0.7667\n",
            "Epoch 1500/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5719 - accuracy: 0.7869 - val_loss: 0.8376 - val_accuracy: 0.7492\n",
            "Epoch 1501/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5978 - accuracy: 0.7836 - val_loss: 0.7703 - val_accuracy: 0.7658\n",
            "Epoch 1502/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5452 - accuracy: 0.7997 - val_loss: 0.7399 - val_accuracy: 0.7733\n",
            "Epoch 1503/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5460 - accuracy: 0.7977 - val_loss: 0.7503 - val_accuracy: 0.7575\n",
            "Epoch 1504/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5387 - accuracy: 0.8004 - val_loss: 0.7643 - val_accuracy: 0.7650\n",
            "Epoch 1505/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5518 - accuracy: 0.7997 - val_loss: 0.7468 - val_accuracy: 0.7733\n",
            "Epoch 1506/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5403 - accuracy: 0.8066 - val_loss: 0.7436 - val_accuracy: 0.7675\n",
            "Epoch 1507/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5444 - accuracy: 0.7967 - val_loss: 0.7546 - val_accuracy: 0.7583\n",
            "Epoch 1508/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5496 - accuracy: 0.7897 - val_loss: 0.7465 - val_accuracy: 0.7800\n",
            "Epoch 1509/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5341 - accuracy: 0.8019 - val_loss: 0.7253 - val_accuracy: 0.7675\n",
            "Epoch 1510/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5428 - accuracy: 0.8008 - val_loss: 0.7483 - val_accuracy: 0.7775\n",
            "Epoch 1511/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5500 - accuracy: 0.8002 - val_loss: 0.7466 - val_accuracy: 0.7833\n",
            "Epoch 1512/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5576 - accuracy: 0.7894 - val_loss: 0.7589 - val_accuracy: 0.7767\n",
            "Epoch 1513/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5395 - accuracy: 0.8059 - val_loss: 0.7630 - val_accuracy: 0.7633\n",
            "Epoch 1514/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5594 - accuracy: 0.7949 - val_loss: 0.8069 - val_accuracy: 0.7525\n",
            "Epoch 1515/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5595 - accuracy: 0.7971 - val_loss: 0.7447 - val_accuracy: 0.7792\n",
            "Epoch 1516/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5343 - accuracy: 0.8015 - val_loss: 0.7617 - val_accuracy: 0.7642\n",
            "Epoch 1517/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5315 - accuracy: 0.8051 - val_loss: 0.7476 - val_accuracy: 0.7742\n",
            "Epoch 1518/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5554 - accuracy: 0.7929 - val_loss: 0.7448 - val_accuracy: 0.7800\n",
            "Epoch 1519/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5229 - accuracy: 0.8108 - val_loss: 0.7267 - val_accuracy: 0.7783\n",
            "Epoch 1520/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5467 - accuracy: 0.7952 - val_loss: 0.7730 - val_accuracy: 0.7825\n",
            "Epoch 1521/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5614 - accuracy: 0.7926 - val_loss: 0.8019 - val_accuracy: 0.7600\n",
            "Epoch 1522/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5664 - accuracy: 0.7932 - val_loss: 0.7777 - val_accuracy: 0.7617\n",
            "Epoch 1523/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5529 - accuracy: 0.7928 - val_loss: 0.8332 - val_accuracy: 0.7533\n",
            "Epoch 1524/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5840 - accuracy: 0.7911 - val_loss: 0.7682 - val_accuracy: 0.7700\n",
            "Epoch 1525/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5643 - accuracy: 0.7901 - val_loss: 0.7901 - val_accuracy: 0.7550\n",
            "Epoch 1526/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5438 - accuracy: 0.8022 - val_loss: 0.7582 - val_accuracy: 0.7683\n",
            "Epoch 1527/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5743 - accuracy: 0.7927 - val_loss: 0.7492 - val_accuracy: 0.7792\n",
            "Epoch 1528/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5515 - accuracy: 0.7968 - val_loss: 0.7520 - val_accuracy: 0.7767\n",
            "Epoch 1529/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5372 - accuracy: 0.8130 - val_loss: 0.7639 - val_accuracy: 0.7692\n",
            "Epoch 1530/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5665 - accuracy: 0.8023 - val_loss: 0.7895 - val_accuracy: 0.7583\n",
            "Epoch 1531/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5752 - accuracy: 0.7910 - val_loss: 0.7483 - val_accuracy: 0.7708\n",
            "Epoch 1532/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5582 - accuracy: 0.7897 - val_loss: 0.7707 - val_accuracy: 0.7583\n",
            "Epoch 1533/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5385 - accuracy: 0.8033 - val_loss: 0.7702 - val_accuracy: 0.7675\n",
            "Epoch 1534/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5344 - accuracy: 0.8072 - val_loss: 0.7437 - val_accuracy: 0.7775\n",
            "Epoch 1535/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5474 - accuracy: 0.7979 - val_loss: 0.7382 - val_accuracy: 0.7692\n",
            "Epoch 1536/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5258 - accuracy: 0.8007 - val_loss: 0.7542 - val_accuracy: 0.7733\n",
            "Epoch 1537/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5464 - accuracy: 0.7992 - val_loss: 0.7632 - val_accuracy: 0.7692\n",
            "Epoch 1538/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5696 - accuracy: 0.7825 - val_loss: 0.7736 - val_accuracy: 0.7658\n",
            "Epoch 1539/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5616 - accuracy: 0.8045 - val_loss: 0.7427 - val_accuracy: 0.7825\n",
            "Epoch 1540/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5569 - accuracy: 0.8005 - val_loss: 0.7300 - val_accuracy: 0.7742\n",
            "Epoch 1541/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5309 - accuracy: 0.8068 - val_loss: 0.7315 - val_accuracy: 0.7817\n",
            "Epoch 1542/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5609 - accuracy: 0.7980 - val_loss: 0.7595 - val_accuracy: 0.7708\n",
            "Epoch 1543/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5809 - accuracy: 0.7800 - val_loss: 0.7795 - val_accuracy: 0.7675\n",
            "Epoch 1544/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5429 - accuracy: 0.7954 - val_loss: 0.7788 - val_accuracy: 0.7708\n",
            "Epoch 1545/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5678 - accuracy: 0.7940 - val_loss: 0.7496 - val_accuracy: 0.7575\n",
            "Epoch 1546/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5266 - accuracy: 0.8117 - val_loss: 0.7485 - val_accuracy: 0.7725\n",
            "Epoch 1547/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5508 - accuracy: 0.7860 - val_loss: 0.7450 - val_accuracy: 0.7775\n",
            "Epoch 1548/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5404 - accuracy: 0.7980 - val_loss: 0.7722 - val_accuracy: 0.7700\n",
            "Epoch 1549/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5556 - accuracy: 0.8016 - val_loss: 0.7685 - val_accuracy: 0.7683\n",
            "Epoch 1550/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5533 - accuracy: 0.8041 - val_loss: 0.7356 - val_accuracy: 0.7742\n",
            "Epoch 1551/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5357 - accuracy: 0.8117 - val_loss: 0.7677 - val_accuracy: 0.7817\n",
            "Epoch 1552/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5478 - accuracy: 0.7983 - val_loss: 0.7504 - val_accuracy: 0.7625\n",
            "Epoch 1553/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5383 - accuracy: 0.8093 - val_loss: 0.7994 - val_accuracy: 0.7567\n",
            "Epoch 1554/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5837 - accuracy: 0.7793 - val_loss: 0.7483 - val_accuracy: 0.7658\n",
            "Epoch 1555/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5629 - accuracy: 0.7930 - val_loss: 0.7545 - val_accuracy: 0.7733\n",
            "Epoch 1556/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5479 - accuracy: 0.7926 - val_loss: 0.7513 - val_accuracy: 0.7842\n",
            "Epoch 1557/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5572 - accuracy: 0.7971 - val_loss: 0.7576 - val_accuracy: 0.7633\n",
            "Epoch 1558/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5809 - accuracy: 0.7878 - val_loss: 0.8201 - val_accuracy: 0.7550\n",
            "Epoch 1559/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5349 - accuracy: 0.8039 - val_loss: 0.7789 - val_accuracy: 0.7517\n",
            "Epoch 1560/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5792 - accuracy: 0.7891 - val_loss: 0.7513 - val_accuracy: 0.7633\n",
            "Epoch 1561/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5341 - accuracy: 0.8048 - val_loss: 0.9448 - val_accuracy: 0.7558\n",
            "Epoch 1562/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7463 - accuracy: 0.7777 - val_loss: 0.8321 - val_accuracy: 0.7583\n",
            "Epoch 1563/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5838 - accuracy: 0.7961 - val_loss: 0.7250 - val_accuracy: 0.7792\n",
            "Epoch 1564/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5503 - accuracy: 0.7880 - val_loss: 0.7369 - val_accuracy: 0.7692\n",
            "Epoch 1565/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5404 - accuracy: 0.7976 - val_loss: 0.7384 - val_accuracy: 0.7708\n",
            "Epoch 1566/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5423 - accuracy: 0.8005 - val_loss: 0.7344 - val_accuracy: 0.7783\n",
            "Epoch 1567/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5285 - accuracy: 0.8135 - val_loss: 0.7387 - val_accuracy: 0.7717\n",
            "Epoch 1568/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5355 - accuracy: 0.8035 - val_loss: 0.8108 - val_accuracy: 0.7650\n",
            "Epoch 1569/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6031 - accuracy: 0.7785 - val_loss: 0.7255 - val_accuracy: 0.7658\n",
            "Epoch 1570/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5178 - accuracy: 0.8045 - val_loss: 0.7485 - val_accuracy: 0.7625\n",
            "Epoch 1571/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5356 - accuracy: 0.7974 - val_loss: 0.7868 - val_accuracy: 0.7517\n",
            "Epoch 1572/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5477 - accuracy: 0.7923 - val_loss: 0.7542 - val_accuracy: 0.7767\n",
            "Epoch 1573/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5433 - accuracy: 0.7974 - val_loss: 0.7299 - val_accuracy: 0.7792\n",
            "Epoch 1574/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5320 - accuracy: 0.8066 - val_loss: 0.7945 - val_accuracy: 0.7517\n",
            "Epoch 1575/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5602 - accuracy: 0.7856 - val_loss: 0.7559 - val_accuracy: 0.7583\n",
            "Epoch 1576/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5511 - accuracy: 0.8044 - val_loss: 0.7700 - val_accuracy: 0.7692\n",
            "Epoch 1577/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5422 - accuracy: 0.7972 - val_loss: 0.7425 - val_accuracy: 0.7858\n",
            "Epoch 1578/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5492 - accuracy: 0.8010 - val_loss: 0.7321 - val_accuracy: 0.7717\n",
            "Epoch 1579/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5387 - accuracy: 0.8010 - val_loss: 0.7412 - val_accuracy: 0.7683\n",
            "Epoch 1580/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5409 - accuracy: 0.8028 - val_loss: 0.7638 - val_accuracy: 0.7658\n",
            "Epoch 1581/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5345 - accuracy: 0.7969 - val_loss: 0.7846 - val_accuracy: 0.7608\n",
            "Epoch 1582/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5342 - accuracy: 0.8047 - val_loss: 0.7482 - val_accuracy: 0.7658\n",
            "Epoch 1583/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5465 - accuracy: 0.7935 - val_loss: 0.7398 - val_accuracy: 0.7758\n",
            "Epoch 1584/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5364 - accuracy: 0.7982 - val_loss: 0.7522 - val_accuracy: 0.7550\n",
            "Epoch 1585/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5352 - accuracy: 0.8016 - val_loss: 0.7902 - val_accuracy: 0.7708\n",
            "Epoch 1586/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5457 - accuracy: 0.7988 - val_loss: 0.7280 - val_accuracy: 0.7892\n",
            "Epoch 1587/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5108 - accuracy: 0.8114 - val_loss: 0.8190 - val_accuracy: 0.7542\n",
            "Epoch 1588/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5441 - accuracy: 0.7889 - val_loss: 0.8008 - val_accuracy: 0.7500\n",
            "Epoch 1589/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5791 - accuracy: 0.7907 - val_loss: 0.8348 - val_accuracy: 0.7483\n",
            "Epoch 1590/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5630 - accuracy: 0.7918 - val_loss: 0.7632 - val_accuracy: 0.7642\n",
            "Epoch 1591/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.8080 - val_loss: 0.7599 - val_accuracy: 0.7733\n",
            "Epoch 1592/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5603 - accuracy: 0.7927 - val_loss: 0.7530 - val_accuracy: 0.7800\n",
            "Epoch 1593/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5371 - accuracy: 0.8059 - val_loss: 0.7415 - val_accuracy: 0.7725\n",
            "Epoch 1594/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5415 - accuracy: 0.8076 - val_loss: 0.7630 - val_accuracy: 0.7600\n",
            "Epoch 1595/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5611 - accuracy: 0.7919 - val_loss: 0.7242 - val_accuracy: 0.7767\n",
            "Epoch 1596/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5416 - accuracy: 0.8092 - val_loss: 0.7429 - val_accuracy: 0.7692\n",
            "Epoch 1597/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5418 - accuracy: 0.8055 - val_loss: 0.7685 - val_accuracy: 0.7625\n",
            "Epoch 1598/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5299 - accuracy: 0.8017 - val_loss: 0.7702 - val_accuracy: 0.7633\n",
            "Epoch 1599/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5147 - accuracy: 0.8126 - val_loss: 0.7619 - val_accuracy: 0.7575\n",
            "Epoch 1600/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5540 - accuracy: 0.7894 - val_loss: 0.7556 - val_accuracy: 0.7733\n",
            "Epoch 1601/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5256 - accuracy: 0.8031 - val_loss: 0.7684 - val_accuracy: 0.7575\n",
            "Epoch 1602/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5461 - accuracy: 0.8049 - val_loss: 0.7665 - val_accuracy: 0.7683\n",
            "Epoch 1603/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5233 - accuracy: 0.8013 - val_loss: 0.8049 - val_accuracy: 0.7550\n",
            "Epoch 1604/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5523 - accuracy: 0.7904 - val_loss: 0.7350 - val_accuracy: 0.7742\n",
            "Epoch 1605/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5278 - accuracy: 0.8066 - val_loss: 0.7893 - val_accuracy: 0.7617\n",
            "Epoch 1606/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5450 - accuracy: 0.7964 - val_loss: 0.7446 - val_accuracy: 0.7683\n",
            "Epoch 1607/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5537 - accuracy: 0.8012 - val_loss: 0.8016 - val_accuracy: 0.7533\n",
            "Epoch 1608/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5515 - accuracy: 0.7983 - val_loss: 0.7437 - val_accuracy: 0.7742\n",
            "Epoch 1609/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5169 - accuracy: 0.8096 - val_loss: 0.7568 - val_accuracy: 0.7667\n",
            "Epoch 1610/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.5356 - accuracy: 0.7970 - val_loss: 0.7466 - val_accuracy: 0.7567\n",
            "Epoch 1611/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5478 - accuracy: 0.7973 - val_loss: 0.7770 - val_accuracy: 0.7658\n",
            "Epoch 1612/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5683 - accuracy: 0.7879 - val_loss: 0.7614 - val_accuracy: 0.7642\n",
            "Epoch 1613/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5490 - accuracy: 0.7985 - val_loss: 0.7425 - val_accuracy: 0.7808\n",
            "Epoch 1614/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5423 - accuracy: 0.7997 - val_loss: 0.7947 - val_accuracy: 0.7525\n",
            "Epoch 1615/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5352 - accuracy: 0.8021 - val_loss: 0.7436 - val_accuracy: 0.7800\n",
            "Epoch 1616/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5137 - accuracy: 0.8057 - val_loss: 0.7699 - val_accuracy: 0.7767\n",
            "Epoch 1617/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5295 - accuracy: 0.8025 - val_loss: 0.7764 - val_accuracy: 0.7683\n",
            "Epoch 1618/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5711 - accuracy: 0.7911 - val_loss: 0.7458 - val_accuracy: 0.7750\n",
            "Epoch 1619/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5580 - accuracy: 0.7929 - val_loss: 0.7667 - val_accuracy: 0.7717\n",
            "Epoch 1620/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5585 - accuracy: 0.8010 - val_loss: 0.7273 - val_accuracy: 0.7725\n",
            "Epoch 1621/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5214 - accuracy: 0.8046 - val_loss: 0.7389 - val_accuracy: 0.7825\n",
            "Epoch 1622/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5388 - accuracy: 0.7991 - val_loss: 0.7420 - val_accuracy: 0.7725\n",
            "Epoch 1623/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5258 - accuracy: 0.8068 - val_loss: 0.7985 - val_accuracy: 0.7658\n",
            "Epoch 1624/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5875 - accuracy: 0.7872 - val_loss: 0.7288 - val_accuracy: 0.7817\n",
            "Epoch 1625/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5492 - accuracy: 0.7990 - val_loss: 0.7715 - val_accuracy: 0.7667\n",
            "Epoch 1626/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5494 - accuracy: 0.7925 - val_loss: 0.7470 - val_accuracy: 0.7608\n",
            "Epoch 1627/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5631 - accuracy: 0.7877 - val_loss: 0.7496 - val_accuracy: 0.7742\n",
            "Epoch 1628/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5531 - accuracy: 0.7883 - val_loss: 0.7588 - val_accuracy: 0.7592\n",
            "Epoch 1629/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5406 - accuracy: 0.8116 - val_loss: 0.7766 - val_accuracy: 0.7800\n",
            "Epoch 1630/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5321 - accuracy: 0.8074 - val_loss: 0.7631 - val_accuracy: 0.7758\n",
            "Epoch 1631/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5555 - accuracy: 0.8016 - val_loss: 0.7675 - val_accuracy: 0.7592\n",
            "Epoch 1632/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5536 - accuracy: 0.8020 - val_loss: 0.7664 - val_accuracy: 0.7758\n",
            "Epoch 1633/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5465 - accuracy: 0.7971 - val_loss: 0.7396 - val_accuracy: 0.7750\n",
            "Epoch 1634/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5869 - accuracy: 0.7865 - val_loss: 0.8059 - val_accuracy: 0.7550\n",
            "Epoch 1635/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5423 - accuracy: 0.8030 - val_loss: 0.7361 - val_accuracy: 0.7750\n",
            "Epoch 1636/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5309 - accuracy: 0.8035 - val_loss: 0.7382 - val_accuracy: 0.7867\n",
            "Epoch 1637/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5322 - accuracy: 0.8121 - val_loss: 0.7509 - val_accuracy: 0.7692\n",
            "Epoch 1638/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5362 - accuracy: 0.7950 - val_loss: 0.7768 - val_accuracy: 0.7783\n",
            "Epoch 1639/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5452 - accuracy: 0.8065 - val_loss: 0.7497 - val_accuracy: 0.7625\n",
            "Epoch 1640/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5244 - accuracy: 0.8086 - val_loss: 0.7963 - val_accuracy: 0.7400\n",
            "Epoch 1641/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5755 - accuracy: 0.7895 - val_loss: 0.7718 - val_accuracy: 0.7725\n",
            "Epoch 1642/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5375 - accuracy: 0.7982 - val_loss: 0.7749 - val_accuracy: 0.7700\n",
            "Epoch 1643/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5352 - accuracy: 0.8051 - val_loss: 0.7821 - val_accuracy: 0.7717\n",
            "Epoch 1644/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5385 - accuracy: 0.8024 - val_loss: 0.8234 - val_accuracy: 0.7642\n",
            "Epoch 1645/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5698 - accuracy: 0.8000 - val_loss: 0.7602 - val_accuracy: 0.7700\n",
            "Epoch 1646/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5339 - accuracy: 0.7966 - val_loss: 0.7772 - val_accuracy: 0.7567\n",
            "Epoch 1647/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5587 - accuracy: 0.8061 - val_loss: 0.7610 - val_accuracy: 0.7758\n",
            "Epoch 1648/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5466 - accuracy: 0.7924 - val_loss: 0.7700 - val_accuracy: 0.7717\n",
            "Epoch 1649/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5026 - accuracy: 0.8204 - val_loss: 0.7351 - val_accuracy: 0.7717\n",
            "Epoch 1650/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5343 - accuracy: 0.7961 - val_loss: 0.7446 - val_accuracy: 0.7875\n",
            "Epoch 1651/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5417 - accuracy: 0.8000 - val_loss: 0.7962 - val_accuracy: 0.7625\n",
            "Epoch 1652/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5777 - accuracy: 0.7908 - val_loss: 0.8007 - val_accuracy: 0.7558\n",
            "Epoch 1653/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5590 - accuracy: 0.7872 - val_loss: 0.8303 - val_accuracy: 0.7467\n",
            "Epoch 1654/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5336 - accuracy: 0.8029 - val_loss: 0.7800 - val_accuracy: 0.7567\n",
            "Epoch 1655/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5600 - accuracy: 0.7955 - val_loss: 0.7839 - val_accuracy: 0.7683\n",
            "Epoch 1656/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5395 - accuracy: 0.7963 - val_loss: 0.7597 - val_accuracy: 0.7758\n",
            "Epoch 1657/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5466 - accuracy: 0.7977 - val_loss: 0.7821 - val_accuracy: 0.7583\n",
            "Epoch 1658/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.5663 - accuracy: 0.7933 - val_loss: 0.7904 - val_accuracy: 0.7758\n",
            "Epoch 1659/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5328 - accuracy: 0.8068 - val_loss: 0.7714 - val_accuracy: 0.7642\n",
            "Epoch 1660/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5396 - accuracy: 0.8051 - val_loss: 0.7642 - val_accuracy: 0.7642\n",
            "Epoch 1661/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5623 - accuracy: 0.7916 - val_loss: 0.8552 - val_accuracy: 0.7583\n",
            "Epoch 1662/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5344 - accuracy: 0.8140 - val_loss: 0.8015 - val_accuracy: 0.7575\n",
            "Epoch 1663/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5281 - accuracy: 0.7883 - val_loss: 0.7682 - val_accuracy: 0.7775\n",
            "Epoch 1664/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5546 - accuracy: 0.7916 - val_loss: 0.7585 - val_accuracy: 0.7775\n",
            "Epoch 1665/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5573 - accuracy: 0.7999 - val_loss: 0.7649 - val_accuracy: 0.7692\n",
            "Epoch 1666/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5556 - accuracy: 0.7979 - val_loss: 0.8012 - val_accuracy: 0.7650\n",
            "Epoch 1667/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5236 - accuracy: 0.8114 - val_loss: 0.7598 - val_accuracy: 0.7700\n",
            "Epoch 1668/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5502 - accuracy: 0.7959 - val_loss: 0.7411 - val_accuracy: 0.7833\n",
            "Epoch 1669/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5233 - accuracy: 0.8103 - val_loss: 0.7639 - val_accuracy: 0.7683\n",
            "Epoch 1670/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5454 - accuracy: 0.8000 - val_loss: 0.7537 - val_accuracy: 0.7808\n",
            "Epoch 1671/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5277 - accuracy: 0.8052 - val_loss: 0.7620 - val_accuracy: 0.7725\n",
            "Epoch 1672/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5227 - accuracy: 0.8177 - val_loss: 0.7410 - val_accuracy: 0.7808\n",
            "Epoch 1673/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5545 - accuracy: 0.7971 - val_loss: 0.7613 - val_accuracy: 0.7858\n",
            "Epoch 1674/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5539 - accuracy: 0.8020 - val_loss: 0.8013 - val_accuracy: 0.7650\n",
            "Epoch 1675/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5563 - accuracy: 0.7949 - val_loss: 0.7275 - val_accuracy: 0.7950\n",
            "Epoch 1676/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5464 - accuracy: 0.8002 - val_loss: 0.7862 - val_accuracy: 0.7683\n",
            "Epoch 1677/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5784 - accuracy: 0.7852 - val_loss: 0.8010 - val_accuracy: 0.7542\n",
            "Epoch 1678/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5426 - accuracy: 0.7899 - val_loss: 0.7870 - val_accuracy: 0.7683\n",
            "Epoch 1679/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5484 - accuracy: 0.7925 - val_loss: 0.7731 - val_accuracy: 0.7667\n",
            "Epoch 1680/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5481 - accuracy: 0.7996 - val_loss: 0.7380 - val_accuracy: 0.7892\n",
            "Epoch 1681/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5029 - accuracy: 0.8180 - val_loss: 0.7488 - val_accuracy: 0.7675\n",
            "Epoch 1682/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5370 - accuracy: 0.7958 - val_loss: 0.7729 - val_accuracy: 0.7633\n",
            "Epoch 1683/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5551 - accuracy: 0.7965 - val_loss: 0.7734 - val_accuracy: 0.7617\n",
            "Epoch 1684/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5197 - accuracy: 0.8108 - val_loss: 0.7664 - val_accuracy: 0.7792\n",
            "Epoch 1685/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5102 - accuracy: 0.8184 - val_loss: 0.7563 - val_accuracy: 0.7658\n",
            "Epoch 1686/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5380 - accuracy: 0.8067 - val_loss: 0.7505 - val_accuracy: 0.7750\n",
            "Epoch 1687/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5548 - accuracy: 0.7965 - val_loss: 0.7570 - val_accuracy: 0.7750\n",
            "Epoch 1688/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5455 - accuracy: 0.8012 - val_loss: 0.7808 - val_accuracy: 0.7783\n",
            "Epoch 1689/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5499 - accuracy: 0.8088 - val_loss: 0.7820 - val_accuracy: 0.7792\n",
            "Epoch 1690/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5656 - accuracy: 0.7959 - val_loss: 0.7582 - val_accuracy: 0.7633\n",
            "Epoch 1691/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5476 - accuracy: 0.8054 - val_loss: 0.7812 - val_accuracy: 0.7550\n",
            "Epoch 1692/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5349 - accuracy: 0.8075 - val_loss: 0.7822 - val_accuracy: 0.7542\n",
            "Epoch 1693/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5365 - accuracy: 0.7935 - val_loss: 0.7835 - val_accuracy: 0.7692\n",
            "Epoch 1694/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5200 - accuracy: 0.8068 - val_loss: 0.7507 - val_accuracy: 0.7808\n",
            "Epoch 1695/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5498 - accuracy: 0.7865 - val_loss: 0.8170 - val_accuracy: 0.7600\n",
            "Epoch 1696/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5371 - accuracy: 0.8043 - val_loss: 0.7511 - val_accuracy: 0.7650\n",
            "Epoch 1697/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5430 - accuracy: 0.7910 - val_loss: 0.7874 - val_accuracy: 0.7650\n",
            "Epoch 1698/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5313 - accuracy: 0.8056 - val_loss: 0.7837 - val_accuracy: 0.7583\n",
            "Epoch 1699/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5218 - accuracy: 0.8065 - val_loss: 0.8224 - val_accuracy: 0.7700\n",
            "Epoch 1700/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5527 - accuracy: 0.8031 - val_loss: 0.8005 - val_accuracy: 0.7575\n",
            "Epoch 1701/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5602 - accuracy: 0.7942 - val_loss: 0.8123 - val_accuracy: 0.7658\n",
            "Epoch 1702/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5681 - accuracy: 0.7935 - val_loss: 0.7940 - val_accuracy: 0.7700\n",
            "Epoch 1703/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5426 - accuracy: 0.8001 - val_loss: 0.7871 - val_accuracy: 0.7692\n",
            "Epoch 1704/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5766 - accuracy: 0.7971 - val_loss: 0.7696 - val_accuracy: 0.7750\n",
            "Epoch 1705/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5429 - accuracy: 0.8024 - val_loss: 0.7470 - val_accuracy: 0.7792\n",
            "Epoch 1706/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5228 - accuracy: 0.8071 - val_loss: 0.8201 - val_accuracy: 0.7483\n",
            "Epoch 1707/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5446 - accuracy: 0.7952 - val_loss: 0.7560 - val_accuracy: 0.7833\n",
            "Epoch 1708/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5394 - accuracy: 0.7988 - val_loss: 0.7730 - val_accuracy: 0.7850\n",
            "Epoch 1709/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5502 - accuracy: 0.7953 - val_loss: 0.7878 - val_accuracy: 0.7708\n",
            "Epoch 1710/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5398 - accuracy: 0.8038 - val_loss: 0.7557 - val_accuracy: 0.7725\n",
            "Epoch 1711/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5422 - accuracy: 0.7990 - val_loss: 0.7304 - val_accuracy: 0.7733\n",
            "Epoch 1712/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5327 - accuracy: 0.7971 - val_loss: 0.7686 - val_accuracy: 0.7775\n",
            "Epoch 1713/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5808 - accuracy: 0.7940 - val_loss: 0.7735 - val_accuracy: 0.7808\n",
            "Epoch 1714/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.5247 - accuracy: 0.8072 - val_loss: 0.7591 - val_accuracy: 0.7858\n",
            "Epoch 1715/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5456 - accuracy: 0.8013 - val_loss: 0.7805 - val_accuracy: 0.7717\n",
            "Epoch 1716/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5514 - accuracy: 0.7926 - val_loss: 0.7912 - val_accuracy: 0.7600\n",
            "Epoch 1717/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5454 - accuracy: 0.7948 - val_loss: 0.8024 - val_accuracy: 0.7567\n",
            "Epoch 1718/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5709 - accuracy: 0.7841 - val_loss: 0.8289 - val_accuracy: 0.7592\n",
            "Epoch 1719/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5889 - accuracy: 0.7847 - val_loss: 0.7416 - val_accuracy: 0.7950\n",
            "Epoch 1720/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5328 - accuracy: 0.8029 - val_loss: 0.7538 - val_accuracy: 0.7783\n",
            "Epoch 1721/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5164 - accuracy: 0.8093 - val_loss: 0.7690 - val_accuracy: 0.7767\n",
            "Epoch 1722/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5205 - accuracy: 0.8140 - val_loss: 0.7566 - val_accuracy: 0.7675\n",
            "Epoch 1723/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5539 - accuracy: 0.7939 - val_loss: 0.7868 - val_accuracy: 0.7675\n",
            "Epoch 1724/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5382 - accuracy: 0.7967 - val_loss: 0.7689 - val_accuracy: 0.7850\n",
            "Epoch 1725/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5279 - accuracy: 0.8123 - val_loss: 0.7628 - val_accuracy: 0.7817\n",
            "Epoch 1726/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4969 - accuracy: 0.8204 - val_loss: 0.7608 - val_accuracy: 0.7892\n",
            "Epoch 1727/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5317 - accuracy: 0.8069 - val_loss: 0.7437 - val_accuracy: 0.8025\n",
            "Epoch 1728/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5365 - accuracy: 0.8063 - val_loss: 0.7703 - val_accuracy: 0.7725\n",
            "Epoch 1729/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5480 - accuracy: 0.7978 - val_loss: 0.8099 - val_accuracy: 0.7592\n",
            "Epoch 1730/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5354 - accuracy: 0.8066 - val_loss: 0.8031 - val_accuracy: 0.7542\n",
            "Epoch 1731/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5487 - accuracy: 0.7963 - val_loss: 0.7988 - val_accuracy: 0.7667\n",
            "Epoch 1732/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5271 - accuracy: 0.7999 - val_loss: 0.7937 - val_accuracy: 0.7633\n",
            "Epoch 1733/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5548 - accuracy: 0.8019 - val_loss: 0.7547 - val_accuracy: 0.7833\n",
            "Epoch 1734/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5423 - accuracy: 0.7978 - val_loss: 0.7858 - val_accuracy: 0.7725\n",
            "Epoch 1735/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5539 - accuracy: 0.7907 - val_loss: 0.7695 - val_accuracy: 0.7783\n",
            "Epoch 1736/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5258 - accuracy: 0.8022 - val_loss: 0.7868 - val_accuracy: 0.7642\n",
            "Epoch 1737/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5455 - accuracy: 0.7973 - val_loss: 0.7953 - val_accuracy: 0.7642\n",
            "Epoch 1738/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5349 - accuracy: 0.8022 - val_loss: 0.7420 - val_accuracy: 0.7867\n",
            "Epoch 1739/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 0.8062 - val_loss: 0.7957 - val_accuracy: 0.7775\n",
            "Epoch 1740/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5165 - accuracy: 0.8080 - val_loss: 0.8593 - val_accuracy: 0.7517\n",
            "Epoch 1741/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5799 - accuracy: 0.7838 - val_loss: 0.7583 - val_accuracy: 0.7717\n",
            "Epoch 1742/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5343 - accuracy: 0.7985 - val_loss: 0.7619 - val_accuracy: 0.7783\n",
            "Epoch 1743/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5543 - accuracy: 0.7921 - val_loss: 0.8443 - val_accuracy: 0.7633\n",
            "Epoch 1744/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6126 - accuracy: 0.7870 - val_loss: 0.7896 - val_accuracy: 0.7675\n",
            "Epoch 1745/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5459 - accuracy: 0.7925 - val_loss: 0.7404 - val_accuracy: 0.7833\n",
            "Epoch 1746/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5425 - accuracy: 0.7981 - val_loss: 0.7850 - val_accuracy: 0.7658\n",
            "Epoch 1747/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5339 - accuracy: 0.8036 - val_loss: 0.7437 - val_accuracy: 0.7917\n",
            "Epoch 1748/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5400 - accuracy: 0.7993 - val_loss: 0.8354 - val_accuracy: 0.7600\n",
            "Epoch 1749/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5727 - accuracy: 0.7928 - val_loss: 0.7940 - val_accuracy: 0.7675\n",
            "Epoch 1750/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5316 - accuracy: 0.8010 - val_loss: 0.7732 - val_accuracy: 0.7683\n",
            "Epoch 1751/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5056 - accuracy: 0.8169 - val_loss: 0.7715 - val_accuracy: 0.7617\n",
            "Epoch 1752/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5373 - accuracy: 0.8045 - val_loss: 0.7795 - val_accuracy: 0.7667\n",
            "Epoch 1753/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5364 - accuracy: 0.8010 - val_loss: 0.7743 - val_accuracy: 0.7767\n",
            "Epoch 1754/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5232 - accuracy: 0.8103 - val_loss: 0.7657 - val_accuracy: 0.7675\n",
            "Epoch 1755/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5530 - accuracy: 0.7916 - val_loss: 0.7892 - val_accuracy: 0.7683\n",
            "Epoch 1756/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5352 - accuracy: 0.8045 - val_loss: 0.7595 - val_accuracy: 0.7858\n",
            "Epoch 1757/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5374 - accuracy: 0.8091 - val_loss: 0.7810 - val_accuracy: 0.7692\n",
            "Epoch 1758/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5463 - accuracy: 0.7925 - val_loss: 0.7678 - val_accuracy: 0.7858\n",
            "Epoch 1759/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5373 - accuracy: 0.8016 - val_loss: 0.8052 - val_accuracy: 0.7742\n",
            "Epoch 1760/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5690 - accuracy: 0.7818 - val_loss: 0.7618 - val_accuracy: 0.7708\n",
            "Epoch 1761/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5302 - accuracy: 0.8032 - val_loss: 0.7735 - val_accuracy: 0.7825\n",
            "Epoch 1762/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5603 - accuracy: 0.7927 - val_loss: 0.7608 - val_accuracy: 0.7875\n",
            "Epoch 1763/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5340 - accuracy: 0.8042 - val_loss: 0.8069 - val_accuracy: 0.7575\n",
            "Epoch 1764/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5407 - accuracy: 0.7924 - val_loss: 0.8200 - val_accuracy: 0.7567\n",
            "Epoch 1765/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5307 - accuracy: 0.8012 - val_loss: 0.7583 - val_accuracy: 0.7775\n",
            "Epoch 1766/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5573 - accuracy: 0.7859 - val_loss: 0.7580 - val_accuracy: 0.7775\n",
            "Epoch 1767/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5166 - accuracy: 0.8159 - val_loss: 0.7643 - val_accuracy: 0.7775\n",
            "Epoch 1768/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5304 - accuracy: 0.7894 - val_loss: 0.8027 - val_accuracy: 0.7608\n",
            "Epoch 1769/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5562 - accuracy: 0.7846 - val_loss: 0.7824 - val_accuracy: 0.7633\n",
            "Epoch 1770/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5813 - accuracy: 0.7840 - val_loss: 0.8030 - val_accuracy: 0.7608\n",
            "Epoch 1771/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5483 - accuracy: 0.7957 - val_loss: 0.7659 - val_accuracy: 0.7725\n",
            "Epoch 1772/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5262 - accuracy: 0.8076 - val_loss: 0.7741 - val_accuracy: 0.7725\n",
            "Epoch 1773/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5071 - accuracy: 0.8135 - val_loss: 0.8111 - val_accuracy: 0.7625\n",
            "Epoch 1774/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5552 - accuracy: 0.7914 - val_loss: 0.8197 - val_accuracy: 0.7450\n",
            "Epoch 1775/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5800 - accuracy: 0.7768 - val_loss: 0.7686 - val_accuracy: 0.7617\n",
            "Epoch 1776/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5532 - accuracy: 0.7959 - val_loss: 0.7909 - val_accuracy: 0.7725\n",
            "Epoch 1777/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.5654 - accuracy: 0.7807 - val_loss: 0.7927 - val_accuracy: 0.7633\n",
            "Epoch 1778/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5298 - accuracy: 0.8101 - val_loss: 0.8214 - val_accuracy: 0.7608\n",
            "Epoch 1779/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5480 - accuracy: 0.8027 - val_loss: 0.7636 - val_accuracy: 0.7817\n",
            "Epoch 1780/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5274 - accuracy: 0.8011 - val_loss: 0.7774 - val_accuracy: 0.7767\n",
            "Epoch 1781/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5410 - accuracy: 0.8014 - val_loss: 0.8377 - val_accuracy: 0.7600\n",
            "Epoch 1782/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.5587 - accuracy: 0.7979 - val_loss: 0.7698 - val_accuracy: 0.7725\n",
            "Epoch 1783/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5498 - accuracy: 0.7998 - val_loss: 0.7404 - val_accuracy: 0.7858\n",
            "Epoch 1784/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5306 - accuracy: 0.8042 - val_loss: 0.8057 - val_accuracy: 0.7700\n",
            "Epoch 1785/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5433 - accuracy: 0.8118 - val_loss: 0.8310 - val_accuracy: 0.7550\n",
            "Epoch 1786/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5846 - accuracy: 0.7881 - val_loss: 0.7736 - val_accuracy: 0.7775\n",
            "Epoch 1787/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5397 - accuracy: 0.7963 - val_loss: 0.8097 - val_accuracy: 0.7517\n",
            "Epoch 1788/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5276 - accuracy: 0.8118 - val_loss: 0.7708 - val_accuracy: 0.7625\n",
            "Epoch 1789/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5169 - accuracy: 0.8066 - val_loss: 0.7669 - val_accuracy: 0.7817\n",
            "Epoch 1790/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5261 - accuracy: 0.8022 - val_loss: 0.7873 - val_accuracy: 0.7658\n",
            "Epoch 1791/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5428 - accuracy: 0.7965 - val_loss: 0.8053 - val_accuracy: 0.7608\n",
            "Epoch 1792/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5469 - accuracy: 0.7927 - val_loss: 0.7857 - val_accuracy: 0.7708\n",
            "Epoch 1793/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5361 - accuracy: 0.8022 - val_loss: 0.7932 - val_accuracy: 0.7625\n",
            "Epoch 1794/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5655 - accuracy: 0.7908 - val_loss: 0.7612 - val_accuracy: 0.7658\n",
            "Epoch 1795/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5382 - accuracy: 0.8051 - val_loss: 0.7798 - val_accuracy: 0.7717\n",
            "Epoch 1796/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5488 - accuracy: 0.7953 - val_loss: 0.7877 - val_accuracy: 0.7733\n",
            "Epoch 1797/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5415 - accuracy: 0.8011 - val_loss: 0.7678 - val_accuracy: 0.7783\n",
            "Epoch 1798/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5463 - accuracy: 0.7988 - val_loss: 0.7728 - val_accuracy: 0.7783\n",
            "Epoch 1799/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5243 - accuracy: 0.8080 - val_loss: 0.7712 - val_accuracy: 0.7850\n",
            "Epoch 1800/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5192 - accuracy: 0.8237 - val_loss: 0.7612 - val_accuracy: 0.7725\n",
            "Epoch 1801/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 0.8006 - val_loss: 0.7679 - val_accuracy: 0.7700\n",
            "Epoch 1802/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5385 - accuracy: 0.7950 - val_loss: 0.7952 - val_accuracy: 0.7608\n",
            "Epoch 1803/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5270 - accuracy: 0.8057 - val_loss: 0.7744 - val_accuracy: 0.7708\n",
            "Epoch 1804/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5106 - accuracy: 0.8061 - val_loss: 0.7788 - val_accuracy: 0.7725\n",
            "Epoch 1805/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5387 - accuracy: 0.7936 - val_loss: 0.7602 - val_accuracy: 0.7800\n",
            "Epoch 1806/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5287 - accuracy: 0.8082 - val_loss: 0.7810 - val_accuracy: 0.7792\n",
            "Epoch 1807/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5453 - accuracy: 0.8024 - val_loss: 0.8057 - val_accuracy: 0.7683\n",
            "Epoch 1808/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5611 - accuracy: 0.7941 - val_loss: 0.8131 - val_accuracy: 0.7625\n",
            "Epoch 1809/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5671 - accuracy: 0.7898 - val_loss: 0.7710 - val_accuracy: 0.7825\n",
            "Epoch 1810/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5340 - accuracy: 0.8069 - val_loss: 0.8373 - val_accuracy: 0.7642\n",
            "Epoch 1811/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5508 - accuracy: 0.8007 - val_loss: 0.7801 - val_accuracy: 0.7667\n",
            "Epoch 1812/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5292 - accuracy: 0.8033 - val_loss: 0.7578 - val_accuracy: 0.7683\n",
            "Epoch 1813/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5446 - accuracy: 0.7984 - val_loss: 0.8473 - val_accuracy: 0.7642\n",
            "Epoch 1814/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5917 - accuracy: 0.7910 - val_loss: 0.7842 - val_accuracy: 0.7700\n",
            "Epoch 1815/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5377 - accuracy: 0.8090 - val_loss: 0.7869 - val_accuracy: 0.7658\n",
            "Epoch 1816/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5396 - accuracy: 0.7981 - val_loss: 0.7768 - val_accuracy: 0.7692\n",
            "Epoch 1817/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5501 - accuracy: 0.7971 - val_loss: 0.8063 - val_accuracy: 0.7642\n",
            "Epoch 1818/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5454 - accuracy: 0.7979 - val_loss: 0.7535 - val_accuracy: 0.7733\n",
            "Epoch 1819/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5115 - accuracy: 0.8109 - val_loss: 0.8166 - val_accuracy: 0.7575\n",
            "Epoch 1820/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5410 - accuracy: 0.8045 - val_loss: 0.7731 - val_accuracy: 0.7800\n",
            "Epoch 1821/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5526 - accuracy: 0.7967 - val_loss: 0.7964 - val_accuracy: 0.7850\n",
            "Epoch 1822/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5371 - accuracy: 0.8052 - val_loss: 0.7702 - val_accuracy: 0.7683\n",
            "Epoch 1823/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5273 - accuracy: 0.8127 - val_loss: 0.7724 - val_accuracy: 0.7775\n",
            "Epoch 1824/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5218 - accuracy: 0.8049 - val_loss: 0.7857 - val_accuracy: 0.7783\n",
            "Epoch 1825/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5234 - accuracy: 0.8083 - val_loss: 0.7805 - val_accuracy: 0.7650\n",
            "Epoch 1826/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5322 - accuracy: 0.8059 - val_loss: 0.7668 - val_accuracy: 0.7825\n",
            "Epoch 1827/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5215 - accuracy: 0.8146 - val_loss: 0.7867 - val_accuracy: 0.7625\n",
            "Epoch 1828/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5214 - accuracy: 0.8031 - val_loss: 0.7837 - val_accuracy: 0.7658\n",
            "Epoch 1829/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5588 - accuracy: 0.7870 - val_loss: 0.8051 - val_accuracy: 0.7733\n",
            "Epoch 1830/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5574 - accuracy: 0.7893 - val_loss: 0.7639 - val_accuracy: 0.7792\n",
            "Epoch 1831/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5406 - accuracy: 0.8012 - val_loss: 0.8277 - val_accuracy: 0.7633\n",
            "Epoch 1832/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5547 - accuracy: 0.7977 - val_loss: 0.8128 - val_accuracy: 0.7650\n",
            "Epoch 1833/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5420 - accuracy: 0.7968 - val_loss: 0.8207 - val_accuracy: 0.7667\n",
            "Epoch 1834/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5253 - accuracy: 0.8032 - val_loss: 0.7696 - val_accuracy: 0.7733\n",
            "Epoch 1835/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5002 - accuracy: 0.8181 - val_loss: 0.7701 - val_accuracy: 0.7733\n",
            "Epoch 1836/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5448 - accuracy: 0.7943 - val_loss: 0.7739 - val_accuracy: 0.7708\n",
            "Epoch 1837/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5298 - accuracy: 0.8078 - val_loss: 0.7849 - val_accuracy: 0.7767\n",
            "Epoch 1838/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5423 - accuracy: 0.7983 - val_loss: 0.7390 - val_accuracy: 0.7833\n",
            "Epoch 1839/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5328 - accuracy: 0.8099 - val_loss: 0.7500 - val_accuracy: 0.7742\n",
            "Epoch 1840/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.5180 - accuracy: 0.7997 - val_loss: 0.7950 - val_accuracy: 0.7692\n",
            "Epoch 1841/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5352 - accuracy: 0.8059 - val_loss: 0.8114 - val_accuracy: 0.7692\n",
            "Epoch 1842/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5316 - accuracy: 0.8040 - val_loss: 0.7694 - val_accuracy: 0.7758\n",
            "Epoch 1843/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5291 - accuracy: 0.8070 - val_loss: 0.7754 - val_accuracy: 0.7850\n",
            "Epoch 1844/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5212 - accuracy: 0.8092 - val_loss: 0.8023 - val_accuracy: 0.7625\n",
            "Epoch 1845/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5549 - accuracy: 0.7924 - val_loss: 0.8725 - val_accuracy: 0.7492\n",
            "Epoch 1846/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5776 - accuracy: 0.7845 - val_loss: 0.7843 - val_accuracy: 0.7733\n",
            "Epoch 1847/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5561 - accuracy: 0.7864 - val_loss: 0.8084 - val_accuracy: 0.7758\n",
            "Epoch 1848/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5362 - accuracy: 0.7990 - val_loss: 0.7678 - val_accuracy: 0.7817\n",
            "Epoch 1849/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5294 - accuracy: 0.7958 - val_loss: 0.7711 - val_accuracy: 0.7850\n",
            "Epoch 1850/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5117 - accuracy: 0.8085 - val_loss: 0.7910 - val_accuracy: 0.7658\n",
            "Epoch 1851/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5390 - accuracy: 0.7989 - val_loss: 0.7877 - val_accuracy: 0.7725\n",
            "Epoch 1852/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5464 - accuracy: 0.7983 - val_loss: 0.7958 - val_accuracy: 0.7642\n",
            "Epoch 1853/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5680 - accuracy: 0.7959 - val_loss: 0.8226 - val_accuracy: 0.7750\n",
            "Epoch 1854/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5230 - accuracy: 0.8007 - val_loss: 0.7682 - val_accuracy: 0.7900\n",
            "Epoch 1855/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5147 - accuracy: 0.8093 - val_loss: 0.7778 - val_accuracy: 0.7742\n",
            "Epoch 1856/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5468 - accuracy: 0.7985 - val_loss: 0.7835 - val_accuracy: 0.7775\n",
            "Epoch 1857/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5385 - accuracy: 0.7976 - val_loss: 0.8255 - val_accuracy: 0.7642\n",
            "Epoch 1858/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5181 - accuracy: 0.8095 - val_loss: 0.7845 - val_accuracy: 0.7808\n",
            "Epoch 1859/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5566 - accuracy: 0.8002 - val_loss: 0.7867 - val_accuracy: 0.7717\n",
            "Epoch 1860/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5273 - accuracy: 0.8045 - val_loss: 0.8997 - val_accuracy: 0.7717\n",
            "Epoch 1861/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.6265 - accuracy: 0.7923 - val_loss: 0.7735 - val_accuracy: 0.7783\n",
            "Epoch 1862/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5552 - accuracy: 0.7942 - val_loss: 0.7714 - val_accuracy: 0.7675\n",
            "Epoch 1863/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5468 - accuracy: 0.8108 - val_loss: 0.7584 - val_accuracy: 0.7825\n",
            "Epoch 1864/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5243 - accuracy: 0.8000 - val_loss: 0.7668 - val_accuracy: 0.7817\n",
            "Epoch 1865/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5360 - accuracy: 0.8007 - val_loss: 0.8086 - val_accuracy: 0.7567\n",
            "Epoch 1866/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5486 - accuracy: 0.7903 - val_loss: 0.7805 - val_accuracy: 0.7675\n",
            "Epoch 1867/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5400 - accuracy: 0.7982 - val_loss: 0.8324 - val_accuracy: 0.7425\n",
            "Epoch 1868/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.5696 - accuracy: 0.7913 - val_loss: 0.7316 - val_accuracy: 0.7950\n",
            "Epoch 1869/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5264 - accuracy: 0.7920 - val_loss: 0.7407 - val_accuracy: 0.7725\n",
            "Epoch 1870/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5467 - accuracy: 0.7918 - val_loss: 0.8019 - val_accuracy: 0.7800\n",
            "Epoch 1871/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5328 - accuracy: 0.8044 - val_loss: 0.8194 - val_accuracy: 0.7558\n",
            "Epoch 1872/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5539 - accuracy: 0.7967 - val_loss: 0.7871 - val_accuracy: 0.7775\n",
            "Epoch 1873/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5303 - accuracy: 0.8061 - val_loss: 0.7528 - val_accuracy: 0.7775\n",
            "Epoch 1874/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5208 - accuracy: 0.8107 - val_loss: 0.7629 - val_accuracy: 0.7883\n",
            "Epoch 1875/2000\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.5117 - accuracy: 0.8116 - val_loss: 0.7785 - val_accuracy: 0.7808\n",
            "Epoch 1876/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5345 - accuracy: 0.7976 - val_loss: 0.7908 - val_accuracy: 0.7625\n",
            "Epoch 1877/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5307 - accuracy: 0.7999 - val_loss: 0.7546 - val_accuracy: 0.7792\n",
            "Epoch 1878/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5098 - accuracy: 0.8125 - val_loss: 0.7679 - val_accuracy: 0.7800\n",
            "Epoch 1879/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5297 - accuracy: 0.8009 - val_loss: 0.7613 - val_accuracy: 0.7808\n",
            "Epoch 1880/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5037 - accuracy: 0.8096 - val_loss: 0.7834 - val_accuracy: 0.7742\n",
            "Epoch 1881/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5220 - accuracy: 0.8009 - val_loss: 0.7676 - val_accuracy: 0.7750\n",
            "Epoch 1882/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5066 - accuracy: 0.8198 - val_loss: 0.7564 - val_accuracy: 0.7833\n",
            "Epoch 1883/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5184 - accuracy: 0.8100 - val_loss: 0.7506 - val_accuracy: 0.7808\n",
            "Epoch 1884/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5287 - accuracy: 0.8082 - val_loss: 0.7925 - val_accuracy: 0.7592\n",
            "Epoch 1885/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5690 - accuracy: 0.7874 - val_loss: 0.8918 - val_accuracy: 0.7600\n",
            "Epoch 1886/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5990 - accuracy: 0.7808 - val_loss: 0.7770 - val_accuracy: 0.7842\n",
            "Epoch 1887/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5416 - accuracy: 0.7964 - val_loss: 0.7582 - val_accuracy: 0.7800\n",
            "Epoch 1888/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5287 - accuracy: 0.8105 - val_loss: 0.7700 - val_accuracy: 0.7625\n",
            "Epoch 1889/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5193 - accuracy: 0.8027 - val_loss: 0.7945 - val_accuracy: 0.7592\n",
            "Epoch 1890/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5420 - accuracy: 0.7947 - val_loss: 0.7800 - val_accuracy: 0.7683\n",
            "Epoch 1891/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5352 - accuracy: 0.8051 - val_loss: 0.7499 - val_accuracy: 0.7808\n",
            "Epoch 1892/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5104 - accuracy: 0.8057 - val_loss: 0.7918 - val_accuracy: 0.7658\n",
            "Epoch 1893/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5205 - accuracy: 0.8118 - val_loss: 0.7718 - val_accuracy: 0.7767\n",
            "Epoch 1894/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5311 - accuracy: 0.8009 - val_loss: 0.7939 - val_accuracy: 0.7733\n",
            "Epoch 1895/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5276 - accuracy: 0.7958 - val_loss: 0.7675 - val_accuracy: 0.7758\n",
            "Epoch 1896/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5614 - accuracy: 0.7900 - val_loss: 0.7765 - val_accuracy: 0.7717\n",
            "Epoch 1897/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5195 - accuracy: 0.8105 - val_loss: 0.7811 - val_accuracy: 0.7725\n",
            "Epoch 1898/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4972 - accuracy: 0.8082 - val_loss: 0.7990 - val_accuracy: 0.7592\n",
            "Epoch 1899/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5284 - accuracy: 0.8070 - val_loss: 0.8077 - val_accuracy: 0.7583\n",
            "Epoch 1900/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5853 - accuracy: 0.7791 - val_loss: 0.7697 - val_accuracy: 0.7650\n",
            "Epoch 1901/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5249 - accuracy: 0.8034 - val_loss: 0.7839 - val_accuracy: 0.7817\n",
            "Epoch 1902/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5292 - accuracy: 0.7985 - val_loss: 0.8166 - val_accuracy: 0.7575\n",
            "Epoch 1903/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5397 - accuracy: 0.8061 - val_loss: 0.7666 - val_accuracy: 0.7825\n",
            "Epoch 1904/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5126 - accuracy: 0.8153 - val_loss: 0.7920 - val_accuracy: 0.7717\n",
            "Epoch 1905/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5073 - accuracy: 0.8037 - val_loss: 0.7865 - val_accuracy: 0.7700\n",
            "Epoch 1906/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5093 - accuracy: 0.8128 - val_loss: 0.8089 - val_accuracy: 0.7667\n",
            "Epoch 1907/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5402 - accuracy: 0.7887 - val_loss: 0.7797 - val_accuracy: 0.7775\n",
            "Epoch 1908/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.5350 - accuracy: 0.8014 - val_loss: 0.7625 - val_accuracy: 0.7883\n",
            "Epoch 1909/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5227 - accuracy: 0.8138 - val_loss: 0.8055 - val_accuracy: 0.7783\n",
            "Epoch 1910/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5140 - accuracy: 0.8103 - val_loss: 0.7605 - val_accuracy: 0.7883\n",
            "Epoch 1911/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5066 - accuracy: 0.8109 - val_loss: 0.7619 - val_accuracy: 0.7808\n",
            "Epoch 1912/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5113 - accuracy: 0.8121 - val_loss: 0.7730 - val_accuracy: 0.7883\n",
            "Epoch 1913/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5476 - accuracy: 0.7916 - val_loss: 0.7863 - val_accuracy: 0.7767\n",
            "Epoch 1914/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5313 - accuracy: 0.8014 - val_loss: 0.7792 - val_accuracy: 0.7875\n",
            "Epoch 1915/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5173 - accuracy: 0.8110 - val_loss: 0.7730 - val_accuracy: 0.7892\n",
            "Epoch 1916/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5366 - accuracy: 0.7921 - val_loss: 0.7649 - val_accuracy: 0.7883\n",
            "Epoch 1917/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5297 - accuracy: 0.7994 - val_loss: 0.8061 - val_accuracy: 0.7625\n",
            "Epoch 1918/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5322 - accuracy: 0.8016 - val_loss: 0.8213 - val_accuracy: 0.7658\n",
            "Epoch 1919/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5278 - accuracy: 0.8015 - val_loss: 0.7987 - val_accuracy: 0.7900\n",
            "Epoch 1920/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5242 - accuracy: 0.8046 - val_loss: 0.7868 - val_accuracy: 0.7667\n",
            "Epoch 1921/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5355 - accuracy: 0.8050 - val_loss: 0.7819 - val_accuracy: 0.7742\n",
            "Epoch 1922/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5247 - accuracy: 0.8063 - val_loss: 0.8009 - val_accuracy: 0.7733\n",
            "Epoch 1923/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.5249 - accuracy: 0.8039 - val_loss: 0.8152 - val_accuracy: 0.7583\n",
            "Epoch 1924/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.5182 - accuracy: 0.8049 - val_loss: 0.7829 - val_accuracy: 0.7700\n",
            "Epoch 1925/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5698 - accuracy: 0.7885 - val_loss: 0.8961 - val_accuracy: 0.7558\n",
            "Epoch 1926/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.5483 - accuracy: 0.7951 - val_loss: 0.7864 - val_accuracy: 0.7617\n",
            "Epoch 1927/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5583 - accuracy: 0.7839 - val_loss: 0.7947 - val_accuracy: 0.7708\n",
            "Epoch 1928/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5598 - accuracy: 0.7877 - val_loss: 0.7818 - val_accuracy: 0.7750\n",
            "Epoch 1929/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5722 - accuracy: 0.7917 - val_loss: 0.8727 - val_accuracy: 0.7633\n",
            "Epoch 1930/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.5853 - accuracy: 0.7960 - val_loss: 0.8162 - val_accuracy: 0.7792\n",
            "Epoch 1931/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5484 - accuracy: 0.7907 - val_loss: 0.7971 - val_accuracy: 0.7642\n",
            "Epoch 1932/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5183 - accuracy: 0.8130 - val_loss: 0.7910 - val_accuracy: 0.7683\n",
            "Epoch 1933/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5312 - accuracy: 0.8033 - val_loss: 0.7782 - val_accuracy: 0.7825\n",
            "Epoch 1934/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5161 - accuracy: 0.8176 - val_loss: 0.7650 - val_accuracy: 0.7942\n",
            "Epoch 1935/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5082 - accuracy: 0.8143 - val_loss: 0.7806 - val_accuracy: 0.7750\n",
            "Epoch 1936/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5140 - accuracy: 0.8139 - val_loss: 0.7519 - val_accuracy: 0.7958\n",
            "Epoch 1937/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5350 - accuracy: 0.7953 - val_loss: 0.7950 - val_accuracy: 0.7750\n",
            "Epoch 1938/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5249 - accuracy: 0.8099 - val_loss: 0.7718 - val_accuracy: 0.7683\n",
            "Epoch 1939/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5336 - accuracy: 0.7999 - val_loss: 0.7755 - val_accuracy: 0.7825\n",
            "Epoch 1940/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5327 - accuracy: 0.8068 - val_loss: 0.7982 - val_accuracy: 0.7600\n",
            "Epoch 1941/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5283 - accuracy: 0.8018 - val_loss: 0.7672 - val_accuracy: 0.7850\n",
            "Epoch 1942/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5407 - accuracy: 0.7969 - val_loss: 0.8072 - val_accuracy: 0.7692\n",
            "Epoch 1943/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5150 - accuracy: 0.8104 - val_loss: 0.7873 - val_accuracy: 0.7833\n",
            "Epoch 1944/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5163 - accuracy: 0.8171 - val_loss: 0.7745 - val_accuracy: 0.7808\n",
            "Epoch 1945/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5455 - accuracy: 0.7939 - val_loss: 0.8233 - val_accuracy: 0.7625\n",
            "Epoch 1946/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5314 - accuracy: 0.8061 - val_loss: 0.8116 - val_accuracy: 0.7758\n",
            "Epoch 1947/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5280 - accuracy: 0.8074 - val_loss: 0.7846 - val_accuracy: 0.7883\n",
            "Epoch 1948/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5353 - accuracy: 0.8041 - val_loss: 0.7784 - val_accuracy: 0.7792\n",
            "Epoch 1949/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5337 - accuracy: 0.7992 - val_loss: 0.7650 - val_accuracy: 0.7800\n",
            "Epoch 1950/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.5249 - accuracy: 0.8017 - val_loss: 0.7758 - val_accuracy: 0.7658\n",
            "Epoch 1951/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5371 - accuracy: 0.8007 - val_loss: 0.7873 - val_accuracy: 0.7692\n",
            "Epoch 1952/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5412 - accuracy: 0.7908 - val_loss: 0.8594 - val_accuracy: 0.7575\n",
            "Epoch 1953/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5509 - accuracy: 0.8022 - val_loss: 0.7909 - val_accuracy: 0.7733\n",
            "Epoch 1954/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5031 - accuracy: 0.8118 - val_loss: 0.8098 - val_accuracy: 0.7792\n",
            "Epoch 1955/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5354 - accuracy: 0.8032 - val_loss: 0.7761 - val_accuracy: 0.7608\n",
            "Epoch 1956/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5180 - accuracy: 0.8074 - val_loss: 0.8143 - val_accuracy: 0.7692\n",
            "Epoch 1957/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5337 - accuracy: 0.8031 - val_loss: 0.7797 - val_accuracy: 0.7758\n",
            "Epoch 1958/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4994 - accuracy: 0.8159 - val_loss: 0.7837 - val_accuracy: 0.7742\n",
            "Epoch 1959/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5340 - accuracy: 0.8044 - val_loss: 0.7853 - val_accuracy: 0.7850\n",
            "Epoch 1960/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5350 - accuracy: 0.8042 - val_loss: 0.8397 - val_accuracy: 0.7650\n",
            "Epoch 1961/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5202 - accuracy: 0.8096 - val_loss: 0.8058 - val_accuracy: 0.7742\n",
            "Epoch 1962/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5321 - accuracy: 0.8065 - val_loss: 0.7758 - val_accuracy: 0.7850\n",
            "Epoch 1963/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5389 - accuracy: 0.7930 - val_loss: 0.8001 - val_accuracy: 0.7725\n",
            "Epoch 1964/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5185 - accuracy: 0.8036 - val_loss: 0.8260 - val_accuracy: 0.7642\n",
            "Epoch 1965/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5724 - accuracy: 0.7913 - val_loss: 0.7814 - val_accuracy: 0.7708\n",
            "Epoch 1966/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.5194 - accuracy: 0.8082 - val_loss: 0.7952 - val_accuracy: 0.7750\n",
            "Epoch 1967/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5281 - accuracy: 0.8002 - val_loss: 0.8138 - val_accuracy: 0.7575\n",
            "Epoch 1968/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5263 - accuracy: 0.8032 - val_loss: 0.7739 - val_accuracy: 0.7683\n",
            "Epoch 1969/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5209 - accuracy: 0.8083 - val_loss: 0.8047 - val_accuracy: 0.7733\n",
            "Epoch 1970/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5123 - accuracy: 0.8069 - val_loss: 0.7784 - val_accuracy: 0.7817\n",
            "Epoch 1971/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5138 - accuracy: 0.8090 - val_loss: 0.7954 - val_accuracy: 0.7692\n",
            "Epoch 1972/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5145 - accuracy: 0.8093 - val_loss: 0.7917 - val_accuracy: 0.7692\n",
            "Epoch 1973/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5130 - accuracy: 0.8038 - val_loss: 0.7866 - val_accuracy: 0.7758\n",
            "Epoch 1974/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5133 - accuracy: 0.8013 - val_loss: 0.8254 - val_accuracy: 0.7683\n",
            "Epoch 1975/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5257 - accuracy: 0.8068 - val_loss: 0.7963 - val_accuracy: 0.7667\n",
            "Epoch 1976/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5407 - accuracy: 0.7921 - val_loss: 0.8014 - val_accuracy: 0.7742\n",
            "Epoch 1977/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5257 - accuracy: 0.8073 - val_loss: 0.7812 - val_accuracy: 0.7725\n",
            "Epoch 1978/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5043 - accuracy: 0.8117 - val_loss: 0.7972 - val_accuracy: 0.7742\n",
            "Epoch 1979/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5289 - accuracy: 0.7979 - val_loss: 0.8010 - val_accuracy: 0.7650\n",
            "Epoch 1980/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5197 - accuracy: 0.8090 - val_loss: 0.8263 - val_accuracy: 0.7708\n",
            "Epoch 1981/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5498 - accuracy: 0.7914 - val_loss: 0.8322 - val_accuracy: 0.7675\n",
            "Epoch 1982/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5475 - accuracy: 0.7957 - val_loss: 0.7850 - val_accuracy: 0.7933\n",
            "Epoch 1983/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5414 - accuracy: 0.8049 - val_loss: 0.7864 - val_accuracy: 0.7750\n",
            "Epoch 1984/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5106 - accuracy: 0.8162 - val_loss: 0.7745 - val_accuracy: 0.7708\n",
            "Epoch 1985/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5263 - accuracy: 0.8041 - val_loss: 0.8307 - val_accuracy: 0.7642\n",
            "Epoch 1986/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5222 - accuracy: 0.8145 - val_loss: 0.8418 - val_accuracy: 0.7608\n",
            "Epoch 1987/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5337 - accuracy: 0.8028 - val_loss: 0.8875 - val_accuracy: 0.7650\n",
            "Epoch 1988/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6516 - accuracy: 0.7894 - val_loss: 0.8561 - val_accuracy: 0.7458\n",
            "Epoch 1989/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5817 - accuracy: 0.7864 - val_loss: 0.7735 - val_accuracy: 0.7800\n",
            "Epoch 1990/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5084 - accuracy: 0.8143 - val_loss: 0.7694 - val_accuracy: 0.7775\n",
            "Epoch 1991/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5320 - accuracy: 0.8067 - val_loss: 0.7433 - val_accuracy: 0.7950\n",
            "Epoch 1992/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5347 - accuracy: 0.7978 - val_loss: 0.7687 - val_accuracy: 0.7833\n",
            "Epoch 1993/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5475 - accuracy: 0.7998 - val_loss: 0.7779 - val_accuracy: 0.7717\n",
            "Epoch 1994/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5175 - accuracy: 0.8108 - val_loss: 0.8017 - val_accuracy: 0.7700\n",
            "Epoch 1995/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5287 - accuracy: 0.8055 - val_loss: 0.7739 - val_accuracy: 0.7825\n",
            "Epoch 1996/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5179 - accuracy: 0.8018 - val_loss: 0.7887 - val_accuracy: 0.7800\n",
            "Epoch 1997/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5335 - accuracy: 0.7964 - val_loss: 0.7993 - val_accuracy: 0.7758\n",
            "Epoch 1998/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5414 - accuracy: 0.7996 - val_loss: 0.7765 - val_accuracy: 0.7892\n",
            "Epoch 1999/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5159 - accuracy: 0.8129 - val_loss: 0.7676 - val_accuracy: 0.7775\n",
            "Epoch 2000/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5195 - accuracy: 0.8121 - val_loss: 0.7922 - val_accuracy: 0.7717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU0m9q2MFxsK",
        "outputId": "e605fd7a-3e37-47b6-ca0f-187c5ca4fc84"
      },
      "source": [
        "# モデルの評価(位置)\n",
        "position_score = position_model.evaluate(X_ans_data, position_Y_ans_data, verbose=1)\n",
        "print('Test loss:', position_score[0])\n",
        "print('Test accuracy:', position_score[1])"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "317/317 [==============================] - 0s 1ms/step - loss: 0.8740 - accuracy: 0.7704\n",
            "Test loss: 0.8739935755729675\n",
            "Test accuracy: 0.7703849673271179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Q96PZO6_GYDt",
        "outputId": "3acc7add-dfdc-47e7-b1e7-0a554aebe83e"
      },
      "source": [
        "# 学習経過の可視化(位置)\n",
        "position_loss     = position_history.history['loss']\n",
        "position_val_loss = position_history.history['val_loss']\n",
        "\n",
        "nb_epoch = len(position_loss)\n",
        "plt.plot(range(nb_epoch), position_loss,     marker='.', label='position_loss')\n",
        "plt.plot(range(nb_epoch), position_val_loss, marker='.', label='position_val_loss')\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "MacBhQBOG5WW",
        "outputId": "8a9d71f2-3169-4cdd-ab18-ce8df11edb44"
      },
      "source": [
        "# 学習経過の可視化(位置)\n",
        "position_acc     = position_history.history['accuracy']\n",
        "position_val_acc = position_history.history['val_accuracy']\n",
        "\n",
        "nb_epoch = len(position_acc)\n",
        "plt.plot(range(nb_epoch), position_acc,     marker='.', label='position_acc')\n",
        "plt.plot(range(nb_epoch), position_val_acc, marker='.', label='position_val_acc')\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.show()"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skVRvqwnHQVN"
      },
      "source": [
        "## CNN(位置)\n",
        "\n",
        "### modelの作成\n",
        "position_ne_model = Sequential()\n",
        "### 畳み込み層\n",
        "position_ne_model.add(Conv1D(32, 3, padding='same', activation='relu', input_shape=(50, 1)))\n",
        "### プーリング層\n",
        "position_ne_model.add(MaxPooling1D(2, padding='same'))\n",
        "### Flatten層\n",
        "position_ne_model.add(Flatten())\n",
        "### 全結合層\n",
        "position_ne_model.add(Dense(26, activation='softmax'))\n",
        "### バッチ正規化\n",
        "BatchNormalization()\n",
        "### optimizer\n",
        "adam = keras.optimizers.Adam()\n",
        "\n",
        "###modelのコンパイル\n",
        "position_ne_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdfEm4DrO7RH",
        "outputId": "c498c9bd-07eb-4b7a-ac6b-214d5fd35fa5"
      },
      "source": [
        "# 学習(位置)\n",
        "epochs = 2000\n",
        "batch_size = 128\n",
        "position_ne_history = position_ne_model.fit(X_ne_ss_train, position_Y_ne_ss_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_ne_ss_test, position_Y_ne_ss_test))"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 3.1387 - accuracy: 0.1169 - val_loss: 2.8219 - val_accuracy: 0.2017\n",
            "Epoch 2/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 2.7088 - accuracy: 0.2685 - val_loss: 2.5120 - val_accuracy: 0.2967\n",
            "Epoch 3/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 2.4591 - accuracy: 0.3060 - val_loss: 2.3067 - val_accuracy: 0.3400\n",
            "Epoch 4/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 2.2534 - accuracy: 0.3628 - val_loss: 2.1764 - val_accuracy: 0.3758\n",
            "Epoch 5/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 2.1161 - accuracy: 0.3816 - val_loss: 2.0544 - val_accuracy: 0.4108\n",
            "Epoch 6/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 2.0058 - accuracy: 0.4131 - val_loss: 1.9672 - val_accuracy: 0.4250\n",
            "Epoch 7/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.9349 - accuracy: 0.4255 - val_loss: 1.8995 - val_accuracy: 0.4392\n",
            "Epoch 8/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.8817 - accuracy: 0.4478 - val_loss: 1.8360 - val_accuracy: 0.4517\n",
            "Epoch 9/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.8064 - accuracy: 0.4656 - val_loss: 1.7941 - val_accuracy: 0.4475\n",
            "Epoch 10/2000\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.8022 - accuracy: 0.4523 - val_loss: 1.7470 - val_accuracy: 0.4733\n",
            "Epoch 11/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.7122 - accuracy: 0.4707 - val_loss: 1.7113 - val_accuracy: 0.4467\n",
            "Epoch 12/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.6699 - accuracy: 0.4713 - val_loss: 1.6633 - val_accuracy: 0.5042\n",
            "Epoch 13/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.6273 - accuracy: 0.5164 - val_loss: 1.6219 - val_accuracy: 0.5000\n",
            "Epoch 14/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.6063 - accuracy: 0.5039 - val_loss: 1.6083 - val_accuracy: 0.4967\n",
            "Epoch 15/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.5712 - accuracy: 0.5367 - val_loss: 1.5488 - val_accuracy: 0.5317\n",
            "Epoch 16/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.5294 - accuracy: 0.5348 - val_loss: 1.5290 - val_accuracy: 0.5400\n",
            "Epoch 17/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.5250 - accuracy: 0.5350 - val_loss: 1.5126 - val_accuracy: 0.5367\n",
            "Epoch 18/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.4941 - accuracy: 0.5366 - val_loss: 1.4871 - val_accuracy: 0.5392\n",
            "Epoch 19/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 1.4580 - accuracy: 0.5592 - val_loss: 1.4470 - val_accuracy: 0.5583\n",
            "Epoch 20/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.4355 - accuracy: 0.5661 - val_loss: 1.4473 - val_accuracy: 0.5542\n",
            "Epoch 21/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.4342 - accuracy: 0.5408 - val_loss: 1.4258 - val_accuracy: 0.5517\n",
            "Epoch 22/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.4117 - accuracy: 0.5610 - val_loss: 1.4232 - val_accuracy: 0.5625\n",
            "Epoch 23/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.4147 - accuracy: 0.5598 - val_loss: 1.4060 - val_accuracy: 0.5642\n",
            "Epoch 24/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.3554 - accuracy: 0.5665 - val_loss: 1.3767 - val_accuracy: 0.5575\n",
            "Epoch 25/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.3294 - accuracy: 0.5798 - val_loss: 1.3674 - val_accuracy: 0.5592\n",
            "Epoch 26/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.3461 - accuracy: 0.5807 - val_loss: 1.3472 - val_accuracy: 0.5650\n",
            "Epoch 27/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.3122 - accuracy: 0.5930 - val_loss: 1.3403 - val_accuracy: 0.6000\n",
            "Epoch 28/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2859 - accuracy: 0.5878 - val_loss: 1.3050 - val_accuracy: 0.6033\n",
            "Epoch 29/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2871 - accuracy: 0.5972 - val_loss: 1.3002 - val_accuracy: 0.5950\n",
            "Epoch 30/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2883 - accuracy: 0.5899 - val_loss: 1.2980 - val_accuracy: 0.5817\n",
            "Epoch 31/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2675 - accuracy: 0.5872 - val_loss: 1.2800 - val_accuracy: 0.5950\n",
            "Epoch 32/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2510 - accuracy: 0.6050 - val_loss: 1.2829 - val_accuracy: 0.5833\n",
            "Epoch 33/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2385 - accuracy: 0.5875 - val_loss: 1.2716 - val_accuracy: 0.5892\n",
            "Epoch 34/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2480 - accuracy: 0.5778 - val_loss: 1.2496 - val_accuracy: 0.5842\n",
            "Epoch 35/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.2190 - accuracy: 0.5972 - val_loss: 1.2354 - val_accuracy: 0.6150\n",
            "Epoch 36/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1936 - accuracy: 0.6295 - val_loss: 1.2277 - val_accuracy: 0.6008\n",
            "Epoch 37/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1763 - accuracy: 0.6239 - val_loss: 1.2322 - val_accuracy: 0.6108\n",
            "Epoch 38/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1960 - accuracy: 0.6245 - val_loss: 1.1971 - val_accuracy: 0.6158\n",
            "Epoch 39/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1638 - accuracy: 0.6212 - val_loss: 1.2116 - val_accuracy: 0.5942\n",
            "Epoch 40/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.1671 - accuracy: 0.6212 - val_loss: 1.1869 - val_accuracy: 0.6467\n",
            "Epoch 41/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1656 - accuracy: 0.6305 - val_loss: 1.2178 - val_accuracy: 0.5900\n",
            "Epoch 42/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1476 - accuracy: 0.6310 - val_loss: 1.1785 - val_accuracy: 0.5858\n",
            "Epoch 43/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1335 - accuracy: 0.6217 - val_loss: 1.1684 - val_accuracy: 0.6142\n",
            "Epoch 44/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1463 - accuracy: 0.6211 - val_loss: 1.1667 - val_accuracy: 0.6158\n",
            "Epoch 45/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1111 - accuracy: 0.6458 - val_loss: 1.1480 - val_accuracy: 0.6150\n",
            "Epoch 46/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1092 - accuracy: 0.6342 - val_loss: 1.1631 - val_accuracy: 0.6183\n",
            "Epoch 47/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1232 - accuracy: 0.6176 - val_loss: 1.1608 - val_accuracy: 0.6250\n",
            "Epoch 48/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1021 - accuracy: 0.6490 - val_loss: 1.1405 - val_accuracy: 0.6292\n",
            "Epoch 49/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0862 - accuracy: 0.6433 - val_loss: 1.1229 - val_accuracy: 0.6300\n",
            "Epoch 50/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0984 - accuracy: 0.6305 - val_loss: 1.1503 - val_accuracy: 0.6233\n",
            "Epoch 51/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1224 - accuracy: 0.6274 - val_loss: 1.1267 - val_accuracy: 0.6275\n",
            "Epoch 52/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.1161 - accuracy: 0.6346 - val_loss: 1.1162 - val_accuracy: 0.6283\n",
            "Epoch 53/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0821 - accuracy: 0.6319 - val_loss: 1.1166 - val_accuracy: 0.6317\n",
            "Epoch 54/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0657 - accuracy: 0.6494 - val_loss: 1.1222 - val_accuracy: 0.6158\n",
            "Epoch 55/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0807 - accuracy: 0.6269 - val_loss: 1.1399 - val_accuracy: 0.6408\n",
            "Epoch 56/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0600 - accuracy: 0.6454 - val_loss: 1.1091 - val_accuracy: 0.6383\n",
            "Epoch 57/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0615 - accuracy: 0.6437 - val_loss: 1.0929 - val_accuracy: 0.6267\n",
            "Epoch 58/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0507 - accuracy: 0.6535 - val_loss: 1.0814 - val_accuracy: 0.6483\n",
            "Epoch 59/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0515 - accuracy: 0.6522 - val_loss: 1.0756 - val_accuracy: 0.6375\n",
            "Epoch 60/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0677 - accuracy: 0.6420 - val_loss: 1.1050 - val_accuracy: 0.6200\n",
            "Epoch 61/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0590 - accuracy: 0.6410 - val_loss: 1.0611 - val_accuracy: 0.6342\n",
            "Epoch 62/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0375 - accuracy: 0.6582 - val_loss: 1.0397 - val_accuracy: 0.6600\n",
            "Epoch 63/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0276 - accuracy: 0.6671 - val_loss: 1.0781 - val_accuracy: 0.6417\n",
            "Epoch 64/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0253 - accuracy: 0.6598 - val_loss: 1.0574 - val_accuracy: 0.6317\n",
            "Epoch 65/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0363 - accuracy: 0.6486 - val_loss: 1.0976 - val_accuracy: 0.6483\n",
            "Epoch 66/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0402 - accuracy: 0.6552 - val_loss: 1.0468 - val_accuracy: 0.6525\n",
            "Epoch 67/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9938 - accuracy: 0.6666 - val_loss: 1.0476 - val_accuracy: 0.6375\n",
            "Epoch 68/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0086 - accuracy: 0.6588 - val_loss: 1.0381 - val_accuracy: 0.6583\n",
            "Epoch 69/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0128 - accuracy: 0.6655 - val_loss: 1.0206 - val_accuracy: 0.6592\n",
            "Epoch 70/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9769 - accuracy: 0.6660 - val_loss: 1.0290 - val_accuracy: 0.6700\n",
            "Epoch 71/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9867 - accuracy: 0.6609 - val_loss: 1.0246 - val_accuracy: 0.6625\n",
            "Epoch 72/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0008 - accuracy: 0.6634 - val_loss: 1.0202 - val_accuracy: 0.6567\n",
            "Epoch 73/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.0025 - accuracy: 0.6509 - val_loss: 1.0201 - val_accuracy: 0.6592\n",
            "Epoch 74/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9817 - accuracy: 0.6624 - val_loss: 1.0175 - val_accuracy: 0.6458\n",
            "Epoch 75/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9706 - accuracy: 0.6690 - val_loss: 1.0013 - val_accuracy: 0.6500\n",
            "Epoch 76/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9813 - accuracy: 0.6624 - val_loss: 1.0432 - val_accuracy: 0.6300\n",
            "Epoch 77/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.9749 - accuracy: 0.6653 - val_loss: 1.0342 - val_accuracy: 0.6617\n",
            "Epoch 78/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9691 - accuracy: 0.6686 - val_loss: 0.9924 - val_accuracy: 0.6550\n",
            "Epoch 79/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9424 - accuracy: 0.6756 - val_loss: 1.0105 - val_accuracy: 0.6500\n",
            "Epoch 80/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9545 - accuracy: 0.6747 - val_loss: 0.9985 - val_accuracy: 0.6642\n",
            "Epoch 81/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9648 - accuracy: 0.6728 - val_loss: 1.0174 - val_accuracy: 0.6500\n",
            "Epoch 82/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9457 - accuracy: 0.6848 - val_loss: 1.0081 - val_accuracy: 0.6425\n",
            "Epoch 83/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9654 - accuracy: 0.6634 - val_loss: 1.0311 - val_accuracy: 0.6617\n",
            "Epoch 84/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9455 - accuracy: 0.6769 - val_loss: 0.9932 - val_accuracy: 0.6750\n",
            "Epoch 85/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9539 - accuracy: 0.6686 - val_loss: 1.0022 - val_accuracy: 0.6658\n",
            "Epoch 86/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9301 - accuracy: 0.6856 - val_loss: 0.9982 - val_accuracy: 0.6725\n",
            "Epoch 87/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9268 - accuracy: 0.6859 - val_loss: 0.9846 - val_accuracy: 0.6800\n",
            "Epoch 88/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9281 - accuracy: 0.6900 - val_loss: 0.9853 - val_accuracy: 0.6775\n",
            "Epoch 89/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9298 - accuracy: 0.6868 - val_loss: 0.9761 - val_accuracy: 0.6708\n",
            "Epoch 90/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9274 - accuracy: 0.6903 - val_loss: 0.9815 - val_accuracy: 0.6767\n",
            "Epoch 91/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9452 - accuracy: 0.6850 - val_loss: 0.9874 - val_accuracy: 0.6608\n",
            "Epoch 92/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9255 - accuracy: 0.6828 - val_loss: 0.9791 - val_accuracy: 0.6625\n",
            "Epoch 93/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9290 - accuracy: 0.6737 - val_loss: 0.9722 - val_accuracy: 0.6708\n",
            "Epoch 94/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9195 - accuracy: 0.6872 - val_loss: 0.9891 - val_accuracy: 0.6692\n",
            "Epoch 95/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9212 - accuracy: 0.6835 - val_loss: 0.9615 - val_accuracy: 0.6858\n",
            "Epoch 96/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9103 - accuracy: 0.6954 - val_loss: 0.9682 - val_accuracy: 0.6750\n",
            "Epoch 97/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9062 - accuracy: 0.6747 - val_loss: 0.9453 - val_accuracy: 0.6908\n",
            "Epoch 98/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9322 - accuracy: 0.6764 - val_loss: 0.9773 - val_accuracy: 0.6825\n",
            "Epoch 99/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9177 - accuracy: 0.6768 - val_loss: 0.9794 - val_accuracy: 0.6667\n",
            "Epoch 100/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8887 - accuracy: 0.6951 - val_loss: 0.9600 - val_accuracy: 0.6642\n",
            "Epoch 101/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9122 - accuracy: 0.6694 - val_loss: 0.9496 - val_accuracy: 0.6792\n",
            "Epoch 102/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8912 - accuracy: 0.7055 - val_loss: 0.9503 - val_accuracy: 0.6767\n",
            "Epoch 103/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8963 - accuracy: 0.6870 - val_loss: 0.9548 - val_accuracy: 0.6758\n",
            "Epoch 104/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8940 - accuracy: 0.6930 - val_loss: 0.9447 - val_accuracy: 0.6900\n",
            "Epoch 105/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8713 - accuracy: 0.7036 - val_loss: 0.9417 - val_accuracy: 0.6867\n",
            "Epoch 106/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8827 - accuracy: 0.7031 - val_loss: 0.9403 - val_accuracy: 0.6725\n",
            "Epoch 107/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8774 - accuracy: 0.6965 - val_loss: 0.9215 - val_accuracy: 0.6875\n",
            "Epoch 108/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8862 - accuracy: 0.6934 - val_loss: 0.9402 - val_accuracy: 0.6833\n",
            "Epoch 109/2000\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.8709 - accuracy: 0.7058 - val_loss: 0.9212 - val_accuracy: 0.6783\n",
            "Epoch 110/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8561 - accuracy: 0.7165 - val_loss: 0.9470 - val_accuracy: 0.6708\n",
            "Epoch 111/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8775 - accuracy: 0.6860 - val_loss: 0.9307 - val_accuracy: 0.6867\n",
            "Epoch 112/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8851 - accuracy: 0.6926 - val_loss: 0.9335 - val_accuracy: 0.6933\n",
            "Epoch 113/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8608 - accuracy: 0.7065 - val_loss: 0.9152 - val_accuracy: 0.6908\n",
            "Epoch 114/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8758 - accuracy: 0.6948 - val_loss: 0.9527 - val_accuracy: 0.6708\n",
            "Epoch 115/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8755 - accuracy: 0.6978 - val_loss: 0.9653 - val_accuracy: 0.6675\n",
            "Epoch 116/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9269 - accuracy: 0.6817 - val_loss: 0.9154 - val_accuracy: 0.6900\n",
            "Epoch 117/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8733 - accuracy: 0.6926 - val_loss: 0.9382 - val_accuracy: 0.6733\n",
            "Epoch 118/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8585 - accuracy: 0.7019 - val_loss: 0.9024 - val_accuracy: 0.6992\n",
            "Epoch 119/2000\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.8372 - accuracy: 0.7268 - val_loss: 0.9157 - val_accuracy: 0.6908\n",
            "Epoch 120/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8660 - accuracy: 0.6892 - val_loss: 0.8998 - val_accuracy: 0.6900\n",
            "Epoch 121/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8658 - accuracy: 0.6958 - val_loss: 0.9023 - val_accuracy: 0.6850\n",
            "Epoch 122/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8367 - accuracy: 0.6987 - val_loss: 0.9211 - val_accuracy: 0.6708\n",
            "Epoch 123/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8767 - accuracy: 0.6931 - val_loss: 0.9098 - val_accuracy: 0.6967\n",
            "Epoch 124/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8593 - accuracy: 0.7088 - val_loss: 0.9201 - val_accuracy: 0.7017\n",
            "Epoch 125/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8370 - accuracy: 0.7073 - val_loss: 0.9244 - val_accuracy: 0.6883\n",
            "Epoch 126/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8770 - accuracy: 0.6940 - val_loss: 0.9074 - val_accuracy: 0.6767\n",
            "Epoch 127/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8717 - accuracy: 0.6805 - val_loss: 0.8914 - val_accuracy: 0.7125\n",
            "Epoch 128/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8380 - accuracy: 0.7182 - val_loss: 0.9609 - val_accuracy: 0.6767\n",
            "Epoch 129/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8415 - accuracy: 0.6964 - val_loss: 0.8941 - val_accuracy: 0.6692\n",
            "Epoch 130/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8397 - accuracy: 0.7012 - val_loss: 0.9441 - val_accuracy: 0.6933\n",
            "Epoch 131/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8711 - accuracy: 0.7020 - val_loss: 0.9046 - val_accuracy: 0.6808\n",
            "Epoch 132/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8300 - accuracy: 0.7138 - val_loss: 0.8897 - val_accuracy: 0.6892\n",
            "Epoch 133/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8445 - accuracy: 0.7076 - val_loss: 0.8997 - val_accuracy: 0.6908\n",
            "Epoch 134/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8187 - accuracy: 0.7132 - val_loss: 0.8904 - val_accuracy: 0.6875\n",
            "Epoch 135/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8454 - accuracy: 0.7033 - val_loss: 0.8842 - val_accuracy: 0.6942\n",
            "Epoch 136/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8179 - accuracy: 0.7181 - val_loss: 0.8731 - val_accuracy: 0.7083\n",
            "Epoch 137/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8278 - accuracy: 0.7061 - val_loss: 0.9095 - val_accuracy: 0.6950\n",
            "Epoch 138/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8488 - accuracy: 0.6988 - val_loss: 0.9372 - val_accuracy: 0.6733\n",
            "Epoch 139/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8567 - accuracy: 0.6844 - val_loss: 0.8824 - val_accuracy: 0.6917\n",
            "Epoch 140/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8221 - accuracy: 0.7247 - val_loss: 0.8775 - val_accuracy: 0.6875\n",
            "Epoch 141/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8103 - accuracy: 0.7107 - val_loss: 0.8775 - val_accuracy: 0.7050\n",
            "Epoch 142/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8423 - accuracy: 0.7148 - val_loss: 0.9252 - val_accuracy: 0.6850\n",
            "Epoch 143/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8451 - accuracy: 0.6957 - val_loss: 0.8753 - val_accuracy: 0.6808\n",
            "Epoch 144/2000\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.8167 - accuracy: 0.7130 - val_loss: 0.8644 - val_accuracy: 0.7167\n",
            "Epoch 145/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8244 - accuracy: 0.7050 - val_loss: 0.8737 - val_accuracy: 0.6808\n",
            "Epoch 146/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8416 - accuracy: 0.7023 - val_loss: 0.8884 - val_accuracy: 0.6850\n",
            "Epoch 147/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8437 - accuracy: 0.6969 - val_loss: 0.9007 - val_accuracy: 0.6917\n",
            "Epoch 148/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7975 - accuracy: 0.7303 - val_loss: 0.8719 - val_accuracy: 0.7083\n",
            "Epoch 149/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7886 - accuracy: 0.7319 - val_loss: 0.8649 - val_accuracy: 0.7075\n",
            "Epoch 150/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8012 - accuracy: 0.7222 - val_loss: 0.8763 - val_accuracy: 0.6892\n",
            "Epoch 151/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8009 - accuracy: 0.7055 - val_loss: 0.8574 - val_accuracy: 0.7142\n",
            "Epoch 152/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8141 - accuracy: 0.7176 - val_loss: 0.8678 - val_accuracy: 0.7050\n",
            "Epoch 153/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8009 - accuracy: 0.7148 - val_loss: 0.8634 - val_accuracy: 0.7175\n",
            "Epoch 154/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8074 - accuracy: 0.7249 - val_loss: 0.8973 - val_accuracy: 0.7125\n",
            "Epoch 155/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8139 - accuracy: 0.7142 - val_loss: 0.8715 - val_accuracy: 0.7183\n",
            "Epoch 156/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7990 - accuracy: 0.7334 - val_loss: 0.8784 - val_accuracy: 0.7058\n",
            "Epoch 157/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8007 - accuracy: 0.7160 - val_loss: 0.8731 - val_accuracy: 0.6942\n",
            "Epoch 158/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7851 - accuracy: 0.7303 - val_loss: 0.8589 - val_accuracy: 0.7117\n",
            "Epoch 159/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7976 - accuracy: 0.7127 - val_loss: 0.8551 - val_accuracy: 0.7000\n",
            "Epoch 160/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7793 - accuracy: 0.7294 - val_loss: 0.8834 - val_accuracy: 0.7050\n",
            "Epoch 161/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8035 - accuracy: 0.7177 - val_loss: 0.8980 - val_accuracy: 0.7033\n",
            "Epoch 162/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8117 - accuracy: 0.7248 - val_loss: 0.8352 - val_accuracy: 0.7292\n",
            "Epoch 163/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7914 - accuracy: 0.7298 - val_loss: 0.8841 - val_accuracy: 0.6933\n",
            "Epoch 164/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7868 - accuracy: 0.7361 - val_loss: 0.8570 - val_accuracy: 0.7142\n",
            "Epoch 165/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7972 - accuracy: 0.7199 - val_loss: 0.8500 - val_accuracy: 0.7000\n",
            "Epoch 166/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7696 - accuracy: 0.7262 - val_loss: 0.8617 - val_accuracy: 0.7050\n",
            "Epoch 167/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7878 - accuracy: 0.7215 - val_loss: 0.8588 - val_accuracy: 0.7175\n",
            "Epoch 168/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7941 - accuracy: 0.7304 - val_loss: 0.8846 - val_accuracy: 0.7183\n",
            "Epoch 169/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8025 - accuracy: 0.7260 - val_loss: 0.8950 - val_accuracy: 0.6950\n",
            "Epoch 170/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8007 - accuracy: 0.7143 - val_loss: 0.8563 - val_accuracy: 0.6900\n",
            "Epoch 171/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7653 - accuracy: 0.7188 - val_loss: 0.8578 - val_accuracy: 0.7133\n",
            "Epoch 172/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7568 - accuracy: 0.7378 - val_loss: 0.8401 - val_accuracy: 0.7300\n",
            "Epoch 173/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7935 - accuracy: 0.7207 - val_loss: 0.8411 - val_accuracy: 0.7317\n",
            "Epoch 174/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7799 - accuracy: 0.7378 - val_loss: 0.8864 - val_accuracy: 0.7100\n",
            "Epoch 175/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8024 - accuracy: 0.7283 - val_loss: 0.8665 - val_accuracy: 0.6875\n",
            "Epoch 176/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7993 - accuracy: 0.7240 - val_loss: 0.8497 - val_accuracy: 0.6758\n",
            "Epoch 177/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7629 - accuracy: 0.7341 - val_loss: 0.8412 - val_accuracy: 0.7208\n",
            "Epoch 178/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7920 - accuracy: 0.7289 - val_loss: 0.8370 - val_accuracy: 0.7075\n",
            "Epoch 179/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7565 - accuracy: 0.7305 - val_loss: 0.8398 - val_accuracy: 0.7158\n",
            "Epoch 180/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7634 - accuracy: 0.7329 - val_loss: 0.8493 - val_accuracy: 0.7117\n",
            "Epoch 181/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7833 - accuracy: 0.7302 - val_loss: 0.8822 - val_accuracy: 0.6908\n",
            "Epoch 182/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7846 - accuracy: 0.7290 - val_loss: 0.8932 - val_accuracy: 0.6792\n",
            "Epoch 183/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7811 - accuracy: 0.7219 - val_loss: 0.8529 - val_accuracy: 0.7242\n",
            "Epoch 184/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7709 - accuracy: 0.7251 - val_loss: 0.8577 - val_accuracy: 0.6842\n",
            "Epoch 185/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7753 - accuracy: 0.7276 - val_loss: 0.8411 - val_accuracy: 0.7083\n",
            "Epoch 186/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7789 - accuracy: 0.7162 - val_loss: 0.8609 - val_accuracy: 0.7125\n",
            "Epoch 187/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7615 - accuracy: 0.7487 - val_loss: 0.8584 - val_accuracy: 0.6983\n",
            "Epoch 188/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7654 - accuracy: 0.7358 - val_loss: 0.8424 - val_accuracy: 0.7192\n",
            "Epoch 189/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7601 - accuracy: 0.7219 - val_loss: 0.8280 - val_accuracy: 0.7117\n",
            "Epoch 190/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7572 - accuracy: 0.7285 - val_loss: 0.8317 - val_accuracy: 0.7025\n",
            "Epoch 191/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7615 - accuracy: 0.7390 - val_loss: 0.8859 - val_accuracy: 0.7133\n",
            "Epoch 192/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7793 - accuracy: 0.7326 - val_loss: 0.8138 - val_accuracy: 0.7400\n",
            "Epoch 193/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7490 - accuracy: 0.7323 - val_loss: 0.8338 - val_accuracy: 0.7108\n",
            "Epoch 194/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7666 - accuracy: 0.7343 - val_loss: 0.8098 - val_accuracy: 0.7350\n",
            "Epoch 195/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7541 - accuracy: 0.7368 - val_loss: 0.7972 - val_accuracy: 0.7458\n",
            "Epoch 196/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7482 - accuracy: 0.7318 - val_loss: 0.8181 - val_accuracy: 0.7142\n",
            "Epoch 197/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7475 - accuracy: 0.7346 - val_loss: 0.8467 - val_accuracy: 0.7250\n",
            "Epoch 198/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7325 - accuracy: 0.7441 - val_loss: 0.8245 - val_accuracy: 0.7200\n",
            "Epoch 199/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7644 - accuracy: 0.7332 - val_loss: 0.8463 - val_accuracy: 0.7142\n",
            "Epoch 200/2000\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.7547 - accuracy: 0.7401 - val_loss: 0.8356 - val_accuracy: 0.7175\n",
            "Epoch 201/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7300 - accuracy: 0.7475 - val_loss: 0.8510 - val_accuracy: 0.6942\n",
            "Epoch 202/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7549 - accuracy: 0.7411 - val_loss: 0.8352 - val_accuracy: 0.7008\n",
            "Epoch 203/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7514 - accuracy: 0.7420 - val_loss: 0.8326 - val_accuracy: 0.7000\n",
            "Epoch 204/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7546 - accuracy: 0.7370 - val_loss: 0.9320 - val_accuracy: 0.6958\n",
            "Epoch 205/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7989 - accuracy: 0.7231 - val_loss: 0.8260 - val_accuracy: 0.7292\n",
            "Epoch 206/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7257 - accuracy: 0.7453 - val_loss: 0.8143 - val_accuracy: 0.7275\n",
            "Epoch 207/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7476 - accuracy: 0.7420 - val_loss: 0.8372 - val_accuracy: 0.6925\n",
            "Epoch 208/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7472 - accuracy: 0.7349 - val_loss: 0.8136 - val_accuracy: 0.7233\n",
            "Epoch 209/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7454 - accuracy: 0.7369 - val_loss: 0.7857 - val_accuracy: 0.7142\n",
            "Epoch 210/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7371 - accuracy: 0.7400 - val_loss: 0.8078 - val_accuracy: 0.7150\n",
            "Epoch 211/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7748 - accuracy: 0.7335 - val_loss: 0.8013 - val_accuracy: 0.7350\n",
            "Epoch 212/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7147 - accuracy: 0.7547 - val_loss: 0.7891 - val_accuracy: 0.7150\n",
            "Epoch 213/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7102 - accuracy: 0.7576 - val_loss: 0.7901 - val_accuracy: 0.7258\n",
            "Epoch 214/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7224 - accuracy: 0.7445 - val_loss: 0.7936 - val_accuracy: 0.7258\n",
            "Epoch 215/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7262 - accuracy: 0.7461 - val_loss: 0.8281 - val_accuracy: 0.7092\n",
            "Epoch 216/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7342 - accuracy: 0.7516 - val_loss: 0.8144 - val_accuracy: 0.7008\n",
            "Epoch 217/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7449 - accuracy: 0.7281 - val_loss: 0.8023 - val_accuracy: 0.6950\n",
            "Epoch 218/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7131 - accuracy: 0.7479 - val_loss: 0.7843 - val_accuracy: 0.7392\n",
            "Epoch 219/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7149 - accuracy: 0.7677 - val_loss: 0.7980 - val_accuracy: 0.7383\n",
            "Epoch 220/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7215 - accuracy: 0.7601 - val_loss: 0.8084 - val_accuracy: 0.7217\n",
            "Epoch 221/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7056 - accuracy: 0.7458 - val_loss: 0.7707 - val_accuracy: 0.7442\n",
            "Epoch 222/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7215 - accuracy: 0.7508 - val_loss: 0.8221 - val_accuracy: 0.7108\n",
            "Epoch 223/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7264 - accuracy: 0.7462 - val_loss: 0.8026 - val_accuracy: 0.7333\n",
            "Epoch 224/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7145 - accuracy: 0.7543 - val_loss: 0.8019 - val_accuracy: 0.7342\n",
            "Epoch 225/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7176 - accuracy: 0.7520 - val_loss: 0.8384 - val_accuracy: 0.7000\n",
            "Epoch 226/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7159 - accuracy: 0.7479 - val_loss: 0.8219 - val_accuracy: 0.7383\n",
            "Epoch 227/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7415 - accuracy: 0.7422 - val_loss: 0.8991 - val_accuracy: 0.7317\n",
            "Epoch 228/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7895 - accuracy: 0.7296 - val_loss: 0.8184 - val_accuracy: 0.7067\n",
            "Epoch 229/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7231 - accuracy: 0.7523 - val_loss: 0.8242 - val_accuracy: 0.7175\n",
            "Epoch 230/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7425 - accuracy: 0.7307 - val_loss: 0.8259 - val_accuracy: 0.7117\n",
            "Epoch 231/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7463 - accuracy: 0.7328 - val_loss: 0.7941 - val_accuracy: 0.7125\n",
            "Epoch 232/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7159 - accuracy: 0.7444 - val_loss: 0.7776 - val_accuracy: 0.7217\n",
            "Epoch 233/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7156 - accuracy: 0.7440 - val_loss: 0.7795 - val_accuracy: 0.7300\n",
            "Epoch 234/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7020 - accuracy: 0.7570 - val_loss: 0.7839 - val_accuracy: 0.7408\n",
            "Epoch 235/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7174 - accuracy: 0.7502 - val_loss: 0.8385 - val_accuracy: 0.7108\n",
            "Epoch 236/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7096 - accuracy: 0.7518 - val_loss: 0.8267 - val_accuracy: 0.7317\n",
            "Epoch 237/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7156 - accuracy: 0.7548 - val_loss: 0.7927 - val_accuracy: 0.7308\n",
            "Epoch 238/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7220 - accuracy: 0.7503 - val_loss: 0.8115 - val_accuracy: 0.7208\n",
            "Epoch 239/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6943 - accuracy: 0.7403 - val_loss: 0.7938 - val_accuracy: 0.7233\n",
            "Epoch 240/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6990 - accuracy: 0.7580 - val_loss: 0.7786 - val_accuracy: 0.7058\n",
            "Epoch 241/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6911 - accuracy: 0.7545 - val_loss: 0.8178 - val_accuracy: 0.7175\n",
            "Epoch 242/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7046 - accuracy: 0.7586 - val_loss: 0.7871 - val_accuracy: 0.7367\n",
            "Epoch 243/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7131 - accuracy: 0.7539 - val_loss: 0.8204 - val_accuracy: 0.7233\n",
            "Epoch 244/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6935 - accuracy: 0.7548 - val_loss: 0.8026 - val_accuracy: 0.7208\n",
            "Epoch 245/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7146 - accuracy: 0.7525 - val_loss: 0.8031 - val_accuracy: 0.7367\n",
            "Epoch 246/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6956 - accuracy: 0.7552 - val_loss: 0.7912 - val_accuracy: 0.7225\n",
            "Epoch 247/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7074 - accuracy: 0.7417 - val_loss: 0.7869 - val_accuracy: 0.7150\n",
            "Epoch 248/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7232 - accuracy: 0.7430 - val_loss: 0.8093 - val_accuracy: 0.7192\n",
            "Epoch 249/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6998 - accuracy: 0.7523 - val_loss: 0.8539 - val_accuracy: 0.7175\n",
            "Epoch 250/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7485 - accuracy: 0.7316 - val_loss: 0.8102 - val_accuracy: 0.7200\n",
            "Epoch 251/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7263 - accuracy: 0.7437 - val_loss: 0.8025 - val_accuracy: 0.7058\n",
            "Epoch 252/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7032 - accuracy: 0.7496 - val_loss: 0.7940 - val_accuracy: 0.7092\n",
            "Epoch 253/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7232 - accuracy: 0.7452 - val_loss: 0.7583 - val_accuracy: 0.7350\n",
            "Epoch 254/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6846 - accuracy: 0.7677 - val_loss: 0.7905 - val_accuracy: 0.7267\n",
            "Epoch 255/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6975 - accuracy: 0.7512 - val_loss: 0.7478 - val_accuracy: 0.7433\n",
            "Epoch 256/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.7537 - val_loss: 0.7622 - val_accuracy: 0.7358\n",
            "Epoch 257/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7267 - accuracy: 0.7474 - val_loss: 0.7933 - val_accuracy: 0.7250\n",
            "Epoch 258/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7013 - accuracy: 0.7461 - val_loss: 0.7736 - val_accuracy: 0.7300\n",
            "Epoch 259/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6839 - accuracy: 0.7625 - val_loss: 0.7971 - val_accuracy: 0.7358\n",
            "Epoch 260/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7070 - accuracy: 0.7481 - val_loss: 0.7989 - val_accuracy: 0.7275\n",
            "Epoch 261/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.7464 - val_loss: 0.7606 - val_accuracy: 0.7300\n",
            "Epoch 262/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7163 - accuracy: 0.7425 - val_loss: 0.7870 - val_accuracy: 0.7183\n",
            "Epoch 263/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7110 - accuracy: 0.7471 - val_loss: 0.7665 - val_accuracy: 0.7392\n",
            "Epoch 264/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6792 - accuracy: 0.7608 - val_loss: 0.7994 - val_accuracy: 0.7283\n",
            "Epoch 265/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7068 - accuracy: 0.7376 - val_loss: 0.8047 - val_accuracy: 0.7383\n",
            "Epoch 266/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7118 - accuracy: 0.7459 - val_loss: 0.7545 - val_accuracy: 0.7633\n",
            "Epoch 267/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7033 - accuracy: 0.7591 - val_loss: 0.7850 - val_accuracy: 0.7367\n",
            "Epoch 268/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.6927 - accuracy: 0.7528 - val_loss: 0.7973 - val_accuracy: 0.7250\n",
            "Epoch 269/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7173 - accuracy: 0.7426 - val_loss: 0.7485 - val_accuracy: 0.7558\n",
            "Epoch 270/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6826 - accuracy: 0.7616 - val_loss: 0.7610 - val_accuracy: 0.7333\n",
            "Epoch 271/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6939 - accuracy: 0.7507 - val_loss: 0.8365 - val_accuracy: 0.7025\n",
            "Epoch 272/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.7396 - accuracy: 0.7543 - val_loss: 0.8322 - val_accuracy: 0.7192\n",
            "Epoch 273/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7021 - accuracy: 0.7645 - val_loss: 0.7591 - val_accuracy: 0.7483\n",
            "Epoch 274/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6814 - accuracy: 0.7675 - val_loss: 0.7465 - val_accuracy: 0.7675\n",
            "Epoch 275/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6786 - accuracy: 0.7679 - val_loss: 0.7807 - val_accuracy: 0.7167\n",
            "Epoch 276/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6880 - accuracy: 0.7638 - val_loss: 0.7732 - val_accuracy: 0.7433\n",
            "Epoch 277/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6899 - accuracy: 0.7529 - val_loss: 0.7755 - val_accuracy: 0.7508\n",
            "Epoch 278/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7213 - accuracy: 0.7580 - val_loss: 0.7548 - val_accuracy: 0.7383\n",
            "Epoch 279/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6760 - accuracy: 0.7620 - val_loss: 0.8030 - val_accuracy: 0.7275\n",
            "Epoch 280/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7000 - accuracy: 0.7628 - val_loss: 0.7502 - val_accuracy: 0.7667\n",
            "Epoch 281/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7054 - accuracy: 0.7552 - val_loss: 0.7491 - val_accuracy: 0.7600\n",
            "Epoch 282/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6770 - accuracy: 0.7683 - val_loss: 0.7918 - val_accuracy: 0.7250\n",
            "Epoch 283/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7055 - accuracy: 0.7547 - val_loss: 0.7549 - val_accuracy: 0.7392\n",
            "Epoch 284/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6927 - accuracy: 0.7667 - val_loss: 0.7704 - val_accuracy: 0.7233\n",
            "Epoch 285/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6667 - accuracy: 0.7663 - val_loss: 0.7887 - val_accuracy: 0.7125\n",
            "Epoch 286/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.7463 - val_loss: 0.7480 - val_accuracy: 0.7758\n",
            "Epoch 287/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6837 - accuracy: 0.7699 - val_loss: 0.7839 - val_accuracy: 0.7233\n",
            "Epoch 288/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6859 - accuracy: 0.7503 - val_loss: 0.7455 - val_accuracy: 0.7408\n",
            "Epoch 289/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6736 - accuracy: 0.7596 - val_loss: 0.7883 - val_accuracy: 0.7483\n",
            "Epoch 290/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.7542 - val_loss: 0.7815 - val_accuracy: 0.7267\n",
            "Epoch 291/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6962 - accuracy: 0.7569 - val_loss: 0.7845 - val_accuracy: 0.7492\n",
            "Epoch 292/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6753 - accuracy: 0.7675 - val_loss: 0.8343 - val_accuracy: 0.7342\n",
            "Epoch 293/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6890 - accuracy: 0.7704 - val_loss: 0.7607 - val_accuracy: 0.7442\n",
            "Epoch 294/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6827 - accuracy: 0.7736 - val_loss: 0.8230 - val_accuracy: 0.7350\n",
            "Epoch 295/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6734 - accuracy: 0.7693 - val_loss: 0.7510 - val_accuracy: 0.7425\n",
            "Epoch 296/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7046 - accuracy: 0.7600 - val_loss: 0.7769 - val_accuracy: 0.7283\n",
            "Epoch 297/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6831 - accuracy: 0.7640 - val_loss: 0.7280 - val_accuracy: 0.7683\n",
            "Epoch 298/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6662 - accuracy: 0.7733 - val_loss: 0.7983 - val_accuracy: 0.7042\n",
            "Epoch 299/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6627 - accuracy: 0.7561 - val_loss: 0.7465 - val_accuracy: 0.7458\n",
            "Epoch 300/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6737 - accuracy: 0.7668 - val_loss: 0.7338 - val_accuracy: 0.7517\n",
            "Epoch 301/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6520 - accuracy: 0.7709 - val_loss: 0.7495 - val_accuracy: 0.7383\n",
            "Epoch 302/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6691 - accuracy: 0.7638 - val_loss: 0.7723 - val_accuracy: 0.7417\n",
            "Epoch 303/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6464 - accuracy: 0.7630 - val_loss: 0.7362 - val_accuracy: 0.7633\n",
            "Epoch 304/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6496 - accuracy: 0.7720 - val_loss: 0.7656 - val_accuracy: 0.7467\n",
            "Epoch 305/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6694 - accuracy: 0.7747 - val_loss: 0.7755 - val_accuracy: 0.7225\n",
            "Epoch 306/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6738 - accuracy: 0.7552 - val_loss: 0.7728 - val_accuracy: 0.7308\n",
            "Epoch 307/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6807 - accuracy: 0.7568 - val_loss: 0.7888 - val_accuracy: 0.7325\n",
            "Epoch 308/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7067 - accuracy: 0.7554 - val_loss: 0.7827 - val_accuracy: 0.7300\n",
            "Epoch 309/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6609 - accuracy: 0.7561 - val_loss: 0.7815 - val_accuracy: 0.7308\n",
            "Epoch 310/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6846 - accuracy: 0.7609 - val_loss: 0.7545 - val_accuracy: 0.7358\n",
            "Epoch 311/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6717 - accuracy: 0.7615 - val_loss: 0.8026 - val_accuracy: 0.7492\n",
            "Epoch 312/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6801 - accuracy: 0.7624 - val_loss: 0.9479 - val_accuracy: 0.7400\n",
            "Epoch 313/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7924 - accuracy: 0.7612 - val_loss: 0.7690 - val_accuracy: 0.7400\n",
            "Epoch 314/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6600 - accuracy: 0.7650 - val_loss: 0.7298 - val_accuracy: 0.7475\n",
            "Epoch 315/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6547 - accuracy: 0.7639 - val_loss: 0.7782 - val_accuracy: 0.7450\n",
            "Epoch 316/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6548 - accuracy: 0.7698 - val_loss: 0.7336 - val_accuracy: 0.7600\n",
            "Epoch 317/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6687 - accuracy: 0.7675 - val_loss: 0.7427 - val_accuracy: 0.7533\n",
            "Epoch 318/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6651 - accuracy: 0.7683 - val_loss: 0.7306 - val_accuracy: 0.7625\n",
            "Epoch 319/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6402 - accuracy: 0.7814 - val_loss: 0.7580 - val_accuracy: 0.7567\n",
            "Epoch 320/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6515 - accuracy: 0.7760 - val_loss: 0.7418 - val_accuracy: 0.7608\n",
            "Epoch 321/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6647 - accuracy: 0.7761 - val_loss: 0.7338 - val_accuracy: 0.7517\n",
            "Epoch 322/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6442 - accuracy: 0.7744 - val_loss: 0.7258 - val_accuracy: 0.7317\n",
            "Epoch 323/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6476 - accuracy: 0.7625 - val_loss: 0.7730 - val_accuracy: 0.7233\n",
            "Epoch 324/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6661 - accuracy: 0.7636 - val_loss: 0.7514 - val_accuracy: 0.7417\n",
            "Epoch 325/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6683 - accuracy: 0.7649 - val_loss: 0.7472 - val_accuracy: 0.7392\n",
            "Epoch 326/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.6637 - accuracy: 0.7689 - val_loss: 0.7340 - val_accuracy: 0.7550\n",
            "Epoch 327/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.7721 - val_loss: 0.7586 - val_accuracy: 0.7100\n",
            "Epoch 328/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6592 - accuracy: 0.7692 - val_loss: 0.7740 - val_accuracy: 0.7392\n",
            "Epoch 329/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6837 - accuracy: 0.7650 - val_loss: 0.7408 - val_accuracy: 0.7492\n",
            "Epoch 330/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6698 - accuracy: 0.7612 - val_loss: 0.8017 - val_accuracy: 0.7400\n",
            "Epoch 331/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6799 - accuracy: 0.7635 - val_loss: 0.7443 - val_accuracy: 0.7408\n",
            "Epoch 332/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6578 - accuracy: 0.7672 - val_loss: 0.7531 - val_accuracy: 0.7583\n",
            "Epoch 333/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6400 - accuracy: 0.7720 - val_loss: 0.7630 - val_accuracy: 0.7525\n",
            "Epoch 334/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6439 - accuracy: 0.7787 - val_loss: 0.8026 - val_accuracy: 0.7450\n",
            "Epoch 335/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6638 - accuracy: 0.7599 - val_loss: 0.7344 - val_accuracy: 0.7525\n",
            "Epoch 336/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6406 - accuracy: 0.7755 - val_loss: 0.7849 - val_accuracy: 0.7483\n",
            "Epoch 337/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6798 - accuracy: 0.7729 - val_loss: 0.7570 - val_accuracy: 0.7458\n",
            "Epoch 338/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.7734 - val_loss: 0.7523 - val_accuracy: 0.7467\n",
            "Epoch 339/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6589 - accuracy: 0.7813 - val_loss: 0.7949 - val_accuracy: 0.7567\n",
            "Epoch 340/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6413 - accuracy: 0.7770 - val_loss: 0.7722 - val_accuracy: 0.7475\n",
            "Epoch 341/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6622 - accuracy: 0.7732 - val_loss: 0.7779 - val_accuracy: 0.7525\n",
            "Epoch 342/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6581 - accuracy: 0.7696 - val_loss: 0.7789 - val_accuracy: 0.7183\n",
            "Epoch 343/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6883 - accuracy: 0.7565 - val_loss: 0.7521 - val_accuracy: 0.7533\n",
            "Epoch 344/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6799 - accuracy: 0.7597 - val_loss: 0.7461 - val_accuracy: 0.7592\n",
            "Epoch 345/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6388 - accuracy: 0.7854 - val_loss: 0.7489 - val_accuracy: 0.7633\n",
            "Epoch 346/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6210 - accuracy: 0.7914 - val_loss: 0.7762 - val_accuracy: 0.7400\n",
            "Epoch 347/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6728 - accuracy: 0.7600 - val_loss: 0.7903 - val_accuracy: 0.7408\n",
            "Epoch 348/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6444 - accuracy: 0.7743 - val_loss: 0.7599 - val_accuracy: 0.7533\n",
            "Epoch 349/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6291 - accuracy: 0.7755 - val_loss: 0.7528 - val_accuracy: 0.7533\n",
            "Epoch 350/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6594 - accuracy: 0.7647 - val_loss: 0.8667 - val_accuracy: 0.7417\n",
            "Epoch 351/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7093 - accuracy: 0.7663 - val_loss: 0.7348 - val_accuracy: 0.7567\n",
            "Epoch 352/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6257 - accuracy: 0.7937 - val_loss: 0.7541 - val_accuracy: 0.7425\n",
            "Epoch 353/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6603 - accuracy: 0.7622 - val_loss: 0.8022 - val_accuracy: 0.7258\n",
            "Epoch 354/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6658 - accuracy: 0.7689 - val_loss: 0.7313 - val_accuracy: 0.7575\n",
            "Epoch 355/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6620 - accuracy: 0.7678 - val_loss: 0.7253 - val_accuracy: 0.7675\n",
            "Epoch 356/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6157 - accuracy: 0.7846 - val_loss: 0.7931 - val_accuracy: 0.7342\n",
            "Epoch 357/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.7617 - val_loss: 0.7423 - val_accuracy: 0.7433\n",
            "Epoch 358/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6584 - accuracy: 0.7622 - val_loss: 0.7093 - val_accuracy: 0.7683\n",
            "Epoch 359/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6378 - accuracy: 0.7840 - val_loss: 0.7554 - val_accuracy: 0.7675\n",
            "Epoch 360/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6612 - accuracy: 0.7668 - val_loss: 0.7315 - val_accuracy: 0.7417\n",
            "Epoch 361/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6222 - accuracy: 0.7786 - val_loss: 0.7260 - val_accuracy: 0.7592\n",
            "Epoch 362/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6356 - accuracy: 0.7810 - val_loss: 0.7841 - val_accuracy: 0.7367\n",
            "Epoch 363/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6653 - accuracy: 0.7622 - val_loss: 0.7503 - val_accuracy: 0.7783\n",
            "Epoch 364/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6274 - accuracy: 0.7924 - val_loss: 0.7430 - val_accuracy: 0.7417\n",
            "Epoch 365/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6278 - accuracy: 0.7734 - val_loss: 0.7355 - val_accuracy: 0.7800\n",
            "Epoch 366/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6221 - accuracy: 0.7953 - val_loss: 0.7329 - val_accuracy: 0.7650\n",
            "Epoch 367/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6283 - accuracy: 0.7841 - val_loss: 0.7380 - val_accuracy: 0.7583\n",
            "Epoch 368/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6340 - accuracy: 0.7775 - val_loss: 0.7191 - val_accuracy: 0.7567\n",
            "Epoch 369/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6438 - accuracy: 0.7670 - val_loss: 0.7322 - val_accuracy: 0.7683\n",
            "Epoch 370/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6581 - accuracy: 0.7575 - val_loss: 0.7791 - val_accuracy: 0.7167\n",
            "Epoch 371/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6363 - accuracy: 0.7796 - val_loss: 0.7237 - val_accuracy: 0.7550\n",
            "Epoch 372/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6151 - accuracy: 0.7821 - val_loss: 0.7300 - val_accuracy: 0.7408\n",
            "Epoch 373/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6536 - accuracy: 0.7636 - val_loss: 0.7449 - val_accuracy: 0.7650\n",
            "Epoch 374/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6578 - accuracy: 0.7776 - val_loss: 0.8790 - val_accuracy: 0.7600\n",
            "Epoch 375/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6473 - accuracy: 0.7801 - val_loss: 0.7174 - val_accuracy: 0.7633\n",
            "Epoch 376/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6478 - accuracy: 0.7886 - val_loss: 0.7558 - val_accuracy: 0.7417\n",
            "Epoch 377/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6406 - accuracy: 0.7773 - val_loss: 0.7388 - val_accuracy: 0.7408\n",
            "Epoch 378/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6532 - accuracy: 0.7705 - val_loss: 0.7391 - val_accuracy: 0.7542\n",
            "Epoch 379/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6276 - accuracy: 0.7813 - val_loss: 0.7222 - val_accuracy: 0.7600\n",
            "Epoch 380/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6396 - accuracy: 0.7721 - val_loss: 0.7215 - val_accuracy: 0.7592\n",
            "Epoch 381/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6474 - accuracy: 0.7799 - val_loss: 0.7183 - val_accuracy: 0.7583\n",
            "Epoch 382/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6392 - accuracy: 0.7721 - val_loss: 0.7484 - val_accuracy: 0.7542\n",
            "Epoch 383/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6417 - accuracy: 0.7704 - val_loss: 0.7370 - val_accuracy: 0.7517\n",
            "Epoch 384/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6275 - accuracy: 0.7868 - val_loss: 0.7005 - val_accuracy: 0.7817\n",
            "Epoch 385/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6203 - accuracy: 0.7795 - val_loss: 0.7102 - val_accuracy: 0.7817\n",
            "Epoch 386/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6306 - accuracy: 0.7791 - val_loss: 0.7368 - val_accuracy: 0.7467\n",
            "Epoch 387/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6328 - accuracy: 0.7771 - val_loss: 0.7195 - val_accuracy: 0.7625\n",
            "Epoch 388/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6365 - accuracy: 0.7848 - val_loss: 0.6904 - val_accuracy: 0.7792\n",
            "Epoch 389/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6453 - accuracy: 0.7780 - val_loss: 0.7053 - val_accuracy: 0.7617\n",
            "Epoch 390/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6356 - accuracy: 0.7787 - val_loss: 0.7503 - val_accuracy: 0.7367\n",
            "Epoch 391/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6343 - accuracy: 0.7742 - val_loss: 0.7110 - val_accuracy: 0.7542\n",
            "Epoch 392/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6366 - accuracy: 0.7697 - val_loss: 0.7183 - val_accuracy: 0.7633\n",
            "Epoch 393/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6237 - accuracy: 0.7752 - val_loss: 0.7756 - val_accuracy: 0.7367\n",
            "Epoch 394/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.6536 - accuracy: 0.7731 - val_loss: 0.7220 - val_accuracy: 0.7508\n",
            "Epoch 395/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6067 - accuracy: 0.7894 - val_loss: 0.7407 - val_accuracy: 0.7450\n",
            "Epoch 396/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6575 - accuracy: 0.7719 - val_loss: 0.7397 - val_accuracy: 0.7442\n",
            "Epoch 397/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6409 - accuracy: 0.7746 - val_loss: 0.7248 - val_accuracy: 0.7575\n",
            "Epoch 398/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6494 - accuracy: 0.7723 - val_loss: 0.7637 - val_accuracy: 0.7617\n",
            "Epoch 399/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6304 - accuracy: 0.7881 - val_loss: 0.6893 - val_accuracy: 0.7600\n",
            "Epoch 400/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6271 - accuracy: 0.7923 - val_loss: 0.6957 - val_accuracy: 0.7733\n",
            "Epoch 401/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6285 - accuracy: 0.7854 - val_loss: 0.7037 - val_accuracy: 0.7492\n",
            "Epoch 402/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6172 - accuracy: 0.7751 - val_loss: 0.7119 - val_accuracy: 0.7542\n",
            "Epoch 403/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6248 - accuracy: 0.7789 - val_loss: 0.7085 - val_accuracy: 0.7833\n",
            "Epoch 404/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5988 - accuracy: 0.8005 - val_loss: 0.7222 - val_accuracy: 0.7683\n",
            "Epoch 405/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6248 - accuracy: 0.7827 - val_loss: 0.8233 - val_accuracy: 0.7400\n",
            "Epoch 406/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6605 - accuracy: 0.7811 - val_loss: 0.7158 - val_accuracy: 0.7733\n",
            "Epoch 407/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6414 - accuracy: 0.7692 - val_loss: 0.7872 - val_accuracy: 0.7708\n",
            "Epoch 408/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6139 - accuracy: 0.7915 - val_loss: 0.7019 - val_accuracy: 0.7783\n",
            "Epoch 409/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6239 - accuracy: 0.7774 - val_loss: 0.7293 - val_accuracy: 0.7617\n",
            "Epoch 410/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6328 - accuracy: 0.7831 - val_loss: 0.7333 - val_accuracy: 0.7600\n",
            "Epoch 411/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6115 - accuracy: 0.7855 - val_loss: 0.7201 - val_accuracy: 0.7592\n",
            "Epoch 412/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6402 - accuracy: 0.7831 - val_loss: 0.7374 - val_accuracy: 0.7333\n",
            "Epoch 413/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6285 - accuracy: 0.7709 - val_loss: 0.7012 - val_accuracy: 0.7642\n",
            "Epoch 414/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6300 - accuracy: 0.7800 - val_loss: 0.7572 - val_accuracy: 0.7433\n",
            "Epoch 415/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6245 - accuracy: 0.7936 - val_loss: 0.7072 - val_accuracy: 0.7875\n",
            "Epoch 416/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6120 - accuracy: 0.7795 - val_loss: 0.7189 - val_accuracy: 0.7350\n",
            "Epoch 417/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6068 - accuracy: 0.7837 - val_loss: 0.7103 - val_accuracy: 0.7650\n",
            "Epoch 418/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6328 - accuracy: 0.7735 - val_loss: 0.7138 - val_accuracy: 0.7583\n",
            "Epoch 419/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6196 - accuracy: 0.7821 - val_loss: 0.7403 - val_accuracy: 0.7700\n",
            "Epoch 420/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6432 - accuracy: 0.7781 - val_loss: 0.7072 - val_accuracy: 0.7600\n",
            "Epoch 421/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6188 - accuracy: 0.7666 - val_loss: 0.6913 - val_accuracy: 0.7683\n",
            "Epoch 422/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6133 - accuracy: 0.7869 - val_loss: 0.7466 - val_accuracy: 0.7517\n",
            "Epoch 423/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6580 - accuracy: 0.7688 - val_loss: 0.7189 - val_accuracy: 0.7683\n",
            "Epoch 424/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6534 - accuracy: 0.7766 - val_loss: 0.7544 - val_accuracy: 0.7575\n",
            "Epoch 425/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6436 - accuracy: 0.7720 - val_loss: 0.7027 - val_accuracy: 0.7625\n",
            "Epoch 426/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6164 - accuracy: 0.7923 - val_loss: 0.8779 - val_accuracy: 0.7500\n",
            "Epoch 427/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6637 - accuracy: 0.7716 - val_loss: 0.7454 - val_accuracy: 0.7592\n",
            "Epoch 428/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6044 - accuracy: 0.7938 - val_loss: 0.7220 - val_accuracy: 0.7417\n",
            "Epoch 429/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6144 - accuracy: 0.7838 - val_loss: 0.6954 - val_accuracy: 0.7792\n",
            "Epoch 430/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6374 - accuracy: 0.7796 - val_loss: 0.7069 - val_accuracy: 0.7750\n",
            "Epoch 431/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5997 - accuracy: 0.7898 - val_loss: 0.7108 - val_accuracy: 0.7692\n",
            "Epoch 432/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6120 - accuracy: 0.7864 - val_loss: 0.7022 - val_accuracy: 0.7683\n",
            "Epoch 433/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6038 - accuracy: 0.7815 - val_loss: 0.7084 - val_accuracy: 0.7617\n",
            "Epoch 434/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6121 - accuracy: 0.7846 - val_loss: 0.7050 - val_accuracy: 0.7675\n",
            "Epoch 435/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6198 - accuracy: 0.7814 - val_loss: 0.7129 - val_accuracy: 0.7592\n",
            "Epoch 436/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6137 - accuracy: 0.7806 - val_loss: 0.7074 - val_accuracy: 0.7442\n",
            "Epoch 437/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6030 - accuracy: 0.7922 - val_loss: 0.6902 - val_accuracy: 0.7850\n",
            "Epoch 438/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6075 - accuracy: 0.7995 - val_loss: 0.7512 - val_accuracy: 0.7383\n",
            "Epoch 439/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6434 - accuracy: 0.7731 - val_loss: 0.7140 - val_accuracy: 0.7533\n",
            "Epoch 440/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6198 - accuracy: 0.7893 - val_loss: 0.7454 - val_accuracy: 0.7575\n",
            "Epoch 441/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6246 - accuracy: 0.7838 - val_loss: 0.7294 - val_accuracy: 0.7492\n",
            "Epoch 442/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5935 - accuracy: 0.7851 - val_loss: 0.7099 - val_accuracy: 0.7650\n",
            "Epoch 443/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6096 - accuracy: 0.7941 - val_loss: 0.7360 - val_accuracy: 0.7542\n",
            "Epoch 444/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6086 - accuracy: 0.7878 - val_loss: 0.7100 - val_accuracy: 0.7800\n",
            "Epoch 445/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6187 - accuracy: 0.7969 - val_loss: 0.6822 - val_accuracy: 0.7775\n",
            "Epoch 446/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5993 - accuracy: 0.7974 - val_loss: 0.7700 - val_accuracy: 0.7600\n",
            "Epoch 447/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6480 - accuracy: 0.7707 - val_loss: 0.6944 - val_accuracy: 0.7558\n",
            "Epoch 448/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6061 - accuracy: 0.7907 - val_loss: 0.7454 - val_accuracy: 0.7742\n",
            "Epoch 449/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6229 - accuracy: 0.7793 - val_loss: 0.6885 - val_accuracy: 0.7867\n",
            "Epoch 450/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5873 - accuracy: 0.7946 - val_loss: 0.7383 - val_accuracy: 0.7550\n",
            "Epoch 451/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6329 - accuracy: 0.7735 - val_loss: 0.6979 - val_accuracy: 0.7592\n",
            "Epoch 452/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.6006 - accuracy: 0.7848 - val_loss: 0.6881 - val_accuracy: 0.7842\n",
            "Epoch 453/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5727 - accuracy: 0.8131 - val_loss: 0.6905 - val_accuracy: 0.7800\n",
            "Epoch 454/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6018 - accuracy: 0.7863 - val_loss: 0.6997 - val_accuracy: 0.7733\n",
            "Epoch 455/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5895 - accuracy: 0.7930 - val_loss: 0.7255 - val_accuracy: 0.7567\n",
            "Epoch 456/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6029 - accuracy: 0.7793 - val_loss: 0.7113 - val_accuracy: 0.7700\n",
            "Epoch 457/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6411 - accuracy: 0.7794 - val_loss: 0.8251 - val_accuracy: 0.7442\n",
            "Epoch 458/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6383 - accuracy: 0.7832 - val_loss: 0.6846 - val_accuracy: 0.7817\n",
            "Epoch 459/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5794 - accuracy: 0.8001 - val_loss: 0.7285 - val_accuracy: 0.7417\n",
            "Epoch 460/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6377 - accuracy: 0.7777 - val_loss: 0.7142 - val_accuracy: 0.7717\n",
            "Epoch 461/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6065 - accuracy: 0.7847 - val_loss: 0.7274 - val_accuracy: 0.7683\n",
            "Epoch 462/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6178 - accuracy: 0.7902 - val_loss: 0.7334 - val_accuracy: 0.7883\n",
            "Epoch 463/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6268 - accuracy: 0.7857 - val_loss: 0.6965 - val_accuracy: 0.7683\n",
            "Epoch 464/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6107 - accuracy: 0.7866 - val_loss: 0.7215 - val_accuracy: 0.7575\n",
            "Epoch 465/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5933 - accuracy: 0.7962 - val_loss: 0.6849 - val_accuracy: 0.7700\n",
            "Epoch 466/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5909 - accuracy: 0.8007 - val_loss: 0.6864 - val_accuracy: 0.7708\n",
            "Epoch 467/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5810 - accuracy: 0.7954 - val_loss: 0.7215 - val_accuracy: 0.7642\n",
            "Epoch 468/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6137 - accuracy: 0.7810 - val_loss: 0.7320 - val_accuracy: 0.7408\n",
            "Epoch 469/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6283 - accuracy: 0.7764 - val_loss: 0.7810 - val_accuracy: 0.7475\n",
            "Epoch 470/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6363 - accuracy: 0.7833 - val_loss: 0.7446 - val_accuracy: 0.7308\n",
            "Epoch 471/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6227 - accuracy: 0.7744 - val_loss: 0.7168 - val_accuracy: 0.7542\n",
            "Epoch 472/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6069 - accuracy: 0.7914 - val_loss: 0.7298 - val_accuracy: 0.7567\n",
            "Epoch 473/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.7813 - val_loss: 0.7102 - val_accuracy: 0.7675\n",
            "Epoch 474/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5995 - accuracy: 0.7835 - val_loss: 0.7138 - val_accuracy: 0.7558\n",
            "Epoch 475/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5956 - accuracy: 0.7857 - val_loss: 0.7684 - val_accuracy: 0.7433\n",
            "Epoch 476/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6124 - accuracy: 0.7805 - val_loss: 0.7407 - val_accuracy: 0.7492\n",
            "Epoch 477/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6179 - accuracy: 0.7856 - val_loss: 0.7315 - val_accuracy: 0.7717\n",
            "Epoch 478/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6157 - accuracy: 0.7785 - val_loss: 0.7182 - val_accuracy: 0.7592\n",
            "Epoch 479/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6161 - accuracy: 0.7795 - val_loss: 0.7217 - val_accuracy: 0.7667\n",
            "Epoch 480/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6149 - accuracy: 0.7956 - val_loss: 0.7012 - val_accuracy: 0.7700\n",
            "Epoch 481/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5853 - accuracy: 0.7896 - val_loss: 0.7363 - val_accuracy: 0.7567\n",
            "Epoch 482/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6107 - accuracy: 0.7840 - val_loss: 0.7412 - val_accuracy: 0.7692\n",
            "Epoch 483/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5957 - accuracy: 0.7809 - val_loss: 0.7049 - val_accuracy: 0.7642\n",
            "Epoch 484/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5593 - accuracy: 0.8082 - val_loss: 0.7489 - val_accuracy: 0.7500\n",
            "Epoch 485/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5920 - accuracy: 0.7896 - val_loss: 0.7372 - val_accuracy: 0.7583\n",
            "Epoch 486/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5872 - accuracy: 0.7955 - val_loss: 0.7088 - val_accuracy: 0.7642\n",
            "Epoch 487/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5980 - accuracy: 0.7891 - val_loss: 0.7245 - val_accuracy: 0.7642\n",
            "Epoch 488/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5894 - accuracy: 0.8068 - val_loss: 0.7085 - val_accuracy: 0.7842\n",
            "Epoch 489/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6093 - accuracy: 0.7837 - val_loss: 0.7101 - val_accuracy: 0.7683\n",
            "Epoch 490/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5628 - accuracy: 0.8012 - val_loss: 0.7794 - val_accuracy: 0.7550\n",
            "Epoch 491/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6074 - accuracy: 0.7865 - val_loss: 0.7144 - val_accuracy: 0.7625\n",
            "Epoch 492/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6083 - accuracy: 0.7866 - val_loss: 0.7571 - val_accuracy: 0.7475\n",
            "Epoch 493/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6072 - accuracy: 0.7776 - val_loss: 0.7278 - val_accuracy: 0.7783\n",
            "Epoch 494/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6004 - accuracy: 0.7986 - val_loss: 0.7301 - val_accuracy: 0.7700\n",
            "Epoch 495/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5836 - accuracy: 0.7902 - val_loss: 0.7424 - val_accuracy: 0.7700\n",
            "Epoch 496/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5840 - accuracy: 0.8030 - val_loss: 0.7326 - val_accuracy: 0.7775\n",
            "Epoch 497/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5738 - accuracy: 0.7979 - val_loss: 0.7275 - val_accuracy: 0.7800\n",
            "Epoch 498/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5945 - accuracy: 0.8083 - val_loss: 0.7142 - val_accuracy: 0.7833\n",
            "Epoch 499/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5902 - accuracy: 0.7932 - val_loss: 0.7378 - val_accuracy: 0.7775\n",
            "Epoch 500/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5838 - accuracy: 0.7974 - val_loss: 0.7264 - val_accuracy: 0.7633\n",
            "Epoch 501/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5949 - accuracy: 0.7939 - val_loss: 0.7567 - val_accuracy: 0.7575\n",
            "Epoch 502/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6076 - accuracy: 0.7921 - val_loss: 0.7247 - val_accuracy: 0.7625\n",
            "Epoch 503/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5761 - accuracy: 0.8022 - val_loss: 0.6883 - val_accuracy: 0.7700\n",
            "Epoch 504/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5737 - accuracy: 0.8009 - val_loss: 0.7046 - val_accuracy: 0.7733\n",
            "Epoch 505/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5892 - accuracy: 0.7824 - val_loss: 0.6738 - val_accuracy: 0.7883\n",
            "Epoch 506/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5907 - accuracy: 0.7858 - val_loss: 0.6882 - val_accuracy: 0.7700\n",
            "Epoch 507/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5975 - accuracy: 0.7895 - val_loss: 0.7191 - val_accuracy: 0.7658\n",
            "Epoch 508/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6015 - accuracy: 0.7849 - val_loss: 0.6658 - val_accuracy: 0.7817\n",
            "Epoch 509/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5589 - accuracy: 0.8068 - val_loss: 0.7086 - val_accuracy: 0.7767\n",
            "Epoch 510/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5932 - accuracy: 0.8064 - val_loss: 0.6822 - val_accuracy: 0.7783\n",
            "Epoch 511/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6064 - accuracy: 0.7789 - val_loss: 0.6944 - val_accuracy: 0.7708\n",
            "Epoch 512/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6036 - accuracy: 0.7839 - val_loss: 0.7282 - val_accuracy: 0.7458\n",
            "Epoch 513/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5965 - accuracy: 0.7827 - val_loss: 0.6984 - val_accuracy: 0.7592\n",
            "Epoch 514/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6172 - accuracy: 0.7772 - val_loss: 0.6922 - val_accuracy: 0.7658\n",
            "Epoch 515/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5802 - accuracy: 0.7912 - val_loss: 0.7167 - val_accuracy: 0.7667\n",
            "Epoch 516/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5694 - accuracy: 0.8103 - val_loss: 0.6731 - val_accuracy: 0.7933\n",
            "Epoch 517/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5946 - accuracy: 0.7949 - val_loss: 0.6901 - val_accuracy: 0.7825\n",
            "Epoch 518/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5711 - accuracy: 0.7978 - val_loss: 0.7406 - val_accuracy: 0.7442\n",
            "Epoch 519/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.6100 - accuracy: 0.7797 - val_loss: 0.7560 - val_accuracy: 0.7717\n",
            "Epoch 520/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5890 - accuracy: 0.7893 - val_loss: 0.6724 - val_accuracy: 0.7867\n",
            "Epoch 521/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5773 - accuracy: 0.8018 - val_loss: 0.6739 - val_accuracy: 0.7725\n",
            "Epoch 522/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5869 - accuracy: 0.7929 - val_loss: 0.7172 - val_accuracy: 0.7692\n",
            "Epoch 523/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5910 - accuracy: 0.7979 - val_loss: 0.7000 - val_accuracy: 0.7675\n",
            "Epoch 524/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5884 - accuracy: 0.7882 - val_loss: 0.7181 - val_accuracy: 0.7675\n",
            "Epoch 525/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6018 - accuracy: 0.7968 - val_loss: 0.6806 - val_accuracy: 0.7500\n",
            "Epoch 526/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5548 - accuracy: 0.8051 - val_loss: 0.6733 - val_accuracy: 0.7717\n",
            "Epoch 527/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5982 - accuracy: 0.7962 - val_loss: 0.7070 - val_accuracy: 0.7567\n",
            "Epoch 528/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5867 - accuracy: 0.7950 - val_loss: 0.6783 - val_accuracy: 0.7825\n",
            "Epoch 529/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5808 - accuracy: 0.8034 - val_loss: 0.7155 - val_accuracy: 0.7667\n",
            "Epoch 530/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5855 - accuracy: 0.8006 - val_loss: 0.6853 - val_accuracy: 0.7875\n",
            "Epoch 531/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5805 - accuracy: 0.7995 - val_loss: 0.7452 - val_accuracy: 0.7367\n",
            "Epoch 532/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6039 - accuracy: 0.7803 - val_loss: 0.7410 - val_accuracy: 0.7550\n",
            "Epoch 533/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6188 - accuracy: 0.7804 - val_loss: 0.6864 - val_accuracy: 0.7775\n",
            "Epoch 534/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5574 - accuracy: 0.7932 - val_loss: 0.6638 - val_accuracy: 0.7950\n",
            "Epoch 535/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5579 - accuracy: 0.8051 - val_loss: 0.7464 - val_accuracy: 0.7708\n",
            "Epoch 536/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6259 - accuracy: 0.7886 - val_loss: 0.7114 - val_accuracy: 0.7575\n",
            "Epoch 537/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5933 - accuracy: 0.7915 - val_loss: 0.6888 - val_accuracy: 0.7750\n",
            "Epoch 538/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5910 - accuracy: 0.7967 - val_loss: 0.6742 - val_accuracy: 0.7792\n",
            "Epoch 539/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5365 - accuracy: 0.8194 - val_loss: 0.7479 - val_accuracy: 0.7525\n",
            "Epoch 540/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6045 - accuracy: 0.7869 - val_loss: 0.7088 - val_accuracy: 0.7633\n",
            "Epoch 541/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5691 - accuracy: 0.7967 - val_loss: 0.7207 - val_accuracy: 0.7692\n",
            "Epoch 542/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5893 - accuracy: 0.7907 - val_loss: 0.6699 - val_accuracy: 0.8008\n",
            "Epoch 543/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5936 - accuracy: 0.7884 - val_loss: 0.6993 - val_accuracy: 0.7592\n",
            "Epoch 544/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6028 - accuracy: 0.7826 - val_loss: 0.6933 - val_accuracy: 0.7825\n",
            "Epoch 545/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.8093 - val_loss: 0.7125 - val_accuracy: 0.7433\n",
            "Epoch 546/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5893 - accuracy: 0.7915 - val_loss: 0.6652 - val_accuracy: 0.7875\n",
            "Epoch 547/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5473 - accuracy: 0.8006 - val_loss: 0.7829 - val_accuracy: 0.7517\n",
            "Epoch 548/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6300 - accuracy: 0.7703 - val_loss: 0.7247 - val_accuracy: 0.7858\n",
            "Epoch 549/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5752 - accuracy: 0.8023 - val_loss: 0.6831 - val_accuracy: 0.7850\n",
            "Epoch 550/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5822 - accuracy: 0.7998 - val_loss: 0.6875 - val_accuracy: 0.7783\n",
            "Epoch 551/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5732 - accuracy: 0.7926 - val_loss: 0.7278 - val_accuracy: 0.7408\n",
            "Epoch 552/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5643 - accuracy: 0.8058 - val_loss: 0.7400 - val_accuracy: 0.7433\n",
            "Epoch 553/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6082 - accuracy: 0.7862 - val_loss: 0.6771 - val_accuracy: 0.7842\n",
            "Epoch 554/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5590 - accuracy: 0.8045 - val_loss: 0.6808 - val_accuracy: 0.7700\n",
            "Epoch 555/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5941 - accuracy: 0.7922 - val_loss: 0.6926 - val_accuracy: 0.7608\n",
            "Epoch 556/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5796 - accuracy: 0.7912 - val_loss: 0.7189 - val_accuracy: 0.7808\n",
            "Epoch 557/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6027 - accuracy: 0.7898 - val_loss: 0.7334 - val_accuracy: 0.7633\n",
            "Epoch 558/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5758 - accuracy: 0.7888 - val_loss: 0.7178 - val_accuracy: 0.7708\n",
            "Epoch 559/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6157 - accuracy: 0.7853 - val_loss: 0.7489 - val_accuracy: 0.7875\n",
            "Epoch 560/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5712 - accuracy: 0.7992 - val_loss: 0.6940 - val_accuracy: 0.7808\n",
            "Epoch 561/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5546 - accuracy: 0.8041 - val_loss: 0.7095 - val_accuracy: 0.7658\n",
            "Epoch 562/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5666 - accuracy: 0.8036 - val_loss: 0.6974 - val_accuracy: 0.7758\n",
            "Epoch 563/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5836 - accuracy: 0.7901 - val_loss: 0.7086 - val_accuracy: 0.7842\n",
            "Epoch 564/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5490 - accuracy: 0.8045 - val_loss: 0.7403 - val_accuracy: 0.7617\n",
            "Epoch 565/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5933 - accuracy: 0.7891 - val_loss: 0.7435 - val_accuracy: 0.7458\n",
            "Epoch 566/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5717 - accuracy: 0.7942 - val_loss: 0.7197 - val_accuracy: 0.7850\n",
            "Epoch 567/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5675 - accuracy: 0.8033 - val_loss: 0.6817 - val_accuracy: 0.7717\n",
            "Epoch 568/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5677 - accuracy: 0.8044 - val_loss: 0.7196 - val_accuracy: 0.7683\n",
            "Epoch 569/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5634 - accuracy: 0.8100 - val_loss: 0.7864 - val_accuracy: 0.7508\n",
            "Epoch 570/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6129 - accuracy: 0.7886 - val_loss: 0.6834 - val_accuracy: 0.7858\n",
            "Epoch 571/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5889 - accuracy: 0.7954 - val_loss: 0.6802 - val_accuracy: 0.7967\n",
            "Epoch 572/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5632 - accuracy: 0.8025 - val_loss: 0.7359 - val_accuracy: 0.7575\n",
            "Epoch 573/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5756 - accuracy: 0.8001 - val_loss: 0.6959 - val_accuracy: 0.7858\n",
            "Epoch 574/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5406 - accuracy: 0.8205 - val_loss: 0.7021 - val_accuracy: 0.7942\n",
            "Epoch 575/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.5663 - accuracy: 0.8007 - val_loss: 0.7015 - val_accuracy: 0.7767\n",
            "Epoch 576/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5676 - accuracy: 0.8009 - val_loss: 0.7343 - val_accuracy: 0.7650\n",
            "Epoch 577/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5802 - accuracy: 0.7960 - val_loss: 0.6989 - val_accuracy: 0.7675\n",
            "Epoch 578/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5781 - accuracy: 0.7926 - val_loss: 0.7117 - val_accuracy: 0.7900\n",
            "Epoch 579/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6013 - accuracy: 0.7937 - val_loss: 0.7122 - val_accuracy: 0.7792\n",
            "Epoch 580/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5664 - accuracy: 0.8023 - val_loss: 0.7411 - val_accuracy: 0.7642\n",
            "Epoch 581/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5652 - accuracy: 0.7986 - val_loss: 0.7777 - val_accuracy: 0.7575\n",
            "Epoch 582/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6141 - accuracy: 0.7889 - val_loss: 0.7140 - val_accuracy: 0.7517\n",
            "Epoch 583/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5575 - accuracy: 0.8064 - val_loss: 0.6676 - val_accuracy: 0.7792\n",
            "Epoch 584/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5642 - accuracy: 0.8010 - val_loss: 0.6777 - val_accuracy: 0.7708\n",
            "Epoch 585/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5765 - accuracy: 0.7891 - val_loss: 0.6993 - val_accuracy: 0.7742\n",
            "Epoch 586/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5730 - accuracy: 0.8087 - val_loss: 0.6647 - val_accuracy: 0.7833\n",
            "Epoch 587/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5602 - accuracy: 0.8027 - val_loss: 0.8496 - val_accuracy: 0.7558\n",
            "Epoch 588/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6025 - accuracy: 0.8022 - val_loss: 0.7423 - val_accuracy: 0.7492\n",
            "Epoch 589/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5723 - accuracy: 0.7933 - val_loss: 0.6681 - val_accuracy: 0.7817\n",
            "Epoch 590/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5359 - accuracy: 0.8103 - val_loss: 0.7013 - val_accuracy: 0.7550\n",
            "Epoch 591/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5656 - accuracy: 0.8015 - val_loss: 0.6931 - val_accuracy: 0.7667\n",
            "Epoch 592/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5553 - accuracy: 0.7992 - val_loss: 0.6823 - val_accuracy: 0.7725\n",
            "Epoch 593/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5497 - accuracy: 0.8095 - val_loss: 0.6602 - val_accuracy: 0.7767\n",
            "Epoch 594/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5700 - accuracy: 0.8077 - val_loss: 0.6598 - val_accuracy: 0.7775\n",
            "Epoch 595/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5529 - accuracy: 0.8088 - val_loss: 0.6849 - val_accuracy: 0.7750\n",
            "Epoch 596/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5541 - accuracy: 0.8013 - val_loss: 0.6804 - val_accuracy: 0.7725\n",
            "Epoch 597/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5771 - accuracy: 0.7945 - val_loss: 0.6984 - val_accuracy: 0.7592\n",
            "Epoch 598/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5748 - accuracy: 0.7899 - val_loss: 0.6977 - val_accuracy: 0.7883\n",
            "Epoch 599/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5559 - accuracy: 0.8039 - val_loss: 0.6962 - val_accuracy: 0.7783\n",
            "Epoch 600/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5542 - accuracy: 0.8053 - val_loss: 0.7205 - val_accuracy: 0.7658\n",
            "Epoch 601/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6061 - accuracy: 0.7830 - val_loss: 0.6650 - val_accuracy: 0.7875\n",
            "Epoch 602/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5521 - accuracy: 0.8009 - val_loss: 0.6799 - val_accuracy: 0.7892\n",
            "Epoch 603/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5653 - accuracy: 0.8099 - val_loss: 0.6861 - val_accuracy: 0.7775\n",
            "Epoch 604/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5601 - accuracy: 0.7962 - val_loss: 0.6674 - val_accuracy: 0.7883\n",
            "Epoch 605/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5626 - accuracy: 0.8013 - val_loss: 0.6952 - val_accuracy: 0.7825\n",
            "Epoch 606/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5745 - accuracy: 0.7969 - val_loss: 0.6739 - val_accuracy: 0.7900\n",
            "Epoch 607/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5471 - accuracy: 0.8064 - val_loss: 0.6829 - val_accuracy: 0.7742\n",
            "Epoch 608/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5495 - accuracy: 0.7975 - val_loss: 0.7021 - val_accuracy: 0.7933\n",
            "Epoch 609/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5627 - accuracy: 0.8103 - val_loss: 0.7205 - val_accuracy: 0.7617\n",
            "Epoch 610/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5913 - accuracy: 0.7966 - val_loss: 0.6963 - val_accuracy: 0.7917\n",
            "Epoch 611/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5531 - accuracy: 0.8051 - val_loss: 0.6792 - val_accuracy: 0.7783\n",
            "Epoch 612/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5592 - accuracy: 0.8109 - val_loss: 0.6959 - val_accuracy: 0.7900\n",
            "Epoch 613/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6006 - accuracy: 0.7910 - val_loss: 0.6809 - val_accuracy: 0.7808\n",
            "Epoch 614/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5843 - accuracy: 0.8102 - val_loss: 0.7159 - val_accuracy: 0.7708\n",
            "Epoch 615/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5729 - accuracy: 0.7922 - val_loss: 0.6853 - val_accuracy: 0.7792\n",
            "Epoch 616/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5526 - accuracy: 0.8120 - val_loss: 0.6709 - val_accuracy: 0.7775\n",
            "Epoch 617/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5474 - accuracy: 0.8097 - val_loss: 0.7116 - val_accuracy: 0.7733\n",
            "Epoch 618/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5753 - accuracy: 0.7924 - val_loss: 0.7314 - val_accuracy: 0.7792\n",
            "Epoch 619/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5520 - accuracy: 0.8063 - val_loss: 0.6959 - val_accuracy: 0.7717\n",
            "Epoch 620/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5548 - accuracy: 0.8059 - val_loss: 0.7284 - val_accuracy: 0.7783\n",
            "Epoch 621/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5731 - accuracy: 0.7899 - val_loss: 0.7113 - val_accuracy: 0.7742\n",
            "Epoch 622/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5734 - accuracy: 0.7979 - val_loss: 0.7121 - val_accuracy: 0.7883\n",
            "Epoch 623/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5419 - accuracy: 0.8184 - val_loss: 0.7219 - val_accuracy: 0.7783\n",
            "Epoch 624/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5665 - accuracy: 0.8046 - val_loss: 0.6886 - val_accuracy: 0.7942\n",
            "Epoch 625/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5541 - accuracy: 0.8066 - val_loss: 0.6894 - val_accuracy: 0.7900\n",
            "Epoch 626/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5534 - accuracy: 0.8046 - val_loss: 0.7702 - val_accuracy: 0.7533\n",
            "Epoch 627/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5878 - accuracy: 0.7889 - val_loss: 0.7392 - val_accuracy: 0.7658\n",
            "Epoch 628/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5798 - accuracy: 0.7995 - val_loss: 0.7526 - val_accuracy: 0.7608\n",
            "Epoch 629/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5555 - accuracy: 0.7994 - val_loss: 0.7013 - val_accuracy: 0.7733\n",
            "Epoch 630/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5282 - accuracy: 0.8142 - val_loss: 0.6756 - val_accuracy: 0.7933\n",
            "Epoch 631/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5209 - accuracy: 0.8178 - val_loss: 0.7313 - val_accuracy: 0.7425\n",
            "Epoch 632/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5779 - accuracy: 0.7975 - val_loss: 0.7113 - val_accuracy: 0.7667\n",
            "Epoch 633/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5747 - accuracy: 0.7865 - val_loss: 0.6799 - val_accuracy: 0.8042\n",
            "Epoch 634/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5858 - accuracy: 0.8010 - val_loss: 0.7313 - val_accuracy: 0.7833\n",
            "Epoch 635/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5722 - accuracy: 0.7932 - val_loss: 0.7138 - val_accuracy: 0.7792\n",
            "Epoch 636/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5368 - accuracy: 0.8093 - val_loss: 0.6835 - val_accuracy: 0.8050\n",
            "Epoch 637/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5760 - accuracy: 0.7968 - val_loss: 0.7838 - val_accuracy: 0.7625\n",
            "Epoch 638/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5739 - accuracy: 0.7952 - val_loss: 0.7411 - val_accuracy: 0.7892\n",
            "Epoch 639/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5664 - accuracy: 0.8006 - val_loss: 0.6820 - val_accuracy: 0.8067\n",
            "Epoch 640/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5582 - accuracy: 0.8088 - val_loss: 0.7130 - val_accuracy: 0.7842\n",
            "Epoch 641/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5745 - accuracy: 0.7965 - val_loss: 0.6920 - val_accuracy: 0.8133\n",
            "Epoch 642/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5250 - accuracy: 0.8223 - val_loss: 0.7492 - val_accuracy: 0.7858\n",
            "Epoch 643/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5743 - accuracy: 0.7913 - val_loss: 0.6925 - val_accuracy: 0.7792\n",
            "Epoch 644/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5522 - accuracy: 0.8107 - val_loss: 0.7088 - val_accuracy: 0.7975\n",
            "Epoch 645/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5511 - accuracy: 0.8016 - val_loss: 0.6878 - val_accuracy: 0.7933\n",
            "Epoch 646/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5542 - accuracy: 0.8062 - val_loss: 0.7239 - val_accuracy: 0.7792\n",
            "Epoch 647/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5575 - accuracy: 0.8037 - val_loss: 0.7508 - val_accuracy: 0.7425\n",
            "Epoch 648/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5602 - accuracy: 0.8015 - val_loss: 0.7385 - val_accuracy: 0.7750\n",
            "Epoch 649/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5500 - accuracy: 0.8025 - val_loss: 0.6976 - val_accuracy: 0.7958\n",
            "Epoch 650/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5249 - accuracy: 0.8145 - val_loss: 0.7305 - val_accuracy: 0.7800\n",
            "Epoch 651/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5367 - accuracy: 0.8037 - val_loss: 0.7339 - val_accuracy: 0.7725\n",
            "Epoch 652/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5701 - accuracy: 0.8007 - val_loss: 0.7277 - val_accuracy: 0.7592\n",
            "Epoch 653/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5834 - accuracy: 0.8007 - val_loss: 0.6683 - val_accuracy: 0.7692\n",
            "Epoch 654/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5548 - accuracy: 0.8071 - val_loss: 0.6552 - val_accuracy: 0.7950\n",
            "Epoch 655/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5345 - accuracy: 0.8164 - val_loss: 0.6696 - val_accuracy: 0.7675\n",
            "Epoch 656/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5354 - accuracy: 0.8079 - val_loss: 0.6626 - val_accuracy: 0.7967\n",
            "Epoch 657/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5498 - accuracy: 0.7992 - val_loss: 0.6744 - val_accuracy: 0.7767\n",
            "Epoch 658/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5493 - accuracy: 0.8054 - val_loss: 0.6908 - val_accuracy: 0.7675\n",
            "Epoch 659/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5732 - accuracy: 0.7965 - val_loss: 0.7065 - val_accuracy: 0.7567\n",
            "Epoch 660/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5807 - accuracy: 0.7847 - val_loss: 0.7490 - val_accuracy: 0.7767\n",
            "Epoch 661/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5522 - accuracy: 0.8107 - val_loss: 0.6615 - val_accuracy: 0.7875\n",
            "Epoch 662/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5423 - accuracy: 0.8057 - val_loss: 0.6750 - val_accuracy: 0.7767\n",
            "Epoch 663/2000\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5666 - accuracy: 0.8077 - val_loss: 0.6810 - val_accuracy: 0.7858\n",
            "Epoch 664/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5537 - accuracy: 0.7993 - val_loss: 0.6652 - val_accuracy: 0.7842\n",
            "Epoch 665/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5413 - accuracy: 0.8063 - val_loss: 0.6726 - val_accuracy: 0.7875\n",
            "Epoch 666/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5256 - accuracy: 0.8135 - val_loss: 0.6836 - val_accuracy: 0.7692\n",
            "Epoch 667/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5277 - accuracy: 0.8197 - val_loss: 0.6598 - val_accuracy: 0.7867\n",
            "Epoch 668/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5346 - accuracy: 0.8034 - val_loss: 0.7245 - val_accuracy: 0.7708\n",
            "Epoch 669/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5909 - accuracy: 0.7948 - val_loss: 0.6577 - val_accuracy: 0.8025\n",
            "Epoch 670/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5342 - accuracy: 0.8157 - val_loss: 0.6779 - val_accuracy: 0.7758\n",
            "Epoch 671/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5507 - accuracy: 0.8087 - val_loss: 0.6868 - val_accuracy: 0.7750\n",
            "Epoch 672/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5572 - accuracy: 0.7980 - val_loss: 0.6602 - val_accuracy: 0.7783\n",
            "Epoch 673/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5353 - accuracy: 0.8142 - val_loss: 0.6543 - val_accuracy: 0.7942\n",
            "Epoch 674/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5440 - accuracy: 0.8055 - val_loss: 0.6473 - val_accuracy: 0.7975\n",
            "Epoch 675/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5502 - accuracy: 0.8108 - val_loss: 0.6927 - val_accuracy: 0.7550\n",
            "Epoch 676/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5351 - accuracy: 0.8081 - val_loss: 0.6698 - val_accuracy: 0.8008\n",
            "Epoch 677/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5205 - accuracy: 0.8180 - val_loss: 0.6723 - val_accuracy: 0.7808\n",
            "Epoch 678/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5556 - accuracy: 0.8063 - val_loss: 0.6627 - val_accuracy: 0.7792\n",
            "Epoch 679/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5404 - accuracy: 0.8150 - val_loss: 0.6869 - val_accuracy: 0.7667\n",
            "Epoch 680/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5419 - accuracy: 0.8144 - val_loss: 0.6549 - val_accuracy: 0.7850\n",
            "Epoch 681/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5443 - accuracy: 0.8186 - val_loss: 0.6706 - val_accuracy: 0.7958\n",
            "Epoch 682/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5596 - accuracy: 0.8084 - val_loss: 0.6498 - val_accuracy: 0.8125\n",
            "Epoch 683/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5359 - accuracy: 0.8166 - val_loss: 0.6847 - val_accuracy: 0.7825\n",
            "Epoch 684/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5385 - accuracy: 0.8094 - val_loss: 0.6858 - val_accuracy: 0.7950\n",
            "Epoch 685/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5480 - accuracy: 0.8107 - val_loss: 0.6607 - val_accuracy: 0.7850\n",
            "Epoch 686/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5590 - accuracy: 0.8041 - val_loss: 0.6870 - val_accuracy: 0.7850\n",
            "Epoch 687/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5673 - accuracy: 0.7980 - val_loss: 0.7565 - val_accuracy: 0.7925\n",
            "Epoch 688/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6026 - accuracy: 0.7905 - val_loss: 0.6663 - val_accuracy: 0.7908\n",
            "Epoch 689/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5609 - accuracy: 0.7926 - val_loss: 0.6602 - val_accuracy: 0.7858\n",
            "Epoch 690/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5514 - accuracy: 0.8093 - val_loss: 0.6603 - val_accuracy: 0.7892\n",
            "Epoch 691/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5308 - accuracy: 0.8069 - val_loss: 0.6664 - val_accuracy: 0.7692\n",
            "Epoch 692/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5265 - accuracy: 0.8166 - val_loss: 0.6669 - val_accuracy: 0.7933\n",
            "Epoch 693/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5401 - accuracy: 0.8061 - val_loss: 0.7247 - val_accuracy: 0.7608\n",
            "Epoch 694/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5590 - accuracy: 0.7962 - val_loss: 0.6977 - val_accuracy: 0.7733\n",
            "Epoch 695/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5707 - accuracy: 0.7941 - val_loss: 0.6949 - val_accuracy: 0.7750\n",
            "Epoch 696/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5601 - accuracy: 0.8003 - val_loss: 0.7225 - val_accuracy: 0.7667\n",
            "Epoch 697/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5568 - accuracy: 0.7990 - val_loss: 0.6366 - val_accuracy: 0.7992\n",
            "Epoch 698/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5393 - accuracy: 0.8043 - val_loss: 0.7443 - val_accuracy: 0.7742\n",
            "Epoch 699/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5483 - accuracy: 0.8042 - val_loss: 0.6771 - val_accuracy: 0.7867\n",
            "Epoch 700/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5392 - accuracy: 0.8157 - val_loss: 0.6791 - val_accuracy: 0.7817\n",
            "Epoch 701/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5540 - accuracy: 0.8074 - val_loss: 0.7561 - val_accuracy: 0.7650\n",
            "Epoch 702/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5756 - accuracy: 0.7894 - val_loss: 0.6722 - val_accuracy: 0.7975\n",
            "Epoch 703/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5346 - accuracy: 0.8136 - val_loss: 0.6755 - val_accuracy: 0.7950\n",
            "Epoch 704/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5534 - accuracy: 0.8071 - val_loss: 0.8002 - val_accuracy: 0.7917\n",
            "Epoch 705/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5682 - accuracy: 0.8020 - val_loss: 0.6527 - val_accuracy: 0.7908\n",
            "Epoch 706/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5477 - accuracy: 0.8019 - val_loss: 0.7172 - val_accuracy: 0.7650\n",
            "Epoch 707/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5535 - accuracy: 0.7917 - val_loss: 0.6752 - val_accuracy: 0.7800\n",
            "Epoch 708/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5270 - accuracy: 0.8114 - val_loss: 0.6878 - val_accuracy: 0.8008\n",
            "Epoch 709/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5615 - accuracy: 0.8134 - val_loss: 0.7027 - val_accuracy: 0.7825\n",
            "Epoch 710/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5462 - accuracy: 0.8051 - val_loss: 0.6984 - val_accuracy: 0.7608\n",
            "Epoch 711/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5431 - accuracy: 0.8092 - val_loss: 0.6578 - val_accuracy: 0.7825\n",
            "Epoch 712/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5372 - accuracy: 0.8080 - val_loss: 0.6540 - val_accuracy: 0.8075\n",
            "Epoch 713/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5408 - accuracy: 0.8221 - val_loss: 0.6502 - val_accuracy: 0.8083\n",
            "Epoch 714/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5445 - accuracy: 0.8156 - val_loss: 0.6860 - val_accuracy: 0.7825\n",
            "Epoch 715/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5514 - accuracy: 0.8081 - val_loss: 0.7321 - val_accuracy: 0.8008\n",
            "Epoch 716/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5307 - accuracy: 0.8211 - val_loss: 0.6900 - val_accuracy: 0.7933\n",
            "Epoch 717/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5308 - accuracy: 0.8154 - val_loss: 0.6863 - val_accuracy: 0.8000\n",
            "Epoch 718/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5304 - accuracy: 0.8123 - val_loss: 0.6869 - val_accuracy: 0.7800\n",
            "Epoch 719/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5518 - accuracy: 0.7894 - val_loss: 0.6902 - val_accuracy: 0.7742\n",
            "Epoch 720/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5153 - accuracy: 0.8166 - val_loss: 0.7072 - val_accuracy: 0.7833\n",
            "Epoch 721/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5372 - accuracy: 0.8037 - val_loss: 0.7088 - val_accuracy: 0.7817\n",
            "Epoch 722/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5516 - accuracy: 0.8116 - val_loss: 0.6723 - val_accuracy: 0.7933\n",
            "Epoch 723/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5400 - accuracy: 0.8133 - val_loss: 0.6974 - val_accuracy: 0.7808\n",
            "Epoch 724/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5240 - accuracy: 0.8187 - val_loss: 0.6603 - val_accuracy: 0.7967\n",
            "Epoch 725/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5523 - accuracy: 0.7984 - val_loss: 0.7257 - val_accuracy: 0.7833\n",
            "Epoch 726/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5412 - accuracy: 0.8092 - val_loss: 0.7086 - val_accuracy: 0.7675\n",
            "Epoch 727/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5704 - accuracy: 0.7961 - val_loss: 0.7282 - val_accuracy: 0.7592\n",
            "Epoch 728/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5545 - accuracy: 0.7987 - val_loss: 0.6838 - val_accuracy: 0.7808\n",
            "Epoch 729/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5272 - accuracy: 0.8136 - val_loss: 0.7356 - val_accuracy: 0.7600\n",
            "Epoch 730/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5292 - accuracy: 0.8056 - val_loss: 0.7037 - val_accuracy: 0.7800\n",
            "Epoch 731/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5425 - accuracy: 0.8027 - val_loss: 0.7242 - val_accuracy: 0.7767\n",
            "Epoch 732/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5565 - accuracy: 0.8010 - val_loss: 0.7138 - val_accuracy: 0.7808\n",
            "Epoch 733/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5437 - accuracy: 0.8096 - val_loss: 0.6738 - val_accuracy: 0.8000\n",
            "Epoch 734/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5445 - accuracy: 0.8065 - val_loss: 0.7664 - val_accuracy: 0.7825\n",
            "Epoch 735/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5977 - accuracy: 0.7941 - val_loss: 0.7492 - val_accuracy: 0.7750\n",
            "Epoch 736/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5228 - accuracy: 0.8086 - val_loss: 0.7240 - val_accuracy: 0.7742\n",
            "Epoch 737/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5597 - accuracy: 0.7989 - val_loss: 0.7054 - val_accuracy: 0.7867\n",
            "Epoch 738/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5451 - accuracy: 0.8096 - val_loss: 0.7197 - val_accuracy: 0.7842\n",
            "Epoch 739/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5256 - accuracy: 0.8064 - val_loss: 0.7689 - val_accuracy: 0.7642\n",
            "Epoch 740/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5714 - accuracy: 0.7934 - val_loss: 0.7402 - val_accuracy: 0.7675\n",
            "Epoch 741/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5405 - accuracy: 0.8009 - val_loss: 0.7667 - val_accuracy: 0.7683\n",
            "Epoch 742/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5387 - accuracy: 0.8100 - val_loss: 0.6998 - val_accuracy: 0.8083\n",
            "Epoch 743/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5192 - accuracy: 0.8136 - val_loss: 0.7306 - val_accuracy: 0.7808\n",
            "Epoch 744/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5300 - accuracy: 0.8129 - val_loss: 0.7057 - val_accuracy: 0.7950\n",
            "Epoch 745/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5298 - accuracy: 0.8046 - val_loss: 0.6998 - val_accuracy: 0.8000\n",
            "Epoch 746/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5496 - accuracy: 0.8083 - val_loss: 0.7248 - val_accuracy: 0.7833\n",
            "Epoch 747/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5756 - accuracy: 0.7894 - val_loss: 0.7430 - val_accuracy: 0.7725\n",
            "Epoch 748/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5553 - accuracy: 0.8041 - val_loss: 0.8054 - val_accuracy: 0.7717\n",
            "Epoch 749/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5456 - accuracy: 0.8068 - val_loss: 0.7460 - val_accuracy: 0.7750\n",
            "Epoch 750/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5687 - accuracy: 0.8026 - val_loss: 0.6897 - val_accuracy: 0.7900\n",
            "Epoch 751/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5198 - accuracy: 0.8099 - val_loss: 0.7072 - val_accuracy: 0.7975\n",
            "Epoch 752/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5378 - accuracy: 0.8114 - val_loss: 0.7115 - val_accuracy: 0.7675\n",
            "Epoch 753/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5183 - accuracy: 0.8123 - val_loss: 0.7501 - val_accuracy: 0.7775\n",
            "Epoch 754/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5426 - accuracy: 0.8126 - val_loss: 0.7507 - val_accuracy: 0.7758\n",
            "Epoch 755/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5736 - accuracy: 0.7934 - val_loss: 0.7334 - val_accuracy: 0.8042\n",
            "Epoch 756/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5403 - accuracy: 0.8088 - val_loss: 0.7334 - val_accuracy: 0.7867\n",
            "Epoch 757/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5394 - accuracy: 0.8099 - val_loss: 0.7503 - val_accuracy: 0.7708\n",
            "Epoch 758/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5311 - accuracy: 0.8111 - val_loss: 0.7801 - val_accuracy: 0.7683\n",
            "Epoch 759/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5357 - accuracy: 0.8064 - val_loss: 0.7090 - val_accuracy: 0.7950\n",
            "Epoch 760/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5588 - accuracy: 0.8105 - val_loss: 0.6611 - val_accuracy: 0.7967\n",
            "Epoch 761/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5255 - accuracy: 0.8176 - val_loss: 0.6733 - val_accuracy: 0.7567\n",
            "Epoch 762/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5147 - accuracy: 0.8196 - val_loss: 0.6706 - val_accuracy: 0.7925\n",
            "Epoch 763/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5496 - accuracy: 0.8057 - val_loss: 0.6952 - val_accuracy: 0.7942\n",
            "Epoch 764/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5792 - accuracy: 0.7840 - val_loss: 0.6656 - val_accuracy: 0.7867\n",
            "Epoch 765/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5100 - accuracy: 0.8163 - val_loss: 0.6391 - val_accuracy: 0.8033\n",
            "Epoch 766/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5097 - accuracy: 0.8134 - val_loss: 0.6324 - val_accuracy: 0.8008\n",
            "Epoch 767/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5099 - accuracy: 0.8323 - val_loss: 0.6304 - val_accuracy: 0.8033\n",
            "Epoch 768/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5006 - accuracy: 0.8307 - val_loss: 0.6516 - val_accuracy: 0.7983\n",
            "Epoch 769/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5111 - accuracy: 0.8248 - val_loss: 0.6852 - val_accuracy: 0.7967\n",
            "Epoch 770/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5177 - accuracy: 0.8087 - val_loss: 0.6517 - val_accuracy: 0.8008\n",
            "Epoch 771/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5224 - accuracy: 0.8285 - val_loss: 0.6667 - val_accuracy: 0.7892\n",
            "Epoch 772/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5286 - accuracy: 0.8098 - val_loss: 0.6830 - val_accuracy: 0.7717\n",
            "Epoch 773/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5485 - accuracy: 0.8019 - val_loss: 0.8506 - val_accuracy: 0.7775\n",
            "Epoch 774/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5836 - accuracy: 0.8029 - val_loss: 0.6700 - val_accuracy: 0.7975\n",
            "Epoch 775/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5214 - accuracy: 0.8130 - val_loss: 0.7006 - val_accuracy: 0.7800\n",
            "Epoch 776/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5280 - accuracy: 0.8085 - val_loss: 0.6434 - val_accuracy: 0.8017\n",
            "Epoch 777/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5167 - accuracy: 0.8194 - val_loss: 0.6751 - val_accuracy: 0.7800\n",
            "Epoch 778/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5242 - accuracy: 0.8172 - val_loss: 0.6773 - val_accuracy: 0.7983\n",
            "Epoch 779/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5429 - accuracy: 0.8039 - val_loss: 0.6713 - val_accuracy: 0.7792\n",
            "Epoch 780/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5245 - accuracy: 0.8138 - val_loss: 0.6853 - val_accuracy: 0.7850\n",
            "Epoch 781/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5120 - accuracy: 0.8227 - val_loss: 0.6455 - val_accuracy: 0.7833\n",
            "Epoch 782/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5195 - accuracy: 0.8221 - val_loss: 0.6267 - val_accuracy: 0.8075\n",
            "Epoch 783/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5106 - accuracy: 0.8116 - val_loss: 0.6967 - val_accuracy: 0.7783\n",
            "Epoch 784/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5240 - accuracy: 0.8146 - val_loss: 0.6488 - val_accuracy: 0.8000\n",
            "Epoch 785/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5359 - accuracy: 0.8169 - val_loss: 0.6670 - val_accuracy: 0.7842\n",
            "Epoch 786/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5271 - accuracy: 0.8150 - val_loss: 0.6550 - val_accuracy: 0.7992\n",
            "Epoch 787/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5219 - accuracy: 0.8218 - val_loss: 0.6745 - val_accuracy: 0.7800\n",
            "Epoch 788/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5307 - accuracy: 0.8160 - val_loss: 0.6783 - val_accuracy: 0.7892\n",
            "Epoch 789/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5265 - accuracy: 0.8183 - val_loss: 0.6734 - val_accuracy: 0.7833\n",
            "Epoch 790/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5360 - accuracy: 0.8201 - val_loss: 0.6471 - val_accuracy: 0.7958\n",
            "Epoch 791/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5183 - accuracy: 0.8125 - val_loss: 0.6406 - val_accuracy: 0.7967\n",
            "Epoch 792/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5054 - accuracy: 0.8191 - val_loss: 0.6715 - val_accuracy: 0.8067\n",
            "Epoch 793/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5240 - accuracy: 0.8173 - val_loss: 0.6773 - val_accuracy: 0.7725\n",
            "Epoch 794/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5360 - accuracy: 0.7991 - val_loss: 0.7035 - val_accuracy: 0.7842\n",
            "Epoch 795/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5353 - accuracy: 0.8062 - val_loss: 0.6139 - val_accuracy: 0.8142\n",
            "Epoch 796/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4995 - accuracy: 0.8254 - val_loss: 0.6340 - val_accuracy: 0.8025\n",
            "Epoch 797/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5219 - accuracy: 0.8124 - val_loss: 0.6409 - val_accuracy: 0.8083\n",
            "Epoch 798/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5015 - accuracy: 0.8183 - val_loss: 0.6399 - val_accuracy: 0.8167\n",
            "Epoch 799/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5155 - accuracy: 0.8172 - val_loss: 0.6326 - val_accuracy: 0.7975\n",
            "Epoch 800/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5307 - accuracy: 0.8017 - val_loss: 0.6713 - val_accuracy: 0.7808\n",
            "Epoch 801/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5149 - accuracy: 0.8152 - val_loss: 0.6208 - val_accuracy: 0.8092\n",
            "Epoch 802/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5050 - accuracy: 0.8161 - val_loss: 0.6696 - val_accuracy: 0.7800\n",
            "Epoch 803/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5307 - accuracy: 0.8043 - val_loss: 0.7117 - val_accuracy: 0.7567\n",
            "Epoch 804/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6089 - accuracy: 0.8015 - val_loss: 0.7237 - val_accuracy: 0.7850\n",
            "Epoch 805/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5533 - accuracy: 0.8019 - val_loss: 0.6877 - val_accuracy: 0.7783\n",
            "Epoch 806/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5380 - accuracy: 0.8125 - val_loss: 0.6517 - val_accuracy: 0.7875\n",
            "Epoch 807/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.8256 - val_loss: 0.6724 - val_accuracy: 0.7858\n",
            "Epoch 808/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5609 - accuracy: 0.7958 - val_loss: 0.6936 - val_accuracy: 0.7783\n",
            "Epoch 809/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5185 - accuracy: 0.8263 - val_loss: 0.8332 - val_accuracy: 0.7867\n",
            "Epoch 810/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5468 - accuracy: 0.8086 - val_loss: 0.7055 - val_accuracy: 0.7892\n",
            "Epoch 811/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5810 - accuracy: 0.7987 - val_loss: 0.6539 - val_accuracy: 0.8050\n",
            "Epoch 812/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5156 - accuracy: 0.8241 - val_loss: 0.6842 - val_accuracy: 0.7883\n",
            "Epoch 813/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5242 - accuracy: 0.8131 - val_loss: 0.6515 - val_accuracy: 0.7975\n",
            "Epoch 814/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5500 - accuracy: 0.8058 - val_loss: 0.6738 - val_accuracy: 0.8042\n",
            "Epoch 815/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5169 - accuracy: 0.8220 - val_loss: 0.6583 - val_accuracy: 0.7883\n",
            "Epoch 816/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5088 - accuracy: 0.8190 - val_loss: 0.6595 - val_accuracy: 0.8133\n",
            "Epoch 817/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5197 - accuracy: 0.8125 - val_loss: 0.7081 - val_accuracy: 0.7967\n",
            "Epoch 818/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4995 - accuracy: 0.8340 - val_loss: 0.6974 - val_accuracy: 0.7958\n",
            "Epoch 819/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5587 - accuracy: 0.8018 - val_loss: 0.7069 - val_accuracy: 0.7733\n",
            "Epoch 820/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5237 - accuracy: 0.8120 - val_loss: 0.6871 - val_accuracy: 0.7683\n",
            "Epoch 821/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5246 - accuracy: 0.8076 - val_loss: 0.6733 - val_accuracy: 0.7892\n",
            "Epoch 822/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5153 - accuracy: 0.8229 - val_loss: 0.6631 - val_accuracy: 0.8067\n",
            "Epoch 823/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5157 - accuracy: 0.8250 - val_loss: 0.6973 - val_accuracy: 0.7717\n",
            "Epoch 824/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5310 - accuracy: 0.8052 - val_loss: 0.6820 - val_accuracy: 0.7792\n",
            "Epoch 825/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5615 - accuracy: 0.7906 - val_loss: 0.7035 - val_accuracy: 0.7750\n",
            "Epoch 826/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5292 - accuracy: 0.8076 - val_loss: 0.6675 - val_accuracy: 0.7875\n",
            "Epoch 827/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.5019 - accuracy: 0.8261 - val_loss: 0.6681 - val_accuracy: 0.8108\n",
            "Epoch 828/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5356 - accuracy: 0.8078 - val_loss: 0.6892 - val_accuracy: 0.8033\n",
            "Epoch 829/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5269 - accuracy: 0.8150 - val_loss: 0.6804 - val_accuracy: 0.7958\n",
            "Epoch 830/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5178 - accuracy: 0.8229 - val_loss: 0.6855 - val_accuracy: 0.7858\n",
            "Epoch 831/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5375 - accuracy: 0.8165 - val_loss: 0.6807 - val_accuracy: 0.8000\n",
            "Epoch 832/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5031 - accuracy: 0.8242 - val_loss: 0.7050 - val_accuracy: 0.7958\n",
            "Epoch 833/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5340 - accuracy: 0.8110 - val_loss: 0.7535 - val_accuracy: 0.7683\n",
            "Epoch 834/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5341 - accuracy: 0.8077 - val_loss: 0.7576 - val_accuracy: 0.7675\n",
            "Epoch 835/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5262 - accuracy: 0.8196 - val_loss: 0.6690 - val_accuracy: 0.7967\n",
            "Epoch 836/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5199 - accuracy: 0.8245 - val_loss: 0.7093 - val_accuracy: 0.7967\n",
            "Epoch 837/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5419 - accuracy: 0.8078 - val_loss: 0.7079 - val_accuracy: 0.8133\n",
            "Epoch 838/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5285 - accuracy: 0.8164 - val_loss: 0.6405 - val_accuracy: 0.8008\n",
            "Epoch 839/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5281 - accuracy: 0.8226 - val_loss: 0.7391 - val_accuracy: 0.8025\n",
            "Epoch 840/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5299 - accuracy: 0.8175 - val_loss: 0.6726 - val_accuracy: 0.7667\n",
            "Epoch 841/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5387 - accuracy: 0.8079 - val_loss: 0.7276 - val_accuracy: 0.7675\n",
            "Epoch 842/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5526 - accuracy: 0.8116 - val_loss: 0.6487 - val_accuracy: 0.7850\n",
            "Epoch 843/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5214 - accuracy: 0.8095 - val_loss: 0.6329 - val_accuracy: 0.7967\n",
            "Epoch 844/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5122 - accuracy: 0.8211 - val_loss: 0.6471 - val_accuracy: 0.7892\n",
            "Epoch 845/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5216 - accuracy: 0.8092 - val_loss: 0.6482 - val_accuracy: 0.7842\n",
            "Epoch 846/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5187 - accuracy: 0.8256 - val_loss: 0.6665 - val_accuracy: 0.7942\n",
            "Epoch 847/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5205 - accuracy: 0.8164 - val_loss: 0.6427 - val_accuracy: 0.7967\n",
            "Epoch 848/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5088 - accuracy: 0.8231 - val_loss: 0.6786 - val_accuracy: 0.7783\n",
            "Epoch 849/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5341 - accuracy: 0.8149 - val_loss: 0.6407 - val_accuracy: 0.8017\n",
            "Epoch 850/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5044 - accuracy: 0.8162 - val_loss: 0.6426 - val_accuracy: 0.7858\n",
            "Epoch 851/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5004 - accuracy: 0.8297 - val_loss: 0.6413 - val_accuracy: 0.7958\n",
            "Epoch 852/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4877 - accuracy: 0.8330 - val_loss: 0.6382 - val_accuracy: 0.7975\n",
            "Epoch 853/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5201 - accuracy: 0.8131 - val_loss: 0.6639 - val_accuracy: 0.7850\n",
            "Epoch 854/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5153 - accuracy: 0.8236 - val_loss: 0.6695 - val_accuracy: 0.7892\n",
            "Epoch 855/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5287 - accuracy: 0.8160 - val_loss: 0.6437 - val_accuracy: 0.7975\n",
            "Epoch 856/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5142 - accuracy: 0.8265 - val_loss: 0.6545 - val_accuracy: 0.7850\n",
            "Epoch 857/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5269 - accuracy: 0.8095 - val_loss: 0.6612 - val_accuracy: 0.7767\n",
            "Epoch 858/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5047 - accuracy: 0.8181 - val_loss: 0.6427 - val_accuracy: 0.7925\n",
            "Epoch 859/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5209 - accuracy: 0.8153 - val_loss: 0.6568 - val_accuracy: 0.7925\n",
            "Epoch 860/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5323 - accuracy: 0.8044 - val_loss: 0.6688 - val_accuracy: 0.7875\n",
            "Epoch 861/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5144 - accuracy: 0.8254 - val_loss: 0.6687 - val_accuracy: 0.7892\n",
            "Epoch 862/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5196 - accuracy: 0.8149 - val_loss: 0.6703 - val_accuracy: 0.7758\n",
            "Epoch 863/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5010 - accuracy: 0.8190 - val_loss: 0.6549 - val_accuracy: 0.7867\n",
            "Epoch 864/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5152 - accuracy: 0.8227 - val_loss: 0.6184 - val_accuracy: 0.8050\n",
            "Epoch 865/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4961 - accuracy: 0.8271 - val_loss: 0.6349 - val_accuracy: 0.8092\n",
            "Epoch 866/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5462 - accuracy: 0.8057 - val_loss: 0.6749 - val_accuracy: 0.7983\n",
            "Epoch 867/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5788 - accuracy: 0.8022 - val_loss: 0.6839 - val_accuracy: 0.7892\n",
            "Epoch 868/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5169 - accuracy: 0.8164 - val_loss: 0.6531 - val_accuracy: 0.7967\n",
            "Epoch 869/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4854 - accuracy: 0.8309 - val_loss: 0.6505 - val_accuracy: 0.7900\n",
            "Epoch 870/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5438 - accuracy: 0.8121 - val_loss: 0.6604 - val_accuracy: 0.7808\n",
            "Epoch 871/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5271 - accuracy: 0.8058 - val_loss: 0.7051 - val_accuracy: 0.7908\n",
            "Epoch 872/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5064 - accuracy: 0.8223 - val_loss: 0.6823 - val_accuracy: 0.7675\n",
            "Epoch 873/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5259 - accuracy: 0.8059 - val_loss: 0.6946 - val_accuracy: 0.7617\n",
            "Epoch 874/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5105 - accuracy: 0.8230 - val_loss: 0.6258 - val_accuracy: 0.8017\n",
            "Epoch 875/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5063 - accuracy: 0.8231 - val_loss: 0.7465 - val_accuracy: 0.8000\n",
            "Epoch 876/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5147 - accuracy: 0.8212 - val_loss: 0.6165 - val_accuracy: 0.7933\n",
            "Epoch 877/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5277 - accuracy: 0.8126 - val_loss: 0.6297 - val_accuracy: 0.8008\n",
            "Epoch 878/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5037 - accuracy: 0.8194 - val_loss: 0.6428 - val_accuracy: 0.7892\n",
            "Epoch 879/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5076 - accuracy: 0.8178 - val_loss: 0.6484 - val_accuracy: 0.7917\n",
            "Epoch 880/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5107 - accuracy: 0.8171 - val_loss: 0.6177 - val_accuracy: 0.8017\n",
            "Epoch 881/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4967 - accuracy: 0.8215 - val_loss: 0.6478 - val_accuracy: 0.7933\n",
            "Epoch 882/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5259 - accuracy: 0.8121 - val_loss: 0.6584 - val_accuracy: 0.7992\n",
            "Epoch 883/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5343 - accuracy: 0.8137 - val_loss: 0.6625 - val_accuracy: 0.7908\n",
            "Epoch 884/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5172 - accuracy: 0.8203 - val_loss: 0.6834 - val_accuracy: 0.7883\n",
            "Epoch 885/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5390 - accuracy: 0.8222 - val_loss: 0.6524 - val_accuracy: 0.7917\n",
            "Epoch 886/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5284 - accuracy: 0.8167 - val_loss: 0.6499 - val_accuracy: 0.8025\n",
            "Epoch 887/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4910 - accuracy: 0.8289 - val_loss: 0.6640 - val_accuracy: 0.8000\n",
            "Epoch 888/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5470 - accuracy: 0.8165 - val_loss: 0.6744 - val_accuracy: 0.7850\n",
            "Epoch 889/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4959 - accuracy: 0.8236 - val_loss: 0.6386 - val_accuracy: 0.7958\n",
            "Epoch 890/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4906 - accuracy: 0.8276 - val_loss: 0.6291 - val_accuracy: 0.7975\n",
            "Epoch 891/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4894 - accuracy: 0.8225 - val_loss: 0.6419 - val_accuracy: 0.8025\n",
            "Epoch 892/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4956 - accuracy: 0.8320 - val_loss: 0.6405 - val_accuracy: 0.8067\n",
            "Epoch 893/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5079 - accuracy: 0.8117 - val_loss: 0.6592 - val_accuracy: 0.7883\n",
            "Epoch 894/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.4979 - accuracy: 0.8149 - val_loss: 0.6919 - val_accuracy: 0.7892\n",
            "Epoch 895/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5493 - accuracy: 0.8147 - val_loss: 0.6506 - val_accuracy: 0.8017\n",
            "Epoch 896/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5145 - accuracy: 0.8244 - val_loss: 0.6468 - val_accuracy: 0.7925\n",
            "Epoch 897/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5007 - accuracy: 0.8259 - val_loss: 0.6680 - val_accuracy: 0.7792\n",
            "Epoch 898/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5171 - accuracy: 0.8135 - val_loss: 0.6742 - val_accuracy: 0.7842\n",
            "Epoch 899/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5278 - accuracy: 0.8063 - val_loss: 0.6646 - val_accuracy: 0.7908\n",
            "Epoch 900/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5227 - accuracy: 0.8156 - val_loss: 0.6551 - val_accuracy: 0.7950\n",
            "Epoch 901/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5498 - accuracy: 0.7923 - val_loss: 0.6329 - val_accuracy: 0.7875\n",
            "Epoch 902/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5318 - accuracy: 0.8108 - val_loss: 0.6176 - val_accuracy: 0.8208\n",
            "Epoch 903/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5136 - accuracy: 0.8229 - val_loss: 0.6288 - val_accuracy: 0.8025\n",
            "Epoch 904/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5306 - accuracy: 0.8188 - val_loss: 0.6384 - val_accuracy: 0.8108\n",
            "Epoch 905/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5237 - accuracy: 0.8100 - val_loss: 0.6316 - val_accuracy: 0.8158\n",
            "Epoch 906/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4998 - accuracy: 0.8301 - val_loss: 0.7297 - val_accuracy: 0.7717\n",
            "Epoch 907/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5510 - accuracy: 0.8092 - val_loss: 0.7062 - val_accuracy: 0.7550\n",
            "Epoch 908/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5498 - accuracy: 0.8017 - val_loss: 0.6185 - val_accuracy: 0.8050\n",
            "Epoch 909/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4774 - accuracy: 0.8452 - val_loss: 0.6467 - val_accuracy: 0.7958\n",
            "Epoch 910/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5254 - accuracy: 0.8080 - val_loss: 0.6435 - val_accuracy: 0.7958\n",
            "Epoch 911/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4987 - accuracy: 0.8214 - val_loss: 0.6521 - val_accuracy: 0.7858\n",
            "Epoch 912/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5345 - accuracy: 0.8183 - val_loss: 0.6950 - val_accuracy: 0.7983\n",
            "Epoch 913/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5217 - accuracy: 0.8158 - val_loss: 0.6293 - val_accuracy: 0.8125\n",
            "Epoch 914/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5169 - accuracy: 0.8204 - val_loss: 0.6960 - val_accuracy: 0.7692\n",
            "Epoch 915/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5225 - accuracy: 0.8202 - val_loss: 0.6260 - val_accuracy: 0.8042\n",
            "Epoch 916/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5113 - accuracy: 0.8109 - val_loss: 0.6544 - val_accuracy: 0.7917\n",
            "Epoch 917/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5179 - accuracy: 0.8124 - val_loss: 0.6692 - val_accuracy: 0.7958\n",
            "Epoch 918/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5127 - accuracy: 0.8124 - val_loss: 0.6659 - val_accuracy: 0.7917\n",
            "Epoch 919/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5428 - accuracy: 0.8059 - val_loss: 0.7096 - val_accuracy: 0.7875\n",
            "Epoch 920/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5205 - accuracy: 0.8199 - val_loss: 0.6691 - val_accuracy: 0.7958\n",
            "Epoch 921/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5427 - accuracy: 0.8138 - val_loss: 0.6586 - val_accuracy: 0.7983\n",
            "Epoch 922/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5156 - accuracy: 0.8153 - val_loss: 0.6757 - val_accuracy: 0.7925\n",
            "Epoch 923/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.8132 - val_loss: 0.7649 - val_accuracy: 0.8025\n",
            "Epoch 924/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5390 - accuracy: 0.8188 - val_loss: 0.6781 - val_accuracy: 0.7958\n",
            "Epoch 925/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5173 - accuracy: 0.8255 - val_loss: 0.6814 - val_accuracy: 0.7825\n",
            "Epoch 926/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5139 - accuracy: 0.8167 - val_loss: 0.6783 - val_accuracy: 0.7983\n",
            "Epoch 927/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4936 - accuracy: 0.8239 - val_loss: 0.6330 - val_accuracy: 0.8033\n",
            "Epoch 928/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5104 - accuracy: 0.8138 - val_loss: 0.6539 - val_accuracy: 0.8125\n",
            "Epoch 929/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5002 - accuracy: 0.8317 - val_loss: 0.7372 - val_accuracy: 0.7750\n",
            "Epoch 930/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5031 - accuracy: 0.8224 - val_loss: 0.6310 - val_accuracy: 0.7967\n",
            "Epoch 931/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5036 - accuracy: 0.8218 - val_loss: 0.6415 - val_accuracy: 0.8075\n",
            "Epoch 932/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5303 - accuracy: 0.8204 - val_loss: 0.6531 - val_accuracy: 0.8092\n",
            "Epoch 933/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5081 - accuracy: 0.8193 - val_loss: 0.6543 - val_accuracy: 0.7975\n",
            "Epoch 934/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5201 - accuracy: 0.8068 - val_loss: 0.6633 - val_accuracy: 0.7950\n",
            "Epoch 935/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5102 - accuracy: 0.8285 - val_loss: 0.7062 - val_accuracy: 0.7875\n",
            "Epoch 936/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5020 - accuracy: 0.8173 - val_loss: 0.6968 - val_accuracy: 0.8025\n",
            "Epoch 937/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4773 - accuracy: 0.8341 - val_loss: 0.6696 - val_accuracy: 0.7875\n",
            "Epoch 938/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5003 - accuracy: 0.8219 - val_loss: 0.6771 - val_accuracy: 0.7850\n",
            "Epoch 939/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5199 - accuracy: 0.8145 - val_loss: 0.6335 - val_accuracy: 0.8042\n",
            "Epoch 940/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4787 - accuracy: 0.8291 - val_loss: 0.7565 - val_accuracy: 0.7867\n",
            "Epoch 941/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5232 - accuracy: 0.8192 - val_loss: 0.7138 - val_accuracy: 0.7850\n",
            "Epoch 942/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5112 - accuracy: 0.8218 - val_loss: 0.8764 - val_accuracy: 0.7875\n",
            "Epoch 943/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5793 - accuracy: 0.8122 - val_loss: 0.6823 - val_accuracy: 0.7992\n",
            "Epoch 944/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4993 - accuracy: 0.8114 - val_loss: 0.7435 - val_accuracy: 0.7750\n",
            "Epoch 945/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5131 - accuracy: 0.8147 - val_loss: 0.6923 - val_accuracy: 0.7908\n",
            "Epoch 946/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4885 - accuracy: 0.8291 - val_loss: 0.6766 - val_accuracy: 0.8108\n",
            "Epoch 947/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4786 - accuracy: 0.8258 - val_loss: 0.6986 - val_accuracy: 0.7933\n",
            "Epoch 948/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5060 - accuracy: 0.8196 - val_loss: 0.6947 - val_accuracy: 0.7808\n",
            "Epoch 949/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5367 - accuracy: 0.8062 - val_loss: 0.7252 - val_accuracy: 0.7900\n",
            "Epoch 950/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5111 - accuracy: 0.8349 - val_loss: 0.7154 - val_accuracy: 0.7833\n",
            "Epoch 951/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5263 - accuracy: 0.8071 - val_loss: 0.7117 - val_accuracy: 0.7642\n",
            "Epoch 952/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4922 - accuracy: 0.8242 - val_loss: 0.7051 - val_accuracy: 0.7908\n",
            "Epoch 953/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5135 - accuracy: 0.8211 - val_loss: 0.6928 - val_accuracy: 0.7875\n",
            "Epoch 954/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5041 - accuracy: 0.8181 - val_loss: 0.7113 - val_accuracy: 0.7942\n",
            "Epoch 955/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5264 - accuracy: 0.8043 - val_loss: 0.6668 - val_accuracy: 0.7942\n",
            "Epoch 956/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4972 - accuracy: 0.8235 - val_loss: 0.7474 - val_accuracy: 0.7717\n",
            "Epoch 957/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4973 - accuracy: 0.8308 - val_loss: 0.6607 - val_accuracy: 0.8050\n",
            "Epoch 958/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4887 - accuracy: 0.8226 - val_loss: 0.6910 - val_accuracy: 0.8050\n",
            "Epoch 959/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5330 - accuracy: 0.8118 - val_loss: 0.7064 - val_accuracy: 0.7842\n",
            "Epoch 960/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4994 - accuracy: 0.8208 - val_loss: 0.6667 - val_accuracy: 0.8075\n",
            "Epoch 961/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4987 - accuracy: 0.8252 - val_loss: 0.6849 - val_accuracy: 0.8100\n",
            "Epoch 962/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4802 - accuracy: 0.8285 - val_loss: 0.6764 - val_accuracy: 0.8017\n",
            "Epoch 963/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4930 - accuracy: 0.8211 - val_loss: 0.7757 - val_accuracy: 0.7950\n",
            "Epoch 964/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5385 - accuracy: 0.8134 - val_loss: 0.6522 - val_accuracy: 0.7875\n",
            "Epoch 965/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5161 - accuracy: 0.8186 - val_loss: 0.6670 - val_accuracy: 0.7958\n",
            "Epoch 966/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5017 - accuracy: 0.8247 - val_loss: 0.6292 - val_accuracy: 0.8158\n",
            "Epoch 967/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4862 - accuracy: 0.8244 - val_loss: 0.6384 - val_accuracy: 0.7975\n",
            "Epoch 968/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5006 - accuracy: 0.8252 - val_loss: 0.6235 - val_accuracy: 0.8017\n",
            "Epoch 969/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5074 - accuracy: 0.8165 - val_loss: 0.6816 - val_accuracy: 0.7817\n",
            "Epoch 970/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4993 - accuracy: 0.8169 - val_loss: 0.6252 - val_accuracy: 0.7942\n",
            "Epoch 971/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4878 - accuracy: 0.8245 - val_loss: 0.6095 - val_accuracy: 0.8242\n",
            "Epoch 972/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4785 - accuracy: 0.8222 - val_loss: 0.6341 - val_accuracy: 0.8100\n",
            "Epoch 973/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4913 - accuracy: 0.8262 - val_loss: 0.6406 - val_accuracy: 0.7975\n",
            "Epoch 974/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5220 - accuracy: 0.8067 - val_loss: 0.6509 - val_accuracy: 0.7900\n",
            "Epoch 975/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.8295 - val_loss: 0.6738 - val_accuracy: 0.7775\n",
            "Epoch 976/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4871 - accuracy: 0.8324 - val_loss: 0.6733 - val_accuracy: 0.7817\n",
            "Epoch 977/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5107 - accuracy: 0.8165 - val_loss: 0.6177 - val_accuracy: 0.8142\n",
            "Epoch 978/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4965 - accuracy: 0.8243 - val_loss: 0.6425 - val_accuracy: 0.8133\n",
            "Epoch 979/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4923 - accuracy: 0.8286 - val_loss: 0.6742 - val_accuracy: 0.7892\n",
            "Epoch 980/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5238 - accuracy: 0.8027 - val_loss: 0.6855 - val_accuracy: 0.7675\n",
            "Epoch 981/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4984 - accuracy: 0.8235 - val_loss: 0.6778 - val_accuracy: 0.7950\n",
            "Epoch 982/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5169 - accuracy: 0.8145 - val_loss: 0.6762 - val_accuracy: 0.7700\n",
            "Epoch 983/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5186 - accuracy: 0.8076 - val_loss: 0.6494 - val_accuracy: 0.7983\n",
            "Epoch 984/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5026 - accuracy: 0.8306 - val_loss: 0.7194 - val_accuracy: 0.7850\n",
            "Epoch 985/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4967 - accuracy: 0.8179 - val_loss: 0.6322 - val_accuracy: 0.7792\n",
            "Epoch 986/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5049 - accuracy: 0.8125 - val_loss: 0.7047 - val_accuracy: 0.7783\n",
            "Epoch 987/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5049 - accuracy: 0.8105 - val_loss: 0.6152 - val_accuracy: 0.7983\n",
            "Epoch 988/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4951 - accuracy: 0.8237 - val_loss: 0.6302 - val_accuracy: 0.8117\n",
            "Epoch 989/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.8212 - val_loss: 0.6245 - val_accuracy: 0.8025\n",
            "Epoch 990/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5331 - accuracy: 0.8113 - val_loss: 0.6545 - val_accuracy: 0.7950\n",
            "Epoch 991/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5070 - accuracy: 0.8219 - val_loss: 0.6929 - val_accuracy: 0.7767\n",
            "Epoch 992/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5456 - accuracy: 0.8048 - val_loss: 0.6598 - val_accuracy: 0.7983\n",
            "Epoch 993/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5064 - accuracy: 0.8238 - val_loss: 0.6193 - val_accuracy: 0.8058\n",
            "Epoch 994/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4937 - accuracy: 0.8271 - val_loss: 0.6372 - val_accuracy: 0.7967\n",
            "Epoch 995/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5323 - accuracy: 0.8104 - val_loss: 0.6562 - val_accuracy: 0.7917\n",
            "Epoch 996/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5035 - accuracy: 0.8300 - val_loss: 0.6556 - val_accuracy: 0.8017\n",
            "Epoch 997/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4823 - accuracy: 0.8330 - val_loss: 0.6888 - val_accuracy: 0.7800\n",
            "Epoch 998/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4767 - accuracy: 0.8293 - val_loss: 0.6534 - val_accuracy: 0.7942\n",
            "Epoch 999/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5182 - accuracy: 0.8105 - val_loss: 0.7291 - val_accuracy: 0.7775\n",
            "Epoch 1000/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5382 - accuracy: 0.8019 - val_loss: 0.7131 - val_accuracy: 0.7733\n",
            "Epoch 1001/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4984 - accuracy: 0.8267 - val_loss: 0.6993 - val_accuracy: 0.7817\n",
            "Epoch 1002/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5089 - accuracy: 0.8127 - val_loss: 0.6165 - val_accuracy: 0.7992\n",
            "Epoch 1003/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5028 - accuracy: 0.8232 - val_loss: 0.6759 - val_accuracy: 0.7825\n",
            "Epoch 1004/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5095 - accuracy: 0.8249 - val_loss: 0.6331 - val_accuracy: 0.8117\n",
            "Epoch 1005/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.8302 - val_loss: 0.6954 - val_accuracy: 0.7758\n",
            "Epoch 1006/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5324 - accuracy: 0.8107 - val_loss: 0.6582 - val_accuracy: 0.7875\n",
            "Epoch 1007/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5111 - accuracy: 0.8198 - val_loss: 0.6434 - val_accuracy: 0.7992\n",
            "Epoch 1008/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4926 - accuracy: 0.8226 - val_loss: 0.6298 - val_accuracy: 0.8092\n",
            "Epoch 1009/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4771 - accuracy: 0.8322 - val_loss: 0.6075 - val_accuracy: 0.8192\n",
            "Epoch 1010/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4765 - accuracy: 0.8378 - val_loss: 0.6337 - val_accuracy: 0.8142\n",
            "Epoch 1011/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4934 - accuracy: 0.8234 - val_loss: 0.6512 - val_accuracy: 0.7958\n",
            "Epoch 1012/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5147 - accuracy: 0.8161 - val_loss: 0.6610 - val_accuracy: 0.7942\n",
            "Epoch 1013/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5077 - accuracy: 0.8268 - val_loss: 0.6269 - val_accuracy: 0.7975\n",
            "Epoch 1014/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5180 - accuracy: 0.8195 - val_loss: 0.6444 - val_accuracy: 0.8092\n",
            "Epoch 1015/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4762 - accuracy: 0.8351 - val_loss: 0.6135 - val_accuracy: 0.8092\n",
            "Epoch 1016/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4651 - accuracy: 0.8353 - val_loss: 0.6791 - val_accuracy: 0.7983\n",
            "Epoch 1017/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5168 - accuracy: 0.8187 - val_loss: 0.6554 - val_accuracy: 0.8017\n",
            "Epoch 1018/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4950 - accuracy: 0.8285 - val_loss: 0.6596 - val_accuracy: 0.7850\n",
            "Epoch 1019/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4949 - accuracy: 0.8336 - val_loss: 0.6264 - val_accuracy: 0.8108\n",
            "Epoch 1020/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4814 - accuracy: 0.8297 - val_loss: 0.7870 - val_accuracy: 0.7958\n",
            "Epoch 1021/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5252 - accuracy: 0.8165 - val_loss: 0.6711 - val_accuracy: 0.8058\n",
            "Epoch 1022/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5136 - accuracy: 0.8230 - val_loss: 0.6509 - val_accuracy: 0.7908\n",
            "Epoch 1023/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5020 - accuracy: 0.8246 - val_loss: 0.6489 - val_accuracy: 0.8000\n",
            "Epoch 1024/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5101 - accuracy: 0.8147 - val_loss: 0.6469 - val_accuracy: 0.8108\n",
            "Epoch 1025/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4811 - accuracy: 0.8315 - val_loss: 0.6699 - val_accuracy: 0.7908\n",
            "Epoch 1026/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4980 - accuracy: 0.8254 - val_loss: 0.6644 - val_accuracy: 0.7950\n",
            "Epoch 1027/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4904 - accuracy: 0.8257 - val_loss: 0.6350 - val_accuracy: 0.8058\n",
            "Epoch 1028/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5189 - accuracy: 0.8091 - val_loss: 0.6872 - val_accuracy: 0.8033\n",
            "Epoch 1029/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5134 - accuracy: 0.8206 - val_loss: 0.6467 - val_accuracy: 0.7883\n",
            "Epoch 1030/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4919 - accuracy: 0.8267 - val_loss: 0.7124 - val_accuracy: 0.7758\n",
            "Epoch 1031/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5376 - accuracy: 0.7988 - val_loss: 0.6580 - val_accuracy: 0.7900\n",
            "Epoch 1032/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4983 - accuracy: 0.8207 - val_loss: 0.6332 - val_accuracy: 0.8133\n",
            "Epoch 1033/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4630 - accuracy: 0.8376 - val_loss: 0.6780 - val_accuracy: 0.7733\n",
            "Epoch 1034/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5142 - accuracy: 0.8169 - val_loss: 0.6644 - val_accuracy: 0.8000\n",
            "Epoch 1035/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5038 - accuracy: 0.8249 - val_loss: 0.6661 - val_accuracy: 0.8008\n",
            "Epoch 1036/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5251 - accuracy: 0.8250 - val_loss: 0.6546 - val_accuracy: 0.7992\n",
            "Epoch 1037/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4752 - accuracy: 0.8293 - val_loss: 0.6552 - val_accuracy: 0.8008\n",
            "Epoch 1038/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4891 - accuracy: 0.8301 - val_loss: 0.6567 - val_accuracy: 0.7950\n",
            "Epoch 1039/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4797 - accuracy: 0.8319 - val_loss: 0.6395 - val_accuracy: 0.8083\n",
            "Epoch 1040/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4823 - accuracy: 0.8237 - val_loss: 0.6576 - val_accuracy: 0.8067\n",
            "Epoch 1041/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4837 - accuracy: 0.8222 - val_loss: 0.6935 - val_accuracy: 0.7875\n",
            "Epoch 1042/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5241 - accuracy: 0.8133 - val_loss: 0.6853 - val_accuracy: 0.7883\n",
            "Epoch 1043/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5098 - accuracy: 0.8206 - val_loss: 0.6874 - val_accuracy: 0.8058\n",
            "Epoch 1044/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5091 - accuracy: 0.8243 - val_loss: 0.7230 - val_accuracy: 0.7792\n",
            "Epoch 1045/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5053 - accuracy: 0.8128 - val_loss: 0.7723 - val_accuracy: 0.7667\n",
            "Epoch 1046/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5122 - accuracy: 0.8082 - val_loss: 0.7029 - val_accuracy: 0.7750\n",
            "Epoch 1047/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4804 - accuracy: 0.8267 - val_loss: 0.7270 - val_accuracy: 0.7908\n",
            "Epoch 1048/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5194 - accuracy: 0.8139 - val_loss: 0.6691 - val_accuracy: 0.7983\n",
            "Epoch 1049/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4774 - accuracy: 0.8257 - val_loss: 0.6981 - val_accuracy: 0.7808\n",
            "Epoch 1050/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4963 - accuracy: 0.8146 - val_loss: 0.6517 - val_accuracy: 0.8033\n",
            "Epoch 1051/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5216 - accuracy: 0.8101 - val_loss: 0.6599 - val_accuracy: 0.8083\n",
            "Epoch 1052/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4710 - accuracy: 0.8395 - val_loss: 0.7419 - val_accuracy: 0.7733\n",
            "Epoch 1053/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4958 - accuracy: 0.8265 - val_loss: 0.6568 - val_accuracy: 0.7875\n",
            "Epoch 1054/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5013 - accuracy: 0.8177 - val_loss: 0.6624 - val_accuracy: 0.7942\n",
            "Epoch 1055/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5012 - accuracy: 0.8188 - val_loss: 0.6705 - val_accuracy: 0.8067\n",
            "Epoch 1056/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4970 - accuracy: 0.8267 - val_loss: 0.6976 - val_accuracy: 0.7983\n",
            "Epoch 1057/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4984 - accuracy: 0.8238 - val_loss: 0.6572 - val_accuracy: 0.8083\n",
            "Epoch 1058/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4751 - accuracy: 0.8285 - val_loss: 0.6493 - val_accuracy: 0.7992\n",
            "Epoch 1059/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4541 - accuracy: 0.8476 - val_loss: 0.6576 - val_accuracy: 0.8083\n",
            "Epoch 1060/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4766 - accuracy: 0.8336 - val_loss: 0.6609 - val_accuracy: 0.8150\n",
            "Epoch 1061/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4763 - accuracy: 0.8371 - val_loss: 0.6636 - val_accuracy: 0.8167\n",
            "Epoch 1062/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4955 - accuracy: 0.8206 - val_loss: 0.6805 - val_accuracy: 0.8008\n",
            "Epoch 1063/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4886 - accuracy: 0.8226 - val_loss: 0.7254 - val_accuracy: 0.8183\n",
            "Epoch 1064/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5012 - accuracy: 0.8245 - val_loss: 0.6824 - val_accuracy: 0.8075\n",
            "Epoch 1065/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5050 - accuracy: 0.8220 - val_loss: 0.8448 - val_accuracy: 0.7750\n",
            "Epoch 1066/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5453 - accuracy: 0.7927 - val_loss: 0.6830 - val_accuracy: 0.7867\n",
            "Epoch 1067/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4933 - accuracy: 0.8235 - val_loss: 0.6905 - val_accuracy: 0.7975\n",
            "Epoch 1068/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4821 - accuracy: 0.8361 - val_loss: 0.7378 - val_accuracy: 0.7658\n",
            "Epoch 1069/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5227 - accuracy: 0.8212 - val_loss: 0.7237 - val_accuracy: 0.7858\n",
            "Epoch 1070/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5606 - accuracy: 0.8054 - val_loss: 0.6987 - val_accuracy: 0.8058\n",
            "Epoch 1071/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4972 - accuracy: 0.8176 - val_loss: 0.7230 - val_accuracy: 0.8042\n",
            "Epoch 1072/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5164 - accuracy: 0.8050 - val_loss: 0.6835 - val_accuracy: 0.7975\n",
            "Epoch 1073/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4767 - accuracy: 0.8302 - val_loss: 0.7160 - val_accuracy: 0.8058\n",
            "Epoch 1074/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4988 - accuracy: 0.8247 - val_loss: 0.6930 - val_accuracy: 0.7983\n",
            "Epoch 1075/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4995 - accuracy: 0.8246 - val_loss: 0.7002 - val_accuracy: 0.7983\n",
            "Epoch 1076/2000\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.4844 - accuracy: 0.8265 - val_loss: 0.6830 - val_accuracy: 0.8033\n",
            "Epoch 1077/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4883 - accuracy: 0.8307 - val_loss: 0.7277 - val_accuracy: 0.7817\n",
            "Epoch 1078/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4692 - accuracy: 0.8351 - val_loss: 0.7222 - val_accuracy: 0.7842\n",
            "Epoch 1079/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4823 - accuracy: 0.8255 - val_loss: 0.7191 - val_accuracy: 0.8000\n",
            "Epoch 1080/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5016 - accuracy: 0.8150 - val_loss: 0.7233 - val_accuracy: 0.7933\n",
            "Epoch 1081/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4843 - accuracy: 0.8266 - val_loss: 0.7868 - val_accuracy: 0.7700\n",
            "Epoch 1082/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5417 - accuracy: 0.8184 - val_loss: 0.7841 - val_accuracy: 0.7933\n",
            "Epoch 1083/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5416 - accuracy: 0.8155 - val_loss: 0.7216 - val_accuracy: 0.8092\n",
            "Epoch 1084/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4809 - accuracy: 0.8293 - val_loss: 0.7081 - val_accuracy: 0.8000\n",
            "Epoch 1085/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4685 - accuracy: 0.8338 - val_loss: 0.7029 - val_accuracy: 0.8033\n",
            "Epoch 1086/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4992 - accuracy: 0.8208 - val_loss: 0.7409 - val_accuracy: 0.8017\n",
            "Epoch 1087/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5018 - accuracy: 0.8215 - val_loss: 0.7784 - val_accuracy: 0.7733\n",
            "Epoch 1088/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5174 - accuracy: 0.8248 - val_loss: 0.6903 - val_accuracy: 0.8133\n",
            "Epoch 1089/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4948 - accuracy: 0.8261 - val_loss: 0.6825 - val_accuracy: 0.8200\n",
            "Epoch 1090/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4911 - accuracy: 0.8281 - val_loss: 0.7542 - val_accuracy: 0.7933\n",
            "Epoch 1091/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4798 - accuracy: 0.8347 - val_loss: 0.7087 - val_accuracy: 0.8117\n",
            "Epoch 1092/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4884 - accuracy: 0.8305 - val_loss: 0.6991 - val_accuracy: 0.8208\n",
            "Epoch 1093/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4658 - accuracy: 0.8346 - val_loss: 0.7343 - val_accuracy: 0.7908\n",
            "Epoch 1094/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5148 - accuracy: 0.8103 - val_loss: 0.7458 - val_accuracy: 0.7875\n",
            "Epoch 1095/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5096 - accuracy: 0.8124 - val_loss: 0.7035 - val_accuracy: 0.8025\n",
            "Epoch 1096/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4926 - accuracy: 0.8121 - val_loss: 0.7147 - val_accuracy: 0.7992\n",
            "Epoch 1097/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4960 - accuracy: 0.8202 - val_loss: 0.7825 - val_accuracy: 0.7767\n",
            "Epoch 1098/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4923 - accuracy: 0.8240 - val_loss: 0.7760 - val_accuracy: 0.7750\n",
            "Epoch 1099/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5037 - accuracy: 0.8220 - val_loss: 0.7382 - val_accuracy: 0.7925\n",
            "Epoch 1100/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5369 - accuracy: 0.8212 - val_loss: 0.6350 - val_accuracy: 0.8100\n",
            "Epoch 1101/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4969 - accuracy: 0.8121 - val_loss: 0.6325 - val_accuracy: 0.7892\n",
            "Epoch 1102/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4901 - accuracy: 0.8233 - val_loss: 0.6323 - val_accuracy: 0.8175\n",
            "Epoch 1103/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4994 - accuracy: 0.8232 - val_loss: 0.6371 - val_accuracy: 0.7867\n",
            "Epoch 1104/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4738 - accuracy: 0.8295 - val_loss: 0.6362 - val_accuracy: 0.8192\n",
            "Epoch 1105/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4995 - accuracy: 0.8278 - val_loss: 0.6326 - val_accuracy: 0.8067\n",
            "Epoch 1106/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4972 - accuracy: 0.8217 - val_loss: 0.7100 - val_accuracy: 0.7783\n",
            "Epoch 1107/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5137 - accuracy: 0.8198 - val_loss: 0.6700 - val_accuracy: 0.7925\n",
            "Epoch 1108/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5321 - accuracy: 0.8230 - val_loss: 0.6721 - val_accuracy: 0.7742\n",
            "Epoch 1109/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5173 - accuracy: 0.8033 - val_loss: 0.6221 - val_accuracy: 0.8217\n",
            "Epoch 1110/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4954 - accuracy: 0.8287 - val_loss: 0.6250 - val_accuracy: 0.8217\n",
            "Epoch 1111/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4993 - accuracy: 0.8220 - val_loss: 0.7438 - val_accuracy: 0.7775\n",
            "Epoch 1112/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5673 - accuracy: 0.8061 - val_loss: 0.6614 - val_accuracy: 0.7867\n",
            "Epoch 1113/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5059 - accuracy: 0.8226 - val_loss: 0.6746 - val_accuracy: 0.7900\n",
            "Epoch 1114/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5274 - accuracy: 0.8173 - val_loss: 0.6356 - val_accuracy: 0.8025\n",
            "Epoch 1115/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4841 - accuracy: 0.8237 - val_loss: 0.6652 - val_accuracy: 0.7850\n",
            "Epoch 1116/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4893 - accuracy: 0.8186 - val_loss: 0.6302 - val_accuracy: 0.8050\n",
            "Epoch 1117/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4827 - accuracy: 0.8339 - val_loss: 0.6785 - val_accuracy: 0.7933\n",
            "Epoch 1118/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4938 - accuracy: 0.8316 - val_loss: 0.6212 - val_accuracy: 0.8042\n",
            "Epoch 1119/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4672 - accuracy: 0.8386 - val_loss: 0.6892 - val_accuracy: 0.7708\n",
            "Epoch 1120/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4704 - accuracy: 0.8323 - val_loss: 0.6189 - val_accuracy: 0.8150\n",
            "Epoch 1121/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4647 - accuracy: 0.8331 - val_loss: 0.6079 - val_accuracy: 0.8283\n",
            "Epoch 1122/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4979 - accuracy: 0.8280 - val_loss: 0.6869 - val_accuracy: 0.7850\n",
            "Epoch 1123/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4906 - accuracy: 0.8252 - val_loss: 0.7101 - val_accuracy: 0.7950\n",
            "Epoch 1124/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5146 - accuracy: 0.8154 - val_loss: 0.6096 - val_accuracy: 0.8000\n",
            "Epoch 1125/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4773 - accuracy: 0.8360 - val_loss: 0.7223 - val_accuracy: 0.7792\n",
            "Epoch 1126/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5190 - accuracy: 0.8151 - val_loss: 0.6098 - val_accuracy: 0.8000\n",
            "Epoch 1127/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4976 - accuracy: 0.8157 - val_loss: 0.6558 - val_accuracy: 0.8050\n",
            "Epoch 1128/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4885 - accuracy: 0.8280 - val_loss: 0.6603 - val_accuracy: 0.7900\n",
            "Epoch 1129/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5086 - accuracy: 0.8191 - val_loss: 0.6832 - val_accuracy: 0.7983\n",
            "Epoch 1130/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4911 - accuracy: 0.8185 - val_loss: 0.6332 - val_accuracy: 0.8042\n",
            "Epoch 1131/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4923 - accuracy: 0.8225 - val_loss: 0.6190 - val_accuracy: 0.8158\n",
            "Epoch 1132/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4915 - accuracy: 0.8208 - val_loss: 0.6316 - val_accuracy: 0.8100\n",
            "Epoch 1133/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4713 - accuracy: 0.8357 - val_loss: 0.6368 - val_accuracy: 0.8000\n",
            "Epoch 1134/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4612 - accuracy: 0.8385 - val_loss: 0.6248 - val_accuracy: 0.8042\n",
            "Epoch 1135/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5081 - accuracy: 0.8177 - val_loss: 0.6801 - val_accuracy: 0.7875\n",
            "Epoch 1136/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4878 - accuracy: 0.8301 - val_loss: 0.6522 - val_accuracy: 0.7883\n",
            "Epoch 1137/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5324 - accuracy: 0.8115 - val_loss: 0.6610 - val_accuracy: 0.7942\n",
            "Epoch 1138/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5126 - accuracy: 0.8178 - val_loss: 0.6992 - val_accuracy: 0.8092\n",
            "Epoch 1139/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4933 - accuracy: 0.8350 - val_loss: 0.6245 - val_accuracy: 0.8017\n",
            "Epoch 1140/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4813 - accuracy: 0.8237 - val_loss: 0.6286 - val_accuracy: 0.8008\n",
            "Epoch 1141/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4742 - accuracy: 0.8326 - val_loss: 0.6710 - val_accuracy: 0.7992\n",
            "Epoch 1142/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5015 - accuracy: 0.8243 - val_loss: 0.6383 - val_accuracy: 0.8108\n",
            "Epoch 1143/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4600 - accuracy: 0.8353 - val_loss: 0.6207 - val_accuracy: 0.8250\n",
            "Epoch 1144/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4625 - accuracy: 0.8392 - val_loss: 0.6253 - val_accuracy: 0.8175\n",
            "Epoch 1145/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4734 - accuracy: 0.8273 - val_loss: 0.6558 - val_accuracy: 0.8050\n",
            "Epoch 1146/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4959 - accuracy: 0.8215 - val_loss: 0.6349 - val_accuracy: 0.8025\n",
            "Epoch 1147/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4722 - accuracy: 0.8309 - val_loss: 0.6523 - val_accuracy: 0.7975\n",
            "Epoch 1148/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5184 - accuracy: 0.8159 - val_loss: 0.6584 - val_accuracy: 0.8008\n",
            "Epoch 1149/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4796 - accuracy: 0.8293 - val_loss: 0.6921 - val_accuracy: 0.8067\n",
            "Epoch 1150/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5180 - accuracy: 0.8179 - val_loss: 0.6862 - val_accuracy: 0.8108\n",
            "Epoch 1151/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4880 - accuracy: 0.8260 - val_loss: 0.6412 - val_accuracy: 0.7983\n",
            "Epoch 1152/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4956 - accuracy: 0.8334 - val_loss: 0.6979 - val_accuracy: 0.7883\n",
            "Epoch 1153/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4999 - accuracy: 0.8213 - val_loss: 0.6849 - val_accuracy: 0.7800\n",
            "Epoch 1154/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5288 - accuracy: 0.8114 - val_loss: 0.8050 - val_accuracy: 0.7758\n",
            "Epoch 1155/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4936 - accuracy: 0.8297 - val_loss: 0.6420 - val_accuracy: 0.8283\n",
            "Epoch 1156/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4830 - accuracy: 0.8330 - val_loss: 0.6478 - val_accuracy: 0.8025\n",
            "Epoch 1157/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4990 - accuracy: 0.8174 - val_loss: 0.6931 - val_accuracy: 0.7708\n",
            "Epoch 1158/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5209 - accuracy: 0.8123 - val_loss: 0.6547 - val_accuracy: 0.7925\n",
            "Epoch 1159/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5147 - accuracy: 0.8181 - val_loss: 0.6662 - val_accuracy: 0.8025\n",
            "Epoch 1160/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4912 - accuracy: 0.8176 - val_loss: 0.6736 - val_accuracy: 0.7867\n",
            "Epoch 1161/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4967 - accuracy: 0.8267 - val_loss: 0.6824 - val_accuracy: 0.7950\n",
            "Epoch 1162/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4896 - accuracy: 0.8240 - val_loss: 0.6298 - val_accuracy: 0.8125\n",
            "Epoch 1163/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4758 - accuracy: 0.8333 - val_loss: 0.6463 - val_accuracy: 0.8000\n",
            "Epoch 1164/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5085 - accuracy: 0.8165 - val_loss: 0.6557 - val_accuracy: 0.8125\n",
            "Epoch 1165/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4994 - accuracy: 0.8209 - val_loss: 0.6538 - val_accuracy: 0.8000\n",
            "Epoch 1166/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4747 - accuracy: 0.8290 - val_loss: 0.6474 - val_accuracy: 0.8042\n",
            "Epoch 1167/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4694 - accuracy: 0.8369 - val_loss: 0.6679 - val_accuracy: 0.7958\n",
            "Epoch 1168/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4751 - accuracy: 0.8270 - val_loss: 0.7148 - val_accuracy: 0.7742\n",
            "Epoch 1169/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4854 - accuracy: 0.8222 - val_loss: 0.6415 - val_accuracy: 0.8167\n",
            "Epoch 1170/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4921 - accuracy: 0.8296 - val_loss: 0.6146 - val_accuracy: 0.8383\n",
            "Epoch 1171/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4594 - accuracy: 0.8317 - val_loss: 0.6215 - val_accuracy: 0.8200\n",
            "Epoch 1172/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5026 - accuracy: 0.8135 - val_loss: 0.6649 - val_accuracy: 0.8033\n",
            "Epoch 1173/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4823 - accuracy: 0.8234 - val_loss: 0.7287 - val_accuracy: 0.7750\n",
            "Epoch 1174/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4928 - accuracy: 0.8299 - val_loss: 0.6555 - val_accuracy: 0.8067\n",
            "Epoch 1175/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4603 - accuracy: 0.8416 - val_loss: 0.6722 - val_accuracy: 0.7900\n",
            "Epoch 1176/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4783 - accuracy: 0.8255 - val_loss: 0.6916 - val_accuracy: 0.7850\n",
            "Epoch 1177/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5144 - accuracy: 0.8207 - val_loss: 0.6677 - val_accuracy: 0.8033\n",
            "Epoch 1178/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4846 - accuracy: 0.8251 - val_loss: 0.6351 - val_accuracy: 0.8033\n",
            "Epoch 1179/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4582 - accuracy: 0.8372 - val_loss: 0.6518 - val_accuracy: 0.8167\n",
            "Epoch 1180/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4860 - accuracy: 0.8285 - val_loss: 0.6958 - val_accuracy: 0.7867\n",
            "Epoch 1181/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5388 - accuracy: 0.8009 - val_loss: 0.6695 - val_accuracy: 0.7983\n",
            "Epoch 1182/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4738 - accuracy: 0.8312 - val_loss: 0.7078 - val_accuracy: 0.8025\n",
            "Epoch 1183/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4492 - accuracy: 0.8376 - val_loss: 0.7592 - val_accuracy: 0.7825\n",
            "Epoch 1184/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4912 - accuracy: 0.8309 - val_loss: 0.6739 - val_accuracy: 0.7975\n",
            "Epoch 1185/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4832 - accuracy: 0.8280 - val_loss: 0.6733 - val_accuracy: 0.8050\n",
            "Epoch 1186/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4776 - accuracy: 0.8268 - val_loss: 0.8113 - val_accuracy: 0.7950\n",
            "Epoch 1187/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5411 - accuracy: 0.8304 - val_loss: 0.6848 - val_accuracy: 0.8075\n",
            "Epoch 1188/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4755 - accuracy: 0.8309 - val_loss: 0.6183 - val_accuracy: 0.8058\n",
            "Epoch 1189/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4978 - accuracy: 0.8212 - val_loss: 0.6213 - val_accuracy: 0.8058\n",
            "Epoch 1190/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4791 - accuracy: 0.8319 - val_loss: 0.6801 - val_accuracy: 0.7850\n",
            "Epoch 1191/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4735 - accuracy: 0.8216 - val_loss: 0.6334 - val_accuracy: 0.8075\n",
            "Epoch 1192/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4892 - accuracy: 0.8333 - val_loss: 0.6883 - val_accuracy: 0.7783\n",
            "Epoch 1193/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4717 - accuracy: 0.8276 - val_loss: 0.6375 - val_accuracy: 0.8017\n",
            "Epoch 1194/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4970 - accuracy: 0.8248 - val_loss: 0.6564 - val_accuracy: 0.7842\n",
            "Epoch 1195/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4875 - accuracy: 0.8226 - val_loss: 0.6546 - val_accuracy: 0.7900\n",
            "Epoch 1196/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4944 - accuracy: 0.8294 - val_loss: 0.6368 - val_accuracy: 0.8125\n",
            "Epoch 1197/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4907 - accuracy: 0.8256 - val_loss: 0.6209 - val_accuracy: 0.8008\n",
            "Epoch 1198/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4692 - accuracy: 0.8308 - val_loss: 0.6290 - val_accuracy: 0.8200\n",
            "Epoch 1199/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4860 - accuracy: 0.8303 - val_loss: 0.7259 - val_accuracy: 0.7858\n",
            "Epoch 1200/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5052 - accuracy: 0.8216 - val_loss: 0.6470 - val_accuracy: 0.8050\n",
            "Epoch 1201/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4844 - accuracy: 0.8238 - val_loss: 0.6414 - val_accuracy: 0.8125\n",
            "Epoch 1202/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.5178 - accuracy: 0.8219 - val_loss: 0.6363 - val_accuracy: 0.8100\n",
            "Epoch 1203/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4837 - accuracy: 0.8304 - val_loss: 0.6175 - val_accuracy: 0.7983\n",
            "Epoch 1204/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4736 - accuracy: 0.8256 - val_loss: 0.6245 - val_accuracy: 0.8025\n",
            "Epoch 1205/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4650 - accuracy: 0.8344 - val_loss: 0.5944 - val_accuracy: 0.8067\n",
            "Epoch 1206/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4707 - accuracy: 0.8314 - val_loss: 0.6292 - val_accuracy: 0.8100\n",
            "Epoch 1207/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4888 - accuracy: 0.8238 - val_loss: 0.6543 - val_accuracy: 0.8100\n",
            "Epoch 1208/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4884 - accuracy: 0.8288 - val_loss: 0.7107 - val_accuracy: 0.7700\n",
            "Epoch 1209/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4972 - accuracy: 0.8204 - val_loss: 0.6701 - val_accuracy: 0.7875\n",
            "Epoch 1210/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4696 - accuracy: 0.8282 - val_loss: 0.6029 - val_accuracy: 0.8100\n",
            "Epoch 1211/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4761 - accuracy: 0.8304 - val_loss: 0.6186 - val_accuracy: 0.8100\n",
            "Epoch 1212/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4655 - accuracy: 0.8308 - val_loss: 0.5957 - val_accuracy: 0.8200\n",
            "Epoch 1213/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4569 - accuracy: 0.8385 - val_loss: 0.6302 - val_accuracy: 0.7958\n",
            "Epoch 1214/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4785 - accuracy: 0.8300 - val_loss: 0.6537 - val_accuracy: 0.8117\n",
            "Epoch 1215/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4686 - accuracy: 0.8294 - val_loss: 0.6381 - val_accuracy: 0.8000\n",
            "Epoch 1216/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4680 - accuracy: 0.8349 - val_loss: 0.6244 - val_accuracy: 0.8008\n",
            "Epoch 1217/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5081 - accuracy: 0.8224 - val_loss: 0.5946 - val_accuracy: 0.8158\n",
            "Epoch 1218/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4884 - accuracy: 0.8326 - val_loss: 0.6309 - val_accuracy: 0.8100\n",
            "Epoch 1219/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4906 - accuracy: 0.8314 - val_loss: 0.8399 - val_accuracy: 0.8058\n",
            "Epoch 1220/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5305 - accuracy: 0.8227 - val_loss: 0.5995 - val_accuracy: 0.8225\n",
            "Epoch 1221/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4617 - accuracy: 0.8388 - val_loss: 0.6851 - val_accuracy: 0.7725\n",
            "Epoch 1222/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4792 - accuracy: 0.8250 - val_loss: 0.6749 - val_accuracy: 0.7942\n",
            "Epoch 1223/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4941 - accuracy: 0.8257 - val_loss: 0.7005 - val_accuracy: 0.7958\n",
            "Epoch 1224/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5037 - accuracy: 0.8254 - val_loss: 0.6467 - val_accuracy: 0.8000\n",
            "Epoch 1225/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4885 - accuracy: 0.8287 - val_loss: 0.6436 - val_accuracy: 0.7925\n",
            "Epoch 1226/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4402 - accuracy: 0.8403 - val_loss: 0.6370 - val_accuracy: 0.7983\n",
            "Epoch 1227/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4765 - accuracy: 0.8287 - val_loss: 0.6772 - val_accuracy: 0.7908\n",
            "Epoch 1228/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4899 - accuracy: 0.8265 - val_loss: 0.6387 - val_accuracy: 0.8033\n",
            "Epoch 1229/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4469 - accuracy: 0.8400 - val_loss: 0.6078 - val_accuracy: 0.8075\n",
            "Epoch 1230/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4612 - accuracy: 0.8243 - val_loss: 0.6550 - val_accuracy: 0.7917\n",
            "Epoch 1231/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5241 - accuracy: 0.8287 - val_loss: 0.6442 - val_accuracy: 0.8117\n",
            "Epoch 1232/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4776 - accuracy: 0.8340 - val_loss: 0.6438 - val_accuracy: 0.7983\n",
            "Epoch 1233/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4741 - accuracy: 0.8307 - val_loss: 0.6406 - val_accuracy: 0.7900\n",
            "Epoch 1234/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4750 - accuracy: 0.8281 - val_loss: 0.6263 - val_accuracy: 0.8017\n",
            "Epoch 1235/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4740 - accuracy: 0.8279 - val_loss: 0.6180 - val_accuracy: 0.8175\n",
            "Epoch 1236/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4516 - accuracy: 0.8344 - val_loss: 0.6233 - val_accuracy: 0.8042\n",
            "Epoch 1237/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4684 - accuracy: 0.8323 - val_loss: 0.6370 - val_accuracy: 0.7950\n",
            "Epoch 1238/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5015 - accuracy: 0.8279 - val_loss: 0.6330 - val_accuracy: 0.7900\n",
            "Epoch 1239/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5120 - accuracy: 0.8230 - val_loss: 0.7049 - val_accuracy: 0.7658\n",
            "Epoch 1240/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5024 - accuracy: 0.8229 - val_loss: 0.6333 - val_accuracy: 0.7975\n",
            "Epoch 1241/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4486 - accuracy: 0.8446 - val_loss: 0.6534 - val_accuracy: 0.8025\n",
            "Epoch 1242/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4792 - accuracy: 0.8325 - val_loss: 0.7517 - val_accuracy: 0.7792\n",
            "Epoch 1243/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4791 - accuracy: 0.8304 - val_loss: 0.6116 - val_accuracy: 0.8150\n",
            "Epoch 1244/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4807 - accuracy: 0.8249 - val_loss: 0.6203 - val_accuracy: 0.8100\n",
            "Epoch 1245/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4595 - accuracy: 0.8363 - val_loss: 0.6944 - val_accuracy: 0.7958\n",
            "Epoch 1246/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4714 - accuracy: 0.8336 - val_loss: 0.6210 - val_accuracy: 0.8133\n",
            "Epoch 1247/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4806 - accuracy: 0.8344 - val_loss: 0.6369 - val_accuracy: 0.8058\n",
            "Epoch 1248/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4725 - accuracy: 0.8448 - val_loss: 0.6240 - val_accuracy: 0.8133\n",
            "Epoch 1249/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4587 - accuracy: 0.8429 - val_loss: 0.6279 - val_accuracy: 0.8175\n",
            "Epoch 1250/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4703 - accuracy: 0.8341 - val_loss: 0.6066 - val_accuracy: 0.8117\n",
            "Epoch 1251/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4749 - accuracy: 0.8213 - val_loss: 0.6197 - val_accuracy: 0.8000\n",
            "Epoch 1252/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4603 - accuracy: 0.8362 - val_loss: 0.6231 - val_accuracy: 0.8058\n",
            "Epoch 1253/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4777 - accuracy: 0.8223 - val_loss: 0.6521 - val_accuracy: 0.7967\n",
            "Epoch 1254/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4699 - accuracy: 0.8266 - val_loss: 0.5968 - val_accuracy: 0.8125\n",
            "Epoch 1255/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4433 - accuracy: 0.8418 - val_loss: 0.6127 - val_accuracy: 0.8208\n",
            "Epoch 1256/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4631 - accuracy: 0.8361 - val_loss: 0.7153 - val_accuracy: 0.8033\n",
            "Epoch 1257/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5033 - accuracy: 0.8365 - val_loss: 0.7213 - val_accuracy: 0.7800\n",
            "Epoch 1258/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4787 - accuracy: 0.8198 - val_loss: 0.6605 - val_accuracy: 0.8025\n",
            "Epoch 1259/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4719 - accuracy: 0.8342 - val_loss: 0.6865 - val_accuracy: 0.7875\n",
            "Epoch 1260/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4830 - accuracy: 0.8263 - val_loss: 0.6468 - val_accuracy: 0.8058\n",
            "Epoch 1261/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4992 - accuracy: 0.8178 - val_loss: 0.6232 - val_accuracy: 0.8067\n",
            "Epoch 1262/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4901 - accuracy: 0.8225 - val_loss: 0.6657 - val_accuracy: 0.7800\n",
            "Epoch 1263/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5063 - accuracy: 0.8172 - val_loss: 0.6725 - val_accuracy: 0.7967\n",
            "Epoch 1264/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4931 - accuracy: 0.8311 - val_loss: 0.6154 - val_accuracy: 0.8067\n",
            "Epoch 1265/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4601 - accuracy: 0.8420 - val_loss: 0.6722 - val_accuracy: 0.7767\n",
            "Epoch 1266/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4633 - accuracy: 0.8304 - val_loss: 0.7093 - val_accuracy: 0.7783\n",
            "Epoch 1267/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4861 - accuracy: 0.8327 - val_loss: 0.6759 - val_accuracy: 0.7925\n",
            "Epoch 1268/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4850 - accuracy: 0.8281 - val_loss: 0.6562 - val_accuracy: 0.7917\n",
            "Epoch 1269/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4697 - accuracy: 0.8298 - val_loss: 0.6772 - val_accuracy: 0.7858\n",
            "Epoch 1270/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4534 - accuracy: 0.8381 - val_loss: 0.6434 - val_accuracy: 0.8092\n",
            "Epoch 1271/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4750 - accuracy: 0.8276 - val_loss: 0.6816 - val_accuracy: 0.7858\n",
            "Epoch 1272/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4728 - accuracy: 0.8334 - val_loss: 0.6197 - val_accuracy: 0.8150\n",
            "Epoch 1273/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4538 - accuracy: 0.8440 - val_loss: 0.7012 - val_accuracy: 0.7908\n",
            "Epoch 1274/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4897 - accuracy: 0.8307 - val_loss: 0.6260 - val_accuracy: 0.8067\n",
            "Epoch 1275/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4732 - accuracy: 0.8276 - val_loss: 0.6535 - val_accuracy: 0.7992\n",
            "Epoch 1276/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5015 - accuracy: 0.8147 - val_loss: 0.7982 - val_accuracy: 0.7950\n",
            "Epoch 1277/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5165 - accuracy: 0.8268 - val_loss: 0.7821 - val_accuracy: 0.7950\n",
            "Epoch 1278/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4990 - accuracy: 0.8197 - val_loss: 0.6713 - val_accuracy: 0.8117\n",
            "Epoch 1279/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4744 - accuracy: 0.8364 - val_loss: 0.6443 - val_accuracy: 0.8208\n",
            "Epoch 1280/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4595 - accuracy: 0.8392 - val_loss: 0.6734 - val_accuracy: 0.8042\n",
            "Epoch 1281/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4745 - accuracy: 0.8285 - val_loss: 0.6511 - val_accuracy: 0.8175\n",
            "Epoch 1282/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4811 - accuracy: 0.8263 - val_loss: 0.6983 - val_accuracy: 0.7942\n",
            "Epoch 1283/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5040 - accuracy: 0.8176 - val_loss: 0.6774 - val_accuracy: 0.8042\n",
            "Epoch 1284/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4672 - accuracy: 0.8336 - val_loss: 0.6449 - val_accuracy: 0.8192\n",
            "Epoch 1285/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4406 - accuracy: 0.8486 - val_loss: 0.6901 - val_accuracy: 0.7908\n",
            "Epoch 1286/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4788 - accuracy: 0.8330 - val_loss: 0.6763 - val_accuracy: 0.8067\n",
            "Epoch 1287/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4657 - accuracy: 0.8398 - val_loss: 0.6543 - val_accuracy: 0.8042\n",
            "Epoch 1288/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4477 - accuracy: 0.8469 - val_loss: 0.6854 - val_accuracy: 0.7983\n",
            "Epoch 1289/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4662 - accuracy: 0.8326 - val_loss: 0.6795 - val_accuracy: 0.8075\n",
            "Epoch 1290/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4807 - accuracy: 0.8272 - val_loss: 0.6827 - val_accuracy: 0.8008\n",
            "Epoch 1291/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4638 - accuracy: 0.8370 - val_loss: 0.7097 - val_accuracy: 0.7942\n",
            "Epoch 1292/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4870 - accuracy: 0.8249 - val_loss: 0.8769 - val_accuracy: 0.7875\n",
            "Epoch 1293/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5013 - accuracy: 0.8293 - val_loss: 0.6991 - val_accuracy: 0.8092\n",
            "Epoch 1294/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4721 - accuracy: 0.8345 - val_loss: 0.6839 - val_accuracy: 0.8075\n",
            "Epoch 1295/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4901 - accuracy: 0.8262 - val_loss: 0.7323 - val_accuracy: 0.7850\n",
            "Epoch 1296/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4688 - accuracy: 0.8337 - val_loss: 0.7048 - val_accuracy: 0.8017\n",
            "Epoch 1297/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.5007 - accuracy: 0.8192 - val_loss: 0.7381 - val_accuracy: 0.7742\n",
            "Epoch 1298/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4829 - accuracy: 0.8327 - val_loss: 0.6890 - val_accuracy: 0.8192\n",
            "Epoch 1299/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4847 - accuracy: 0.8316 - val_loss: 0.7012 - val_accuracy: 0.8267\n",
            "Epoch 1300/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4603 - accuracy: 0.8340 - val_loss: 0.6996 - val_accuracy: 0.7942\n",
            "Epoch 1301/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4931 - accuracy: 0.8252 - val_loss: 0.7063 - val_accuracy: 0.7933\n",
            "Epoch 1302/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4841 - accuracy: 0.8268 - val_loss: 0.6852 - val_accuracy: 0.8217\n",
            "Epoch 1303/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4828 - accuracy: 0.8303 - val_loss: 0.7661 - val_accuracy: 0.8017\n",
            "Epoch 1304/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4884 - accuracy: 0.8177 - val_loss: 0.6948 - val_accuracy: 0.8108\n",
            "Epoch 1305/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4668 - accuracy: 0.8301 - val_loss: 0.6530 - val_accuracy: 0.8183\n",
            "Epoch 1306/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4551 - accuracy: 0.8379 - val_loss: 0.7084 - val_accuracy: 0.7925\n",
            "Epoch 1307/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4773 - accuracy: 0.8284 - val_loss: 0.7012 - val_accuracy: 0.7933\n",
            "Epoch 1308/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4661 - accuracy: 0.8307 - val_loss: 0.7451 - val_accuracy: 0.7833\n",
            "Epoch 1309/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4745 - accuracy: 0.8279 - val_loss: 0.7378 - val_accuracy: 0.7933\n",
            "Epoch 1310/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4695 - accuracy: 0.8281 - val_loss: 0.7868 - val_accuracy: 0.7700\n",
            "Epoch 1311/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4802 - accuracy: 0.8334 - val_loss: 0.7233 - val_accuracy: 0.7900\n",
            "Epoch 1312/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4728 - accuracy: 0.8358 - val_loss: 0.6935 - val_accuracy: 0.8108\n",
            "Epoch 1313/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5020 - accuracy: 0.8181 - val_loss: 0.7198 - val_accuracy: 0.7958\n",
            "Epoch 1314/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4735 - accuracy: 0.8195 - val_loss: 0.7628 - val_accuracy: 0.7858\n",
            "Epoch 1315/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4683 - accuracy: 0.8266 - val_loss: 0.7170 - val_accuracy: 0.7967\n",
            "Epoch 1316/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4793 - accuracy: 0.8237 - val_loss: 0.7155 - val_accuracy: 0.8042\n",
            "Epoch 1317/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4940 - accuracy: 0.8259 - val_loss: 0.7014 - val_accuracy: 0.8133\n",
            "Epoch 1318/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4495 - accuracy: 0.8493 - val_loss: 0.7285 - val_accuracy: 0.8075\n",
            "Epoch 1319/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4936 - accuracy: 0.8230 - val_loss: 0.6990 - val_accuracy: 0.8192\n",
            "Epoch 1320/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4834 - accuracy: 0.8321 - val_loss: 0.6885 - val_accuracy: 0.8175\n",
            "Epoch 1321/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4776 - accuracy: 0.8317 - val_loss: 0.7162 - val_accuracy: 0.8000\n",
            "Epoch 1322/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4693 - accuracy: 0.8320 - val_loss: 0.7563 - val_accuracy: 0.7950\n",
            "Epoch 1323/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4744 - accuracy: 0.8348 - val_loss: 0.7418 - val_accuracy: 0.8192\n",
            "Epoch 1324/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4708 - accuracy: 0.8400 - val_loss: 0.7553 - val_accuracy: 0.7925\n",
            "Epoch 1325/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5050 - accuracy: 0.8223 - val_loss: 0.7028 - val_accuracy: 0.8083\n",
            "Epoch 1326/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4784 - accuracy: 0.8309 - val_loss: 0.7473 - val_accuracy: 0.7817\n",
            "Epoch 1327/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4828 - accuracy: 0.8267 - val_loss: 0.6900 - val_accuracy: 0.8267\n",
            "Epoch 1328/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4765 - accuracy: 0.8330 - val_loss: 0.7628 - val_accuracy: 0.7650\n",
            "Epoch 1329/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4773 - accuracy: 0.8361 - val_loss: 0.7023 - val_accuracy: 0.8142\n",
            "Epoch 1330/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4718 - accuracy: 0.8400 - val_loss: 0.8321 - val_accuracy: 0.7808\n",
            "Epoch 1331/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5172 - accuracy: 0.8312 - val_loss: 0.6799 - val_accuracy: 0.8108\n",
            "Epoch 1332/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5030 - accuracy: 0.8188 - val_loss: 0.5975 - val_accuracy: 0.8100\n",
            "Epoch 1333/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4518 - accuracy: 0.8403 - val_loss: 0.5930 - val_accuracy: 0.8258\n",
            "Epoch 1334/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4611 - accuracy: 0.8332 - val_loss: 0.6086 - val_accuracy: 0.8042\n",
            "Epoch 1335/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4809 - accuracy: 0.8307 - val_loss: 0.6168 - val_accuracy: 0.8042\n",
            "Epoch 1336/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4575 - accuracy: 0.8417 - val_loss: 0.6174 - val_accuracy: 0.8217\n",
            "Epoch 1337/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4648 - accuracy: 0.8353 - val_loss: 0.6596 - val_accuracy: 0.8125\n",
            "Epoch 1338/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4680 - accuracy: 0.8249 - val_loss: 0.5993 - val_accuracy: 0.8283\n",
            "Epoch 1339/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4658 - accuracy: 0.8428 - val_loss: 0.6017 - val_accuracy: 0.8092\n",
            "Epoch 1340/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4725 - accuracy: 0.8219 - val_loss: 0.6155 - val_accuracy: 0.8242\n",
            "Epoch 1341/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4512 - accuracy: 0.8440 - val_loss: 0.6182 - val_accuracy: 0.8075\n",
            "Epoch 1342/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4526 - accuracy: 0.8499 - val_loss: 0.6285 - val_accuracy: 0.8100\n",
            "Epoch 1343/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5118 - accuracy: 0.8181 - val_loss: 0.6307 - val_accuracy: 0.8050\n",
            "Epoch 1344/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4652 - accuracy: 0.8384 - val_loss: 0.7456 - val_accuracy: 0.8033\n",
            "Epoch 1345/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4694 - accuracy: 0.8355 - val_loss: 0.6359 - val_accuracy: 0.8142\n",
            "Epoch 1346/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4719 - accuracy: 0.8259 - val_loss: 0.6513 - val_accuracy: 0.7950\n",
            "Epoch 1347/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5038 - accuracy: 0.8209 - val_loss: 0.6280 - val_accuracy: 0.8017\n",
            "Epoch 1348/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4585 - accuracy: 0.8387 - val_loss: 0.5917 - val_accuracy: 0.8192\n",
            "Epoch 1349/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4473 - accuracy: 0.8469 - val_loss: 0.6273 - val_accuracy: 0.8033\n",
            "Epoch 1350/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4704 - accuracy: 0.8292 - val_loss: 0.6609 - val_accuracy: 0.7967\n",
            "Epoch 1351/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4747 - accuracy: 0.8300 - val_loss: 0.7210 - val_accuracy: 0.8083\n",
            "Epoch 1352/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4694 - accuracy: 0.8380 - val_loss: 0.6746 - val_accuracy: 0.7992\n",
            "Epoch 1353/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5089 - accuracy: 0.8224 - val_loss: 0.7593 - val_accuracy: 0.7933\n",
            "Epoch 1354/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4896 - accuracy: 0.8341 - val_loss: 0.6983 - val_accuracy: 0.8017\n",
            "Epoch 1355/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5080 - accuracy: 0.8313 - val_loss: 0.7383 - val_accuracy: 0.7900\n",
            "Epoch 1356/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4991 - accuracy: 0.8293 - val_loss: 0.6579 - val_accuracy: 0.7992\n",
            "Epoch 1357/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4873 - accuracy: 0.8242 - val_loss: 0.6165 - val_accuracy: 0.8183\n",
            "Epoch 1358/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4405 - accuracy: 0.8487 - val_loss: 0.6693 - val_accuracy: 0.7875\n",
            "Epoch 1359/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4713 - accuracy: 0.8371 - val_loss: 0.6649 - val_accuracy: 0.7883\n",
            "Epoch 1360/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4920 - accuracy: 0.8262 - val_loss: 0.6389 - val_accuracy: 0.8075\n",
            "Epoch 1361/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4711 - accuracy: 0.8274 - val_loss: 0.6516 - val_accuracy: 0.7983\n",
            "Epoch 1362/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4391 - accuracy: 0.8373 - val_loss: 0.6296 - val_accuracy: 0.8192\n",
            "Epoch 1363/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4458 - accuracy: 0.8381 - val_loss: 0.6239 - val_accuracy: 0.8083\n",
            "Epoch 1364/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4376 - accuracy: 0.8449 - val_loss: 0.6214 - val_accuracy: 0.8208\n",
            "Epoch 1365/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4592 - accuracy: 0.8380 - val_loss: 0.6488 - val_accuracy: 0.8058\n",
            "Epoch 1366/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4624 - accuracy: 0.8366 - val_loss: 0.7327 - val_accuracy: 0.7908\n",
            "Epoch 1367/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4796 - accuracy: 0.8305 - val_loss: 0.7090 - val_accuracy: 0.7967\n",
            "Epoch 1368/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4791 - accuracy: 0.8233 - val_loss: 0.6437 - val_accuracy: 0.8050\n",
            "Epoch 1369/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4544 - accuracy: 0.8362 - val_loss: 0.6562 - val_accuracy: 0.8133\n",
            "Epoch 1370/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4518 - accuracy: 0.8301 - val_loss: 0.6329 - val_accuracy: 0.8133\n",
            "Epoch 1371/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4312 - accuracy: 0.8487 - val_loss: 0.6369 - val_accuracy: 0.8200\n",
            "Epoch 1372/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4662 - accuracy: 0.8406 - val_loss: 0.6566 - val_accuracy: 0.7958\n",
            "Epoch 1373/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4761 - accuracy: 0.8276 - val_loss: 0.6465 - val_accuracy: 0.8117\n",
            "Epoch 1374/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4478 - accuracy: 0.8399 - val_loss: 0.6974 - val_accuracy: 0.8125\n",
            "Epoch 1375/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4741 - accuracy: 0.8395 - val_loss: 0.6399 - val_accuracy: 0.8108\n",
            "Epoch 1376/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4623 - accuracy: 0.8384 - val_loss: 0.6609 - val_accuracy: 0.7992\n",
            "Epoch 1377/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4561 - accuracy: 0.8363 - val_loss: 0.6412 - val_accuracy: 0.8067\n",
            "Epoch 1378/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4670 - accuracy: 0.8250 - val_loss: 0.6645 - val_accuracy: 0.7967\n",
            "Epoch 1379/2000\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4566 - accuracy: 0.8338 - val_loss: 0.6203 - val_accuracy: 0.8242\n",
            "Epoch 1380/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4616 - accuracy: 0.8410 - val_loss: 0.6673 - val_accuracy: 0.7933\n",
            "Epoch 1381/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4565 - accuracy: 0.8324 - val_loss: 0.6483 - val_accuracy: 0.8217\n",
            "Epoch 1382/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4535 - accuracy: 0.8384 - val_loss: 0.6280 - val_accuracy: 0.8150\n",
            "Epoch 1383/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4592 - accuracy: 0.8387 - val_loss: 0.6335 - val_accuracy: 0.8142\n",
            "Epoch 1384/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4716 - accuracy: 0.8332 - val_loss: 0.6464 - val_accuracy: 0.8133\n",
            "Epoch 1385/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4743 - accuracy: 0.8234 - val_loss: 0.6951 - val_accuracy: 0.8042\n",
            "Epoch 1386/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5027 - accuracy: 0.8273 - val_loss: 0.7972 - val_accuracy: 0.8158\n",
            "Epoch 1387/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4835 - accuracy: 0.8463 - val_loss: 0.6783 - val_accuracy: 0.8075\n",
            "Epoch 1388/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4763 - accuracy: 0.8289 - val_loss: 0.6542 - val_accuracy: 0.7992\n",
            "Epoch 1389/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4399 - accuracy: 0.8383 - val_loss: 0.6621 - val_accuracy: 0.8042\n",
            "Epoch 1390/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5038 - accuracy: 0.8146 - val_loss: 0.6614 - val_accuracy: 0.8042\n",
            "Epoch 1391/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4912 - accuracy: 0.8297 - val_loss: 0.7369 - val_accuracy: 0.7858\n",
            "Epoch 1392/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4927 - accuracy: 0.8150 - val_loss: 0.6336 - val_accuracy: 0.8217\n",
            "Epoch 1393/2000\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4641 - accuracy: 0.8347 - val_loss: 0.6571 - val_accuracy: 0.7950\n",
            "Epoch 1394/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4733 - accuracy: 0.8292 - val_loss: 0.6687 - val_accuracy: 0.7967\n",
            "Epoch 1395/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4818 - accuracy: 0.8249 - val_loss: 0.6422 - val_accuracy: 0.8083\n",
            "Epoch 1396/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4796 - accuracy: 0.8299 - val_loss: 0.7383 - val_accuracy: 0.8050\n",
            "Epoch 1397/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5012 - accuracy: 0.8251 - val_loss: 0.6580 - val_accuracy: 0.8167\n",
            "Epoch 1398/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4943 - accuracy: 0.8310 - val_loss: 0.6442 - val_accuracy: 0.8183\n",
            "Epoch 1399/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4675 - accuracy: 0.8322 - val_loss: 0.6636 - val_accuracy: 0.8058\n",
            "Epoch 1400/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4601 - accuracy: 0.8351 - val_loss: 0.6563 - val_accuracy: 0.8108\n",
            "Epoch 1401/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4497 - accuracy: 0.8422 - val_loss: 0.6778 - val_accuracy: 0.7958\n",
            "Epoch 1402/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4536 - accuracy: 0.8385 - val_loss: 0.6460 - val_accuracy: 0.8125\n",
            "Epoch 1403/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4442 - accuracy: 0.8467 - val_loss: 0.6704 - val_accuracy: 0.7958\n",
            "Epoch 1404/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4348 - accuracy: 0.8314 - val_loss: 0.6452 - val_accuracy: 0.8117\n",
            "Epoch 1405/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4825 - accuracy: 0.8386 - val_loss: 0.6757 - val_accuracy: 0.8017\n",
            "Epoch 1406/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4697 - accuracy: 0.8325 - val_loss: 0.6575 - val_accuracy: 0.8083\n",
            "Epoch 1407/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.8283 - val_loss: 0.7149 - val_accuracy: 0.8000\n",
            "Epoch 1408/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4591 - accuracy: 0.8466 - val_loss: 0.6687 - val_accuracy: 0.8133\n",
            "Epoch 1409/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4511 - accuracy: 0.8385 - val_loss: 0.6826 - val_accuracy: 0.8108\n",
            "Epoch 1410/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4667 - accuracy: 0.8339 - val_loss: 0.6679 - val_accuracy: 0.8058\n",
            "Epoch 1411/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4517 - accuracy: 0.8365 - val_loss: 0.7685 - val_accuracy: 0.7850\n",
            "Epoch 1412/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4723 - accuracy: 0.8363 - val_loss: 0.6686 - val_accuracy: 0.8158\n",
            "Epoch 1413/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4539 - accuracy: 0.8321 - val_loss: 0.7729 - val_accuracy: 0.7942\n",
            "Epoch 1414/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4810 - accuracy: 0.8250 - val_loss: 0.6511 - val_accuracy: 0.8167\n",
            "Epoch 1415/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4376 - accuracy: 0.8404 - val_loss: 1.0024 - val_accuracy: 0.8117\n",
            "Epoch 1416/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5799 - accuracy: 0.8351 - val_loss: 0.7865 - val_accuracy: 0.8042\n",
            "Epoch 1417/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4641 - accuracy: 0.8397 - val_loss: 0.6228 - val_accuracy: 0.8100\n",
            "Epoch 1418/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4868 - accuracy: 0.8323 - val_loss: 0.5974 - val_accuracy: 0.8333\n",
            "Epoch 1419/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4440 - accuracy: 0.8431 - val_loss: 0.6269 - val_accuracy: 0.8092\n",
            "Epoch 1420/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4790 - accuracy: 0.8286 - val_loss: 0.6014 - val_accuracy: 0.8117\n",
            "Epoch 1421/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4537 - accuracy: 0.8372 - val_loss: 0.7021 - val_accuracy: 0.7733\n",
            "Epoch 1422/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5123 - accuracy: 0.8229 - val_loss: 0.6337 - val_accuracy: 0.8117\n",
            "Epoch 1423/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4584 - accuracy: 0.8444 - val_loss: 0.6274 - val_accuracy: 0.8008\n",
            "Epoch 1424/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4386 - accuracy: 0.8457 - val_loss: 0.6255 - val_accuracy: 0.7950\n",
            "Epoch 1425/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4818 - accuracy: 0.8277 - val_loss: 0.6320 - val_accuracy: 0.8142\n",
            "Epoch 1426/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4947 - accuracy: 0.8202 - val_loss: 0.5767 - val_accuracy: 0.8225\n",
            "Epoch 1427/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4579 - accuracy: 0.8417 - val_loss: 0.6286 - val_accuracy: 0.8067\n",
            "Epoch 1428/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4754 - accuracy: 0.8287 - val_loss: 0.6358 - val_accuracy: 0.8008\n",
            "Epoch 1429/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4427 - accuracy: 0.8499 - val_loss: 0.6098 - val_accuracy: 0.8283\n",
            "Epoch 1430/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4667 - accuracy: 0.8338 - val_loss: 0.6047 - val_accuracy: 0.8250\n",
            "Epoch 1431/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4495 - accuracy: 0.8398 - val_loss: 0.6026 - val_accuracy: 0.8208\n",
            "Epoch 1432/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4486 - accuracy: 0.8431 - val_loss: 0.5980 - val_accuracy: 0.8158\n",
            "Epoch 1433/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4673 - accuracy: 0.8301 - val_loss: 0.6514 - val_accuracy: 0.8042\n",
            "Epoch 1434/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4537 - accuracy: 0.8352 - val_loss: 0.5986 - val_accuracy: 0.8225\n",
            "Epoch 1435/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4451 - accuracy: 0.8451 - val_loss: 0.6231 - val_accuracy: 0.8067\n",
            "Epoch 1436/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4466 - accuracy: 0.8447 - val_loss: 0.6391 - val_accuracy: 0.7875\n",
            "Epoch 1437/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4876 - accuracy: 0.8325 - val_loss: 0.6140 - val_accuracy: 0.8117\n",
            "Epoch 1438/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4414 - accuracy: 0.8414 - val_loss: 0.6491 - val_accuracy: 0.7942\n",
            "Epoch 1439/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4643 - accuracy: 0.8325 - val_loss: 0.6733 - val_accuracy: 0.8150\n",
            "Epoch 1440/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4783 - accuracy: 0.8301 - val_loss: 0.6410 - val_accuracy: 0.8042\n",
            "Epoch 1441/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5152 - accuracy: 0.8179 - val_loss: 0.6479 - val_accuracy: 0.7942\n",
            "Epoch 1442/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4720 - accuracy: 0.8243 - val_loss: 0.6469 - val_accuracy: 0.7942\n",
            "Epoch 1443/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4589 - accuracy: 0.8325 - val_loss: 0.6127 - val_accuracy: 0.8133\n",
            "Epoch 1444/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4952 - accuracy: 0.8300 - val_loss: 0.6678 - val_accuracy: 0.7825\n",
            "Epoch 1445/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4879 - accuracy: 0.8240 - val_loss: 0.6772 - val_accuracy: 0.7900\n",
            "Epoch 1446/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.8272 - val_loss: 0.6123 - val_accuracy: 0.8150\n",
            "Epoch 1447/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4730 - accuracy: 0.8323 - val_loss: 0.6089 - val_accuracy: 0.8050\n",
            "Epoch 1448/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4556 - accuracy: 0.8350 - val_loss: 0.5912 - val_accuracy: 0.8258\n",
            "Epoch 1449/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4401 - accuracy: 0.8491 - val_loss: 0.6512 - val_accuracy: 0.7992\n",
            "Epoch 1450/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4692 - accuracy: 0.8267 - val_loss: 0.6294 - val_accuracy: 0.8117\n",
            "Epoch 1451/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.4495 - accuracy: 0.8405 - val_loss: 0.6155 - val_accuracy: 0.8192\n",
            "Epoch 1452/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4478 - accuracy: 0.8462 - val_loss: 0.6506 - val_accuracy: 0.7875\n",
            "Epoch 1453/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4776 - accuracy: 0.8308 - val_loss: 0.6145 - val_accuracy: 0.8133\n",
            "Epoch 1454/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4380 - accuracy: 0.8525 - val_loss: 0.6427 - val_accuracy: 0.8167\n",
            "Epoch 1455/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4372 - accuracy: 0.8456 - val_loss: 0.6586 - val_accuracy: 0.7892\n",
            "Epoch 1456/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4333 - accuracy: 0.8509 - val_loss: 0.6182 - val_accuracy: 0.8183\n",
            "Epoch 1457/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4642 - accuracy: 0.8346 - val_loss: 0.6251 - val_accuracy: 0.8092\n",
            "Epoch 1458/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4890 - accuracy: 0.8199 - val_loss: 0.6139 - val_accuracy: 0.8167\n",
            "Epoch 1459/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4341 - accuracy: 0.8497 - val_loss: 0.6577 - val_accuracy: 0.7967\n",
            "Epoch 1460/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4682 - accuracy: 0.8335 - val_loss: 0.6279 - val_accuracy: 0.7975\n",
            "Epoch 1461/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4962 - accuracy: 0.8135 - val_loss: 0.6192 - val_accuracy: 0.8100\n",
            "Epoch 1462/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4526 - accuracy: 0.8446 - val_loss: 0.6138 - val_accuracy: 0.8233\n",
            "Epoch 1463/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4391 - accuracy: 0.8464 - val_loss: 0.6357 - val_accuracy: 0.7958\n",
            "Epoch 1464/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4639 - accuracy: 0.8311 - val_loss: 0.6503 - val_accuracy: 0.7908\n",
            "Epoch 1465/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5011 - accuracy: 0.8208 - val_loss: 0.6639 - val_accuracy: 0.8017\n",
            "Epoch 1466/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4593 - accuracy: 0.8395 - val_loss: 0.6122 - val_accuracy: 0.8225\n",
            "Epoch 1467/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4416 - accuracy: 0.8393 - val_loss: 0.6264 - val_accuracy: 0.8000\n",
            "Epoch 1468/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4471 - accuracy: 0.8463 - val_loss: 0.6226 - val_accuracy: 0.8125\n",
            "Epoch 1469/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4470 - accuracy: 0.8364 - val_loss: 0.6648 - val_accuracy: 0.7983\n",
            "Epoch 1470/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4697 - accuracy: 0.8324 - val_loss: 0.6420 - val_accuracy: 0.7983\n",
            "Epoch 1471/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4748 - accuracy: 0.8250 - val_loss: 0.6655 - val_accuracy: 0.8075\n",
            "Epoch 1472/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4764 - accuracy: 0.8352 - val_loss: 0.6353 - val_accuracy: 0.8017\n",
            "Epoch 1473/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4581 - accuracy: 0.8350 - val_loss: 0.5968 - val_accuracy: 0.8233\n",
            "Epoch 1474/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4415 - accuracy: 0.8388 - val_loss: 0.6313 - val_accuracy: 0.8233\n",
            "Epoch 1475/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4734 - accuracy: 0.8369 - val_loss: 0.5871 - val_accuracy: 0.8308\n",
            "Epoch 1476/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.4295 - accuracy: 0.8385 - val_loss: 0.6006 - val_accuracy: 0.8192\n",
            "Epoch 1477/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4656 - accuracy: 0.8276 - val_loss: 0.6157 - val_accuracy: 0.8092\n",
            "Epoch 1478/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4465 - accuracy: 0.8399 - val_loss: 0.5847 - val_accuracy: 0.8308\n",
            "Epoch 1479/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4451 - accuracy: 0.8410 - val_loss: 0.6193 - val_accuracy: 0.8067\n",
            "Epoch 1480/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4815 - accuracy: 0.8366 - val_loss: 0.6335 - val_accuracy: 0.8083\n",
            "Epoch 1481/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4333 - accuracy: 0.8552 - val_loss: 0.5963 - val_accuracy: 0.8200\n",
            "Epoch 1482/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4484 - accuracy: 0.8400 - val_loss: 0.6803 - val_accuracy: 0.8042\n",
            "Epoch 1483/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5098 - accuracy: 0.8360 - val_loss: 0.6899 - val_accuracy: 0.7875\n",
            "Epoch 1484/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5076 - accuracy: 0.8245 - val_loss: 0.6689 - val_accuracy: 0.8025\n",
            "Epoch 1485/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4664 - accuracy: 0.8374 - val_loss: 0.6292 - val_accuracy: 0.8358\n",
            "Epoch 1486/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4832 - accuracy: 0.8321 - val_loss: 0.6376 - val_accuracy: 0.8183\n",
            "Epoch 1487/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4641 - accuracy: 0.8333 - val_loss: 0.6411 - val_accuracy: 0.7975\n",
            "Epoch 1488/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4389 - accuracy: 0.8459 - val_loss: 0.5997 - val_accuracy: 0.8258\n",
            "Epoch 1489/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4513 - accuracy: 0.8392 - val_loss: 0.6371 - val_accuracy: 0.8000\n",
            "Epoch 1490/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4661 - accuracy: 0.8287 - val_loss: 0.6224 - val_accuracy: 0.8133\n",
            "Epoch 1491/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4849 - accuracy: 0.8308 - val_loss: 0.6531 - val_accuracy: 0.7942\n",
            "Epoch 1492/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4551 - accuracy: 0.8392 - val_loss: 0.6789 - val_accuracy: 0.7950\n",
            "Epoch 1493/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4618 - accuracy: 0.8377 - val_loss: 0.6383 - val_accuracy: 0.8117\n",
            "Epoch 1494/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4500 - accuracy: 0.8426 - val_loss: 0.6251 - val_accuracy: 0.7950\n",
            "Epoch 1495/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4447 - accuracy: 0.8331 - val_loss: 0.6461 - val_accuracy: 0.7858\n",
            "Epoch 1496/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4629 - accuracy: 0.8244 - val_loss: 0.6284 - val_accuracy: 0.8125\n",
            "Epoch 1497/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4756 - accuracy: 0.8280 - val_loss: 0.6774 - val_accuracy: 0.8008\n",
            "Epoch 1498/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4675 - accuracy: 0.8376 - val_loss: 0.6279 - val_accuracy: 0.8100\n",
            "Epoch 1499/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4454 - accuracy: 0.8379 - val_loss: 0.6139 - val_accuracy: 0.8108\n",
            "Epoch 1500/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4329 - accuracy: 0.8462 - val_loss: 0.6036 - val_accuracy: 0.8167\n",
            "Epoch 1501/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4569 - accuracy: 0.8366 - val_loss: 0.5921 - val_accuracy: 0.8183\n",
            "Epoch 1502/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4428 - accuracy: 0.8425 - val_loss: 0.6199 - val_accuracy: 0.8125\n",
            "Epoch 1503/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4386 - accuracy: 0.8470 - val_loss: 0.6497 - val_accuracy: 0.7958\n",
            "Epoch 1504/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4856 - accuracy: 0.8226 - val_loss: 0.6649 - val_accuracy: 0.8117\n",
            "Epoch 1505/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4605 - accuracy: 0.8338 - val_loss: 0.6465 - val_accuracy: 0.8167\n",
            "Epoch 1506/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4951 - accuracy: 0.8259 - val_loss: 0.6261 - val_accuracy: 0.8208\n",
            "Epoch 1507/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4414 - accuracy: 0.8379 - val_loss: 0.7396 - val_accuracy: 0.7817\n",
            "Epoch 1508/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5158 - accuracy: 0.8204 - val_loss: 0.7227 - val_accuracy: 0.8058\n",
            "Epoch 1509/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4572 - accuracy: 0.8423 - val_loss: 0.6471 - val_accuracy: 0.8233\n",
            "Epoch 1510/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4567 - accuracy: 0.8364 - val_loss: 0.6263 - val_accuracy: 0.8375\n",
            "Epoch 1511/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4674 - accuracy: 0.8343 - val_loss: 0.6668 - val_accuracy: 0.8158\n",
            "Epoch 1512/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4613 - accuracy: 0.8362 - val_loss: 0.6529 - val_accuracy: 0.8158\n",
            "Epoch 1513/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4721 - accuracy: 0.8330 - val_loss: 0.6405 - val_accuracy: 0.8067\n",
            "Epoch 1514/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4617 - accuracy: 0.8300 - val_loss: 0.6676 - val_accuracy: 0.8008\n",
            "Epoch 1515/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4640 - accuracy: 0.8372 - val_loss: 0.6455 - val_accuracy: 0.8133\n",
            "Epoch 1516/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4511 - accuracy: 0.8356 - val_loss: 0.6982 - val_accuracy: 0.7908\n",
            "Epoch 1517/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4592 - accuracy: 0.8348 - val_loss: 0.6453 - val_accuracy: 0.8142\n",
            "Epoch 1518/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4385 - accuracy: 0.8432 - val_loss: 0.7172 - val_accuracy: 0.7967\n",
            "Epoch 1519/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.4899 - accuracy: 0.8277 - val_loss: 0.6528 - val_accuracy: 0.7967\n",
            "Epoch 1520/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4353 - accuracy: 0.8405 - val_loss: 0.7149 - val_accuracy: 0.8042\n",
            "Epoch 1521/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4777 - accuracy: 0.8333 - val_loss: 0.7016 - val_accuracy: 0.7917\n",
            "Epoch 1522/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4953 - accuracy: 0.8210 - val_loss: 0.6909 - val_accuracy: 0.7942\n",
            "Epoch 1523/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4751 - accuracy: 0.8308 - val_loss: 0.6897 - val_accuracy: 0.7933\n",
            "Epoch 1524/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4587 - accuracy: 0.8312 - val_loss: 0.6993 - val_accuracy: 0.7917\n",
            "Epoch 1525/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4533 - accuracy: 0.8366 - val_loss: 0.6578 - val_accuracy: 0.8233\n",
            "Epoch 1526/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4754 - accuracy: 0.8365 - val_loss: 0.6802 - val_accuracy: 0.8008\n",
            "Epoch 1527/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4488 - accuracy: 0.8390 - val_loss: 0.6867 - val_accuracy: 0.8058\n",
            "Epoch 1528/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4667 - accuracy: 0.8346 - val_loss: 0.7307 - val_accuracy: 0.8217\n",
            "Epoch 1529/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4659 - accuracy: 0.8396 - val_loss: 0.7275 - val_accuracy: 0.7917\n",
            "Epoch 1530/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4520 - accuracy: 0.8387 - val_loss: 0.6439 - val_accuracy: 0.8208\n",
            "Epoch 1531/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4215 - accuracy: 0.8536 - val_loss: 0.7110 - val_accuracy: 0.7950\n",
            "Epoch 1532/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4834 - accuracy: 0.8205 - val_loss: 0.7008 - val_accuracy: 0.7925\n",
            "Epoch 1533/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4782 - accuracy: 0.8350 - val_loss: 0.6738 - val_accuracy: 0.8033\n",
            "Epoch 1534/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4574 - accuracy: 0.8411 - val_loss: 0.6254 - val_accuracy: 0.8308\n",
            "Epoch 1535/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4428 - accuracy: 0.8460 - val_loss: 0.6440 - val_accuracy: 0.8250\n",
            "Epoch 1536/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4453 - accuracy: 0.8432 - val_loss: 0.6836 - val_accuracy: 0.7942\n",
            "Epoch 1537/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4359 - accuracy: 0.8371 - val_loss: 0.6396 - val_accuracy: 0.8200\n",
            "Epoch 1538/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4484 - accuracy: 0.8328 - val_loss: 0.6855 - val_accuracy: 0.7983\n",
            "Epoch 1539/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5099 - accuracy: 0.8181 - val_loss: 0.7066 - val_accuracy: 0.7867\n",
            "Epoch 1540/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4606 - accuracy: 0.8268 - val_loss: 0.6936 - val_accuracy: 0.7975\n",
            "Epoch 1541/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4421 - accuracy: 0.8407 - val_loss: 0.6768 - val_accuracy: 0.8025\n",
            "Epoch 1542/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4628 - accuracy: 0.8389 - val_loss: 0.7416 - val_accuracy: 0.7992\n",
            "Epoch 1543/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4957 - accuracy: 0.8256 - val_loss: 0.7405 - val_accuracy: 0.7917\n",
            "Epoch 1544/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4849 - accuracy: 0.8310 - val_loss: 0.7209 - val_accuracy: 0.8108\n",
            "Epoch 1545/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4663 - accuracy: 0.8284 - val_loss: 0.7295 - val_accuracy: 0.7967\n",
            "Epoch 1546/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4559 - accuracy: 0.8361 - val_loss: 0.6893 - val_accuracy: 0.7992\n",
            "Epoch 1547/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4628 - accuracy: 0.8332 - val_loss: 0.6895 - val_accuracy: 0.8150\n",
            "Epoch 1548/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4367 - accuracy: 0.8510 - val_loss: 0.6695 - val_accuracy: 0.8192\n",
            "Epoch 1549/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4445 - accuracy: 0.8448 - val_loss: 0.6711 - val_accuracy: 0.8117\n",
            "Epoch 1550/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4413 - accuracy: 0.8554 - val_loss: 0.7077 - val_accuracy: 0.8067\n",
            "Epoch 1551/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4602 - accuracy: 0.8394 - val_loss: 0.6968 - val_accuracy: 0.8083\n",
            "Epoch 1552/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4795 - accuracy: 0.8365 - val_loss: 0.6915 - val_accuracy: 0.8100\n",
            "Epoch 1553/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4418 - accuracy: 0.8419 - val_loss: 0.7020 - val_accuracy: 0.8183\n",
            "Epoch 1554/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4423 - accuracy: 0.8349 - val_loss: 0.7745 - val_accuracy: 0.7942\n",
            "Epoch 1555/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4915 - accuracy: 0.8268 - val_loss: 0.7218 - val_accuracy: 0.7925\n",
            "Epoch 1556/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4596 - accuracy: 0.8265 - val_loss: 0.7466 - val_accuracy: 0.8025\n",
            "Epoch 1557/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4763 - accuracy: 0.8375 - val_loss: 0.6906 - val_accuracy: 0.8042\n",
            "Epoch 1558/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4523 - accuracy: 0.8436 - val_loss: 0.6920 - val_accuracy: 0.8183\n",
            "Epoch 1559/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4392 - accuracy: 0.8451 - val_loss: 0.7101 - val_accuracy: 0.8067\n",
            "Epoch 1560/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4622 - accuracy: 0.8317 - val_loss: 0.7269 - val_accuracy: 0.8033\n",
            "Epoch 1561/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4477 - accuracy: 0.8444 - val_loss: 0.7324 - val_accuracy: 0.8025\n",
            "Epoch 1562/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4898 - accuracy: 0.8205 - val_loss: 0.7989 - val_accuracy: 0.8200\n",
            "Epoch 1563/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5528 - accuracy: 0.8295 - val_loss: 0.7400 - val_accuracy: 0.8192\n",
            "Epoch 1564/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4822 - accuracy: 0.8360 - val_loss: 0.7020 - val_accuracy: 0.8100\n",
            "Epoch 1565/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4426 - accuracy: 0.8434 - val_loss: 0.6882 - val_accuracy: 0.7992\n",
            "Epoch 1566/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4467 - accuracy: 0.8360 - val_loss: 0.6770 - val_accuracy: 0.8108\n",
            "Epoch 1567/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4524 - accuracy: 0.8358 - val_loss: 0.6993 - val_accuracy: 0.8000\n",
            "Epoch 1568/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4424 - accuracy: 0.8476 - val_loss: 0.6792 - val_accuracy: 0.8175\n",
            "Epoch 1569/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4333 - accuracy: 0.8417 - val_loss: 0.7142 - val_accuracy: 0.8042\n",
            "Epoch 1570/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4542 - accuracy: 0.8327 - val_loss: 0.7348 - val_accuracy: 0.7992\n",
            "Epoch 1571/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4564 - accuracy: 0.8324 - val_loss: 0.7191 - val_accuracy: 0.8000\n",
            "Epoch 1572/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4285 - accuracy: 0.8515 - val_loss: 0.7169 - val_accuracy: 0.7892\n",
            "Epoch 1573/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4546 - accuracy: 0.8381 - val_loss: 0.7044 - val_accuracy: 0.8067\n",
            "Epoch 1574/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4186 - accuracy: 0.8489 - val_loss: 0.7289 - val_accuracy: 0.7967\n",
            "Epoch 1575/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4599 - accuracy: 0.8418 - val_loss: 0.7291 - val_accuracy: 0.8067\n",
            "Epoch 1576/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4434 - accuracy: 0.8398 - val_loss: 0.7199 - val_accuracy: 0.7992\n",
            "Epoch 1577/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.4722 - accuracy: 0.8247 - val_loss: 0.7321 - val_accuracy: 0.8042\n",
            "Epoch 1578/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4431 - accuracy: 0.8380 - val_loss: 0.7402 - val_accuracy: 0.7983\n",
            "Epoch 1579/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4659 - accuracy: 0.8397 - val_loss: 0.7466 - val_accuracy: 0.7958\n",
            "Epoch 1580/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.4380 - accuracy: 0.8396 - val_loss: 0.7133 - val_accuracy: 0.8267\n",
            "Epoch 1581/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4596 - accuracy: 0.8390 - val_loss: 0.7231 - val_accuracy: 0.8117\n",
            "Epoch 1582/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4357 - accuracy: 0.8463 - val_loss: 0.7786 - val_accuracy: 0.7825\n",
            "Epoch 1583/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4600 - accuracy: 0.8289 - val_loss: 0.7672 - val_accuracy: 0.8117\n",
            "Epoch 1584/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4579 - accuracy: 0.8341 - val_loss: 0.7334 - val_accuracy: 0.8167\n",
            "Epoch 1585/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4406 - accuracy: 0.8398 - val_loss: 0.7290 - val_accuracy: 0.8258\n",
            "Epoch 1586/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4682 - accuracy: 0.8314 - val_loss: 0.7561 - val_accuracy: 0.7967\n",
            "Epoch 1587/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4568 - accuracy: 0.8349 - val_loss: 0.7388 - val_accuracy: 0.8067\n",
            "Epoch 1588/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4490 - accuracy: 0.8336 - val_loss: 0.7039 - val_accuracy: 0.8092\n",
            "Epoch 1589/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4508 - accuracy: 0.8364 - val_loss: 0.7143 - val_accuracy: 0.8175\n",
            "Epoch 1590/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4575 - accuracy: 0.8362 - val_loss: 0.7342 - val_accuracy: 0.8275\n",
            "Epoch 1591/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4381 - accuracy: 0.8457 - val_loss: 0.7379 - val_accuracy: 0.8258\n",
            "Epoch 1592/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4368 - accuracy: 0.8436 - val_loss: 0.7346 - val_accuracy: 0.8133\n",
            "Epoch 1593/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4345 - accuracy: 0.8410 - val_loss: 0.7505 - val_accuracy: 0.8217\n",
            "Epoch 1594/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4459 - accuracy: 0.8376 - val_loss: 0.7275 - val_accuracy: 0.8158\n",
            "Epoch 1595/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4321 - accuracy: 0.8480 - val_loss: 0.7592 - val_accuracy: 0.8008\n",
            "Epoch 1596/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4596 - accuracy: 0.8341 - val_loss: 0.7405 - val_accuracy: 0.8233\n",
            "Epoch 1597/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4374 - accuracy: 0.8497 - val_loss: 0.7362 - val_accuracy: 0.8158\n",
            "Epoch 1598/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4847 - accuracy: 0.8265 - val_loss: 0.7853 - val_accuracy: 0.8042\n",
            "Epoch 1599/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4612 - accuracy: 0.8334 - val_loss: 0.7604 - val_accuracy: 0.8100\n",
            "Epoch 1600/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4271 - accuracy: 0.8543 - val_loss: 0.7723 - val_accuracy: 0.7958\n",
            "Epoch 1601/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4530 - accuracy: 0.8421 - val_loss: 0.7885 - val_accuracy: 0.7858\n",
            "Epoch 1602/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4629 - accuracy: 0.8312 - val_loss: 0.6242 - val_accuracy: 0.8175\n",
            "Epoch 1603/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5029 - accuracy: 0.8305 - val_loss: 0.8324 - val_accuracy: 0.7892\n",
            "Epoch 1604/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4812 - accuracy: 0.8350 - val_loss: 0.6802 - val_accuracy: 0.7892\n",
            "Epoch 1605/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4676 - accuracy: 0.8346 - val_loss: 0.6884 - val_accuracy: 0.7892\n",
            "Epoch 1606/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4756 - accuracy: 0.8267 - val_loss: 0.6391 - val_accuracy: 0.8042\n",
            "Epoch 1607/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4431 - accuracy: 0.8400 - val_loss: 0.5943 - val_accuracy: 0.8233\n",
            "Epoch 1608/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4358 - accuracy: 0.8365 - val_loss: 0.6303 - val_accuracy: 0.8142\n",
            "Epoch 1609/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4586 - accuracy: 0.8340 - val_loss: 0.6213 - val_accuracy: 0.8117\n",
            "Epoch 1610/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4503 - accuracy: 0.8322 - val_loss: 0.6448 - val_accuracy: 0.8142\n",
            "Epoch 1611/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4297 - accuracy: 0.8385 - val_loss: 0.6567 - val_accuracy: 0.7883\n",
            "Epoch 1612/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4251 - accuracy: 0.8412 - val_loss: 0.6525 - val_accuracy: 0.7967\n",
            "Epoch 1613/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4786 - accuracy: 0.8292 - val_loss: 0.6725 - val_accuracy: 0.7800\n",
            "Epoch 1614/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4556 - accuracy: 0.8457 - val_loss: 0.6315 - val_accuracy: 0.8092\n",
            "Epoch 1615/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4372 - accuracy: 0.8456 - val_loss: 0.6015 - val_accuracy: 0.8300\n",
            "Epoch 1616/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4371 - accuracy: 0.8500 - val_loss: 0.6320 - val_accuracy: 0.7975\n",
            "Epoch 1617/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4250 - accuracy: 0.8536 - val_loss: 0.6218 - val_accuracy: 0.8208\n",
            "Epoch 1618/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4426 - accuracy: 0.8471 - val_loss: 0.6735 - val_accuracy: 0.8017\n",
            "Epoch 1619/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5051 - accuracy: 0.8196 - val_loss: 0.6574 - val_accuracy: 0.8008\n",
            "Epoch 1620/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4516 - accuracy: 0.8377 - val_loss: 0.6335 - val_accuracy: 0.8133\n",
            "Epoch 1621/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4581 - accuracy: 0.8278 - val_loss: 0.6489 - val_accuracy: 0.7958\n",
            "Epoch 1622/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4722 - accuracy: 0.8274 - val_loss: 0.6803 - val_accuracy: 0.7950\n",
            "Epoch 1623/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4374 - accuracy: 0.8429 - val_loss: 0.6277 - val_accuracy: 0.8133\n",
            "Epoch 1624/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4226 - accuracy: 0.8509 - val_loss: 0.6122 - val_accuracy: 0.8208\n",
            "Epoch 1625/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4542 - accuracy: 0.8329 - val_loss: 0.6492 - val_accuracy: 0.8258\n",
            "Epoch 1626/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4417 - accuracy: 0.8446 - val_loss: 0.6508 - val_accuracy: 0.8108\n",
            "Epoch 1627/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4562 - accuracy: 0.8350 - val_loss: 0.6433 - val_accuracy: 0.8125\n",
            "Epoch 1628/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4441 - accuracy: 0.8445 - val_loss: 0.6421 - val_accuracy: 0.8108\n",
            "Epoch 1629/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4642 - accuracy: 0.8320 - val_loss: 0.6350 - val_accuracy: 0.8217\n",
            "Epoch 1630/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4194 - accuracy: 0.8511 - val_loss: 0.6126 - val_accuracy: 0.8192\n",
            "Epoch 1631/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4333 - accuracy: 0.8392 - val_loss: 0.6089 - val_accuracy: 0.8308\n",
            "Epoch 1632/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4341 - accuracy: 0.8489 - val_loss: 0.6828 - val_accuracy: 0.7983\n",
            "Epoch 1633/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.4670 - accuracy: 0.8368 - val_loss: 0.6367 - val_accuracy: 0.8208\n",
            "Epoch 1634/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5164 - accuracy: 0.8387 - val_loss: 0.6745 - val_accuracy: 0.8125\n",
            "Epoch 1635/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4355 - accuracy: 0.8349 - val_loss: 0.6684 - val_accuracy: 0.8200\n",
            "Epoch 1636/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4436 - accuracy: 0.8524 - val_loss: 0.6591 - val_accuracy: 0.7917\n",
            "Epoch 1637/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4560 - accuracy: 0.8317 - val_loss: 0.6699 - val_accuracy: 0.7917\n",
            "Epoch 1638/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4442 - accuracy: 0.8357 - val_loss: 0.6207 - val_accuracy: 0.8275\n",
            "Epoch 1639/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4344 - accuracy: 0.8447 - val_loss: 0.6376 - val_accuracy: 0.8333\n",
            "Epoch 1640/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4332 - accuracy: 0.8550 - val_loss: 0.6363 - val_accuracy: 0.8275\n",
            "Epoch 1641/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4479 - accuracy: 0.8327 - val_loss: 0.6663 - val_accuracy: 0.8142\n",
            "Epoch 1642/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4414 - accuracy: 0.8429 - val_loss: 0.6316 - val_accuracy: 0.8308\n",
            "Epoch 1643/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4469 - accuracy: 0.8357 - val_loss: 0.6363 - val_accuracy: 0.8208\n",
            "Epoch 1644/2000\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 0.4651 - accuracy: 0.8354 - val_loss: 0.7645 - val_accuracy: 0.7825\n",
            "Epoch 1645/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4783 - accuracy: 0.8418 - val_loss: 0.6570 - val_accuracy: 0.8050\n",
            "Epoch 1646/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4418 - accuracy: 0.8395 - val_loss: 0.6782 - val_accuracy: 0.8000\n",
            "Epoch 1647/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4474 - accuracy: 0.8489 - val_loss: 0.6557 - val_accuracy: 0.8100\n",
            "Epoch 1648/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4499 - accuracy: 0.8357 - val_loss: 0.7221 - val_accuracy: 0.7942\n",
            "Epoch 1649/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4522 - accuracy: 0.8353 - val_loss: 0.6054 - val_accuracy: 0.8275\n",
            "Epoch 1650/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4116 - accuracy: 0.8563 - val_loss: 0.6599 - val_accuracy: 0.7975\n",
            "Epoch 1651/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4272 - accuracy: 0.8498 - val_loss: 0.6425 - val_accuracy: 0.8150\n",
            "Epoch 1652/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4496 - accuracy: 0.8425 - val_loss: 0.7163 - val_accuracy: 0.8108\n",
            "Epoch 1653/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4308 - accuracy: 0.8504 - val_loss: 0.6569 - val_accuracy: 0.8092\n",
            "Epoch 1654/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4537 - accuracy: 0.8318 - val_loss: 0.6520 - val_accuracy: 0.8067\n",
            "Epoch 1655/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4979 - accuracy: 0.8271 - val_loss: 0.6834 - val_accuracy: 0.7950\n",
            "Epoch 1656/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4574 - accuracy: 0.8364 - val_loss: 0.6653 - val_accuracy: 0.8175\n",
            "Epoch 1657/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4533 - accuracy: 0.8313 - val_loss: 0.6319 - val_accuracy: 0.8233\n",
            "Epoch 1658/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4569 - accuracy: 0.8426 - val_loss: 0.7141 - val_accuracy: 0.8067\n",
            "Epoch 1659/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4528 - accuracy: 0.8470 - val_loss: 0.6509 - val_accuracy: 0.8108\n",
            "Epoch 1660/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4432 - accuracy: 0.8406 - val_loss: 0.6427 - val_accuracy: 0.8258\n",
            "Epoch 1661/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4474 - accuracy: 0.8379 - val_loss: 0.6495 - val_accuracy: 0.8158\n",
            "Epoch 1662/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4476 - accuracy: 0.8344 - val_loss: 0.6869 - val_accuracy: 0.7775\n",
            "Epoch 1663/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4582 - accuracy: 0.8332 - val_loss: 0.6920 - val_accuracy: 0.7975\n",
            "Epoch 1664/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4743 - accuracy: 0.8260 - val_loss: 0.6425 - val_accuracy: 0.8208\n",
            "Epoch 1665/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4142 - accuracy: 0.8528 - val_loss: 0.6438 - val_accuracy: 0.8225\n",
            "Epoch 1666/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4291 - accuracy: 0.8523 - val_loss: 0.6266 - val_accuracy: 0.8300\n",
            "Epoch 1667/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4330 - accuracy: 0.8366 - val_loss: 0.7804 - val_accuracy: 0.7933\n",
            "Epoch 1668/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4674 - accuracy: 0.8356 - val_loss: 0.7003 - val_accuracy: 0.8242\n",
            "Epoch 1669/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4498 - accuracy: 0.8331 - val_loss: 0.6952 - val_accuracy: 0.8017\n",
            "Epoch 1670/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4476 - accuracy: 0.8436 - val_loss: 0.6876 - val_accuracy: 0.8025\n",
            "Epoch 1671/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4577 - accuracy: 0.8475 - val_loss: 0.7200 - val_accuracy: 0.7958\n",
            "Epoch 1672/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4417 - accuracy: 0.8360 - val_loss: 0.6573 - val_accuracy: 0.8225\n",
            "Epoch 1673/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4304 - accuracy: 0.8486 - val_loss: 0.6466 - val_accuracy: 0.8233\n",
            "Epoch 1674/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4478 - accuracy: 0.8412 - val_loss: 0.6482 - val_accuracy: 0.8233\n",
            "Epoch 1675/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4521 - accuracy: 0.8418 - val_loss: 0.6555 - val_accuracy: 0.8117\n",
            "Epoch 1676/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4660 - accuracy: 0.8358 - val_loss: 0.6870 - val_accuracy: 0.8033\n",
            "Epoch 1677/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4370 - accuracy: 0.8440 - val_loss: 0.6897 - val_accuracy: 0.8133\n",
            "Epoch 1678/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4594 - accuracy: 0.8277 - val_loss: 0.6768 - val_accuracy: 0.8175\n",
            "Epoch 1679/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4595 - accuracy: 0.8248 - val_loss: 0.6505 - val_accuracy: 0.8175\n",
            "Epoch 1680/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4196 - accuracy: 0.8541 - val_loss: 0.6604 - val_accuracy: 0.8133\n",
            "Epoch 1681/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4212 - accuracy: 0.8543 - val_loss: 0.6544 - val_accuracy: 0.8125\n",
            "Epoch 1682/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4505 - accuracy: 0.8453 - val_loss: 0.6757 - val_accuracy: 0.8217\n",
            "Epoch 1683/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4245 - accuracy: 0.8469 - val_loss: 0.6977 - val_accuracy: 0.8083\n",
            "Epoch 1684/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4379 - accuracy: 0.8387 - val_loss: 0.6945 - val_accuracy: 0.8250\n",
            "Epoch 1685/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4690 - accuracy: 0.8398 - val_loss: 0.7590 - val_accuracy: 0.8200\n",
            "Epoch 1686/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4761 - accuracy: 0.8307 - val_loss: 0.6763 - val_accuracy: 0.8225\n",
            "Epoch 1687/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4480 - accuracy: 0.8388 - val_loss: 0.7081 - val_accuracy: 0.8250\n",
            "Epoch 1688/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4491 - accuracy: 0.8417 - val_loss: 0.6783 - val_accuracy: 0.8217\n",
            "Epoch 1689/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4446 - accuracy: 0.8383 - val_loss: 0.6680 - val_accuracy: 0.8267\n",
            "Epoch 1690/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4133 - accuracy: 0.8465 - val_loss: 0.6822 - val_accuracy: 0.8083\n",
            "Epoch 1691/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4465 - accuracy: 0.8319 - val_loss: 0.7088 - val_accuracy: 0.7933\n",
            "Epoch 1692/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4590 - accuracy: 0.8375 - val_loss: 0.6968 - val_accuracy: 0.8100\n",
            "Epoch 1693/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4376 - accuracy: 0.8444 - val_loss: 0.7122 - val_accuracy: 0.7925\n",
            "Epoch 1694/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4483 - accuracy: 0.8369 - val_loss: 0.6379 - val_accuracy: 0.8308\n",
            "Epoch 1695/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4559 - accuracy: 0.8401 - val_loss: 0.6916 - val_accuracy: 0.8008\n",
            "Epoch 1696/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4521 - accuracy: 0.8376 - val_loss: 0.7114 - val_accuracy: 0.8158\n",
            "Epoch 1697/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4572 - accuracy: 0.8394 - val_loss: 0.7289 - val_accuracy: 0.7950\n",
            "Epoch 1698/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4580 - accuracy: 0.8404 - val_loss: 0.6739 - val_accuracy: 0.8200\n",
            "Epoch 1699/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4566 - accuracy: 0.8361 - val_loss: 0.7244 - val_accuracy: 0.8125\n",
            "Epoch 1700/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.4655 - accuracy: 0.8252 - val_loss: 0.6769 - val_accuracy: 0.8192\n",
            "Epoch 1701/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4468 - accuracy: 0.8400 - val_loss: 0.6506 - val_accuracy: 0.8383\n",
            "Epoch 1702/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4270 - accuracy: 0.8597 - val_loss: 0.6976 - val_accuracy: 0.8092\n",
            "Epoch 1703/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4178 - accuracy: 0.8542 - val_loss: 0.7148 - val_accuracy: 0.8067\n",
            "Epoch 1704/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4465 - accuracy: 0.8400 - val_loss: 0.7792 - val_accuracy: 0.7767\n",
            "Epoch 1705/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4354 - accuracy: 0.8451 - val_loss: 0.6661 - val_accuracy: 0.8175\n",
            "Epoch 1706/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4116 - accuracy: 0.8678 - val_loss: 0.6998 - val_accuracy: 0.8083\n",
            "Epoch 1707/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4321 - accuracy: 0.8488 - val_loss: 0.7180 - val_accuracy: 0.7942\n",
            "Epoch 1708/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4409 - accuracy: 0.8355 - val_loss: 0.7288 - val_accuracy: 0.8033\n",
            "Epoch 1709/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4548 - accuracy: 0.8363 - val_loss: 0.7274 - val_accuracy: 0.8167\n",
            "Epoch 1710/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4450 - accuracy: 0.8401 - val_loss: 0.7230 - val_accuracy: 0.7950\n",
            "Epoch 1711/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4190 - accuracy: 0.8483 - val_loss: 0.6822 - val_accuracy: 0.8358\n",
            "Epoch 1712/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4317 - accuracy: 0.8498 - val_loss: 0.7105 - val_accuracy: 0.8083\n",
            "Epoch 1713/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4601 - accuracy: 0.8414 - val_loss: 0.7842 - val_accuracy: 0.8042\n",
            "Epoch 1714/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4400 - accuracy: 0.8549 - val_loss: 0.6465 - val_accuracy: 0.8092\n",
            "Epoch 1715/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4707 - accuracy: 0.8333 - val_loss: 0.6248 - val_accuracy: 0.7883\n",
            "Epoch 1716/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4652 - accuracy: 0.8300 - val_loss: 0.6169 - val_accuracy: 0.8100\n",
            "Epoch 1717/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4171 - accuracy: 0.8397 - val_loss: 0.6165 - val_accuracy: 0.7975\n",
            "Epoch 1718/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4437 - accuracy: 0.8357 - val_loss: 0.6195 - val_accuracy: 0.8000\n",
            "Epoch 1719/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4895 - accuracy: 0.8238 - val_loss: 0.6633 - val_accuracy: 0.7808\n",
            "Epoch 1720/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4913 - accuracy: 0.8224 - val_loss: 0.6181 - val_accuracy: 0.8108\n",
            "Epoch 1721/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4566 - accuracy: 0.8437 - val_loss: 0.6103 - val_accuracy: 0.8100\n",
            "Epoch 1722/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4304 - accuracy: 0.8455 - val_loss: 0.5966 - val_accuracy: 0.8217\n",
            "Epoch 1723/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4468 - accuracy: 0.8325 - val_loss: 0.6817 - val_accuracy: 0.7808\n",
            "Epoch 1724/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4907 - accuracy: 0.8275 - val_loss: 0.6167 - val_accuracy: 0.8050\n",
            "Epoch 1725/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4224 - accuracy: 0.8432 - val_loss: 0.6203 - val_accuracy: 0.8183\n",
            "Epoch 1726/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4927 - accuracy: 0.8513 - val_loss: 0.6097 - val_accuracy: 0.8342\n",
            "Epoch 1727/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4334 - accuracy: 0.8473 - val_loss: 0.5783 - val_accuracy: 0.8258\n",
            "Epoch 1728/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4208 - accuracy: 0.8517 - val_loss: 0.6096 - val_accuracy: 0.8175\n",
            "Epoch 1729/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4344 - accuracy: 0.8418 - val_loss: 0.6232 - val_accuracy: 0.8075\n",
            "Epoch 1730/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4684 - accuracy: 0.8278 - val_loss: 0.6218 - val_accuracy: 0.7958\n",
            "Epoch 1731/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4474 - accuracy: 0.8364 - val_loss: 0.6354 - val_accuracy: 0.7858\n",
            "Epoch 1732/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4419 - accuracy: 0.8351 - val_loss: 0.6326 - val_accuracy: 0.8283\n",
            "Epoch 1733/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4491 - accuracy: 0.8452 - val_loss: 0.6055 - val_accuracy: 0.8325\n",
            "Epoch 1734/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4143 - accuracy: 0.8527 - val_loss: 0.6191 - val_accuracy: 0.8167\n",
            "Epoch 1735/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4255 - accuracy: 0.8502 - val_loss: 0.5966 - val_accuracy: 0.8300\n",
            "Epoch 1736/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4453 - accuracy: 0.8378 - val_loss: 0.6629 - val_accuracy: 0.7975\n",
            "Epoch 1737/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4687 - accuracy: 0.8346 - val_loss: 0.5985 - val_accuracy: 0.8100\n",
            "Epoch 1738/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4360 - accuracy: 0.8413 - val_loss: 0.6010 - val_accuracy: 0.8142\n",
            "Epoch 1739/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4589 - accuracy: 0.8379 - val_loss: 0.6382 - val_accuracy: 0.8033\n",
            "Epoch 1740/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4461 - accuracy: 0.8469 - val_loss: 0.5795 - val_accuracy: 0.8325\n",
            "Epoch 1741/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4280 - accuracy: 0.8505 - val_loss: 0.6229 - val_accuracy: 0.8117\n",
            "Epoch 1742/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4541 - accuracy: 0.8350 - val_loss: 0.6749 - val_accuracy: 0.7925\n",
            "Epoch 1743/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4297 - accuracy: 0.8443 - val_loss: 0.6079 - val_accuracy: 0.8258\n",
            "Epoch 1744/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4220 - accuracy: 0.8437 - val_loss: 0.5904 - val_accuracy: 0.8208\n",
            "Epoch 1745/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4174 - accuracy: 0.8563 - val_loss: 0.5806 - val_accuracy: 0.8375\n",
            "Epoch 1746/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4264 - accuracy: 0.8428 - val_loss: 0.5945 - val_accuracy: 0.8183\n",
            "Epoch 1747/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4077 - accuracy: 0.8584 - val_loss: 0.6645 - val_accuracy: 0.7917\n",
            "Epoch 1748/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4195 - accuracy: 0.8428 - val_loss: 0.6184 - val_accuracy: 0.8108\n",
            "Epoch 1749/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4544 - accuracy: 0.8389 - val_loss: 0.6233 - val_accuracy: 0.7933\n",
            "Epoch 1750/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4396 - accuracy: 0.8398 - val_loss: 0.6232 - val_accuracy: 0.8117\n",
            "Epoch 1751/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3892 - accuracy: 0.8594 - val_loss: 0.6257 - val_accuracy: 0.8033\n",
            "Epoch 1752/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4289 - accuracy: 0.8435 - val_loss: 0.6199 - val_accuracy: 0.8225\n",
            "Epoch 1753/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4545 - accuracy: 0.8335 - val_loss: 0.6509 - val_accuracy: 0.7942\n",
            "Epoch 1754/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8569 - val_loss: 0.6237 - val_accuracy: 0.7892\n",
            "Epoch 1755/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4350 - accuracy: 0.8445 - val_loss: 0.6078 - val_accuracy: 0.8183\n",
            "Epoch 1756/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4481 - accuracy: 0.8407 - val_loss: 0.6327 - val_accuracy: 0.8058\n",
            "Epoch 1757/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4229 - accuracy: 0.8455 - val_loss: 0.5970 - val_accuracy: 0.8200\n",
            "Epoch 1758/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4342 - accuracy: 0.8469 - val_loss: 0.6219 - val_accuracy: 0.8075\n",
            "Epoch 1759/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4616 - accuracy: 0.8420 - val_loss: 0.6290 - val_accuracy: 0.8042\n",
            "Epoch 1760/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4227 - accuracy: 0.8522 - val_loss: 0.6075 - val_accuracy: 0.8167\n",
            "Epoch 1761/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4457 - accuracy: 0.8404 - val_loss: 0.8172 - val_accuracy: 0.8083\n",
            "Epoch 1762/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4552 - accuracy: 0.8408 - val_loss: 0.6367 - val_accuracy: 0.8033\n",
            "Epoch 1763/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4581 - accuracy: 0.8395 - val_loss: 0.6866 - val_accuracy: 0.7817\n",
            "Epoch 1764/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4418 - accuracy: 0.8464 - val_loss: 0.6365 - val_accuracy: 0.8108\n",
            "Epoch 1765/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4526 - accuracy: 0.8353 - val_loss: 0.6111 - val_accuracy: 0.8192\n",
            "Epoch 1766/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4524 - accuracy: 0.8414 - val_loss: 0.6178 - val_accuracy: 0.8150\n",
            "Epoch 1767/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4517 - accuracy: 0.8318 - val_loss: 0.6428 - val_accuracy: 0.8167\n",
            "Epoch 1768/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.4737 - accuracy: 0.8324 - val_loss: 0.6308 - val_accuracy: 0.8017\n",
            "Epoch 1769/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4466 - accuracy: 0.8385 - val_loss: 0.5950 - val_accuracy: 0.8192\n",
            "Epoch 1770/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4438 - accuracy: 0.8409 - val_loss: 0.6203 - val_accuracy: 0.8142\n",
            "Epoch 1771/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.4517 - accuracy: 0.8395 - val_loss: 0.6128 - val_accuracy: 0.8092\n",
            "Epoch 1772/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4268 - accuracy: 0.8505 - val_loss: 0.6409 - val_accuracy: 0.8100\n",
            "Epoch 1773/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4554 - accuracy: 0.8382 - val_loss: 0.6583 - val_accuracy: 0.7917\n",
            "Epoch 1774/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4573 - accuracy: 0.8367 - val_loss: 0.5972 - val_accuracy: 0.8258\n",
            "Epoch 1775/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4523 - accuracy: 0.8366 - val_loss: 0.6389 - val_accuracy: 0.8117\n",
            "Epoch 1776/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4600 - accuracy: 0.8390 - val_loss: 0.6719 - val_accuracy: 0.8100\n",
            "Epoch 1777/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4841 - accuracy: 0.8273 - val_loss: 0.6143 - val_accuracy: 0.8225\n",
            "Epoch 1778/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4329 - accuracy: 0.8434 - val_loss: 0.6300 - val_accuracy: 0.8175\n",
            "Epoch 1779/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4481 - accuracy: 0.8355 - val_loss: 0.6242 - val_accuracy: 0.8208\n",
            "Epoch 1780/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4112 - accuracy: 0.8515 - val_loss: 0.6418 - val_accuracy: 0.8183\n",
            "Epoch 1781/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4295 - accuracy: 0.8403 - val_loss: 0.6450 - val_accuracy: 0.8108\n",
            "Epoch 1782/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4357 - accuracy: 0.8451 - val_loss: 0.6078 - val_accuracy: 0.8142\n",
            "Epoch 1783/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4397 - accuracy: 0.8414 - val_loss: 0.6515 - val_accuracy: 0.8083\n",
            "Epoch 1784/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4322 - accuracy: 0.8586 - val_loss: 0.6099 - val_accuracy: 0.8167\n",
            "Epoch 1785/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4617 - accuracy: 0.8348 - val_loss: 0.6476 - val_accuracy: 0.7958\n",
            "Epoch 1786/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4200 - accuracy: 0.8474 - val_loss: 0.6441 - val_accuracy: 0.8208\n",
            "Epoch 1787/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4346 - accuracy: 0.8423 - val_loss: 0.6036 - val_accuracy: 0.8250\n",
            "Epoch 1788/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4432 - accuracy: 0.8380 - val_loss: 0.6035 - val_accuracy: 0.8125\n",
            "Epoch 1789/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4612 - accuracy: 0.8303 - val_loss: 0.6287 - val_accuracy: 0.8050\n",
            "Epoch 1790/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4661 - accuracy: 0.8323 - val_loss: 0.6615 - val_accuracy: 0.7958\n",
            "Epoch 1791/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4454 - accuracy: 0.8377 - val_loss: 0.5950 - val_accuracy: 0.8150\n",
            "Epoch 1792/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4297 - accuracy: 0.8453 - val_loss: 0.6559 - val_accuracy: 0.8067\n",
            "Epoch 1793/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4360 - accuracy: 0.8488 - val_loss: 0.6800 - val_accuracy: 0.7842\n",
            "Epoch 1794/2000\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.4729 - accuracy: 0.8323 - val_loss: 0.6127 - val_accuracy: 0.8075\n",
            "Epoch 1795/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4286 - accuracy: 0.8451 - val_loss: 0.6331 - val_accuracy: 0.8108\n",
            "Epoch 1796/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4403 - accuracy: 0.8412 - val_loss: 0.6893 - val_accuracy: 0.7850\n",
            "Epoch 1797/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4381 - accuracy: 0.8428 - val_loss: 0.6507 - val_accuracy: 0.8133\n",
            "Epoch 1798/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4205 - accuracy: 0.8450 - val_loss: 0.6343 - val_accuracy: 0.7925\n",
            "Epoch 1799/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4224 - accuracy: 0.8450 - val_loss: 0.6058 - val_accuracy: 0.8158\n",
            "Epoch 1800/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4220 - accuracy: 0.8493 - val_loss: 0.6191 - val_accuracy: 0.8208\n",
            "Epoch 1801/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4166 - accuracy: 0.8520 - val_loss: 0.6211 - val_accuracy: 0.8142\n",
            "Epoch 1802/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4332 - accuracy: 0.8443 - val_loss: 0.5926 - val_accuracy: 0.8300\n",
            "Epoch 1803/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4670 - accuracy: 0.8279 - val_loss: 0.6259 - val_accuracy: 0.8083\n",
            "Epoch 1804/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4236 - accuracy: 0.8490 - val_loss: 0.6320 - val_accuracy: 0.8050\n",
            "Epoch 1805/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4132 - accuracy: 0.8518 - val_loss: 0.6258 - val_accuracy: 0.8192\n",
            "Epoch 1806/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4230 - accuracy: 0.8519 - val_loss: 0.6836 - val_accuracy: 0.8075\n",
            "Epoch 1807/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4444 - accuracy: 0.8420 - val_loss: 0.6559 - val_accuracy: 0.8067\n",
            "Epoch 1808/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4581 - accuracy: 0.8407 - val_loss: 0.7380 - val_accuracy: 0.7867\n",
            "Epoch 1809/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4920 - accuracy: 0.8233 - val_loss: 0.6602 - val_accuracy: 0.8075\n",
            "Epoch 1810/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4321 - accuracy: 0.8444 - val_loss: 0.6286 - val_accuracy: 0.8192\n",
            "Epoch 1811/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4265 - accuracy: 0.8519 - val_loss: 0.6269 - val_accuracy: 0.8342\n",
            "Epoch 1812/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4423 - accuracy: 0.8400 - val_loss: 0.6377 - val_accuracy: 0.8233\n",
            "Epoch 1813/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4393 - accuracy: 0.8469 - val_loss: 0.9368 - val_accuracy: 0.7967\n",
            "Epoch 1814/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5868 - accuracy: 0.8358 - val_loss: 0.6339 - val_accuracy: 0.8058\n",
            "Epoch 1815/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4674 - accuracy: 0.8307 - val_loss: 0.6690 - val_accuracy: 0.8292\n",
            "Epoch 1816/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4365 - accuracy: 0.8436 - val_loss: 0.6539 - val_accuracy: 0.8050\n",
            "Epoch 1817/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4221 - accuracy: 0.8528 - val_loss: 0.6418 - val_accuracy: 0.8233\n",
            "Epoch 1818/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4319 - accuracy: 0.8490 - val_loss: 0.7577 - val_accuracy: 0.7875\n",
            "Epoch 1819/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4886 - accuracy: 0.8197 - val_loss: 0.6654 - val_accuracy: 0.8117\n",
            "Epoch 1820/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4480 - accuracy: 0.8397 - val_loss: 0.6963 - val_accuracy: 0.7958\n",
            "Epoch 1821/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4426 - accuracy: 0.8428 - val_loss: 0.6564 - val_accuracy: 0.8058\n",
            "Epoch 1822/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4433 - accuracy: 0.8425 - val_loss: 0.6450 - val_accuracy: 0.8150\n",
            "Epoch 1823/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4217 - accuracy: 0.8504 - val_loss: 0.6322 - val_accuracy: 0.8200\n",
            "Epoch 1824/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4273 - accuracy: 0.8448 - val_loss: 0.7060 - val_accuracy: 0.8017\n",
            "Epoch 1825/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4531 - accuracy: 0.8290 - val_loss: 0.6906 - val_accuracy: 0.8017\n",
            "Epoch 1826/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.4430 - accuracy: 0.8429 - val_loss: 0.6530 - val_accuracy: 0.8058\n",
            "Epoch 1827/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4439 - accuracy: 0.8341 - val_loss: 0.6222 - val_accuracy: 0.8433\n",
            "Epoch 1828/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4575 - accuracy: 0.8451 - val_loss: 0.6419 - val_accuracy: 0.8325\n",
            "Epoch 1829/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4407 - accuracy: 0.8335 - val_loss: 0.7050 - val_accuracy: 0.7967\n",
            "Epoch 1830/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4509 - accuracy: 0.8366 - val_loss: 0.6897 - val_accuracy: 0.8042\n",
            "Epoch 1831/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4684 - accuracy: 0.8302 - val_loss: 0.7156 - val_accuracy: 0.7808\n",
            "Epoch 1832/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4599 - accuracy: 0.8304 - val_loss: 0.6489 - val_accuracy: 0.8108\n",
            "Epoch 1833/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4040 - accuracy: 0.8612 - val_loss: 0.6605 - val_accuracy: 0.8192\n",
            "Epoch 1834/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4194 - accuracy: 0.8481 - val_loss: 0.6587 - val_accuracy: 0.8292\n",
            "Epoch 1835/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4682 - accuracy: 0.8340 - val_loss: 0.6464 - val_accuracy: 0.8300\n",
            "Epoch 1836/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4149 - accuracy: 0.8629 - val_loss: 0.6699 - val_accuracy: 0.8175\n",
            "Epoch 1837/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4761 - accuracy: 0.8264 - val_loss: 0.6714 - val_accuracy: 0.8142\n",
            "Epoch 1838/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4368 - accuracy: 0.8449 - val_loss: 0.6613 - val_accuracy: 0.8175\n",
            "Epoch 1839/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.3945 - accuracy: 0.8650 - val_loss: 0.6413 - val_accuracy: 0.8250\n",
            "Epoch 1840/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4201 - accuracy: 0.8519 - val_loss: 0.7166 - val_accuracy: 0.7967\n",
            "Epoch 1841/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4261 - accuracy: 0.8493 - val_loss: 0.6683 - val_accuracy: 0.8292\n",
            "Epoch 1842/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.4198 - accuracy: 0.8489 - val_loss: 0.6527 - val_accuracy: 0.8217\n",
            "Epoch 1843/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4217 - accuracy: 0.8596 - val_loss: 0.7108 - val_accuracy: 0.8067\n",
            "Epoch 1844/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4358 - accuracy: 0.8458 - val_loss: 0.7507 - val_accuracy: 0.7942\n",
            "Epoch 1845/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4463 - accuracy: 0.8434 - val_loss: 0.7421 - val_accuracy: 0.8133\n",
            "Epoch 1846/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4143 - accuracy: 0.8553 - val_loss: 0.6806 - val_accuracy: 0.8175\n",
            "Epoch 1847/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4571 - accuracy: 0.8304 - val_loss: 0.6836 - val_accuracy: 0.8092\n",
            "Epoch 1848/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4191 - accuracy: 0.8558 - val_loss: 0.7021 - val_accuracy: 0.8042\n",
            "Epoch 1849/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4157 - accuracy: 0.8523 - val_loss: 0.7653 - val_accuracy: 0.7892\n",
            "Epoch 1850/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4286 - accuracy: 0.8455 - val_loss: 0.7467 - val_accuracy: 0.8208\n",
            "Epoch 1851/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4165 - accuracy: 0.8534 - val_loss: 0.6937 - val_accuracy: 0.8183\n",
            "Epoch 1852/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4516 - accuracy: 0.8378 - val_loss: 0.6691 - val_accuracy: 0.8308\n",
            "Epoch 1853/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4079 - accuracy: 0.8568 - val_loss: 0.6861 - val_accuracy: 0.8225\n",
            "Epoch 1854/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4125 - accuracy: 0.8408 - val_loss: 0.6766 - val_accuracy: 0.8142\n",
            "Epoch 1855/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4250 - accuracy: 0.8443 - val_loss: 0.7078 - val_accuracy: 0.8050\n",
            "Epoch 1856/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4521 - accuracy: 0.8292 - val_loss: 0.6994 - val_accuracy: 0.8225\n",
            "Epoch 1857/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4579 - accuracy: 0.8374 - val_loss: 0.6735 - val_accuracy: 0.8158\n",
            "Epoch 1858/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4300 - accuracy: 0.8406 - val_loss: 0.6994 - val_accuracy: 0.8283\n",
            "Epoch 1859/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4129 - accuracy: 0.8468 - val_loss: 0.8198 - val_accuracy: 0.8083\n",
            "Epoch 1860/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4971 - accuracy: 0.8259 - val_loss: 0.7440 - val_accuracy: 0.8117\n",
            "Epoch 1861/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4402 - accuracy: 0.8361 - val_loss: 0.7046 - val_accuracy: 0.8217\n",
            "Epoch 1862/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4235 - accuracy: 0.8495 - val_loss: 0.7211 - val_accuracy: 0.8200\n",
            "Epoch 1863/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4668 - accuracy: 0.8296 - val_loss: 0.7110 - val_accuracy: 0.8167\n",
            "Epoch 1864/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4261 - accuracy: 0.8553 - val_loss: 0.7005 - val_accuracy: 0.8192\n",
            "Epoch 1865/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4208 - accuracy: 0.8475 - val_loss: 0.7314 - val_accuracy: 0.7983\n",
            "Epoch 1866/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4513 - accuracy: 0.8448 - val_loss: 0.7282 - val_accuracy: 0.7875\n",
            "Epoch 1867/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4458 - accuracy: 0.8390 - val_loss: 0.7219 - val_accuracy: 0.8117\n",
            "Epoch 1868/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4307 - accuracy: 0.8477 - val_loss: 0.6943 - val_accuracy: 0.8267\n",
            "Epoch 1869/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4284 - accuracy: 0.8536 - val_loss: 0.7577 - val_accuracy: 0.7958\n",
            "Epoch 1870/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4525 - accuracy: 0.8334 - val_loss: 0.7080 - val_accuracy: 0.8175\n",
            "Epoch 1871/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4199 - accuracy: 0.8444 - val_loss: 0.7073 - val_accuracy: 0.8275\n",
            "Epoch 1872/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4127 - accuracy: 0.8550 - val_loss: 0.7067 - val_accuracy: 0.8192\n",
            "Epoch 1873/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4169 - accuracy: 0.8551 - val_loss: 0.7276 - val_accuracy: 0.8183\n",
            "Epoch 1874/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4303 - accuracy: 0.8537 - val_loss: 0.7399 - val_accuracy: 0.8100\n",
            "Epoch 1875/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4243 - accuracy: 0.8410 - val_loss: 0.7057 - val_accuracy: 0.8283\n",
            "Epoch 1876/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4094 - accuracy: 0.8626 - val_loss: 0.7338 - val_accuracy: 0.8075\n",
            "Epoch 1877/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4222 - accuracy: 0.8466 - val_loss: 0.7236 - val_accuracy: 0.8158\n",
            "Epoch 1878/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4058 - accuracy: 0.8465 - val_loss: 0.7229 - val_accuracy: 0.8175\n",
            "Epoch 1879/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4098 - accuracy: 0.8478 - val_loss: 0.7304 - val_accuracy: 0.8108\n",
            "Epoch 1880/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4343 - accuracy: 0.8414 - val_loss: 0.8039 - val_accuracy: 0.7925\n",
            "Epoch 1881/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4198 - accuracy: 0.8397 - val_loss: 0.6941 - val_accuracy: 0.8192\n",
            "Epoch 1882/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4282 - accuracy: 0.8469 - val_loss: 0.6946 - val_accuracy: 0.8350\n",
            "Epoch 1883/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4102 - accuracy: 0.8549 - val_loss: 0.7449 - val_accuracy: 0.8342\n",
            "Epoch 1884/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4691 - accuracy: 0.8419 - val_loss: 0.5796 - val_accuracy: 0.8367\n",
            "Epoch 1885/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4180 - accuracy: 0.8523 - val_loss: 0.6541 - val_accuracy: 0.7933\n",
            "Epoch 1886/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4478 - accuracy: 0.8371 - val_loss: 0.5843 - val_accuracy: 0.8325\n",
            "Epoch 1887/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4194 - accuracy: 0.8543 - val_loss: 0.6377 - val_accuracy: 0.8025\n",
            "Epoch 1888/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4054 - accuracy: 0.8528 - val_loss: 0.5789 - val_accuracy: 0.8267\n",
            "Epoch 1889/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4272 - accuracy: 0.8490 - val_loss: 0.6280 - val_accuracy: 0.8125\n",
            "Epoch 1890/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4568 - accuracy: 0.8347 - val_loss: 0.6150 - val_accuracy: 0.8092\n",
            "Epoch 1891/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4431 - accuracy: 0.8466 - val_loss: 0.6335 - val_accuracy: 0.7992\n",
            "Epoch 1892/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4441 - accuracy: 0.8354 - val_loss: 0.5840 - val_accuracy: 0.8175\n",
            "Epoch 1893/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4533 - accuracy: 0.8245 - val_loss: 0.6493 - val_accuracy: 0.8050\n",
            "Epoch 1894/2000\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.4072 - accuracy: 0.8571 - val_loss: 0.5869 - val_accuracy: 0.8208\n",
            "Epoch 1895/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4053 - accuracy: 0.8570 - val_loss: 0.5930 - val_accuracy: 0.8192\n",
            "Epoch 1896/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4286 - accuracy: 0.8533 - val_loss: 0.5936 - val_accuracy: 0.8233\n",
            "Epoch 1897/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4515 - accuracy: 0.8381 - val_loss: 0.6299 - val_accuracy: 0.8083\n",
            "Epoch 1898/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4186 - accuracy: 0.8476 - val_loss: 0.5971 - val_accuracy: 0.8308\n",
            "Epoch 1899/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4486 - accuracy: 0.8320 - val_loss: 0.6032 - val_accuracy: 0.8208\n",
            "Epoch 1900/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4315 - accuracy: 0.8584 - val_loss: 0.6010 - val_accuracy: 0.8150\n",
            "Epoch 1901/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4210 - accuracy: 0.8490 - val_loss: 0.6420 - val_accuracy: 0.7867\n",
            "Epoch 1902/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4329 - accuracy: 0.8397 - val_loss: 0.6317 - val_accuracy: 0.7983\n",
            "Epoch 1903/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4605 - accuracy: 0.8411 - val_loss: 0.6179 - val_accuracy: 0.8108\n",
            "Epoch 1904/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4207 - accuracy: 0.8528 - val_loss: 0.6034 - val_accuracy: 0.8167\n",
            "Epoch 1905/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4358 - accuracy: 0.8524 - val_loss: 0.6162 - val_accuracy: 0.7933\n",
            "Epoch 1906/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4328 - accuracy: 0.8393 - val_loss: 0.6791 - val_accuracy: 0.7983\n",
            "Epoch 1907/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4451 - accuracy: 0.8454 - val_loss: 0.5995 - val_accuracy: 0.8283\n",
            "Epoch 1908/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4377 - accuracy: 0.8367 - val_loss: 0.6620 - val_accuracy: 0.8050\n",
            "Epoch 1909/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4499 - accuracy: 0.8384 - val_loss: 0.6116 - val_accuracy: 0.8300\n",
            "Epoch 1910/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4103 - accuracy: 0.8505 - val_loss: 0.5724 - val_accuracy: 0.8192\n",
            "Epoch 1911/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4756 - accuracy: 0.8383 - val_loss: 0.7044 - val_accuracy: 0.8167\n",
            "Epoch 1912/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4306 - accuracy: 0.8415 - val_loss: 0.6093 - val_accuracy: 0.8425\n",
            "Epoch 1913/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4085 - accuracy: 0.8647 - val_loss: 0.6326 - val_accuracy: 0.8233\n",
            "Epoch 1914/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4317 - accuracy: 0.8493 - val_loss: 0.6213 - val_accuracy: 0.8308\n",
            "Epoch 1915/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4151 - accuracy: 0.8493 - val_loss: 0.5989 - val_accuracy: 0.8408\n",
            "Epoch 1916/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.3907 - accuracy: 0.8547 - val_loss: 0.6087 - val_accuracy: 0.8117\n",
            "Epoch 1917/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4132 - accuracy: 0.8528 - val_loss: 0.6453 - val_accuracy: 0.8208\n",
            "Epoch 1918/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.4372 - accuracy: 0.8397 - val_loss: 0.6347 - val_accuracy: 0.7983\n",
            "Epoch 1919/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4468 - accuracy: 0.8407 - val_loss: 0.6145 - val_accuracy: 0.8283\n",
            "Epoch 1920/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4088 - accuracy: 0.8507 - val_loss: 0.5960 - val_accuracy: 0.8292\n",
            "Epoch 1921/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4146 - accuracy: 0.8493 - val_loss: 0.6365 - val_accuracy: 0.8133\n",
            "Epoch 1922/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4366 - accuracy: 0.8392 - val_loss: 0.7270 - val_accuracy: 0.7883\n",
            "Epoch 1923/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4966 - accuracy: 0.8232 - val_loss: 0.7574 - val_accuracy: 0.7833\n",
            "Epoch 1924/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4643 - accuracy: 0.8371 - val_loss: 0.5911 - val_accuracy: 0.8325\n",
            "Epoch 1925/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4030 - accuracy: 0.8563 - val_loss: 0.5968 - val_accuracy: 0.8358\n",
            "Epoch 1926/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.3970 - accuracy: 0.8637 - val_loss: 0.6472 - val_accuracy: 0.8025\n",
            "Epoch 1927/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4179 - accuracy: 0.8571 - val_loss: 0.6002 - val_accuracy: 0.8200\n",
            "Epoch 1928/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4469 - accuracy: 0.8418 - val_loss: 0.5990 - val_accuracy: 0.8250\n",
            "Epoch 1929/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4165 - accuracy: 0.8405 - val_loss: 0.6198 - val_accuracy: 0.8158\n",
            "Epoch 1930/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4296 - accuracy: 0.8443 - val_loss: 0.6650 - val_accuracy: 0.7958\n",
            "Epoch 1931/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4301 - accuracy: 0.8471 - val_loss: 0.6039 - val_accuracy: 0.8333\n",
            "Epoch 1932/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4194 - accuracy: 0.8464 - val_loss: 0.6374 - val_accuracy: 0.8033\n",
            "Epoch 1933/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4379 - accuracy: 0.8491 - val_loss: 0.6491 - val_accuracy: 0.7933\n",
            "Epoch 1934/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4507 - accuracy: 0.8316 - val_loss: 0.6149 - val_accuracy: 0.8267\n",
            "Epoch 1935/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4192 - accuracy: 0.8527 - val_loss: 0.6687 - val_accuracy: 0.8083\n",
            "Epoch 1936/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4231 - accuracy: 0.8498 - val_loss: 0.6069 - val_accuracy: 0.8342\n",
            "Epoch 1937/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4112 - accuracy: 0.8576 - val_loss: 0.6065 - val_accuracy: 0.8342\n",
            "Epoch 1938/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4263 - accuracy: 0.8504 - val_loss: 0.6190 - val_accuracy: 0.8192\n",
            "Epoch 1939/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4232 - accuracy: 0.8423 - val_loss: 0.6397 - val_accuracy: 0.8050\n",
            "Epoch 1940/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4133 - accuracy: 0.8556 - val_loss: 0.6206 - val_accuracy: 0.8150\n",
            "Epoch 1941/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4258 - accuracy: 0.8503 - val_loss: 0.6354 - val_accuracy: 0.8100\n",
            "Epoch 1942/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4125 - accuracy: 0.8637 - val_loss: 0.6022 - val_accuracy: 0.8217\n",
            "Epoch 1943/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4066 - accuracy: 0.8460 - val_loss: 0.6388 - val_accuracy: 0.8217\n",
            "Epoch 1944/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4217 - accuracy: 0.8508 - val_loss: 0.6501 - val_accuracy: 0.8192\n",
            "Epoch 1945/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4202 - accuracy: 0.8454 - val_loss: 0.6387 - val_accuracy: 0.8175\n",
            "Epoch 1946/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4018 - accuracy: 0.8563 - val_loss: 0.6258 - val_accuracy: 0.8033\n",
            "Epoch 1947/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4302 - accuracy: 0.8426 - val_loss: 0.6303 - val_accuracy: 0.8125\n",
            "Epoch 1948/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4040 - accuracy: 0.8600 - val_loss: 0.6435 - val_accuracy: 0.8100\n",
            "Epoch 1949/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4200 - accuracy: 0.8494 - val_loss: 0.6778 - val_accuracy: 0.8000\n",
            "Epoch 1950/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4370 - accuracy: 0.8480 - val_loss: 0.6612 - val_accuracy: 0.8233\n",
            "Epoch 1951/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4219 - accuracy: 0.8489 - val_loss: 0.6137 - val_accuracy: 0.8225\n",
            "Epoch 1952/2000\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.4031 - accuracy: 0.8516 - val_loss: 0.6481 - val_accuracy: 0.8108\n",
            "Epoch 1953/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4381 - accuracy: 0.8401 - val_loss: 0.6316 - val_accuracy: 0.8100\n",
            "Epoch 1954/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4280 - accuracy: 0.8469 - val_loss: 0.6198 - val_accuracy: 0.8300\n",
            "Epoch 1955/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4379 - accuracy: 0.8515 - val_loss: 0.8869 - val_accuracy: 0.7917\n",
            "Epoch 1956/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4860 - accuracy: 0.8248 - val_loss: 0.7277 - val_accuracy: 0.8108\n",
            "Epoch 1957/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4876 - accuracy: 0.8378 - val_loss: 0.6629 - val_accuracy: 0.7908\n",
            "Epoch 1958/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4829 - accuracy: 0.8229 - val_loss: 0.6579 - val_accuracy: 0.8142\n",
            "Epoch 1959/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4508 - accuracy: 0.8357 - val_loss: 0.6194 - val_accuracy: 0.8250\n",
            "Epoch 1960/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4256 - accuracy: 0.8485 - val_loss: 0.6387 - val_accuracy: 0.8158\n",
            "Epoch 1961/2000\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4967 - accuracy: 0.8190 - val_loss: 0.6881 - val_accuracy: 0.7942\n",
            "Epoch 1962/2000\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.4571 - accuracy: 0.8322 - val_loss: 0.6125 - val_accuracy: 0.8358\n",
            "Epoch 1963/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4193 - accuracy: 0.8545 - val_loss: 0.7039 - val_accuracy: 0.7850\n",
            "Epoch 1964/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4601 - accuracy: 0.8332 - val_loss: 0.6132 - val_accuracy: 0.8317\n",
            "Epoch 1965/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4165 - accuracy: 0.8510 - val_loss: 0.6312 - val_accuracy: 0.8217\n",
            "Epoch 1966/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4182 - accuracy: 0.8423 - val_loss: 0.6114 - val_accuracy: 0.8308\n",
            "Epoch 1967/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4318 - accuracy: 0.8422 - val_loss: 0.6469 - val_accuracy: 0.8183\n",
            "Epoch 1968/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4290 - accuracy: 0.8496 - val_loss: 0.6718 - val_accuracy: 0.8167\n",
            "Epoch 1969/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4019 - accuracy: 0.8531 - val_loss: 0.6603 - val_accuracy: 0.8183\n",
            "Epoch 1970/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4306 - accuracy: 0.8492 - val_loss: 0.6284 - val_accuracy: 0.8167\n",
            "Epoch 1971/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4056 - accuracy: 0.8498 - val_loss: 0.6685 - val_accuracy: 0.8200\n",
            "Epoch 1972/2000\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.4260 - accuracy: 0.8452 - val_loss: 0.6620 - val_accuracy: 0.8158\n",
            "Epoch 1973/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4314 - accuracy: 0.8468 - val_loss: 0.6697 - val_accuracy: 0.8133\n",
            "Epoch 1974/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4323 - accuracy: 0.8418 - val_loss: 0.6305 - val_accuracy: 0.8125\n",
            "Epoch 1975/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4086 - accuracy: 0.8542 - val_loss: 0.6294 - val_accuracy: 0.8250\n",
            "Epoch 1976/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4497 - accuracy: 0.8368 - val_loss: 0.6908 - val_accuracy: 0.8042\n",
            "Epoch 1977/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4317 - accuracy: 0.8497 - val_loss: 0.6589 - val_accuracy: 0.8125\n",
            "Epoch 1978/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4199 - accuracy: 0.8495 - val_loss: 0.7171 - val_accuracy: 0.7967\n",
            "Epoch 1979/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4499 - accuracy: 0.8348 - val_loss: 0.6622 - val_accuracy: 0.8117\n",
            "Epoch 1980/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4441 - accuracy: 0.8407 - val_loss: 0.6804 - val_accuracy: 0.8017\n",
            "Epoch 1981/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4189 - accuracy: 0.8500 - val_loss: 0.6473 - val_accuracy: 0.8158\n",
            "Epoch 1982/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4167 - accuracy: 0.8497 - val_loss: 0.6675 - val_accuracy: 0.8250\n",
            "Epoch 1983/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4540 - accuracy: 0.8395 - val_loss: 0.6335 - val_accuracy: 0.8333\n",
            "Epoch 1984/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4143 - accuracy: 0.8492 - val_loss: 0.6423 - val_accuracy: 0.8208\n",
            "Epoch 1985/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4186 - accuracy: 0.8492 - val_loss: 0.6551 - val_accuracy: 0.8125\n",
            "Epoch 1986/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4417 - accuracy: 0.8349 - val_loss: 0.6669 - val_accuracy: 0.8033\n",
            "Epoch 1987/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4140 - accuracy: 0.8539 - val_loss: 0.6486 - val_accuracy: 0.8200\n",
            "Epoch 1988/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.3956 - accuracy: 0.8580 - val_loss: 0.6342 - val_accuracy: 0.8325\n",
            "Epoch 1989/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4003 - accuracy: 0.8608 - val_loss: 0.6554 - val_accuracy: 0.8150\n",
            "Epoch 1990/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4349 - accuracy: 0.8393 - val_loss: 0.6755 - val_accuracy: 0.8225\n",
            "Epoch 1991/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4390 - accuracy: 0.8437 - val_loss: 0.6717 - val_accuracy: 0.8167\n",
            "Epoch 1992/2000\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4207 - accuracy: 0.8463 - val_loss: 0.6713 - val_accuracy: 0.8150\n",
            "Epoch 1993/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4637 - accuracy: 0.8320 - val_loss: 0.6536 - val_accuracy: 0.8158\n",
            "Epoch 1994/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4182 - accuracy: 0.8624 - val_loss: 0.6534 - val_accuracy: 0.8192\n",
            "Epoch 1995/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4010 - accuracy: 0.8480 - val_loss: 0.6867 - val_accuracy: 0.8108\n",
            "Epoch 1996/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4543 - accuracy: 0.8313 - val_loss: 0.6842 - val_accuracy: 0.8067\n",
            "Epoch 1997/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4108 - accuracy: 0.8571 - val_loss: 0.6312 - val_accuracy: 0.8400\n",
            "Epoch 1998/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4177 - accuracy: 0.8459 - val_loss: 0.7014 - val_accuracy: 0.8217\n",
            "Epoch 1999/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.3945 - accuracy: 0.8677 - val_loss: 0.6425 - val_accuracy: 0.8392\n",
            "Epoch 2000/2000\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.4178 - accuracy: 0.8520 - val_loss: 0.6769 - val_accuracy: 0.8275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwgqeszBPFDQ",
        "outputId": "3e66c652-14dd-40b5-836e-3b3abb66d5fa"
      },
      "source": [
        "# モデルの評価(位置)\n",
        "position_ne_score = position_ne_model.evaluate(X_ans_data, position_Y_ans_data, verbose=1)\n",
        "print('Test loss:', position_ne_score[0])\n",
        "print('Test accuracy:', position_ne_score[1])"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "317/317 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.8348\n",
            "Test loss: 0.5570282340049744\n",
            "Test accuracy: 0.8348469734191895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "vHbyV9vFQTgw",
        "outputId": "07fd3770-0015-49e8-b117-d896a6cf3ef6"
      },
      "source": [
        "# 学習経過の可視化(位置)\n",
        "position_loss     = position_ne_history.history['loss']\n",
        "position_val_loss = position_ne_history.history['val_loss']\n",
        "\n",
        "nb_epoch = len(position_loss)\n",
        "plt.plot(range(nb_epoch), position_loss,     marker='.', label='position_loss')\n",
        "plt.plot(range(nb_epoch), position_val_loss, marker='.', label='position_val_loss')\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "_KDeE4o9QdYi",
        "outputId": "e0b690d1-d2f4-4b53-ffa9-e9c41db793aa"
      },
      "source": [
        "# 学習経過の可視化(位置)\n",
        "position_acc     = position_ne_history.history['accuracy']\n",
        "position_val_acc = position_ne_history.history['val_accuracy']\n",
        "\n",
        "nb_epoch = len(position_acc)\n",
        "plt.plot(range(nb_epoch), position_acc,     marker='.', label='position_acc')\n",
        "plt.plot(range(nb_epoch), position_val_acc, marker='.', label='position_val_acc')\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.show()"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9qKjieqvx8b"
      },
      "source": [
        ""
      ],
      "execution_count": 241,
      "outputs": []
    }
  ]
}