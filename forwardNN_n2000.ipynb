{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forwardNN_n2000.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8DL8fsVPL2qy/s2/MJgGi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nomchanz/graduation_thesis_new/blob/main/forwardNN_n2000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97L2vb2JQR7l"
      },
      "source": [
        "# 必要なライブラリのimport\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Input, concatenate\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdDJ_XFBiu22"
      },
      "source": [
        "# データの準備、読み込み\n",
        "\n",
        "\n",
        "## データファイルのpath\n",
        "no_hole_path = 'no_hole_data.csv'\n",
        "one_hole_size_path = 'one_hole_size_data.csv'\n",
        "one_hole_position_path = 'one_hole_position_data.csv'\n",
        "four_holes_size_path = 'four_holes_size_data.csv'\n",
        "four_holes_position_path = 'four_holes_position_data.csv'\n",
        "nine_holes_size_path = 'nine_holes_size_data.csv'\n",
        "nine_holes_position_path = 'nine_holes_position_data.csv'\n",
        "sixteen_holes_size_path = 'sixteen_holes_size_data.csv'\n",
        "sixteen_holes_position_path = 'sixteen_holes_position_data.csv'\n",
        "twentyfive_holes_size_path = 'twentyfive_holes_size_data.csv'\n",
        "twentyfive_holes_position_path = 'twentyfive_holes_position_data.csv'\n",
        "\n",
        "\n",
        "## csvファイルをリスト化\n",
        "\n",
        "### 穴なしの温度分布データ\n",
        "with open(no_hole_path) as f0:\n",
        "  lst_f0 = list(csv.reader(f0))\n",
        "lst_f0 = [r[:-1] for r in lst_f0]\n",
        "\n",
        "### 大きさに関するデータ\n",
        "with open(one_hole_size_path) as fs1:\n",
        "  lst_fs1 = list(csv.reader(fs1))\n",
        "with open(four_holes_size_path) as fs2:\n",
        "  lst_fs2 = list(csv.reader(fs2))\n",
        "with open(nine_holes_size_path) as fs3:\n",
        "  lst_fs3 = list(csv.reader(fs3))\n",
        "with open(sixteen_holes_size_path) as fs4:\n",
        "  lst_fs4 = list(csv.reader(fs4))\n",
        "with open(twentyfive_holes_size_path) as fs5:\n",
        "  lst_fs5 = list(csv.reader(fs5))\n",
        "\n",
        "### 位置に関するデータ\n",
        "with open(one_hole_position_path) as fp1:\n",
        "  lst_fp1 = list(csv.reader(fp1))\n",
        "with open(four_holes_position_path) as fp2:\n",
        "  lst_fp2 = list(csv.reader(fp2))\n",
        "with open(nine_holes_position_path) as fp3:\n",
        "  lst_fp3 = list(csv.reader(fp3))\n",
        "with open(sixteen_holes_position_path) as fp4:\n",
        "  lst_fp4 = list(csv.reader(fp4))\n",
        "with open(twentyfive_holes_position_path) as fp5:\n",
        "  lst_fp5 = list(csv.reader(fp5))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zboAkcSShjrH"
      },
      "source": [
        "# model_1\n",
        "\n",
        "# データの前処理\n",
        "\n",
        "\n",
        "## 変数設定(各条件を変えてたくさん試すため)\n",
        "n = 2000                    #nは総抽出データ数\n",
        "train = 0.8                 #train:validのtrainデータの割合\n",
        "seed = 0                       \n",
        "random.seed(seed)           #乱数seed固定\n",
        "\n",
        "\n",
        "## データ加工\n",
        "\n",
        "### データ抽出(各データをランダムにシャッフル→train,valid,testに分割。各大きさのデータが同じ数だけ抽出される。)\n",
        "for i in range (1,6):\n",
        "  exec(\"lst_fs\"+str(i)+\"_shuffle = random.sample(lst_fs\"+str(i)+\", len(lst_fs\"+str(i)+\"))\")  \n",
        "  exec(\"lst_fs\"+str(i)+\"_train = lst_fs\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")       \n",
        "  exec(\"lst_fs\"+str(i)+\"_valid = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\")          \n",
        "  exec(\"lst_fs\"+str(i)+\"_test = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_shuffle = random.sample(lst_fp\"+str(i)+\", len(lst_fp\"+str(i)+\"))\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_train = lst_fp\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_valid = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\") \n",
        "  exec(\"lst_fp\"+str(i)+\"_test = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "\n",
        "### train,valid,testの各々について、大きさ、位置、表面温度分布データに分割\n",
        "for i in range (1,6):\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_train = [r[0] for r in lst_fs\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_train = [r[0] for r in lst_fp\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_train = [r[1:-1] for r in lst_fp\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_valid = [r[0] for r in lst_fs\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_valid = [r[0] for r in lst_fp\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_valid = [r[1:-1] for r in lst_fp\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_test = [r[0] for r in lst_fs\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_test = [r[0] for r in lst_fp\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_test = [r[1:-1] for r in lst_fp\"+str(i)+\"_test]\")\n",
        "\n",
        "### データを結合(入力データ・正解データの大枠完成)\n",
        "lst_x_fs_train = lst_x_fs1_train + lst_x_fs2_train + lst_x_fs3_train + lst_x_fs4_train + lst_x_fs5_train\n",
        "lst_x_fp_train = lst_x_fp1_train + lst_x_fp2_train + lst_x_fp3_train + lst_x_fp4_train + lst_x_fp5_train\n",
        "lst_y_train = lst_y1_train + lst_y2_train + lst_y3_train + lst_y4_train + lst_y5_train\n",
        "\n",
        "lst_x_fs_valid = lst_x_fs1_valid + lst_x_fs2_valid + lst_x_fs3_valid + lst_x_fs4_valid + lst_x_fs5_valid\n",
        "lst_x_fp_valid = lst_x_fp1_valid + lst_x_fp2_valid + lst_x_fp3_valid + lst_x_fp4_valid + lst_x_fp5_valid\n",
        "lst_y_valid = lst_y1_valid + lst_y2_valid + lst_y3_valid + lst_y4_valid + lst_y5_valid\n",
        "\n",
        "lst_x_fs_test = lst_x_fs1_test + lst_x_fs2_test + lst_x_fs3_test + lst_x_fs4_test + lst_x_fs5_test\n",
        "lst_x_fp_test = lst_x_fp1_test + lst_x_fp2_test + lst_x_fp3_test + lst_x_fp4_test + lst_x_fp5_test\n",
        "lst_y_test = lst_y1_test + lst_y2_test + lst_y3_test + lst_y4_test + lst_y5_test\n",
        "\n",
        "### np.arrayで変換\n",
        "lst_f0 = np.array(lst_f0, dtype=float)\n",
        "lst_x_fs_train = np.array(lst_x_fs_train, dtype=int)\n",
        "lst_x_fp_train = np.array(lst_x_fp_train, dtype=int)\n",
        "lst_x_fs_valid = np.array(lst_x_fs_valid, dtype=int)\n",
        "lst_x_fp_valid = np.array(lst_x_fp_valid, dtype=int)\n",
        "lst_x_fs_test = np.array(lst_x_fs_test, dtype=int)\n",
        "lst_x_fp_test = np.array(lst_x_fp_test, dtype=int)\n",
        "lst_y_train = np.array(lst_y_train, dtype=float)\n",
        "lst_y_valid = np.array(lst_y_valid, dtype=float)\n",
        "lst_y_test = np.array(lst_y_test, dtype=float)\n",
        "\n",
        "### 入力データを二次元化\n",
        "x_fs_train = lst_x_fs_train.reshape(-1, 1)\n",
        "x_fs_valid = lst_x_fs_valid.reshape(-1, 1)\n",
        "x_fs_test = lst_x_fs_test.reshape(-1, 1)\n",
        "x_fp_train = lst_x_fp_train.reshape(-1, 1)\n",
        "x_fp_valid = lst_x_fp_valid.reshape(-1, 1)\n",
        "x_fp_test = lst_x_fp_test.reshape(-1, 1)\n",
        "\n",
        "### 温度分布データを、穴なし温度分布データとの差に変換\n",
        "y_train = lst_y_train - lst_f0\n",
        "y_valid = lst_y_valid - lst_f0\n",
        "y_test = lst_y_test - lst_f0\n",
        "\n",
        "### 入力データの正規化\n",
        "scaler_x = MinMaxScaler()\n",
        "x_fs_train_n = scaler_x.fit_transform(x_fs_train)\n",
        "x_fs_valid_n = scaler_x.fit_transform(x_fs_valid)\n",
        "x_fs_test_n = scaler_x.fit_transform(x_fs_test) \n",
        "x_fp_train_n = scaler_x.fit_transform(x_fp_train)\n",
        "x_fp_valid_n = scaler_x.fit_transform(x_fp_valid)\n",
        "x_fp_test_n = scaler_x.fit_transform(x_fp_test) "
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MXVTgrQN4tf"
      },
      "source": [
        "# NN\n",
        "\n",
        "## 入力を定義\n",
        "input1 = Input(shape=(1,))\n",
        "input2 = Input(shape=(1,))\n",
        "\n",
        "## 入力1から結合前まで\n",
        "x = Dense(1, activation=\"linear\")(input1)\n",
        "x = Model(inputs=input1, outputs=x)\n",
        "\n",
        "## 入力2から結合前まで\n",
        "y = Dense(1, activation=\"linear\")(input2)\n",
        "y = Model(inputs=input2, outputs=y)\n",
        "\n",
        "## 結合\n",
        "combined = concatenate([x.output, y.output])\n",
        "\n",
        "## 密結合\n",
        "z = Dense(32, activation=\"relu\")(combined)\n",
        "z = Dense(512, activation=\"relu\")(z)\n",
        "z = Dense(256, activation=\"relu\")(z)\n",
        "z = Dense(128, activation=\"relu\")(z)\n",
        "z = Dense(50)(z)\n",
        "\n",
        "## モデル定義とコンパイル\n",
        "model_1 = Model(inputs=[x.input, y.input], outputs=z)\n",
        "model_1.compile(loss='mse', optimizer='adam', metrics=['mae'])"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDcudI4uQzJ_",
        "outputId": "6aefb27d-a0ef-4db9-985b-e643bf82812d"
      },
      "source": [
        "# 学習\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "history = model_1.fit([x_fs_train_n, x_fp_train_n], y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=([x_fs_valid_n, x_fp_valid_n], y_valid))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "25/25 [==============================] - 1s 16ms/step - loss: 0.3881 - mae: 0.2476 - val_loss: 0.2743 - val_mae: 0.1888\n",
            "Epoch 2/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4854 - mae: 0.1859 - val_loss: 0.2521 - val_mae: 0.1703\n",
            "Epoch 3/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3305 - mae: 0.1702 - val_loss: 0.2461 - val_mae: 0.1834\n",
            "Epoch 4/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.5759 - mae: 0.2035 - val_loss: 0.2507 - val_mae: 0.1776\n",
            "Epoch 5/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3597 - mae: 0.1841 - val_loss: 0.2512 - val_mae: 0.1893\n",
            "Epoch 6/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3072 - mae: 0.1859 - val_loss: 0.2529 - val_mae: 0.1870\n",
            "Epoch 7/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3534 - mae: 0.1835 - val_loss: 0.2513 - val_mae: 0.1854\n",
            "Epoch 8/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2033 - mae: 0.1573 - val_loss: 0.2739 - val_mae: 0.2206\n",
            "Epoch 9/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2538 - mae: 0.1775 - val_loss: 0.2362 - val_mae: 0.1758\n",
            "Epoch 10/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3811 - mae: 0.1777 - val_loss: 0.2292 - val_mae: 0.1675\n",
            "Epoch 11/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2051 - mae: 0.1432 - val_loss: 0.2484 - val_mae: 0.1976\n",
            "Epoch 12/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3037 - mae: 0.1693 - val_loss: 0.2274 - val_mae: 0.1659\n",
            "Epoch 13/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2327 - mae: 0.1540 - val_loss: 0.2307 - val_mae: 0.1933\n",
            "Epoch 14/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2450 - mae: 0.1621 - val_loss: 0.2583 - val_mae: 0.1976\n",
            "Epoch 15/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2193 - mae: 0.1566 - val_loss: 0.2456 - val_mae: 0.2021\n",
            "Epoch 16/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2686 - mae: 0.1694 - val_loss: 0.2286 - val_mae: 0.1834\n",
            "Epoch 17/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2258 - mae: 0.1559 - val_loss: 0.2269 - val_mae: 0.1773\n",
            "Epoch 18/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4771 - mae: 0.1921 - val_loss: 0.2205 - val_mae: 0.1669\n",
            "Epoch 19/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2523 - mae: 0.1541 - val_loss: 0.2051 - val_mae: 0.1652\n",
            "Epoch 20/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2653 - mae: 0.1675 - val_loss: 0.2040 - val_mae: 0.1627\n",
            "Epoch 21/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3787 - mae: 0.1677 - val_loss: 0.2170 - val_mae: 0.1601\n",
            "Epoch 22/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3326 - mae: 0.1759 - val_loss: 0.2072 - val_mae: 0.1553\n",
            "Epoch 23/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2176 - mae: 0.1438 - val_loss: 0.2690 - val_mae: 0.2203\n",
            "Epoch 24/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3439 - mae: 0.1856 - val_loss: 0.2005 - val_mae: 0.1601\n",
            "Epoch 25/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2942 - mae: 0.1679 - val_loss: 0.2194 - val_mae: 0.1682\n",
            "Epoch 26/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3149 - mae: 0.1650 - val_loss: 0.2123 - val_mae: 0.1851\n",
            "Epoch 27/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2707 - mae: 0.1629 - val_loss: 0.2026 - val_mae: 0.1624\n",
            "Epoch 28/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2593 - mae: 0.1422 - val_loss: 0.2029 - val_mae: 0.1652\n",
            "Epoch 29/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3799 - mae: 0.1784 - val_loss: 0.2028 - val_mae: 0.1613\n",
            "Epoch 30/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2817 - mae: 0.1557 - val_loss: 0.2066 - val_mae: 0.1632\n",
            "Epoch 31/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2368 - mae: 0.1462 - val_loss: 0.2136 - val_mae: 0.1677\n",
            "Epoch 32/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1995 - mae: 0.1428 - val_loss: 0.2194 - val_mae: 0.1682\n",
            "Epoch 33/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.2078 - mae: 0.1410 - val_loss: 0.2046 - val_mae: 0.1670\n",
            "Epoch 34/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3675 - mae: 0.1729 - val_loss: 0.2083 - val_mae: 0.1572\n",
            "Epoch 35/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2431 - mae: 0.1475 - val_loss: 0.2255 - val_mae: 0.1761\n",
            "Epoch 36/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1976 - mae: 0.1457 - val_loss: 0.2085 - val_mae: 0.1627\n",
            "Epoch 37/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2048 - mae: 0.1475 - val_loss: 0.2095 - val_mae: 0.1635\n",
            "Epoch 38/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2779 - mae: 0.1541 - val_loss: 0.2067 - val_mae: 0.1605\n",
            "Epoch 39/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3451 - mae: 0.1649 - val_loss: 0.2073 - val_mae: 0.1534\n",
            "Epoch 40/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2858 - mae: 0.1481 - val_loss: 0.2256 - val_mae: 0.1800\n",
            "Epoch 41/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3115 - mae: 0.1647 - val_loss: 0.2060 - val_mae: 0.1611\n",
            "Epoch 42/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3130 - mae: 0.1626 - val_loss: 0.2364 - val_mae: 0.1765\n",
            "Epoch 43/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2164 - mae: 0.1483 - val_loss: 0.2168 - val_mae: 0.1672\n",
            "Epoch 44/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2574 - mae: 0.1651 - val_loss: 0.1994 - val_mae: 0.1554\n",
            "Epoch 45/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2952 - mae: 0.1628 - val_loss: 0.2187 - val_mae: 0.1720\n",
            "Epoch 46/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1971 - mae: 0.1499 - val_loss: 0.2195 - val_mae: 0.1732\n",
            "Epoch 47/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2818 - mae: 0.1543 - val_loss: 0.1983 - val_mae: 0.1563\n",
            "Epoch 48/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3595 - mae: 0.1711 - val_loss: 0.2070 - val_mae: 0.1534\n",
            "Epoch 49/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1644 - mae: 0.1345 - val_loss: 0.2693 - val_mae: 0.1991\n",
            "Epoch 50/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2913 - mae: 0.1626 - val_loss: 0.2038 - val_mae: 0.1591\n",
            "Epoch 51/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2608 - mae: 0.1402 - val_loss: 0.2001 - val_mae: 0.1537\n",
            "Epoch 52/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2420 - mae: 0.1466 - val_loss: 0.2109 - val_mae: 0.1671\n",
            "Epoch 53/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1724 - mae: 0.1359 - val_loss: 0.2159 - val_mae: 0.1660\n",
            "Epoch 54/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1631 - mae: 0.1356 - val_loss: 0.2181 - val_mae: 0.1679\n",
            "Epoch 55/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1382 - mae: 0.1295 - val_loss: 0.2193 - val_mae: 0.1672\n",
            "Epoch 56/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2036 - mae: 0.1408 - val_loss: 0.2053 - val_mae: 0.1566\n",
            "Epoch 57/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1921 - mae: 0.1334 - val_loss: 0.2199 - val_mae: 0.1643\n",
            "Epoch 58/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2546 - mae: 0.1468 - val_loss: 0.2056 - val_mae: 0.1543\n",
            "Epoch 59/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2966 - mae: 0.1472 - val_loss: 0.1996 - val_mae: 0.1542\n",
            "Epoch 60/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3120 - mae: 0.1521 - val_loss: 0.2156 - val_mae: 0.1631\n",
            "Epoch 61/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2591 - mae: 0.1492 - val_loss: 0.2035 - val_mae: 0.1556\n",
            "Epoch 62/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1785 - mae: 0.1341 - val_loss: 0.2065 - val_mae: 0.1583\n",
            "Epoch 63/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1763 - mae: 0.1419 - val_loss: 0.2036 - val_mae: 0.1549\n",
            "Epoch 64/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2716 - mae: 0.1491 - val_loss: 0.2009 - val_mae: 0.1513\n",
            "Epoch 65/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1898 - mae: 0.1295 - val_loss: 0.2133 - val_mae: 0.1625\n",
            "Epoch 66/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2224 - mae: 0.1493 - val_loss: 0.2010 - val_mae: 0.1520\n",
            "Epoch 67/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1876 - mae: 0.1338 - val_loss: 0.2164 - val_mae: 0.1576\n",
            "Epoch 68/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3156 - mae: 0.1556 - val_loss: 0.2078 - val_mae: 0.1505\n",
            "Epoch 69/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1741 - mae: 0.1257 - val_loss: 0.2234 - val_mae: 0.1690\n",
            "Epoch 70/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2668 - mae: 0.1529 - val_loss: 0.2083 - val_mae: 0.1561\n",
            "Epoch 71/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3038 - mae: 0.1532 - val_loss: 0.2032 - val_mae: 0.1521\n",
            "Epoch 72/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2524 - mae: 0.1478 - val_loss: 0.2097 - val_mae: 0.1618\n",
            "Epoch 73/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1729 - mae: 0.1409 - val_loss: 0.2162 - val_mae: 0.1660\n",
            "Epoch 74/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1774 - mae: 0.1376 - val_loss: 0.2009 - val_mae: 0.1504\n",
            "Epoch 75/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1789 - mae: 0.1336 - val_loss: 0.3231 - val_mae: 0.2098\n",
            "Epoch 76/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3633 - mae: 0.1974 - val_loss: 0.2451 - val_mae: 0.1861\n",
            "Epoch 77/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2442 - mae: 0.1557 - val_loss: 0.2148 - val_mae: 0.1730\n",
            "Epoch 78/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3466 - mae: 0.1658 - val_loss: 0.2005 - val_mae: 0.1514\n",
            "Epoch 79/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2384 - mae: 0.1484 - val_loss: 0.2067 - val_mae: 0.1612\n",
            "Epoch 80/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2721 - mae: 0.1536 - val_loss: 0.2070 - val_mae: 0.1589\n",
            "Epoch 81/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1273 - mae: 0.1271 - val_loss: 0.2073 - val_mae: 0.1567\n",
            "Epoch 82/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4054 - mae: 0.1782 - val_loss: 0.1959 - val_mae: 0.1472\n",
            "Epoch 83/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2547 - mae: 0.1398 - val_loss: 0.2027 - val_mae: 0.1570\n",
            "Epoch 84/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1912 - mae: 0.1436 - val_loss: 0.2235 - val_mae: 0.1610\n",
            "Epoch 85/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2667 - mae: 0.1573 - val_loss: 0.2117 - val_mae: 0.1550\n",
            "Epoch 86/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2602 - mae: 0.1391 - val_loss: 0.2044 - val_mae: 0.1507\n",
            "Epoch 87/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2817 - mae: 0.1501 - val_loss: 0.2117 - val_mae: 0.1582\n",
            "Epoch 88/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2952 - mae: 0.1584 - val_loss: 0.2055 - val_mae: 0.1496\n",
            "Epoch 89/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3410 - mae: 0.1536 - val_loss: 0.1973 - val_mae: 0.1441\n",
            "Epoch 90/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1935 - mae: 0.1281 - val_loss: 0.2137 - val_mae: 0.1613\n",
            "Epoch 91/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.2154 - mae: 0.1452 - val_loss: 0.1969 - val_mae: 0.1478\n",
            "Epoch 92/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1753 - mae: 0.1343 - val_loss: 0.2134 - val_mae: 0.1544\n",
            "Epoch 93/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1677 - mae: 0.1322 - val_loss: 0.2235 - val_mae: 0.1602\n",
            "Epoch 94/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3137 - mae: 0.1597 - val_loss: 0.2160 - val_mae: 0.1541\n",
            "Epoch 95/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2584 - mae: 0.1389 - val_loss: 0.2260 - val_mae: 0.1574\n",
            "Epoch 96/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2172 - mae: 0.1328 - val_loss: 0.2092 - val_mae: 0.1493\n",
            "Epoch 97/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2390 - mae: 0.1414 - val_loss: 0.2077 - val_mae: 0.1459\n",
            "Epoch 98/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1488 - mae: 0.1203 - val_loss: 0.2214 - val_mae: 0.1575\n",
            "Epoch 99/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3487 - mae: 0.1617 - val_loss: 0.2066 - val_mae: 0.1453\n",
            "Epoch 100/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4213 - mae: 0.1559 - val_loss: 0.1955 - val_mae: 0.1392\n",
            "Epoch 101/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1614 - mae: 0.1228 - val_loss: 0.2090 - val_mae: 0.1513\n",
            "Epoch 102/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1613 - mae: 0.1268 - val_loss: 0.2155 - val_mae: 0.1525\n",
            "Epoch 103/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1711 - mae: 0.1280 - val_loss: 0.2163 - val_mae: 0.1542\n",
            "Epoch 104/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2587 - mae: 0.1437 - val_loss: 0.2011 - val_mae: 0.1441\n",
            "Epoch 105/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2161 - mae: 0.1364 - val_loss: 0.2117 - val_mae: 0.1464\n",
            "Epoch 106/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2107 - mae: 0.1371 - val_loss: 0.2144 - val_mae: 0.1479\n",
            "Epoch 107/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1561 - mae: 0.1198 - val_loss: 0.2148 - val_mae: 0.1476\n",
            "Epoch 108/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2744 - mae: 0.1413 - val_loss: 0.2164 - val_mae: 0.1499\n",
            "Epoch 109/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2642 - mae: 0.1381 - val_loss: 0.2066 - val_mae: 0.1445\n",
            "Epoch 110/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2039 - mae: 0.1320 - val_loss: 0.2134 - val_mae: 0.1467\n",
            "Epoch 111/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2217 - mae: 0.1323 - val_loss: 0.2129 - val_mae: 0.1454\n",
            "Epoch 112/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2541 - mae: 0.1406 - val_loss: 0.2067 - val_mae: 0.1436\n",
            "Epoch 113/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2208 - mae: 0.1302 - val_loss: 0.2072 - val_mae: 0.1430\n",
            "Epoch 114/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2780 - mae: 0.1381 - val_loss: 0.2072 - val_mae: 0.1425\n",
            "Epoch 115/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2114 - mae: 0.1261 - val_loss: 0.2098 - val_mae: 0.1453\n",
            "Epoch 116/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2015 - mae: 0.1320 - val_loss: 0.1975 - val_mae: 0.1389\n",
            "Epoch 117/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2978 - mae: 0.1391 - val_loss: 0.2157 - val_mae: 0.1452\n",
            "Epoch 118/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1943 - mae: 0.1273 - val_loss: 0.2201 - val_mae: 0.1480\n",
            "Epoch 119/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2727 - mae: 0.1456 - val_loss: 0.2016 - val_mae: 0.1366\n",
            "Epoch 120/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1562 - mae: 0.1188 - val_loss: 0.2149 - val_mae: 0.1449\n",
            "Epoch 121/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2082 - mae: 0.1257 - val_loss: 0.2101 - val_mae: 0.1444\n",
            "Epoch 122/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2444 - mae: 0.1270 - val_loss: 0.2092 - val_mae: 0.1421\n",
            "Epoch 123/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2764 - mae: 0.1343 - val_loss: 0.1987 - val_mae: 0.1351\n",
            "Epoch 124/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2967 - mae: 0.1306 - val_loss: 0.2034 - val_mae: 0.1409\n",
            "Epoch 125/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2530 - mae: 0.1334 - val_loss: 0.2059 - val_mae: 0.1422\n",
            "Epoch 126/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3672 - mae: 0.1424 - val_loss: 0.2062 - val_mae: 0.1420\n",
            "Epoch 127/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2009 - mae: 0.1182 - val_loss: 0.2112 - val_mae: 0.1443\n",
            "Epoch 128/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3500 - mae: 0.1498 - val_loss: 0.1952 - val_mae: 0.1308\n",
            "Epoch 129/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2093 - mae: 0.1217 - val_loss: 0.2145 - val_mae: 0.1543\n",
            "Epoch 130/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2255 - mae: 0.1349 - val_loss: 0.2028 - val_mae: 0.1429\n",
            "Epoch 131/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1708 - mae: 0.1212 - val_loss: 0.2100 - val_mae: 0.1430\n",
            "Epoch 132/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2587 - mae: 0.1398 - val_loss: 0.2061 - val_mae: 0.1391\n",
            "Epoch 133/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2469 - mae: 0.1272 - val_loss: 0.2174 - val_mae: 0.1449\n",
            "Epoch 134/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2289 - mae: 0.1302 - val_loss: 0.2105 - val_mae: 0.1387\n",
            "Epoch 135/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3235 - mae: 0.1436 - val_loss: 0.1972 - val_mae: 0.1318\n",
            "Epoch 136/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2176 - mae: 0.1181 - val_loss: 0.1955 - val_mae: 0.1356\n",
            "Epoch 137/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1454 - mae: 0.1105 - val_loss: 0.2083 - val_mae: 0.1424\n",
            "Epoch 138/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1424 - mae: 0.1170 - val_loss: 0.2154 - val_mae: 0.1427\n",
            "Epoch 139/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1784 - mae: 0.1165 - val_loss: 0.2101 - val_mae: 0.1388\n",
            "Epoch 140/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1367 - mae: 0.1099 - val_loss: 0.2108 - val_mae: 0.1497\n",
            "Epoch 141/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2064 - mae: 0.1358 - val_loss: 0.2182 - val_mae: 0.1455\n",
            "Epoch 142/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2139 - mae: 0.1307 - val_loss: 0.2052 - val_mae: 0.1333\n",
            "Epoch 143/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1940 - mae: 0.1156 - val_loss: 0.2126 - val_mae: 0.1385\n",
            "Epoch 144/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1903 - mae: 0.1218 - val_loss: 0.2107 - val_mae: 0.1376\n",
            "Epoch 145/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2788 - mae: 0.1326 - val_loss: 0.2115 - val_mae: 0.1345\n",
            "Epoch 146/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1874 - mae: 0.1114 - val_loss: 0.2089 - val_mae: 0.1378\n",
            "Epoch 147/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1797 - mae: 0.1170 - val_loss: 0.2101 - val_mae: 0.1381\n",
            "Epoch 148/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2202 - mae: 0.1249 - val_loss: 0.2030 - val_mae: 0.1318\n",
            "Epoch 149/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2617 - mae: 0.1274 - val_loss: 0.2003 - val_mae: 0.1308\n",
            "Epoch 150/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2837 - mae: 0.1322 - val_loss: 0.2020 - val_mae: 0.1344\n",
            "Epoch 151/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2327 - mae: 0.1267 - val_loss: 0.1935 - val_mae: 0.1298\n",
            "Epoch 152/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1680 - mae: 0.1172 - val_loss: 0.2092 - val_mae: 0.1349\n",
            "Epoch 153/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2074 - mae: 0.1209 - val_loss: 0.2159 - val_mae: 0.1380\n",
            "Epoch 154/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1863 - mae: 0.1165 - val_loss: 0.2164 - val_mae: 0.1355\n",
            "Epoch 155/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3160 - mae: 0.1360 - val_loss: 0.2069 - val_mae: 0.1378\n",
            "Epoch 156/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1533 - mae: 0.1084 - val_loss: 0.2059 - val_mae: 0.1379\n",
            "Epoch 157/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2199 - mae: 0.1261 - val_loss: 0.2025 - val_mae: 0.1336\n",
            "Epoch 158/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3157 - mae: 0.1294 - val_loss: 0.2112 - val_mae: 0.1356\n",
            "Epoch 159/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2015 - mae: 0.1147 - val_loss: 0.2024 - val_mae: 0.1336\n",
            "Epoch 160/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2432 - mae: 0.1295 - val_loss: 0.2045 - val_mae: 0.1335\n",
            "Epoch 161/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.3107 - mae: 0.1320 - val_loss: 0.2100 - val_mae: 0.1354\n",
            "Epoch 162/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2784 - mae: 0.1394 - val_loss: 0.2090 - val_mae: 0.1341\n",
            "Epoch 163/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1271 - mae: 0.1033 - val_loss: 0.2060 - val_mae: 0.1377\n",
            "Epoch 164/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3500 - mae: 0.1462 - val_loss: 0.1984 - val_mae: 0.1275\n",
            "Epoch 165/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2233 - mae: 0.1202 - val_loss: 0.2151 - val_mae: 0.1400\n",
            "Epoch 166/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1584 - mae: 0.1139 - val_loss: 0.1967 - val_mae: 0.1260\n",
            "Epoch 167/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1619 - mae: 0.1097 - val_loss: 0.1975 - val_mae: 0.1281\n",
            "Epoch 168/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2614 - mae: 0.1253 - val_loss: 0.2194 - val_mae: 0.1344\n",
            "Epoch 169/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3081 - mae: 0.1298 - val_loss: 0.2051 - val_mae: 0.1285\n",
            "Epoch 170/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1672 - mae: 0.1055 - val_loss: 0.2190 - val_mae: 0.1396\n",
            "Epoch 171/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2679 - mae: 0.1297 - val_loss: 0.2102 - val_mae: 0.1320\n",
            "Epoch 172/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2083 - mae: 0.1142 - val_loss: 0.2024 - val_mae: 0.1297\n",
            "Epoch 173/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1489 - mae: 0.1008 - val_loss: 0.2177 - val_mae: 0.1350\n",
            "Epoch 174/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1887 - mae: 0.1125 - val_loss: 0.1966 - val_mae: 0.1243\n",
            "Epoch 175/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2751 - mae: 0.1246 - val_loss: 0.2125 - val_mae: 0.1328\n",
            "Epoch 176/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1852 - mae: 0.1124 - val_loss: 0.2006 - val_mae: 0.1304\n",
            "Epoch 177/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2132 - mae: 0.1163 - val_loss: 0.2120 - val_mae: 0.1352\n",
            "Epoch 178/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3506 - mae: 0.1324 - val_loss: 0.2022 - val_mae: 0.1272\n",
            "Epoch 179/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2393 - mae: 0.1154 - val_loss: 0.2004 - val_mae: 0.1276\n",
            "Epoch 180/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1709 - mae: 0.1109 - val_loss: 0.2164 - val_mae: 0.1373\n",
            "Epoch 181/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2997 - mae: 0.1274 - val_loss: 0.1981 - val_mae: 0.1260\n",
            "Epoch 182/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1533 - mae: 0.1020 - val_loss: 0.2018 - val_mae: 0.1331\n",
            "Epoch 183/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1661 - mae: 0.1142 - val_loss: 0.2102 - val_mae: 0.1343\n",
            "Epoch 184/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3392 - mae: 0.1376 - val_loss: 0.2021 - val_mae: 0.1291\n",
            "Epoch 185/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2212 - mae: 0.1175 - val_loss: 0.2086 - val_mae: 0.1287\n",
            "Epoch 186/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1943 - mae: 0.1088 - val_loss: 0.2050 - val_mae: 0.1292\n",
            "Epoch 187/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2295 - mae: 0.1197 - val_loss: 0.2140 - val_mae: 0.1320\n",
            "Epoch 188/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2855 - mae: 0.1178 - val_loss: 0.1999 - val_mae: 0.1282\n",
            "Epoch 189/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2328 - mae: 0.1167 - val_loss: 0.2193 - val_mae: 0.1369\n",
            "Epoch 190/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4017 - mae: 0.1475 - val_loss: 0.2043 - val_mae: 0.1274\n",
            "Epoch 191/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1413 - mae: 0.0999 - val_loss: 0.2008 - val_mae: 0.1287\n",
            "Epoch 192/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2354 - mae: 0.1207 - val_loss: 0.2207 - val_mae: 0.1342\n",
            "Epoch 193/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2138 - mae: 0.1234 - val_loss: 0.1987 - val_mae: 0.1277\n",
            "Epoch 194/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3242 - mae: 0.1233 - val_loss: 0.2089 - val_mae: 0.1300\n",
            "Epoch 195/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2756 - mae: 0.1245 - val_loss: 0.2042 - val_mae: 0.1353\n",
            "Epoch 196/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2231 - mae: 0.1208 - val_loss: 0.2094 - val_mae: 0.1325\n",
            "Epoch 197/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2697 - mae: 0.1260 - val_loss: 0.2031 - val_mae: 0.1344\n",
            "Epoch 198/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2076 - mae: 0.1138 - val_loss: 0.1970 - val_mae: 0.1273\n",
            "Epoch 199/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1978 - mae: 0.1154 - val_loss: 0.2041 - val_mae: 0.1294\n",
            "Epoch 200/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1855 - mae: 0.1122 - val_loss: 0.2128 - val_mae: 0.1324\n",
            "Epoch 201/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1869 - mae: 0.1120 - val_loss: 0.2056 - val_mae: 0.1283\n",
            "Epoch 202/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2154 - mae: 0.1120 - val_loss: 0.2082 - val_mae: 0.1302\n",
            "Epoch 203/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1764 - mae: 0.1098 - val_loss: 0.2116 - val_mae: 0.1281\n",
            "Epoch 204/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2959 - mae: 0.1372 - val_loss: 0.2014 - val_mae: 0.1268\n",
            "Epoch 205/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2695 - mae: 0.1259 - val_loss: 0.1971 - val_mae: 0.1252\n",
            "Epoch 206/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2889 - mae: 0.1177 - val_loss: 0.2093 - val_mae: 0.1292\n",
            "Epoch 207/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2156 - mae: 0.1157 - val_loss: 0.2063 - val_mae: 0.1282\n",
            "Epoch 208/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2065 - mae: 0.1188 - val_loss: 0.2040 - val_mae: 0.1299\n",
            "Epoch 209/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2167 - mae: 0.1215 - val_loss: 0.2035 - val_mae: 0.1267\n",
            "Epoch 210/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2201 - mae: 0.1189 - val_loss: 0.2083 - val_mae: 0.1326\n",
            "Epoch 211/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2127 - mae: 0.1181 - val_loss: 0.2109 - val_mae: 0.1331\n",
            "Epoch 212/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1460 - mae: 0.1042 - val_loss: 0.2135 - val_mae: 0.1305\n",
            "Epoch 213/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2064 - mae: 0.1127 - val_loss: 0.1937 - val_mae: 0.1239\n",
            "Epoch 214/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2978 - mae: 0.1247 - val_loss: 0.1860 - val_mae: 0.1182\n",
            "Epoch 215/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4018 - mae: 0.1474 - val_loss: 0.1967 - val_mae: 0.1442\n",
            "Epoch 216/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1733 - mae: 0.1339 - val_loss: 0.2192 - val_mae: 0.1407\n",
            "Epoch 217/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1749 - mae: 0.1113 - val_loss: 0.2102 - val_mae: 0.1313\n",
            "Epoch 218/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1822 - mae: 0.1138 - val_loss: 0.2399 - val_mae: 0.1460\n",
            "Epoch 219/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2172 - mae: 0.1271 - val_loss: 0.1944 - val_mae: 0.1233\n",
            "Epoch 220/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2264 - mae: 0.1177 - val_loss: 0.2000 - val_mae: 0.1258\n",
            "Epoch 221/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1999 - mae: 0.1159 - val_loss: 0.2059 - val_mae: 0.1295\n",
            "Epoch 222/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2559 - mae: 0.1194 - val_loss: 0.1942 - val_mae: 0.1200\n",
            "Epoch 223/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2938 - mae: 0.1197 - val_loss: 0.2013 - val_mae: 0.1262\n",
            "Epoch 224/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1696 - mae: 0.1066 - val_loss: 0.1949 - val_mae: 0.1248\n",
            "Epoch 225/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2190 - mae: 0.1187 - val_loss: 0.2034 - val_mae: 0.1265\n",
            "Epoch 226/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2134 - mae: 0.1125 - val_loss: 0.2102 - val_mae: 0.1292\n",
            "Epoch 227/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3233 - mae: 0.1281 - val_loss: 0.2039 - val_mae: 0.1243\n",
            "Epoch 228/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2734 - mae: 0.1189 - val_loss: 0.1946 - val_mae: 0.1256\n",
            "Epoch 229/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2952 - mae: 0.1269 - val_loss: 0.2069 - val_mae: 0.1276\n",
            "Epoch 230/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1520 - mae: 0.1084 - val_loss: 0.1957 - val_mae: 0.1234\n",
            "Epoch 231/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2131 - mae: 0.1241 - val_loss: 0.2181 - val_mae: 0.1326\n",
            "Epoch 232/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2566 - mae: 0.1154 - val_loss: 0.2044 - val_mae: 0.1242\n",
            "Epoch 233/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.1852 - mae: 0.1055 - val_loss: 0.2046 - val_mae: 0.1288\n",
            "Epoch 234/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1931 - mae: 0.1138 - val_loss: 0.2132 - val_mae: 0.1298\n",
            "Epoch 235/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2426 - mae: 0.1148 - val_loss: 0.1975 - val_mae: 0.1233\n",
            "Epoch 236/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3151 - mae: 0.1351 - val_loss: 0.2078 - val_mae: 0.1278\n",
            "Epoch 237/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1489 - mae: 0.1003 - val_loss: 0.2040 - val_mae: 0.1244\n",
            "Epoch 238/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1480 - mae: 0.0979 - val_loss: 0.2099 - val_mae: 0.1280\n",
            "Epoch 239/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2656 - mae: 0.1261 - val_loss: 0.2158 - val_mae: 0.1325\n",
            "Epoch 240/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1803 - mae: 0.1142 - val_loss: 0.2074 - val_mae: 0.1277\n",
            "Epoch 241/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3201 - mae: 0.1382 - val_loss: 0.2012 - val_mae: 0.1241\n",
            "Epoch 242/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2945 - mae: 0.1193 - val_loss: 0.2109 - val_mae: 0.1277\n",
            "Epoch 243/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1954 - mae: 0.1086 - val_loss: 0.2004 - val_mae: 0.1233\n",
            "Epoch 244/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1724 - mae: 0.1059 - val_loss: 0.2123 - val_mae: 0.1309\n",
            "Epoch 245/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1683 - mae: 0.1072 - val_loss: 0.2035 - val_mae: 0.1273\n",
            "Epoch 246/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1853 - mae: 0.1122 - val_loss: 0.2081 - val_mae: 0.1261\n",
            "Epoch 247/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1583 - mae: 0.0991 - val_loss: 0.2110 - val_mae: 0.1285\n",
            "Epoch 248/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2293 - mae: 0.1187 - val_loss: 0.2060 - val_mae: 0.1253\n",
            "Epoch 249/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1947 - mae: 0.1105 - val_loss: 0.2231 - val_mae: 0.1335\n",
            "Epoch 250/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3048 - mae: 0.1238 - val_loss: 0.2022 - val_mae: 0.1216\n",
            "Epoch 251/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2395 - mae: 0.1111 - val_loss: 0.2049 - val_mae: 0.1260\n",
            "Epoch 252/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3320 - mae: 0.1332 - val_loss: 0.1991 - val_mae: 0.1244\n",
            "Epoch 253/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2237 - mae: 0.1136 - val_loss: 0.2074 - val_mae: 0.1263\n",
            "Epoch 254/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2237 - mae: 0.1099 - val_loss: 0.2158 - val_mae: 0.1290\n",
            "Epoch 255/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2923 - mae: 0.1168 - val_loss: 0.2028 - val_mae: 0.1221\n",
            "Epoch 256/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2363 - mae: 0.1163 - val_loss: 0.2036 - val_mae: 0.1265\n",
            "Epoch 257/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1910 - mae: 0.1046 - val_loss: 0.2133 - val_mae: 0.1275\n",
            "Epoch 258/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2951 - mae: 0.1245 - val_loss: 0.1943 - val_mae: 0.1194\n",
            "Epoch 259/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2406 - mae: 0.1179 - val_loss: 0.2006 - val_mae: 0.1235\n",
            "Epoch 260/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2130 - mae: 0.1088 - val_loss: 0.2118 - val_mae: 0.1280\n",
            "Epoch 261/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2730 - mae: 0.1313 - val_loss: 0.2042 - val_mae: 0.1221\n",
            "Epoch 262/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2402 - mae: 0.1117 - val_loss: 0.2018 - val_mae: 0.1211\n",
            "Epoch 263/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2052 - mae: 0.1073 - val_loss: 0.2055 - val_mae: 0.1242\n",
            "Epoch 264/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2862 - mae: 0.1191 - val_loss: 0.2068 - val_mae: 0.1226\n",
            "Epoch 265/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3422 - mae: 0.1278 - val_loss: 0.2014 - val_mae: 0.1230\n",
            "Epoch 266/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1905 - mae: 0.1067 - val_loss: 0.2074 - val_mae: 0.1269\n",
            "Epoch 267/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2567 - mae: 0.1121 - val_loss: 0.2057 - val_mae: 0.1236\n",
            "Epoch 268/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2487 - mae: 0.1164 - val_loss: 0.2023 - val_mae: 0.1212\n",
            "Epoch 269/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1647 - mae: 0.1072 - val_loss: 0.2020 - val_mae: 0.1242\n",
            "Epoch 270/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3584 - mae: 0.1334 - val_loss: 0.2114 - val_mae: 0.1271\n",
            "Epoch 271/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3145 - mae: 0.1307 - val_loss: 0.1995 - val_mae: 0.1314\n",
            "Epoch 272/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2088 - mae: 0.1146 - val_loss: 0.2136 - val_mae: 0.1349\n",
            "Epoch 273/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4011 - mae: 0.1369 - val_loss: 0.1955 - val_mae: 0.1202\n",
            "Epoch 274/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2215 - mae: 0.1057 - val_loss: 0.2047 - val_mae: 0.1253\n",
            "Epoch 275/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1759 - mae: 0.1095 - val_loss: 0.2004 - val_mae: 0.1224\n",
            "Epoch 276/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2738 - mae: 0.1176 - val_loss: 0.2102 - val_mae: 0.1263\n",
            "Epoch 277/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1855 - mae: 0.1000 - val_loss: 0.2018 - val_mae: 0.1239\n",
            "Epoch 278/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2219 - mae: 0.1119 - val_loss: 0.2085 - val_mae: 0.1294\n",
            "Epoch 279/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2184 - mae: 0.1139 - val_loss: 0.2166 - val_mae: 0.1271\n",
            "Epoch 280/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2221 - mae: 0.1089 - val_loss: 0.2021 - val_mae: 0.1229\n",
            "Epoch 281/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1319 - mae: 0.0933 - val_loss: 0.2137 - val_mae: 0.1279\n",
            "Epoch 282/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1772 - mae: 0.1030 - val_loss: 0.2090 - val_mae: 0.1266\n",
            "Epoch 283/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1892 - mae: 0.1098 - val_loss: 0.2068 - val_mae: 0.1261\n",
            "Epoch 284/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3496 - mae: 0.1286 - val_loss: 0.2104 - val_mae: 0.1234\n",
            "Epoch 285/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1825 - mae: 0.1010 - val_loss: 0.2044 - val_mae: 0.1248\n",
            "Epoch 286/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2667 - mae: 0.1235 - val_loss: 0.2105 - val_mae: 0.1277\n",
            "Epoch 287/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1520 - mae: 0.1001 - val_loss: 0.1936 - val_mae: 0.1188\n",
            "Epoch 288/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1460 - mae: 0.0997 - val_loss: 0.2097 - val_mae: 0.1296\n",
            "Epoch 289/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.2116 - mae: 0.1134 - val_loss: 0.1980 - val_mae: 0.1193\n",
            "Epoch 290/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1929 - mae: 0.1056 - val_loss: 0.2068 - val_mae: 0.1232\n",
            "Epoch 291/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2157 - mae: 0.1119 - val_loss: 0.2093 - val_mae: 0.1240\n",
            "Epoch 292/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2255 - mae: 0.1100 - val_loss: 0.2063 - val_mae: 0.1243\n",
            "Epoch 293/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2268 - mae: 0.1105 - val_loss: 0.2161 - val_mae: 0.1264\n",
            "Epoch 294/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2351 - mae: 0.1146 - val_loss: 0.2021 - val_mae: 0.1218\n",
            "Epoch 295/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2452 - mae: 0.1098 - val_loss: 0.2004 - val_mae: 0.1222\n",
            "Epoch 296/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3108 - mae: 0.1275 - val_loss: 0.2052 - val_mae: 0.1217\n",
            "Epoch 297/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1831 - mae: 0.1040 - val_loss: 0.2021 - val_mae: 0.1242\n",
            "Epoch 298/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2298 - mae: 0.1150 - val_loss: 0.2071 - val_mae: 0.1250\n",
            "Epoch 299/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2082 - mae: 0.1145 - val_loss: 0.2193 - val_mae: 0.1318\n",
            "Epoch 300/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1719 - mae: 0.1079 - val_loss: 0.2062 - val_mae: 0.1254\n",
            "Epoch 301/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2097 - mae: 0.1133 - val_loss: 0.2036 - val_mae: 0.1225\n",
            "Epoch 302/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1854 - mae: 0.1065 - val_loss: 0.2079 - val_mae: 0.1239\n",
            "Epoch 303/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3283 - mae: 0.1255 - val_loss: 0.2043 - val_mae: 0.1232\n",
            "Epoch 304/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2780 - mae: 0.1166 - val_loss: 0.2106 - val_mae: 0.1240\n",
            "Epoch 305/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3402 - mae: 0.1274 - val_loss: 0.1931 - val_mae: 0.1196\n",
            "Epoch 306/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3724 - mae: 0.1357 - val_loss: 0.2028 - val_mae: 0.1232\n",
            "Epoch 307/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1958 - mae: 0.1048 - val_loss: 0.2132 - val_mae: 0.1271\n",
            "Epoch 308/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2028 - mae: 0.1095 - val_loss: 0.2068 - val_mae: 0.1241\n",
            "Epoch 309/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1283 - mae: 0.0923 - val_loss: 0.2008 - val_mae: 0.1225\n",
            "Epoch 310/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2488 - mae: 0.1188 - val_loss: 0.2149 - val_mae: 0.1266\n",
            "Epoch 311/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1919 - mae: 0.1121 - val_loss: 0.2005 - val_mae: 0.1205\n",
            "Epoch 312/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2056 - mae: 0.1046 - val_loss: 0.2091 - val_mae: 0.1297\n",
            "Epoch 313/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1457 - mae: 0.0977 - val_loss: 0.2006 - val_mae: 0.1204\n",
            "Epoch 314/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1352 - mae: 0.0948 - val_loss: 0.2015 - val_mae: 0.1223\n",
            "Epoch 315/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1920 - mae: 0.1046 - val_loss: 0.2242 - val_mae: 0.1310\n",
            "Epoch 316/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2824 - mae: 0.1199 - val_loss: 0.2057 - val_mae: 0.1216\n",
            "Epoch 317/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2346 - mae: 0.1142 - val_loss: 0.1993 - val_mae: 0.1186\n",
            "Epoch 318/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2558 - mae: 0.1134 - val_loss: 0.2086 - val_mae: 0.1241\n",
            "Epoch 319/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1522 - mae: 0.0972 - val_loss: 0.1975 - val_mae: 0.1187\n",
            "Epoch 320/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1743 - mae: 0.1013 - val_loss: 0.2107 - val_mae: 0.1248\n",
            "Epoch 321/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2665 - mae: 0.1128 - val_loss: 0.2068 - val_mae: 0.1218\n",
            "Epoch 322/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3198 - mae: 0.1218 - val_loss: 0.2013 - val_mae: 0.1215\n",
            "Epoch 323/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2944 - mae: 0.1165 - val_loss: 0.2023 - val_mae: 0.1192\n",
            "Epoch 324/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1776 - mae: 0.0996 - val_loss: 0.1965 - val_mae: 0.1188\n",
            "Epoch 325/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1321 - mae: 0.1030 - val_loss: 0.1936 - val_mae: 0.1187\n",
            "Epoch 326/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2842 - mae: 0.1185 - val_loss: 0.2121 - val_mae: 0.1281\n",
            "Epoch 327/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1487 - mae: 0.0995 - val_loss: 0.1980 - val_mae: 0.1281\n",
            "Epoch 328/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2120 - mae: 0.1149 - val_loss: 0.2065 - val_mae: 0.1258\n",
            "Epoch 329/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2311 - mae: 0.1163 - val_loss: 0.2056 - val_mae: 0.1235\n",
            "Epoch 330/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2808 - mae: 0.1209 - val_loss: 0.2028 - val_mae: 0.1227\n",
            "Epoch 331/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2568 - mae: 0.1164 - val_loss: 0.1944 - val_mae: 0.1212\n",
            "Epoch 332/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1353 - mae: 0.0955 - val_loss: 0.2073 - val_mae: 0.1267\n",
            "Epoch 333/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2422 - mae: 0.1118 - val_loss: 0.2147 - val_mae: 0.1259\n",
            "Epoch 334/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2537 - mae: 0.1200 - val_loss: 0.2002 - val_mae: 0.1231\n",
            "Epoch 335/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3204 - mae: 0.1216 - val_loss: 0.1944 - val_mae: 0.1168\n",
            "Epoch 336/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2139 - mae: 0.1142 - val_loss: 0.2076 - val_mae: 0.1238\n",
            "Epoch 337/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1969 - mae: 0.1069 - val_loss: 0.2069 - val_mae: 0.1234\n",
            "Epoch 338/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2184 - mae: 0.1146 - val_loss: 0.2015 - val_mae: 0.1209\n",
            "Epoch 339/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1693 - mae: 0.1066 - val_loss: 0.1995 - val_mae: 0.1195\n",
            "Epoch 340/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2903 - mae: 0.1156 - val_loss: 0.2012 - val_mae: 0.1199\n",
            "Epoch 341/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3266 - mae: 0.1144 - val_loss: 0.2041 - val_mae: 0.1204\n",
            "Epoch 342/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1760 - mae: 0.0951 - val_loss: 0.2017 - val_mae: 0.1224\n",
            "Epoch 343/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3596 - mae: 0.1283 - val_loss: 0.2123 - val_mae: 0.1228\n",
            "Epoch 344/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3367 - mae: 0.1213 - val_loss: 0.1966 - val_mae: 0.1168\n",
            "Epoch 345/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.2181 - mae: 0.1117 - val_loss: 0.2114 - val_mae: 0.1296\n",
            "Epoch 346/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2451 - mae: 0.1189 - val_loss: 0.2079 - val_mae: 0.1232\n",
            "Epoch 347/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2481 - mae: 0.1153 - val_loss: 0.2115 - val_mae: 0.1237\n",
            "Epoch 348/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1611 - mae: 0.0971 - val_loss: 0.2023 - val_mae: 0.1205\n",
            "Epoch 349/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1483 - mae: 0.1004 - val_loss: 0.2083 - val_mae: 0.1253\n",
            "Epoch 350/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1969 - mae: 0.1067 - val_loss: 0.2202 - val_mae: 0.1281\n",
            "Epoch 351/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2011 - mae: 0.1063 - val_loss: 0.1966 - val_mae: 0.1193\n",
            "Epoch 352/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1608 - mae: 0.0947 - val_loss: 0.2091 - val_mae: 0.1250\n",
            "Epoch 353/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1486 - mae: 0.0991 - val_loss: 0.1993 - val_mae: 0.1200\n",
            "Epoch 354/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1935 - mae: 0.1054 - val_loss: 0.2142 - val_mae: 0.1238\n",
            "Epoch 355/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2679 - mae: 0.1248 - val_loss: 0.2113 - val_mae: 0.1225\n",
            "Epoch 356/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1495 - mae: 0.0932 - val_loss: 0.1992 - val_mae: 0.1171\n",
            "Epoch 357/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3205 - mae: 0.1147 - val_loss: 0.2072 - val_mae: 0.1239\n",
            "Epoch 358/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1678 - mae: 0.1093 - val_loss: 0.1974 - val_mae: 0.1264\n",
            "Epoch 359/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2376 - mae: 0.1197 - val_loss: 0.2019 - val_mae: 0.1211\n",
            "Epoch 360/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2480 - mae: 0.1162 - val_loss: 0.2098 - val_mae: 0.1241\n",
            "Epoch 361/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4123 - mae: 0.1340 - val_loss: 0.1984 - val_mae: 0.1213\n",
            "Epoch 362/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2194 - mae: 0.1151 - val_loss: 0.2051 - val_mae: 0.1235\n",
            "Epoch 363/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1928 - mae: 0.1073 - val_loss: 0.2109 - val_mae: 0.1246\n",
            "Epoch 364/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2700 - mae: 0.1245 - val_loss: 0.1984 - val_mae: 0.1187\n",
            "Epoch 365/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3272 - mae: 0.1155 - val_loss: 0.2083 - val_mae: 0.1222\n",
            "Epoch 366/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2692 - mae: 0.1160 - val_loss: 0.1965 - val_mae: 0.1204\n",
            "Epoch 367/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1769 - mae: 0.0983 - val_loss: 0.2032 - val_mae: 0.1211\n",
            "Epoch 368/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2865 - mae: 0.1125 - val_loss: 0.2042 - val_mae: 0.1209\n",
            "Epoch 369/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2034 - mae: 0.1043 - val_loss: 0.2030 - val_mae: 0.1218\n",
            "Epoch 370/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2437 - mae: 0.1139 - val_loss: 0.2006 - val_mae: 0.1186\n",
            "Epoch 371/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2905 - mae: 0.1179 - val_loss: 0.2095 - val_mae: 0.1228\n",
            "Epoch 372/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1758 - mae: 0.1049 - val_loss: 0.1983 - val_mae: 0.1191\n",
            "Epoch 373/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1761 - mae: 0.1061 - val_loss: 0.2041 - val_mae: 0.1210\n",
            "Epoch 374/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1980 - mae: 0.1030 - val_loss: 0.2177 - val_mae: 0.1353\n",
            "Epoch 375/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2334 - mae: 0.1187 - val_loss: 0.2091 - val_mae: 0.1243\n",
            "Epoch 376/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2295 - mae: 0.1147 - val_loss: 0.2104 - val_mae: 0.1225\n",
            "Epoch 377/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3023 - mae: 0.1096 - val_loss: 0.2077 - val_mae: 0.1226\n",
            "Epoch 378/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2621 - mae: 0.1163 - val_loss: 0.2057 - val_mae: 0.1220\n",
            "Epoch 379/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1743 - mae: 0.1042 - val_loss: 0.2016 - val_mae: 0.1244\n",
            "Epoch 380/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2983 - mae: 0.1208 - val_loss: 0.2041 - val_mae: 0.1195\n",
            "Epoch 381/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2926 - mae: 0.1208 - val_loss: 0.2072 - val_mae: 0.1205\n",
            "Epoch 382/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2303 - mae: 0.1069 - val_loss: 0.2084 - val_mae: 0.1218\n",
            "Epoch 383/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2846 - mae: 0.1189 - val_loss: 0.2035 - val_mae: 0.1198\n",
            "Epoch 384/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2041 - mae: 0.1026 - val_loss: 0.2047 - val_mae: 0.1246\n",
            "Epoch 385/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2538 - mae: 0.1108 - val_loss: 0.2073 - val_mae: 0.1214\n",
            "Epoch 386/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2993 - mae: 0.1178 - val_loss: 0.1985 - val_mae: 0.1181\n",
            "Epoch 387/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3677 - mae: 0.1360 - val_loss: 0.2101 - val_mae: 0.1241\n",
            "Epoch 388/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1777 - mae: 0.1028 - val_loss: 0.2083 - val_mae: 0.1236\n",
            "Epoch 389/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2328 - mae: 0.1109 - val_loss: 0.2079 - val_mae: 0.1239\n",
            "Epoch 390/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1826 - mae: 0.1009 - val_loss: 0.2017 - val_mae: 0.1225\n",
            "Epoch 391/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1830 - mae: 0.1026 - val_loss: 0.2136 - val_mae: 0.1254\n",
            "Epoch 392/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2591 - mae: 0.1168 - val_loss: 0.2029 - val_mae: 0.1214\n",
            "Epoch 393/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1211 - mae: 0.0867 - val_loss: 0.2040 - val_mae: 0.1247\n",
            "Epoch 394/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2527 - mae: 0.1214 - val_loss: 0.2123 - val_mae: 0.1237\n",
            "Epoch 395/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1748 - mae: 0.1058 - val_loss: 0.2127 - val_mae: 0.1314\n",
            "Epoch 396/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2946 - mae: 0.1373 - val_loss: 0.2130 - val_mae: 0.1257\n",
            "Epoch 397/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2559 - mae: 0.1154 - val_loss: 0.2078 - val_mae: 0.1229\n",
            "Epoch 398/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2146 - mae: 0.1035 - val_loss: 0.2026 - val_mae: 0.1213\n",
            "Epoch 399/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3204 - mae: 0.1205 - val_loss: 0.2092 - val_mae: 0.1229\n",
            "Epoch 400/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3090 - mae: 0.1204 - val_loss: 0.1940 - val_mae: 0.1171\n",
            "Epoch 401/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.2421 - mae: 0.1143 - val_loss: 0.2125 - val_mae: 0.1228\n",
            "Epoch 402/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2526 - mae: 0.1134 - val_loss: 0.2090 - val_mae: 0.1209\n",
            "Epoch 403/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2035 - mae: 0.1011 - val_loss: 0.2114 - val_mae: 0.1247\n",
            "Epoch 404/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2405 - mae: 0.1197 - val_loss: 0.1956 - val_mae: 0.1171\n",
            "Epoch 405/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3506 - mae: 0.1212 - val_loss: 0.2078 - val_mae: 0.1236\n",
            "Epoch 406/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1801 - mae: 0.1041 - val_loss: 0.1936 - val_mae: 0.1151\n",
            "Epoch 407/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1489 - mae: 0.0924 - val_loss: 0.2111 - val_mae: 0.1253\n",
            "Epoch 408/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2215 - mae: 0.1104 - val_loss: 0.2072 - val_mae: 0.1199\n",
            "Epoch 409/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2650 - mae: 0.1164 - val_loss: 0.1998 - val_mae: 0.1213\n",
            "Epoch 410/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2881 - mae: 0.1168 - val_loss: 0.2073 - val_mae: 0.1209\n",
            "Epoch 411/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3132 - mae: 0.1211 - val_loss: 0.2038 - val_mae: 0.1198\n",
            "Epoch 412/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2091 - mae: 0.1051 - val_loss: 0.1960 - val_mae: 0.1158\n",
            "Epoch 413/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2410 - mae: 0.1067 - val_loss: 0.2076 - val_mae: 0.1204\n",
            "Epoch 414/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3330 - mae: 0.1185 - val_loss: 0.2016 - val_mae: 0.1186\n",
            "Epoch 415/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2430 - mae: 0.1075 - val_loss: 0.2059 - val_mae: 0.1217\n",
            "Epoch 416/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1910 - mae: 0.1051 - val_loss: 0.2054 - val_mae: 0.1213\n",
            "Epoch 417/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1856 - mae: 0.1014 - val_loss: 0.2122 - val_mae: 0.1225\n",
            "Epoch 418/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2643 - mae: 0.1135 - val_loss: 0.2155 - val_mae: 0.1233\n",
            "Epoch 419/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2573 - mae: 0.1134 - val_loss: 0.2032 - val_mae: 0.1183\n",
            "Epoch 420/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2348 - mae: 0.1129 - val_loss: 0.2059 - val_mae: 0.1218\n",
            "Epoch 421/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2481 - mae: 0.1153 - val_loss: 0.2056 - val_mae: 0.1231\n",
            "Epoch 422/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2219 - mae: 0.1209 - val_loss: 0.2017 - val_mae: 0.1184\n",
            "Epoch 423/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1925 - mae: 0.1011 - val_loss: 0.2032 - val_mae: 0.1186\n",
            "Epoch 424/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2644 - mae: 0.1133 - val_loss: 0.2135 - val_mae: 0.1215\n",
            "Epoch 425/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2743 - mae: 0.1111 - val_loss: 0.2126 - val_mae: 0.1213\n",
            "Epoch 426/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2127 - mae: 0.1056 - val_loss: 0.1950 - val_mae: 0.1172\n",
            "Epoch 427/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2900 - mae: 0.1146 - val_loss: 0.2034 - val_mae: 0.1211\n",
            "Epoch 428/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2018 - mae: 0.1106 - val_loss: 0.2075 - val_mae: 0.1344\n",
            "Epoch 429/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1968 - mae: 0.1110 - val_loss: 0.2026 - val_mae: 0.1227\n",
            "Epoch 430/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2183 - mae: 0.1095 - val_loss: 0.2115 - val_mae: 0.1231\n",
            "Epoch 431/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2551 - mae: 0.1147 - val_loss: 0.1977 - val_mae: 0.1174\n",
            "Epoch 432/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2687 - mae: 0.1118 - val_loss: 0.2034 - val_mae: 0.1212\n",
            "Epoch 433/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3073 - mae: 0.1191 - val_loss: 0.2057 - val_mae: 0.1194\n",
            "Epoch 434/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1821 - mae: 0.1041 - val_loss: 0.2040 - val_mae: 0.1263\n",
            "Epoch 435/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2093 - mae: 0.1052 - val_loss: 0.2066 - val_mae: 0.1241\n",
            "Epoch 436/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1460 - mae: 0.0972 - val_loss: 0.2002 - val_mae: 0.1192\n",
            "Epoch 437/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2176 - mae: 0.1041 - val_loss: 0.2036 - val_mae: 0.1184\n",
            "Epoch 438/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1718 - mae: 0.1019 - val_loss: 0.1953 - val_mae: 0.1174\n",
            "Epoch 439/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1499 - mae: 0.0911 - val_loss: 0.2090 - val_mae: 0.1207\n",
            "Epoch 440/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1507 - mae: 0.1029 - val_loss: 0.1997 - val_mae: 0.1179\n",
            "Epoch 441/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2683 - mae: 0.1225 - val_loss: 0.2090 - val_mae: 0.1199\n",
            "Epoch 442/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1937 - mae: 0.0985 - val_loss: 0.2065 - val_mae: 0.1214\n",
            "Epoch 443/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2031 - mae: 0.0978 - val_loss: 0.2073 - val_mae: 0.1201\n",
            "Epoch 444/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1500 - mae: 0.0984 - val_loss: 0.2050 - val_mae: 0.1200\n",
            "Epoch 445/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2121 - mae: 0.1096 - val_loss: 0.2178 - val_mae: 0.1242\n",
            "Epoch 446/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3019 - mae: 0.1121 - val_loss: 0.2097 - val_mae: 0.1199\n",
            "Epoch 447/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2328 - mae: 0.1080 - val_loss: 0.1971 - val_mae: 0.1169\n",
            "Epoch 448/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1454 - mae: 0.0975 - val_loss: 0.2053 - val_mae: 0.1206\n",
            "Epoch 449/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1695 - mae: 0.0913 - val_loss: 0.2042 - val_mae: 0.1183\n",
            "Epoch 450/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2153 - mae: 0.1090 - val_loss: 0.2068 - val_mae: 0.1198\n",
            "Epoch 451/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1256 - mae: 0.0887 - val_loss: 0.2033 - val_mae: 0.1172\n",
            "Epoch 452/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1544 - mae: 0.0958 - val_loss: 0.1986 - val_mae: 0.1157\n",
            "Epoch 453/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2089 - mae: 0.1039 - val_loss: 0.2082 - val_mae: 0.1214\n",
            "Epoch 454/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2873 - mae: 0.1193 - val_loss: 0.2114 - val_mae: 0.1215\n",
            "Epoch 455/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1981 - mae: 0.1031 - val_loss: 0.1989 - val_mae: 0.1177\n",
            "Epoch 456/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2046 - mae: 0.1048 - val_loss: 0.2093 - val_mae: 0.1246\n",
            "Epoch 457/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.1586 - mae: 0.0988 - val_loss: 0.2081 - val_mae: 0.1208\n",
            "Epoch 458/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1692 - mae: 0.0966 - val_loss: 0.2091 - val_mae: 0.1194\n",
            "Epoch 459/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2147 - mae: 0.1081 - val_loss: 0.2026 - val_mae: 0.1176\n",
            "Epoch 460/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1493 - mae: 0.0957 - val_loss: 0.2085 - val_mae: 0.1214\n",
            "Epoch 461/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2673 - mae: 0.1157 - val_loss: 0.2151 - val_mae: 0.1240\n",
            "Epoch 462/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1662 - mae: 0.0966 - val_loss: 0.2058 - val_mae: 0.1186\n",
            "Epoch 463/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2160 - mae: 0.0972 - val_loss: 0.2085 - val_mae: 0.1183\n",
            "Epoch 464/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2612 - mae: 0.1102 - val_loss: 0.2053 - val_mae: 0.1186\n",
            "Epoch 465/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2074 - mae: 0.1048 - val_loss: 0.2018 - val_mae: 0.1179\n",
            "Epoch 466/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2957 - mae: 0.1122 - val_loss: 0.2041 - val_mae: 0.1190\n",
            "Epoch 467/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2147 - mae: 0.1009 - val_loss: 0.2081 - val_mae: 0.1190\n",
            "Epoch 468/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.1022 - val_loss: 0.2078 - val_mae: 0.1240\n",
            "Epoch 469/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2092 - mae: 0.1083 - val_loss: 0.2095 - val_mae: 0.1216\n",
            "Epoch 470/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1629 - mae: 0.0971 - val_loss: 0.2071 - val_mae: 0.1202\n",
            "Epoch 471/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2334 - mae: 0.1115 - val_loss: 0.2129 - val_mae: 0.1210\n",
            "Epoch 472/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2935 - mae: 0.1075 - val_loss: 0.2069 - val_mae: 0.1189\n",
            "Epoch 473/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2612 - mae: 0.1078 - val_loss: 0.2004 - val_mae: 0.1173\n",
            "Epoch 474/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2446 - mae: 0.1060 - val_loss: 0.2032 - val_mae: 0.1189\n",
            "Epoch 475/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2270 - mae: 0.1054 - val_loss: 0.2071 - val_mae: 0.1207\n",
            "Epoch 476/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3195 - mae: 0.1174 - val_loss: 0.2057 - val_mae: 0.1203\n",
            "Epoch 477/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2226 - mae: 0.1075 - val_loss: 0.2118 - val_mae: 0.1235\n",
            "Epoch 478/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1577 - mae: 0.0955 - val_loss: 0.2092 - val_mae: 0.1197\n",
            "Epoch 479/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2047 - mae: 0.1060 - val_loss: 0.2119 - val_mae: 0.1227\n",
            "Epoch 480/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1853 - mae: 0.1057 - val_loss: 0.2055 - val_mae: 0.1186\n",
            "Epoch 481/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2817 - mae: 0.1082 - val_loss: 0.2115 - val_mae: 0.1199\n",
            "Epoch 482/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2346 - mae: 0.1122 - val_loss: 0.1996 - val_mae: 0.1161\n",
            "Epoch 483/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1718 - mae: 0.0967 - val_loss: 0.2072 - val_mae: 0.1202\n",
            "Epoch 484/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2379 - mae: 0.1087 - val_loss: 0.2106 - val_mae: 0.1226\n",
            "Epoch 485/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3852 - mae: 0.1349 - val_loss: 0.2079 - val_mae: 0.1179\n",
            "Epoch 486/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2802 - mae: 0.1202 - val_loss: 0.2024 - val_mae: 0.1199\n",
            "Epoch 487/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2451 - mae: 0.1100 - val_loss: 0.1901 - val_mae: 0.1215\n",
            "Epoch 488/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2605 - mae: 0.1411 - val_loss: 0.2241 - val_mae: 0.1551\n",
            "Epoch 489/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1458 - mae: 0.1088 - val_loss: 0.2026 - val_mae: 0.1269\n",
            "Epoch 490/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4643 - mae: 0.1404 - val_loss: 0.2055 - val_mae: 0.1230\n",
            "Epoch 491/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4330 - mae: 0.1370 - val_loss: 0.2008 - val_mae: 0.1176\n",
            "Epoch 492/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2123 - mae: 0.1058 - val_loss: 0.2017 - val_mae: 0.1232\n",
            "Epoch 493/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1759 - mae: 0.1055 - val_loss: 0.1999 - val_mae: 0.1205\n",
            "Epoch 494/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2030 - mae: 0.1103 - val_loss: 0.2134 - val_mae: 0.1245\n",
            "Epoch 495/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1840 - mae: 0.1070 - val_loss: 0.2052 - val_mae: 0.1173\n",
            "Epoch 496/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1987 - mae: 0.1072 - val_loss: 0.2086 - val_mae: 0.1210\n",
            "Epoch 497/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2174 - mae: 0.1006 - val_loss: 0.2099 - val_mae: 0.1201\n",
            "Epoch 498/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1711 - mae: 0.0989 - val_loss: 0.2078 - val_mae: 0.1209\n",
            "Epoch 499/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2960 - mae: 0.1215 - val_loss: 0.2081 - val_mae: 0.1194\n",
            "Epoch 500/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1547 - mae: 0.0996 - val_loss: 0.1995 - val_mae: 0.1201\n",
            "Epoch 501/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1817 - mae: 0.1061 - val_loss: 0.2118 - val_mae: 0.1227\n",
            "Epoch 502/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2372 - mae: 0.1116 - val_loss: 0.1963 - val_mae: 0.1151\n",
            "Epoch 503/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1643 - mae: 0.1004 - val_loss: 0.2055 - val_mae: 0.1187\n",
            "Epoch 504/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2466 - mae: 0.1162 - val_loss: 0.2175 - val_mae: 0.1223\n",
            "Epoch 505/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1895 - mae: 0.1050 - val_loss: 0.2098 - val_mae: 0.1197\n",
            "Epoch 506/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2511 - mae: 0.1050 - val_loss: 0.2095 - val_mae: 0.1196\n",
            "Epoch 507/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2418 - mae: 0.1150 - val_loss: 0.2097 - val_mae: 0.1211\n",
            "Epoch 508/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2026 - mae: 0.1112 - val_loss: 0.2015 - val_mae: 0.1171\n",
            "Epoch 509/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2051 - mae: 0.0979 - val_loss: 0.2100 - val_mae: 0.1189\n",
            "Epoch 510/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1863 - mae: 0.0982 - val_loss: 0.2013 - val_mae: 0.1166\n",
            "Epoch 511/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2394 - mae: 0.1098 - val_loss: 0.2157 - val_mae: 0.1220\n",
            "Epoch 512/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2696 - mae: 0.1095 - val_loss: 0.2009 - val_mae: 0.1164\n",
            "Epoch 513/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2541 - mae: 0.1185 - val_loss: 0.2071 - val_mae: 0.1210\n",
            "Epoch 514/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2326 - mae: 0.1089 - val_loss: 0.2056 - val_mae: 0.1173\n",
            "Epoch 515/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1909 - mae: 0.0984 - val_loss: 0.2055 - val_mae: 0.1186\n",
            "Epoch 516/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2190 - mae: 0.1068 - val_loss: 0.2123 - val_mae: 0.1207\n",
            "Epoch 517/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1363 - mae: 0.0966 - val_loss: 0.1938 - val_mae: 0.1137\n",
            "Epoch 518/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2336 - mae: 0.1036 - val_loss: 0.2160 - val_mae: 0.1220\n",
            "Epoch 519/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1874 - mae: 0.1050 - val_loss: 0.2051 - val_mae: 0.1180\n",
            "Epoch 520/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2259 - mae: 0.1074 - val_loss: 0.2124 - val_mae: 0.1194\n",
            "Epoch 521/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1160 - mae: 0.0807 - val_loss: 0.2003 - val_mae: 0.1171\n",
            "Epoch 522/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2000 - mae: 0.1038 - val_loss: 0.2130 - val_mae: 0.1216\n",
            "Epoch 523/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2522 - mae: 0.1037 - val_loss: 0.2020 - val_mae: 0.1154\n",
            "Epoch 524/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2228 - mae: 0.1072 - val_loss: 0.2072 - val_mae: 0.1189\n",
            "Epoch 525/2000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2375 - mae: 0.1129 - val_loss: 0.2108 - val_mae: 0.1229\n",
            "Epoch 526/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.3074 - mae: 0.1197 - val_loss: 0.2091 - val_mae: 0.1183\n",
            "Epoch 527/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1930 - mae: 0.0963 - val_loss: 0.2127 - val_mae: 0.1199\n",
            "Epoch 528/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2202 - mae: 0.1094 - val_loss: 0.1984 - val_mae: 0.1160\n",
            "Epoch 529/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2135 - mae: 0.0972 - val_loss: 0.2052 - val_mae: 0.1200\n",
            "Epoch 530/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3330 - mae: 0.1194 - val_loss: 0.2101 - val_mae: 0.1214\n",
            "Epoch 531/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2367 - mae: 0.1014 - val_loss: 0.2093 - val_mae: 0.1189\n",
            "Epoch 532/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1845 - mae: 0.0942 - val_loss: 0.2052 - val_mae: 0.1173\n",
            "Epoch 533/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2331 - mae: 0.1076 - val_loss: 0.2045 - val_mae: 0.1213\n",
            "Epoch 534/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2596 - mae: 0.1101 - val_loss: 0.2015 - val_mae: 0.1156\n",
            "Epoch 535/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1936 - mae: 0.0987 - val_loss: 0.2053 - val_mae: 0.1201\n",
            "Epoch 536/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3570 - mae: 0.1251 - val_loss: 0.2112 - val_mae: 0.1191\n",
            "Epoch 537/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1661 - mae: 0.0976 - val_loss: 0.2011 - val_mae: 0.1176\n",
            "Epoch 538/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1808 - mae: 0.1022 - val_loss: 0.2092 - val_mae: 0.1194\n",
            "Epoch 539/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1985 - mae: 0.1031 - val_loss: 0.2106 - val_mae: 0.1202\n",
            "Epoch 540/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1670 - mae: 0.0997 - val_loss: 0.2036 - val_mae: 0.1192\n",
            "Epoch 541/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2151 - mae: 0.1142 - val_loss: 0.2127 - val_mae: 0.1223\n",
            "Epoch 542/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2261 - mae: 0.1182 - val_loss: 0.2059 - val_mae: 0.1183\n",
            "Epoch 543/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2424 - mae: 0.1092 - val_loss: 0.2033 - val_mae: 0.1202\n",
            "Epoch 544/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3116 - mae: 0.1395 - val_loss: 0.3564 - val_mae: 0.2225\n",
            "Epoch 545/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2827 - mae: 0.1586 - val_loss: 0.2044 - val_mae: 0.1397\n",
            "Epoch 546/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2732 - mae: 0.1369 - val_loss: 0.1899 - val_mae: 0.1302\n",
            "Epoch 547/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2072 - mae: 0.1164 - val_loss: 0.1860 - val_mae: 0.1250\n",
            "Epoch 548/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1869 - mae: 0.1131 - val_loss: 0.1880 - val_mae: 0.1265\n",
            "Epoch 549/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1961 - mae: 0.1210 - val_loss: 0.2103 - val_mae: 0.1433\n",
            "Epoch 550/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2672 - mae: 0.1342 - val_loss: 0.2000 - val_mae: 0.1335\n",
            "Epoch 551/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1378 - mae: 0.1128 - val_loss: 0.2278 - val_mae: 0.1638\n",
            "Epoch 552/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2569 - mae: 0.1428 - val_loss: 0.2137 - val_mae: 0.1413\n",
            "Epoch 553/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2368 - mae: 0.1199 - val_loss: 0.2015 - val_mae: 0.1323\n",
            "Epoch 554/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2521 - mae: 0.1241 - val_loss: 0.2100 - val_mae: 0.1347\n",
            "Epoch 555/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3653 - mae: 0.1362 - val_loss: 0.2016 - val_mae: 0.1303\n",
            "Epoch 556/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1896 - mae: 0.1151 - val_loss: 0.2085 - val_mae: 0.1453\n",
            "Epoch 557/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2609 - mae: 0.1318 - val_loss: 0.2042 - val_mae: 0.1277\n",
            "Epoch 558/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1654 - mae: 0.1101 - val_loss: 0.2054 - val_mae: 0.1283\n",
            "Epoch 559/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2151 - mae: 0.1153 - val_loss: 0.2187 - val_mae: 0.1295\n",
            "Epoch 560/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1880 - mae: 0.1160 - val_loss: 0.2049 - val_mae: 0.1322\n",
            "Epoch 561/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2071 - mae: 0.1158 - val_loss: 0.2173 - val_mae: 0.1286\n",
            "Epoch 562/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2790 - mae: 0.1213 - val_loss: 0.2069 - val_mae: 0.1242\n",
            "Epoch 563/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1904 - mae: 0.1123 - val_loss: 0.1981 - val_mae: 0.1242\n",
            "Epoch 564/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2199 - mae: 0.1144 - val_loss: 0.2063 - val_mae: 0.1217\n",
            "Epoch 565/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2281 - mae: 0.1092 - val_loss: 0.2101 - val_mae: 0.1233\n",
            "Epoch 566/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1581 - mae: 0.1021 - val_loss: 0.1989 - val_mae: 0.1190\n",
            "Epoch 567/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1144 - mae: 0.0911 - val_loss: 0.2068 - val_mae: 0.1223\n",
            "Epoch 568/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1869 - mae: 0.0986 - val_loss: 0.2163 - val_mae: 0.1265\n",
            "Epoch 569/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1961 - mae: 0.1078 - val_loss: 0.1982 - val_mae: 0.1234\n",
            "Epoch 570/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2049 - mae: 0.1054 - val_loss: 0.2079 - val_mae: 0.1219\n",
            "Epoch 571/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2193 - mae: 0.1054 - val_loss: 0.2143 - val_mae: 0.1281\n",
            "Epoch 572/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1228 - mae: 0.0897 - val_loss: 0.2003 - val_mae: 0.1198\n",
            "Epoch 573/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2537 - mae: 0.1200 - val_loss: 0.2155 - val_mae: 0.1237\n",
            "Epoch 574/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2048 - mae: 0.1094 - val_loss: 0.2090 - val_mae: 0.1218\n",
            "Epoch 575/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2033 - mae: 0.1044 - val_loss: 0.2083 - val_mae: 0.1221\n",
            "Epoch 576/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2156 - mae: 0.1032 - val_loss: 0.2095 - val_mae: 0.1222\n",
            "Epoch 577/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2081 - mae: 0.1052 - val_loss: 0.2103 - val_mae: 0.1241\n",
            "Epoch 578/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2978 - mae: 0.1226 - val_loss: 0.2062 - val_mae: 0.1209\n",
            "Epoch 579/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1714 - mae: 0.1003 - val_loss: 0.2033 - val_mae: 0.1225\n",
            "Epoch 580/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2098 - mae: 0.1105 - val_loss: 0.2104 - val_mae: 0.1215\n",
            "Epoch 581/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3396 - mae: 0.1259 - val_loss: 0.2021 - val_mae: 0.1186\n",
            "Epoch 582/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1590 - mae: 0.0985 - val_loss: 0.2064 - val_mae: 0.1239\n",
            "Epoch 583/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2490 - mae: 0.1176 - val_loss: 0.2070 - val_mae: 0.1211\n",
            "Epoch 584/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2425 - mae: 0.1141 - val_loss: 0.2074 - val_mae: 0.1220\n",
            "Epoch 585/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2369 - mae: 0.1059 - val_loss: 0.2028 - val_mae: 0.1194\n",
            "Epoch 586/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.1798 - mae: 0.0967 - val_loss: 0.2163 - val_mae: 0.1252\n",
            "Epoch 587/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1753 - mae: 0.1013 - val_loss: 0.2019 - val_mae: 0.1183\n",
            "Epoch 588/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1938 - mae: 0.1041 - val_loss: 0.2050 - val_mae: 0.1214\n",
            "Epoch 589/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1985 - mae: 0.1047 - val_loss: 0.2077 - val_mae: 0.1226\n",
            "Epoch 590/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2509 - mae: 0.1108 - val_loss: 0.2124 - val_mae: 0.1244\n",
            "Epoch 591/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3064 - mae: 0.1148 - val_loss: 0.2069 - val_mae: 0.1222\n",
            "Epoch 592/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1993 - mae: 0.1005 - val_loss: 0.2031 - val_mae: 0.1191\n",
            "Epoch 593/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2749 - mae: 0.1124 - val_loss: 0.2116 - val_mae: 0.1210\n",
            "Epoch 594/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2187 - mae: 0.1089 - val_loss: 0.2012 - val_mae: 0.1198\n",
            "Epoch 595/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2223 - mae: 0.1088 - val_loss: 0.2091 - val_mae: 0.1191\n",
            "Epoch 596/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2890 - mae: 0.1142 - val_loss: 0.2088 - val_mae: 0.1223\n",
            "Epoch 597/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1502 - mae: 0.0970 - val_loss: 0.2019 - val_mae: 0.1205\n",
            "Epoch 598/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1869 - mae: 0.1039 - val_loss: 0.2052 - val_mae: 0.1208\n",
            "Epoch 599/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1793 - mae: 0.1008 - val_loss: 0.2140 - val_mae: 0.1233\n",
            "Epoch 600/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1729 - mae: 0.0999 - val_loss: 0.2021 - val_mae: 0.1229\n",
            "Epoch 601/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2544 - mae: 0.1117 - val_loss: 0.2085 - val_mae: 0.1226\n",
            "Epoch 602/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1962 - mae: 0.1078 - val_loss: 0.1956 - val_mae: 0.1171\n",
            "Epoch 603/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1912 - mae: 0.1042 - val_loss: 0.2123 - val_mae: 0.1245\n",
            "Epoch 604/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2247 - mae: 0.1057 - val_loss: 0.2090 - val_mae: 0.1201\n",
            "Epoch 605/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2295 - mae: 0.1101 - val_loss: 0.2064 - val_mae: 0.1216\n",
            "Epoch 606/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4350 - mae: 0.1348 - val_loss: 0.2040 - val_mae: 0.1192\n",
            "Epoch 607/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3615 - mae: 0.1261 - val_loss: 0.2049 - val_mae: 0.1186\n",
            "Epoch 608/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2081 - mae: 0.1034 - val_loss: 0.2103 - val_mae: 0.1220\n",
            "Epoch 609/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2140 - mae: 0.1099 - val_loss: 0.2045 - val_mae: 0.1196\n",
            "Epoch 610/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1334 - mae: 0.0969 - val_loss: 0.2004 - val_mae: 0.1210\n",
            "Epoch 611/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2373 - mae: 0.1113 - val_loss: 0.2158 - val_mae: 0.1233\n",
            "Epoch 612/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1910 - mae: 0.1093 - val_loss: 0.2010 - val_mae: 0.1186\n",
            "Epoch 613/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3026 - mae: 0.1315 - val_loss: 0.2063 - val_mae: 0.1233\n",
            "Epoch 614/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2926 - mae: 0.1241 - val_loss: 0.2140 - val_mae: 0.1243\n",
            "Epoch 615/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2545 - mae: 0.1116 - val_loss: 0.2071 - val_mae: 0.1195\n",
            "Epoch 616/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1236 - mae: 0.0905 - val_loss: 0.2049 - val_mae: 0.1185\n",
            "Epoch 617/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1792 - mae: 0.0974 - val_loss: 0.2102 - val_mae: 0.1226\n",
            "Epoch 618/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2699 - mae: 0.1080 - val_loss: 0.2121 - val_mae: 0.1227\n",
            "Epoch 619/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1689 - mae: 0.0986 - val_loss: 0.2022 - val_mae: 0.1170\n",
            "Epoch 620/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3424 - mae: 0.1155 - val_loss: 0.2080 - val_mae: 0.1209\n",
            "Epoch 621/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2371 - mae: 0.1151 - val_loss: 0.2019 - val_mae: 0.1203\n",
            "Epoch 622/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2054 - mae: 0.1060 - val_loss: 0.2086 - val_mae: 0.1212\n",
            "Epoch 623/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2047 - mae: 0.1095 - val_loss: 0.2095 - val_mae: 0.1214\n",
            "Epoch 624/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2395 - mae: 0.1137 - val_loss: 0.2148 - val_mae: 0.1218\n",
            "Epoch 625/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2763 - mae: 0.1104 - val_loss: 0.2056 - val_mae: 0.1196\n",
            "Epoch 626/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2629 - mae: 0.1087 - val_loss: 0.2031 - val_mae: 0.1170\n",
            "Epoch 627/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1916 - mae: 0.1005 - val_loss: 0.2005 - val_mae: 0.1171\n",
            "Epoch 628/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1655 - mae: 0.0905 - val_loss: 0.2061 - val_mae: 0.1230\n",
            "Epoch 629/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2903 - mae: 0.1232 - val_loss: 0.2050 - val_mae: 0.1194\n",
            "Epoch 630/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2144 - mae: 0.1051 - val_loss: 0.2042 - val_mae: 0.1182\n",
            "Epoch 631/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2888 - mae: 0.1207 - val_loss: 0.2128 - val_mae: 0.1226\n",
            "Epoch 632/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1703 - mae: 0.0953 - val_loss: 0.2049 - val_mae: 0.1195\n",
            "Epoch 633/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2250 - mae: 0.1049 - val_loss: 0.2071 - val_mae: 0.1182\n",
            "Epoch 634/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1879 - mae: 0.1051 - val_loss: 0.2071 - val_mae: 0.1211\n",
            "Epoch 635/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2395 - mae: 0.1050 - val_loss: 0.2169 - val_mae: 0.1212\n",
            "Epoch 636/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1523 - mae: 0.0978 - val_loss: 0.1983 - val_mae: 0.1156\n",
            "Epoch 637/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1977 - mae: 0.1090 - val_loss: 0.2055 - val_mae: 0.1206\n",
            "Epoch 638/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1609 - mae: 0.0968 - val_loss: 0.2108 - val_mae: 0.1197\n",
            "Epoch 639/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2601 - mae: 0.1104 - val_loss: 0.2111 - val_mae: 0.1213\n",
            "Epoch 640/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2423 - mae: 0.1024 - val_loss: 0.2091 - val_mae: 0.1228\n",
            "Epoch 641/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1906 - mae: 0.1050 - val_loss: 0.2020 - val_mae: 0.1181\n",
            "Epoch 642/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3783 - mae: 0.1331 - val_loss: 0.2114 - val_mae: 0.1226\n",
            "Epoch 643/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2262 - mae: 0.1076 - val_loss: 0.2083 - val_mae: 0.1195\n",
            "Epoch 644/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2108 - mae: 0.1071 - val_loss: 0.2089 - val_mae: 0.1202\n",
            "Epoch 645/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2397 - mae: 0.1038 - val_loss: 0.2082 - val_mae: 0.1180\n",
            "Epoch 646/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.1549 - mae: 0.0939 - val_loss: 0.2016 - val_mae: 0.1169\n",
            "Epoch 647/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2329 - mae: 0.1097 - val_loss: 0.2170 - val_mae: 0.1235\n",
            "Epoch 648/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1643 - mae: 0.0944 - val_loss: 0.2076 - val_mae: 0.1218\n",
            "Epoch 649/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2224 - mae: 0.1133 - val_loss: 0.2093 - val_mae: 0.1210\n",
            "Epoch 650/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2055 - mae: 0.1003 - val_loss: 0.2034 - val_mae: 0.1222\n",
            "Epoch 651/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1684 - mae: 0.0980 - val_loss: 0.1995 - val_mae: 0.1170\n",
            "Epoch 652/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1948 - mae: 0.1005 - val_loss: 0.2101 - val_mae: 0.1198\n",
            "Epoch 653/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2160 - mae: 0.1100 - val_loss: 0.2092 - val_mae: 0.1195\n",
            "Epoch 654/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3566 - mae: 0.1161 - val_loss: 0.2107 - val_mae: 0.1221\n",
            "Epoch 655/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1519 - mae: 0.0934 - val_loss: 0.2033 - val_mae: 0.1207\n",
            "Epoch 656/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2395 - mae: 0.1060 - val_loss: 0.2098 - val_mae: 0.1235\n",
            "Epoch 657/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2047 - mae: 0.1003 - val_loss: 0.2073 - val_mae: 0.1189\n",
            "Epoch 658/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1710 - mae: 0.0969 - val_loss: 0.2003 - val_mae: 0.1197\n",
            "Epoch 659/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1501 - mae: 0.1013 - val_loss: 0.1992 - val_mae: 0.1156\n",
            "Epoch 660/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2054 - mae: 0.0951 - val_loss: 0.2079 - val_mae: 0.1192\n",
            "Epoch 661/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1826 - mae: 0.1047 - val_loss: 0.2040 - val_mae: 0.1194\n",
            "Epoch 662/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1641 - mae: 0.0994 - val_loss: 0.2099 - val_mae: 0.1247\n",
            "Epoch 663/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2928 - mae: 0.1254 - val_loss: 0.2112 - val_mae: 0.1226\n",
            "Epoch 664/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3038 - mae: 0.1239 - val_loss: 0.2134 - val_mae: 0.1220\n",
            "Epoch 665/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2096 - mae: 0.1066 - val_loss: 0.2055 - val_mae: 0.1169\n",
            "Epoch 666/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1445 - mae: 0.0925 - val_loss: 0.2082 - val_mae: 0.1192\n",
            "Epoch 667/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2912 - mae: 0.1215 - val_loss: 0.2122 - val_mae: 0.1206\n",
            "Epoch 668/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2289 - mae: 0.1013 - val_loss: 0.2118 - val_mae: 0.1227\n",
            "Epoch 669/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2045 - mae: 0.1020 - val_loss: 0.2015 - val_mae: 0.1160\n",
            "Epoch 670/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2098 - mae: 0.1035 - val_loss: 0.2086 - val_mae: 0.1186\n",
            "Epoch 671/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2501 - mae: 0.1112 - val_loss: 0.2109 - val_mae: 0.1200\n",
            "Epoch 672/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2743 - mae: 0.1159 - val_loss: 0.2081 - val_mae: 0.1203\n",
            "Epoch 673/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1971 - mae: 0.1043 - val_loss: 0.2046 - val_mae: 0.1182\n",
            "Epoch 674/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3256 - mae: 0.1231 - val_loss: 0.2113 - val_mae: 0.1213\n",
            "Epoch 675/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2471 - mae: 0.1052 - val_loss: 0.2067 - val_mae: 0.1181\n",
            "Epoch 676/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2228 - mae: 0.1014 - val_loss: 0.2013 - val_mae: 0.1176\n",
            "Epoch 677/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1853 - mae: 0.1008 - val_loss: 0.2089 - val_mae: 0.1202\n",
            "Epoch 678/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2270 - mae: 0.1163 - val_loss: 0.2092 - val_mae: 0.1203\n",
            "Epoch 679/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1877 - mae: 0.0984 - val_loss: 0.2116 - val_mae: 0.1203\n",
            "Epoch 680/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2621 - mae: 0.1096 - val_loss: 0.2077 - val_mae: 0.1188\n",
            "Epoch 681/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1973 - mae: 0.0924 - val_loss: 0.2040 - val_mae: 0.1187\n",
            "Epoch 682/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1615 - mae: 0.0982 - val_loss: 0.2029 - val_mae: 0.1169\n",
            "Epoch 683/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2483 - mae: 0.1062 - val_loss: 0.2134 - val_mae: 0.1230\n",
            "Epoch 684/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1698 - mae: 0.0939 - val_loss: 0.2142 - val_mae: 0.1332\n",
            "Epoch 685/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2857 - mae: 0.1262 - val_loss: 0.2053 - val_mae: 0.1199\n",
            "Epoch 686/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1616 - mae: 0.1035 - val_loss: 0.1985 - val_mae: 0.1192\n",
            "Epoch 687/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2027 - mae: 0.1025 - val_loss: 0.2173 - val_mae: 0.1272\n",
            "Epoch 688/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2044 - mae: 0.1088 - val_loss: 0.2071 - val_mae: 0.1205\n",
            "Epoch 689/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2262 - mae: 0.1077 - val_loss: 0.2034 - val_mae: 0.1186\n",
            "Epoch 690/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3180 - mae: 0.1116 - val_loss: 0.2102 - val_mae: 0.1217\n",
            "Epoch 691/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2274 - mae: 0.1123 - val_loss: 0.2035 - val_mae: 0.1168\n",
            "Epoch 692/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2326 - mae: 0.1054 - val_loss: 0.2116 - val_mae: 0.1199\n",
            "Epoch 693/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3658 - mae: 0.1215 - val_loss: 0.2039 - val_mae: 0.1169\n",
            "Epoch 694/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2935 - mae: 0.1178 - val_loss: 0.2004 - val_mae: 0.1158\n",
            "Epoch 695/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2021 - mae: 0.1055 - val_loss: 0.2008 - val_mae: 0.1167\n",
            "Epoch 696/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1781 - mae: 0.0946 - val_loss: 0.2041 - val_mae: 0.1177\n",
            "Epoch 697/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3371 - mae: 0.1207 - val_loss: 0.2047 - val_mae: 0.1167\n",
            "Epoch 698/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1778 - mae: 0.0984 - val_loss: 0.2047 - val_mae: 0.1200\n",
            "Epoch 699/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2198 - mae: 0.1097 - val_loss: 0.2133 - val_mae: 0.1223\n",
            "Epoch 700/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2062 - mae: 0.1025 - val_loss: 0.2097 - val_mae: 0.1198\n",
            "Epoch 701/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2514 - mae: 0.1104 - val_loss: 0.2096 - val_mae: 0.1253\n",
            "Epoch 702/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1713 - mae: 0.0978 - val_loss: 0.2151 - val_mae: 0.1229\n",
            "Epoch 703/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2403 - mae: 0.1164 - val_loss: 0.2095 - val_mae: 0.1192\n",
            "Epoch 704/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1565 - mae: 0.0940 - val_loss: 0.2028 - val_mae: 0.1178\n",
            "Epoch 705/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2244 - mae: 0.1087 - val_loss: 0.2058 - val_mae: 0.1188\n",
            "Epoch 706/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2661 - mae: 0.1134 - val_loss: 0.2153 - val_mae: 0.1224\n",
            "Epoch 707/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1781 - mae: 0.1016 - val_loss: 0.1979 - val_mae: 0.1176\n",
            "Epoch 708/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1976 - mae: 0.1051 - val_loss: 0.2080 - val_mae: 0.1187\n",
            "Epoch 709/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2264 - mae: 0.1081 - val_loss: 0.2150 - val_mae: 0.1208\n",
            "Epoch 710/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.4602 - mae: 0.1354 - val_loss: 0.2024 - val_mae: 0.1165\n",
            "Epoch 711/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.2309 - mae: 0.1078 - val_loss: 0.2050 - val_mae: 0.1174\n",
            "Epoch 712/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2211 - mae: 0.1073 - val_loss: 0.2014 - val_mae: 0.1169\n",
            "Epoch 713/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1638 - mae: 0.0965 - val_loss: 0.2032 - val_mae: 0.1184\n",
            "Epoch 714/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1786 - mae: 0.1005 - val_loss: 0.2106 - val_mae: 0.1213\n",
            "Epoch 715/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1381 - mae: 0.0852 - val_loss: 0.2055 - val_mae: 0.1184\n",
            "Epoch 716/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2352 - mae: 0.1137 - val_loss: 0.2051 - val_mae: 0.1188\n",
            "Epoch 717/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1557 - mae: 0.0978 - val_loss: 0.2085 - val_mae: 0.1203\n",
            "Epoch 718/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1899 - mae: 0.1035 - val_loss: 0.2199 - val_mae: 0.1233\n",
            "Epoch 719/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1614 - mae: 0.0934 - val_loss: 0.2030 - val_mae: 0.1160\n",
            "Epoch 720/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2730 - mae: 0.1144 - val_loss: 0.2093 - val_mae: 0.1177\n",
            "Epoch 721/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2160 - mae: 0.1042 - val_loss: 0.2066 - val_mae: 0.1171\n",
            "Epoch 722/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2162 - mae: 0.0996 - val_loss: 0.2022 - val_mae: 0.1157\n",
            "Epoch 723/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1920 - mae: 0.0963 - val_loss: 0.2133 - val_mae: 0.1202\n",
            "Epoch 724/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1777 - mae: 0.1012 - val_loss: 0.2095 - val_mae: 0.1199\n",
            "Epoch 725/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1721 - mae: 0.0966 - val_loss: 0.2077 - val_mae: 0.1173\n",
            "Epoch 726/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2252 - mae: 0.1051 - val_loss: 0.2058 - val_mae: 0.1176\n",
            "Epoch 727/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2381 - mae: 0.1105 - val_loss: 0.2100 - val_mae: 0.1182\n",
            "Epoch 728/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1891 - mae: 0.1101 - val_loss: 0.2056 - val_mae: 0.1182\n",
            "Epoch 729/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2695 - mae: 0.1071 - val_loss: 0.2126 - val_mae: 0.1199\n",
            "Epoch 730/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2153 - mae: 0.1132 - val_loss: 0.1964 - val_mae: 0.1164\n",
            "Epoch 731/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2320 - mae: 0.1076 - val_loss: 0.2066 - val_mae: 0.1236\n",
            "Epoch 732/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1991 - mae: 0.1007 - val_loss: 0.2157 - val_mae: 0.1214\n",
            "Epoch 733/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1434 - mae: 0.0939 - val_loss: 0.1966 - val_mae: 0.1141\n",
            "Epoch 734/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2952 - mae: 0.1172 - val_loss: 0.2131 - val_mae: 0.1270\n",
            "Epoch 735/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1891 - mae: 0.1028 - val_loss: 0.2068 - val_mae: 0.1216\n",
            "Epoch 736/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1961 - mae: 0.1120 - val_loss: 0.2058 - val_mae: 0.1218\n",
            "Epoch 737/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1572 - mae: 0.0889 - val_loss: 0.2009 - val_mae: 0.1192\n",
            "Epoch 738/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2072 - mae: 0.1052 - val_loss: 0.2147 - val_mae: 0.1241\n",
            "Epoch 739/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1987 - mae: 0.1100 - val_loss: 0.2073 - val_mae: 0.1195\n",
            "Epoch 740/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2140 - mae: 0.1079 - val_loss: 0.2123 - val_mae: 0.1223\n",
            "Epoch 741/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1966 - mae: 0.1093 - val_loss: 0.2049 - val_mae: 0.1185\n",
            "Epoch 742/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1779 - mae: 0.1031 - val_loss: 0.2039 - val_mae: 0.1176\n",
            "Epoch 743/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2292 - mae: 0.1053 - val_loss: 0.2114 - val_mae: 0.1201\n",
            "Epoch 744/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1809 - mae: 0.1003 - val_loss: 0.2095 - val_mae: 0.1191\n",
            "Epoch 745/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2508 - mae: 0.1124 - val_loss: 0.2118 - val_mae: 0.1206\n",
            "Epoch 746/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3113 - mae: 0.1258 - val_loss: 0.2136 - val_mae: 0.1212\n",
            "Epoch 747/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2743 - mae: 0.1179 - val_loss: 0.2035 - val_mae: 0.1148\n",
            "Epoch 748/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1631 - mae: 0.0969 - val_loss: 0.2045 - val_mae: 0.1163\n",
            "Epoch 749/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2086 - mae: 0.1057 - val_loss: 0.2051 - val_mae: 0.1161\n",
            "Epoch 750/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2809 - mae: 0.1170 - val_loss: 0.2027 - val_mae: 0.1172\n",
            "Epoch 751/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1982 - mae: 0.0989 - val_loss: 0.2136 - val_mae: 0.1187\n",
            "Epoch 752/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1909 - mae: 0.1026 - val_loss: 0.2054 - val_mae: 0.1176\n",
            "Epoch 753/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3439 - mae: 0.1250 - val_loss: 0.1962 - val_mae: 0.1227\n",
            "Epoch 754/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2843 - mae: 0.1445 - val_loss: 0.1979 - val_mae: 0.1398\n",
            "Epoch 755/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3100 - mae: 0.1448 - val_loss: 0.2014 - val_mae: 0.1291\n",
            "Epoch 756/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1873 - mae: 0.1124 - val_loss: 0.2064 - val_mae: 0.1245\n",
            "Epoch 757/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2287 - mae: 0.1117 - val_loss: 0.2076 - val_mae: 0.1211\n",
            "Epoch 758/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2347 - mae: 0.1147 - val_loss: 0.2081 - val_mae: 0.1194\n",
            "Epoch 759/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1757 - mae: 0.1053 - val_loss: 0.2050 - val_mae: 0.1191\n",
            "Epoch 760/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1327 - mae: 0.0924 - val_loss: 0.2075 - val_mae: 0.1215\n",
            "Epoch 761/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2138 - mae: 0.1091 - val_loss: 0.2132 - val_mae: 0.1214\n",
            "Epoch 762/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2159 - mae: 0.1002 - val_loss: 0.2058 - val_mae: 0.1178\n",
            "Epoch 763/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3835 - mae: 0.1236 - val_loss: 0.2099 - val_mae: 0.1187\n",
            "Epoch 764/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2733 - mae: 0.1115 - val_loss: 0.2080 - val_mae: 0.1197\n",
            "Epoch 765/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1531 - mae: 0.0936 - val_loss: 0.2000 - val_mae: 0.1150\n",
            "Epoch 766/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2156 - mae: 0.1066 - val_loss: 0.2055 - val_mae: 0.1162\n",
            "Epoch 767/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1669 - mae: 0.0936 - val_loss: 0.2115 - val_mae: 0.1186\n",
            "Epoch 768/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1911 - mae: 0.1077 - val_loss: 0.2076 - val_mae: 0.1211\n",
            "Epoch 769/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2380 - mae: 0.1109 - val_loss: 0.2093 - val_mae: 0.1209\n",
            "Epoch 770/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2179 - mae: 0.1062 - val_loss: 0.2093 - val_mae: 0.1199\n",
            "Epoch 771/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.1785 - mae: 0.0998 - val_loss: 0.2092 - val_mae: 0.1177\n",
            "Epoch 772/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2292 - mae: 0.1064 - val_loss: 0.2106 - val_mae: 0.1181\n",
            "Epoch 773/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1314 - mae: 0.0898 - val_loss: 0.2025 - val_mae: 0.1156\n",
            "Epoch 774/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2322 - mae: 0.1066 - val_loss: 0.2132 - val_mae: 0.1200\n",
            "Epoch 775/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2465 - mae: 0.1111 - val_loss: 0.2039 - val_mae: 0.1161\n",
            "Epoch 776/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2032 - mae: 0.1000 - val_loss: 0.2138 - val_mae: 0.1197\n",
            "Epoch 777/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2195 - mae: 0.1076 - val_loss: 0.2068 - val_mae: 0.1176\n",
            "Epoch 778/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2056 - mae: 0.1032 - val_loss: 0.2109 - val_mae: 0.1189\n",
            "Epoch 779/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2356 - mae: 0.1051 - val_loss: 0.2085 - val_mae: 0.1174\n",
            "Epoch 780/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2809 - mae: 0.1175 - val_loss: 0.2062 - val_mae: 0.1182\n",
            "Epoch 781/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1671 - mae: 0.0941 - val_loss: 0.2071 - val_mae: 0.1185\n",
            "Epoch 782/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2336 - mae: 0.1092 - val_loss: 0.2108 - val_mae: 0.1185\n",
            "Epoch 783/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2418 - mae: 0.1117 - val_loss: 0.2055 - val_mae: 0.1171\n",
            "Epoch 784/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2068 - mae: 0.1055 - val_loss: 0.2117 - val_mae: 0.1192\n",
            "Epoch 785/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2774 - mae: 0.1101 - val_loss: 0.2071 - val_mae: 0.1168\n",
            "Epoch 786/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2798 - mae: 0.1157 - val_loss: 0.2078 - val_mae: 0.1193\n",
            "Epoch 787/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2048 - mae: 0.1051 - val_loss: 0.2091 - val_mae: 0.1181\n",
            "Epoch 788/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2678 - mae: 0.1173 - val_loss: 0.2054 - val_mae: 0.1163\n",
            "Epoch 789/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2013 - mae: 0.1055 - val_loss: 0.2097 - val_mae: 0.1188\n",
            "Epoch 790/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1647 - mae: 0.0991 - val_loss: 0.2055 - val_mae: 0.1172\n",
            "Epoch 791/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1942 - mae: 0.1035 - val_loss: 0.2090 - val_mae: 0.1177\n",
            "Epoch 792/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2249 - mae: 0.1078 - val_loss: 0.2158 - val_mae: 0.1204\n",
            "Epoch 793/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2302 - mae: 0.1067 - val_loss: 0.2111 - val_mae: 0.1180\n",
            "Epoch 794/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2315 - mae: 0.1055 - val_loss: 0.2023 - val_mae: 0.1141\n",
            "Epoch 795/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2128 - mae: 0.1028 - val_loss: 0.2070 - val_mae: 0.1195\n",
            "Epoch 796/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1481 - mae: 0.0849 - val_loss: 0.2103 - val_mae: 0.1184\n",
            "Epoch 797/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2151 - mae: 0.1082 - val_loss: 0.2071 - val_mae: 0.1179\n",
            "Epoch 798/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2284 - mae: 0.1029 - val_loss: 0.2146 - val_mae: 0.1191\n",
            "Epoch 799/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2080 - mae: 0.0965 - val_loss: 0.2042 - val_mae: 0.1151\n",
            "Epoch 800/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1556 - mae: 0.0980 - val_loss: 0.2038 - val_mae: 0.1186\n",
            "Epoch 801/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1999 - mae: 0.1002 - val_loss: 0.2118 - val_mae: 0.1194\n",
            "Epoch 802/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1398 - mae: 0.0902 - val_loss: 0.2063 - val_mae: 0.1188\n",
            "Epoch 803/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1664 - mae: 0.0970 - val_loss: 0.2119 - val_mae: 0.1184\n",
            "Epoch 804/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2751 - mae: 0.1173 - val_loss: 0.2118 - val_mae: 0.1185\n",
            "Epoch 805/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1999 - mae: 0.0992 - val_loss: 0.2129 - val_mae: 0.1221\n",
            "Epoch 806/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2106 - mae: 0.1039 - val_loss: 0.2134 - val_mae: 0.1198\n",
            "Epoch 807/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3589 - mae: 0.1217 - val_loss: 0.2075 - val_mae: 0.1203\n",
            "Epoch 808/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1534 - mae: 0.0943 - val_loss: 0.2057 - val_mae: 0.1199\n",
            "Epoch 809/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2438 - mae: 0.1040 - val_loss: 0.2095 - val_mae: 0.1196\n",
            "Epoch 810/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2132 - mae: 0.1079 - val_loss: 0.2085 - val_mae: 0.1166\n",
            "Epoch 811/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2695 - mae: 0.1107 - val_loss: 0.2108 - val_mae: 0.1185\n",
            "Epoch 812/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1634 - mae: 0.0957 - val_loss: 0.2057 - val_mae: 0.1180\n",
            "Epoch 813/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1518 - mae: 0.0938 - val_loss: 0.2062 - val_mae: 0.1173\n",
            "Epoch 814/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1845 - mae: 0.1000 - val_loss: 0.2063 - val_mae: 0.1159\n",
            "Epoch 815/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2038 - mae: 0.1041 - val_loss: 0.2071 - val_mae: 0.1174\n",
            "Epoch 816/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2447 - mae: 0.1072 - val_loss: 0.2124 - val_mae: 0.1181\n",
            "Epoch 817/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1525 - mae: 0.0903 - val_loss: 0.2003 - val_mae: 0.1164\n",
            "Epoch 818/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2941 - mae: 0.1151 - val_loss: 0.2111 - val_mae: 0.1186\n",
            "Epoch 819/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1172 - mae: 0.0814 - val_loss: 0.2037 - val_mae: 0.1168\n",
            "Epoch 820/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2518 - mae: 0.1203 - val_loss: 0.2112 - val_mae: 0.1188\n",
            "Epoch 821/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2205 - mae: 0.1047 - val_loss: 0.2125 - val_mae: 0.1195\n",
            "Epoch 822/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1622 - mae: 0.0941 - val_loss: 0.2055 - val_mae: 0.1168\n",
            "Epoch 823/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1826 - mae: 0.0937 - val_loss: 0.2110 - val_mae: 0.1184\n",
            "Epoch 824/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3745 - mae: 0.1240 - val_loss: 0.2089 - val_mae: 0.1192\n",
            "Epoch 825/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2422 - mae: 0.1032 - val_loss: 0.2073 - val_mae: 0.1171\n",
            "Epoch 826/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2183 - mae: 0.1112 - val_loss: 0.1953 - val_mae: 0.1240\n",
            "Epoch 827/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2942 - mae: 0.1253 - val_loss: 0.2061 - val_mae: 0.1226\n",
            "Epoch 828/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.3186 - mae: 0.1286 - val_loss: 0.2001 - val_mae: 0.1196\n",
            "Epoch 829/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2749 - mae: 0.1173 - val_loss: 0.2078 - val_mae: 0.1261\n",
            "Epoch 830/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1569 - mae: 0.1013 - val_loss: 0.2002 - val_mae: 0.1180\n",
            "Epoch 831/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1724 - mae: 0.1035 - val_loss: 0.2078 - val_mae: 0.1190\n",
            "Epoch 832/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2424 - mae: 0.1061 - val_loss: 0.2197 - val_mae: 0.1208\n",
            "Epoch 833/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1584 - mae: 0.0944 - val_loss: 0.2019 - val_mae: 0.1170\n",
            "Epoch 834/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1789 - mae: 0.1015 - val_loss: 0.2060 - val_mae: 0.1186\n",
            "Epoch 835/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1670 - mae: 0.0888 - val_loss: 0.2105 - val_mae: 0.1215\n",
            "Epoch 836/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2663 - mae: 0.1103 - val_loss: 0.2106 - val_mae: 0.1189\n",
            "Epoch 837/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2133 - mae: 0.1031 - val_loss: 0.2040 - val_mae: 0.1164\n",
            "Epoch 838/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2320 - mae: 0.0998 - val_loss: 0.2103 - val_mae: 0.1194\n",
            "Epoch 839/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3274 - mae: 0.1183 - val_loss: 0.2122 - val_mae: 0.1173\n",
            "Epoch 840/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2017 - mae: 0.1081 - val_loss: 0.2044 - val_mae: 0.1167\n",
            "Epoch 841/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1906 - mae: 0.1012 - val_loss: 0.2005 - val_mae: 0.1154\n",
            "Epoch 842/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3497 - mae: 0.1212 - val_loss: 0.2105 - val_mae: 0.1186\n",
            "Epoch 843/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2122 - mae: 0.1039 - val_loss: 0.2092 - val_mae: 0.1182\n",
            "Epoch 844/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3583 - mae: 0.1219 - val_loss: 0.2038 - val_mae: 0.1157\n",
            "Epoch 845/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1750 - mae: 0.0981 - val_loss: 0.2052 - val_mae: 0.1176\n",
            "Epoch 846/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1490 - mae: 0.0889 - val_loss: 0.2068 - val_mae: 0.1221\n",
            "Epoch 847/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2174 - mae: 0.1079 - val_loss: 0.2090 - val_mae: 0.1175\n",
            "Epoch 848/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2505 - mae: 0.1126 - val_loss: 0.2108 - val_mae: 0.1188\n",
            "Epoch 849/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2880 - mae: 0.1125 - val_loss: 0.2117 - val_mae: 0.1172\n",
            "Epoch 850/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1797 - mae: 0.0911 - val_loss: 0.2053 - val_mae: 0.1150\n",
            "Epoch 851/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1912 - mae: 0.0969 - val_loss: 0.2105 - val_mae: 0.1190\n",
            "Epoch 852/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1896 - mae: 0.0983 - val_loss: 0.2030 - val_mae: 0.1167\n",
            "Epoch 853/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1694 - mae: 0.0939 - val_loss: 0.2121 - val_mae: 0.1199\n",
            "Epoch 854/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1534 - mae: 0.0962 - val_loss: 0.2023 - val_mae: 0.1150\n",
            "Epoch 855/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2431 - mae: 0.1043 - val_loss: 0.2165 - val_mae: 0.1211\n",
            "Epoch 856/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2314 - mae: 0.1053 - val_loss: 0.2081 - val_mae: 0.1173\n",
            "Epoch 857/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1748 - mae: 0.0955 - val_loss: 0.2056 - val_mae: 0.1163\n",
            "Epoch 858/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2653 - mae: 0.1119 - val_loss: 0.2113 - val_mae: 0.1199\n",
            "Epoch 859/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1918 - mae: 0.1000 - val_loss: 0.2051 - val_mae: 0.1167\n",
            "Epoch 860/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2749 - mae: 0.1193 - val_loss: 0.2060 - val_mae: 0.1176\n",
            "Epoch 861/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2868 - mae: 0.1174 - val_loss: 0.2080 - val_mae: 0.1179\n",
            "Epoch 862/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2091 - mae: 0.1072 - val_loss: 0.2087 - val_mae: 0.1178\n",
            "Epoch 863/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2913 - mae: 0.1155 - val_loss: 0.2102 - val_mae: 0.1169\n",
            "Epoch 864/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2427 - mae: 0.1078 - val_loss: 0.2122 - val_mae: 0.1200\n",
            "Epoch 865/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2088 - mae: 0.0982 - val_loss: 0.2037 - val_mae: 0.1149\n",
            "Epoch 866/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2144 - mae: 0.1023 - val_loss: 0.2047 - val_mae: 0.1155\n",
            "Epoch 867/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1852 - mae: 0.0957 - val_loss: 0.2021 - val_mae: 0.1145\n",
            "Epoch 868/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2696 - mae: 0.1133 - val_loss: 0.2101 - val_mae: 0.1190\n",
            "Epoch 869/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1811 - mae: 0.0970 - val_loss: 0.2084 - val_mae: 0.1190\n",
            "Epoch 870/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3108 - mae: 0.1193 - val_loss: 0.2100 - val_mae: 0.1181\n",
            "Epoch 871/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2829 - mae: 0.1079 - val_loss: 0.2054 - val_mae: 0.1159\n",
            "Epoch 872/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2497 - mae: 0.1053 - val_loss: 0.2100 - val_mae: 0.1183\n",
            "Epoch 873/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2375 - mae: 0.1138 - val_loss: 0.2043 - val_mae: 0.1158\n",
            "Epoch 874/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2488 - mae: 0.1059 - val_loss: 0.2080 - val_mae: 0.1172\n",
            "Epoch 875/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2961 - mae: 0.1104 - val_loss: 0.2114 - val_mae: 0.1193\n",
            "Epoch 876/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2454 - mae: 0.1147 - val_loss: 0.2004 - val_mae: 0.1182\n",
            "Epoch 877/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1984 - mae: 0.0977 - val_loss: 0.2057 - val_mae: 0.1181\n",
            "Epoch 878/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2321 - mae: 0.1148 - val_loss: 0.2096 - val_mae: 0.1203\n",
            "Epoch 879/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1743 - mae: 0.1037 - val_loss: 0.2020 - val_mae: 0.1162\n",
            "Epoch 880/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2228 - mae: 0.0969 - val_loss: 0.2096 - val_mae: 0.1186\n",
            "Epoch 881/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1872 - mae: 0.0996 - val_loss: 0.2059 - val_mae: 0.1167\n",
            "Epoch 882/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1760 - mae: 0.1002 - val_loss: 0.2095 - val_mae: 0.1196\n",
            "Epoch 883/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1974 - mae: 0.1030 - val_loss: 0.2140 - val_mae: 0.1197\n",
            "Epoch 884/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1588 - mae: 0.0984 - val_loss: 0.2040 - val_mae: 0.1169\n",
            "Epoch 885/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2669 - mae: 0.1094 - val_loss: 0.2111 - val_mae: 0.1195\n",
            "Epoch 886/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2473 - mae: 0.1101 - val_loss: 0.2055 - val_mae: 0.1190\n",
            "Epoch 887/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2129 - mae: 0.0993 - val_loss: 0.2112 - val_mae: 0.1180\n",
            "Epoch 888/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2348 - mae: 0.1084 - val_loss: 0.2106 - val_mae: 0.1219\n",
            "Epoch 889/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1762 - mae: 0.0962 - val_loss: 0.2038 - val_mae: 0.1171\n",
            "Epoch 890/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3356 - mae: 0.1280 - val_loss: 0.2035 - val_mae: 0.1195\n",
            "Epoch 891/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1736 - mae: 0.1037 - val_loss: 0.2007 - val_mae: 0.1216\n",
            "Epoch 892/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2459 - mae: 0.1172 - val_loss: 0.2133 - val_mae: 0.1207\n",
            "Epoch 893/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3743 - mae: 0.1240 - val_loss: 0.2091 - val_mae: 0.1173\n",
            "Epoch 894/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1739 - mae: 0.0934 - val_loss: 0.1995 - val_mae: 0.1138\n",
            "Epoch 895/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.2854 - mae: 0.1199 - val_loss: 0.2014 - val_mae: 0.1143\n",
            "Epoch 896/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1839 - mae: 0.1013 - val_loss: 0.2113 - val_mae: 0.1179\n",
            "Epoch 897/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1466 - mae: 0.0959 - val_loss: 0.2014 - val_mae: 0.1150\n",
            "Epoch 898/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2412 - mae: 0.1058 - val_loss: 0.2165 - val_mae: 0.1197\n",
            "Epoch 899/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1850 - mae: 0.1042 - val_loss: 0.2040 - val_mae: 0.1175\n",
            "Epoch 900/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1398 - mae: 0.0935 - val_loss: 0.2038 - val_mae: 0.1197\n",
            "Epoch 901/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1609 - mae: 0.0910 - val_loss: 0.2153 - val_mae: 0.1215\n",
            "Epoch 902/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1974 - mae: 0.1029 - val_loss: 0.2125 - val_mae: 0.1216\n",
            "Epoch 903/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2552 - mae: 0.1105 - val_loss: 0.2050 - val_mae: 0.1164\n",
            "Epoch 904/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2624 - mae: 0.1130 - val_loss: 0.2071 - val_mae: 0.1184\n",
            "Epoch 905/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3476 - mae: 0.1181 - val_loss: 0.2110 - val_mae: 0.1174\n",
            "Epoch 906/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1969 - mae: 0.1038 - val_loss: 0.2041 - val_mae: 0.1184\n",
            "Epoch 907/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2301 - mae: 0.1047 - val_loss: 0.2137 - val_mae: 0.1211\n",
            "Epoch 908/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2765 - mae: 0.1139 - val_loss: 0.2054 - val_mae: 0.1182\n",
            "Epoch 909/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3060 - mae: 0.1209 - val_loss: 0.2094 - val_mae: 0.1207\n",
            "Epoch 910/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1750 - mae: 0.1032 - val_loss: 0.2031 - val_mae: 0.1173\n",
            "Epoch 911/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2459 - mae: 0.1024 - val_loss: 0.2119 - val_mae: 0.1199\n",
            "Epoch 912/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2624 - mae: 0.1106 - val_loss: 0.2037 - val_mae: 0.1149\n",
            "Epoch 913/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2668 - mae: 0.1123 - val_loss: 0.2022 - val_mae: 0.1166\n",
            "Epoch 914/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2407 - mae: 0.1079 - val_loss: 0.2076 - val_mae: 0.1160\n",
            "Epoch 915/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2980 - mae: 0.1174 - val_loss: 0.2051 - val_mae: 0.1179\n",
            "Epoch 916/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2914 - mae: 0.1135 - val_loss: 0.2000 - val_mae: 0.1191\n",
            "Epoch 917/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2426 - mae: 0.1092 - val_loss: 0.1980 - val_mae: 0.1157\n",
            "Epoch 918/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2275 - mae: 0.1103 - val_loss: 0.1950 - val_mae: 0.1322\n",
            "Epoch 919/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3347 - mae: 0.1391 - val_loss: 0.2110 - val_mae: 0.1327\n",
            "Epoch 920/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2061 - mae: 0.1248 - val_loss: 0.2033 - val_mae: 0.1239\n",
            "Epoch 921/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2190 - mae: 0.1128 - val_loss: 0.2006 - val_mae: 0.1162\n",
            "Epoch 922/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1727 - mae: 0.0973 - val_loss: 0.2090 - val_mae: 0.1178\n",
            "Epoch 923/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.4053 - mae: 0.1303 - val_loss: 0.2087 - val_mae: 0.1195\n",
            "Epoch 924/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2551 - mae: 0.1139 - val_loss: 0.2018 - val_mae: 0.1146\n",
            "Epoch 925/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1809 - mae: 0.0975 - val_loss: 0.2037 - val_mae: 0.1166\n",
            "Epoch 926/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2514 - mae: 0.1084 - val_loss: 0.2123 - val_mae: 0.1195\n",
            "Epoch 927/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1411 - mae: 0.0870 - val_loss: 0.2082 - val_mae: 0.1178\n",
            "Epoch 928/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2158 - mae: 0.1052 - val_loss: 0.2116 - val_mae: 0.1178\n",
            "Epoch 929/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2125 - mae: 0.0995 - val_loss: 0.2104 - val_mae: 0.1176\n",
            "Epoch 930/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2115 - mae: 0.1052 - val_loss: 0.2059 - val_mae: 0.1172\n",
            "Epoch 931/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1483 - mae: 0.0942 - val_loss: 0.2019 - val_mae: 0.1143\n",
            "Epoch 932/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1894 - mae: 0.1000 - val_loss: 0.2106 - val_mae: 0.1188\n",
            "Epoch 933/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2787 - mae: 0.1064 - val_loss: 0.2128 - val_mae: 0.1174\n",
            "Epoch 934/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1398 - mae: 0.0923 - val_loss: 0.2003 - val_mae: 0.1130\n",
            "Epoch 935/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3998 - mae: 0.1217 - val_loss: 0.2140 - val_mae: 0.1199\n",
            "Epoch 936/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3297 - mae: 0.1218 - val_loss: 0.1972 - val_mae: 0.1134\n",
            "Epoch 937/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3099 - mae: 0.1127 - val_loss: 0.2063 - val_mae: 0.1167\n",
            "Epoch 938/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2655 - mae: 0.1159 - val_loss: 0.2088 - val_mae: 0.1173\n",
            "Epoch 939/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2432 - mae: 0.1036 - val_loss: 0.2101 - val_mae: 0.1184\n",
            "Epoch 940/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1954 - mae: 0.1002 - val_loss: 0.2036 - val_mae: 0.1166\n",
            "Epoch 941/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2366 - mae: 0.1045 - val_loss: 0.2061 - val_mae: 0.1175\n",
            "Epoch 942/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1778 - mae: 0.0984 - val_loss: 0.2064 - val_mae: 0.1165\n",
            "Epoch 943/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1446 - mae: 0.0848 - val_loss: 0.2131 - val_mae: 0.1207\n",
            "Epoch 944/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1655 - mae: 0.0994 - val_loss: 0.2051 - val_mae: 0.1166\n",
            "Epoch 945/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2315 - mae: 0.1024 - val_loss: 0.2110 - val_mae: 0.1182\n",
            "Epoch 946/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1469 - mae: 0.0903 - val_loss: 0.2086 - val_mae: 0.1159\n",
            "Epoch 947/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2890 - mae: 0.1108 - val_loss: 0.2079 - val_mae: 0.1166\n",
            "Epoch 948/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3059 - mae: 0.1206 - val_loss: 0.2105 - val_mae: 0.1201\n",
            "Epoch 949/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2563 - mae: 0.1130 - val_loss: 0.2071 - val_mae: 0.1171\n",
            "Epoch 950/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2745 - mae: 0.1099 - val_loss: 0.2079 - val_mae: 0.1185\n",
            "Epoch 951/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2123 - mae: 0.1067 - val_loss: 0.2076 - val_mae: 0.1192\n",
            "Epoch 952/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3001 - mae: 0.1125 - val_loss: 0.2106 - val_mae: 0.1180\n",
            "Epoch 953/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.2019 - mae: 0.1018 - val_loss: 0.2063 - val_mae: 0.1187\n",
            "Epoch 954/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2212 - mae: 0.1113 - val_loss: 0.2071 - val_mae: 0.1161\n",
            "Epoch 955/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2643 - mae: 0.1071 - val_loss: 0.2086 - val_mae: 0.1173\n",
            "Epoch 956/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1633 - mae: 0.1060 - val_loss: 0.2019 - val_mae: 0.1157\n",
            "Epoch 957/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1884 - mae: 0.0963 - val_loss: 0.2125 - val_mae: 0.1200\n",
            "Epoch 958/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1705 - mae: 0.0972 - val_loss: 0.2067 - val_mae: 0.1174\n",
            "Epoch 959/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2598 - mae: 0.1137 - val_loss: 0.2138 - val_mae: 0.1179\n",
            "Epoch 960/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2385 - mae: 0.1004 - val_loss: 0.2113 - val_mae: 0.1179\n",
            "Epoch 961/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2118 - mae: 0.1034 - val_loss: 0.2070 - val_mae: 0.1164\n",
            "Epoch 962/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1527 - mae: 0.0970 - val_loss: 0.2061 - val_mae: 0.1180\n",
            "Epoch 963/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1671 - mae: 0.0884 - val_loss: 0.2158 - val_mae: 0.1208\n",
            "Epoch 964/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2316 - mae: 0.1124 - val_loss: 0.2088 - val_mae: 0.1184\n",
            "Epoch 965/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2763 - mae: 0.1118 - val_loss: 0.2118 - val_mae: 0.1180\n",
            "Epoch 966/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2117 - mae: 0.0976 - val_loss: 0.2086 - val_mae: 0.1169\n",
            "Epoch 967/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1509 - mae: 0.0896 - val_loss: 0.2078 - val_mae: 0.1167\n",
            "Epoch 968/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2025 - mae: 0.0977 - val_loss: 0.2126 - val_mae: 0.1187\n",
            "Epoch 969/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2668 - mae: 0.1069 - val_loss: 0.2075 - val_mae: 0.1163\n",
            "Epoch 970/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2838 - mae: 0.1116 - val_loss: 0.2088 - val_mae: 0.1170\n",
            "Epoch 971/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2068 - mae: 0.0987 - val_loss: 0.2035 - val_mae: 0.1147\n",
            "Epoch 972/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2663 - mae: 0.1047 - val_loss: 0.2073 - val_mae: 0.1198\n",
            "Epoch 973/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2073 - mae: 0.0945 - val_loss: 0.2078 - val_mae: 0.1162\n",
            "Epoch 974/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1463 - mae: 0.0930 - val_loss: 0.2033 - val_mae: 0.1151\n",
            "Epoch 975/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2248 - mae: 0.1065 - val_loss: 0.2115 - val_mae: 0.1198\n",
            "Epoch 976/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2178 - mae: 0.1035 - val_loss: 0.2104 - val_mae: 0.1188\n",
            "Epoch 977/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1976 - mae: 0.0973 - val_loss: 0.2145 - val_mae: 0.1204\n",
            "Epoch 978/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2254 - mae: 0.1050 - val_loss: 0.2103 - val_mae: 0.1183\n",
            "Epoch 979/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3437 - mae: 0.1234 - val_loss: 0.2103 - val_mae: 0.1165\n",
            "Epoch 980/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3318 - mae: 0.1144 - val_loss: 0.2064 - val_mae: 0.1166\n",
            "Epoch 981/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1562 - mae: 0.0882 - val_loss: 0.2058 - val_mae: 0.1163\n",
            "Epoch 982/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1857 - mae: 0.0979 - val_loss: 0.2034 - val_mae: 0.1144\n",
            "Epoch 983/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1674 - mae: 0.1002 - val_loss: 0.2044 - val_mae: 0.1159\n",
            "Epoch 984/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2160 - mae: 0.1010 - val_loss: 0.2099 - val_mae: 0.1167\n",
            "Epoch 985/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2687 - mae: 0.1041 - val_loss: 0.2124 - val_mae: 0.1186\n",
            "Epoch 986/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3730 - mae: 0.1304 - val_loss: 0.2076 - val_mae: 0.1159\n",
            "Epoch 987/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1873 - mae: 0.0948 - val_loss: 0.2048 - val_mae: 0.1159\n",
            "Epoch 988/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2641 - mae: 0.1179 - val_loss: 0.2096 - val_mae: 0.1216\n",
            "Epoch 989/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1812 - mae: 0.1008 - val_loss: 0.2061 - val_mae: 0.1158\n",
            "Epoch 990/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1994 - mae: 0.0979 - val_loss: 0.2082 - val_mae: 0.1165\n",
            "Epoch 991/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1899 - mae: 0.0871 - val_loss: 0.2053 - val_mae: 0.1160\n",
            "Epoch 992/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2911 - mae: 0.1125 - val_loss: 0.2051 - val_mae: 0.1169\n",
            "Epoch 993/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2774 - mae: 0.1066 - val_loss: 0.2088 - val_mae: 0.1177\n",
            "Epoch 994/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2590 - mae: 0.1078 - val_loss: 0.2077 - val_mae: 0.1183\n",
            "Epoch 995/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1388 - mae: 0.0884 - val_loss: 0.2037 - val_mae: 0.1152\n",
            "Epoch 996/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2806 - mae: 0.1149 - val_loss: 0.2080 - val_mae: 0.1166\n",
            "Epoch 997/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3268 - mae: 0.1107 - val_loss: 0.2052 - val_mae: 0.1156\n",
            "Epoch 998/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2250 - mae: 0.0996 - val_loss: 0.2096 - val_mae: 0.1187\n",
            "Epoch 999/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1693 - mae: 0.0941 - val_loss: 0.2023 - val_mae: 0.1168\n",
            "Epoch 1000/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1943 - mae: 0.0997 - val_loss: 0.2062 - val_mae: 0.1179\n",
            "Epoch 1001/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2325 - mae: 0.1006 - val_loss: 0.2099 - val_mae: 0.1185\n",
            "Epoch 1002/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1860 - mae: 0.0900 - val_loss: 0.2092 - val_mae: 0.1176\n",
            "Epoch 1003/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2532 - mae: 0.1137 - val_loss: 0.2050 - val_mae: 0.1151\n",
            "Epoch 1004/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1909 - mae: 0.1007 - val_loss: 0.2064 - val_mae: 0.1164\n",
            "Epoch 1005/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2752 - mae: 0.1126 - val_loss: 0.2083 - val_mae: 0.1167\n",
            "Epoch 1006/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2738 - mae: 0.1087 - val_loss: 0.2095 - val_mae: 0.1184\n",
            "Epoch 1007/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2215 - mae: 0.1074 - val_loss: 0.2039 - val_mae: 0.1149\n",
            "Epoch 1008/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2401 - mae: 0.1008 - val_loss: 0.2080 - val_mae: 0.1185\n",
            "Epoch 1009/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1969 - mae: 0.0995 - val_loss: 0.2081 - val_mae: 0.1225\n",
            "Epoch 1010/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.2190 - mae: 0.1097 - val_loss: 0.2068 - val_mae: 0.1183\n",
            "Epoch 1011/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1787 - mae: 0.0943 - val_loss: 0.2092 - val_mae: 0.1236\n",
            "Epoch 1012/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2593 - mae: 0.1150 - val_loss: 0.2063 - val_mae: 0.1190\n",
            "Epoch 1013/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2015 - mae: 0.0994 - val_loss: 0.2080 - val_mae: 0.1206\n",
            "Epoch 1014/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2545 - mae: 0.1064 - val_loss: 0.2056 - val_mae: 0.1169\n",
            "Epoch 1015/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2653 - mae: 0.1114 - val_loss: 0.2099 - val_mae: 0.1179\n",
            "Epoch 1016/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2019 - mae: 0.1097 - val_loss: 0.2083 - val_mae: 0.1195\n",
            "Epoch 1017/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2769 - mae: 0.1158 - val_loss: 0.2127 - val_mae: 0.1184\n",
            "Epoch 1018/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2784 - mae: 0.1083 - val_loss: 0.2074 - val_mae: 0.1184\n",
            "Epoch 1019/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1587 - mae: 0.0935 - val_loss: 0.2039 - val_mae: 0.1156\n",
            "Epoch 1020/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1382 - mae: 0.0863 - val_loss: 0.2063 - val_mae: 0.1156\n",
            "Epoch 1021/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1666 - mae: 0.0965 - val_loss: 0.2068 - val_mae: 0.1158\n",
            "Epoch 1022/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1511 - mae: 0.0881 - val_loss: 0.2083 - val_mae: 0.1194\n",
            "Epoch 1023/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1609 - mae: 0.0960 - val_loss: 0.2111 - val_mae: 0.1191\n",
            "Epoch 1024/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1844 - mae: 0.0983 - val_loss: 0.2115 - val_mae: 0.1195\n",
            "Epoch 1025/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2589 - mae: 0.1094 - val_loss: 0.2139 - val_mae: 0.1180\n",
            "Epoch 1026/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2169 - mae: 0.0993 - val_loss: 0.2116 - val_mae: 0.1169\n",
            "Epoch 1027/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2541 - mae: 0.1114 - val_loss: 0.2015 - val_mae: 0.1167\n",
            "Epoch 1028/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1723 - mae: 0.0925 - val_loss: 0.2044 - val_mae: 0.1153\n",
            "Epoch 1029/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2168 - mae: 0.0941 - val_loss: 0.2089 - val_mae: 0.1203\n",
            "Epoch 1030/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1431 - mae: 0.0944 - val_loss: 0.2061 - val_mae: 0.1182\n",
            "Epoch 1031/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1796 - mae: 0.0985 - val_loss: 0.2108 - val_mae: 0.1174\n",
            "Epoch 1032/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2144 - mae: 0.1029 - val_loss: 0.2068 - val_mae: 0.1157\n",
            "Epoch 1033/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2244 - mae: 0.1024 - val_loss: 0.2069 - val_mae: 0.1158\n",
            "Epoch 1034/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2093 - mae: 0.1001 - val_loss: 0.2092 - val_mae: 0.1161\n",
            "Epoch 1035/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2401 - mae: 0.1014 - val_loss: 0.2142 - val_mae: 0.1202\n",
            "Epoch 1036/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1864 - mae: 0.0980 - val_loss: 0.2018 - val_mae: 0.1174\n",
            "Epoch 1037/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1823 - mae: 0.0956 - val_loss: 0.2125 - val_mae: 0.1192\n",
            "Epoch 1038/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1796 - mae: 0.0993 - val_loss: 0.2056 - val_mae: 0.1186\n",
            "Epoch 1039/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2102 - mae: 0.1027 - val_loss: 0.2135 - val_mae: 0.1191\n",
            "Epoch 1040/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2100 - mae: 0.1076 - val_loss: 0.2062 - val_mae: 0.1158\n",
            "Epoch 1041/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3090 - mae: 0.1171 - val_loss: 0.2076 - val_mae: 0.1159\n",
            "Epoch 1042/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2443 - mae: 0.1083 - val_loss: 0.2073 - val_mae: 0.1161\n",
            "Epoch 1043/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2040 - mae: 0.1048 - val_loss: 0.2058 - val_mae: 0.1171\n",
            "Epoch 1044/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1846 - mae: 0.1001 - val_loss: 0.2041 - val_mae: 0.1146\n",
            "Epoch 1045/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2632 - mae: 0.1156 - val_loss: 0.2116 - val_mae: 0.1221\n",
            "Epoch 1046/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2340 - mae: 0.1109 - val_loss: 0.2135 - val_mae: 0.1248\n",
            "Epoch 1047/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2500 - mae: 0.1149 - val_loss: 0.2082 - val_mae: 0.1189\n",
            "Epoch 1048/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2501 - mae: 0.1066 - val_loss: 0.2058 - val_mae: 0.1162\n",
            "Epoch 1049/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3799 - mae: 0.1232 - val_loss: 0.2099 - val_mae: 0.1194\n",
            "Epoch 1050/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1605 - mae: 0.0939 - val_loss: 0.2035 - val_mae: 0.1161\n",
            "Epoch 1051/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3635 - mae: 0.1218 - val_loss: 0.2084 - val_mae: 0.1161\n",
            "Epoch 1052/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2246 - mae: 0.0980 - val_loss: 0.2130 - val_mae: 0.1185\n",
            "Epoch 1053/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2300 - mae: 0.1010 - val_loss: 0.2074 - val_mae: 0.1160\n",
            "Epoch 1054/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2508 - mae: 0.1102 - val_loss: 0.2050 - val_mae: 0.1170\n",
            "Epoch 1055/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2189 - mae: 0.1070 - val_loss: 0.2070 - val_mae: 0.1182\n",
            "Epoch 1056/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2790 - mae: 0.1091 - val_loss: 0.2112 - val_mae: 0.1191\n",
            "Epoch 1057/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2571 - mae: 0.1096 - val_loss: 0.2025 - val_mae: 0.1136\n",
            "Epoch 1058/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1946 - mae: 0.1074 - val_loss: 0.2058 - val_mae: 0.1158\n",
            "Epoch 1059/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2697 - mae: 0.1064 - val_loss: 0.2098 - val_mae: 0.1170\n",
            "Epoch 1060/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1702 - mae: 0.0933 - val_loss: 0.2070 - val_mae: 0.1159\n",
            "Epoch 1061/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3080 - mae: 0.1181 - val_loss: 0.2100 - val_mae: 0.1173\n",
            "Epoch 1062/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1880 - mae: 0.1023 - val_loss: 0.2025 - val_mae: 0.1144\n",
            "Epoch 1063/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2075 - mae: 0.0951 - val_loss: 0.2090 - val_mae: 0.1187\n",
            "Epoch 1064/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1707 - mae: 0.0965 - val_loss: 0.2035 - val_mae: 0.1187\n",
            "Epoch 1065/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2787 - mae: 0.1109 - val_loss: 0.2134 - val_mae: 0.1196\n",
            "Epoch 1066/2000\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.2113 - mae: 0.1047 - val_loss: 0.2110 - val_mae: 0.1178\n",
            "Epoch 1067/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1836 - mae: 0.1046 - val_loss: 0.2024 - val_mae: 0.1192\n",
            "Epoch 1068/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2039 - mae: 0.1076 - val_loss: 0.2086 - val_mae: 0.1177\n",
            "Epoch 1069/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1667 - mae: 0.0917 - val_loss: 0.2127 - val_mae: 0.1179\n",
            "Epoch 1070/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2115 - mae: 0.1000 - val_loss: 0.2118 - val_mae: 0.1178\n",
            "Epoch 1071/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1957 - mae: 0.1016 - val_loss: 0.2075 - val_mae: 0.1167\n",
            "Epoch 1072/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1904 - mae: 0.0966 - val_loss: 0.2106 - val_mae: 0.1190\n",
            "Epoch 1073/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1563 - mae: 0.0973 - val_loss: 0.2062 - val_mae: 0.1160\n",
            "Epoch 1074/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1895 - mae: 0.1018 - val_loss: 0.2084 - val_mae: 0.1173\n",
            "Epoch 1075/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1547 - mae: 0.0912 - val_loss: 0.2174 - val_mae: 0.1210\n",
            "Epoch 1076/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1400 - mae: 0.0915 - val_loss: 0.2091 - val_mae: 0.1183\n",
            "Epoch 1077/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1948 - mae: 0.1010 - val_loss: 0.2110 - val_mae: 0.1191\n",
            "Epoch 1078/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1438 - mae: 0.0886 - val_loss: 0.2118 - val_mae: 0.1227\n",
            "Epoch 1079/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2258 - mae: 0.1047 - val_loss: 0.2114 - val_mae: 0.1211\n",
            "Epoch 1080/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2084 - mae: 0.1063 - val_loss: 0.2098 - val_mae: 0.1184\n",
            "Epoch 1081/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1896 - mae: 0.0957 - val_loss: 0.2133 - val_mae: 0.1202\n",
            "Epoch 1082/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2223 - mae: 0.0981 - val_loss: 0.2112 - val_mae: 0.1187\n",
            "Epoch 1083/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2262 - mae: 0.1001 - val_loss: 0.2114 - val_mae: 0.1190\n",
            "Epoch 1084/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2856 - mae: 0.1139 - val_loss: 0.2098 - val_mae: 0.1192\n",
            "Epoch 1085/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1989 - mae: 0.1035 - val_loss: 0.2072 - val_mae: 0.1166\n",
            "Epoch 1086/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2473 - mae: 0.1078 - val_loss: 0.2106 - val_mae: 0.1173\n",
            "Epoch 1087/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1855 - mae: 0.0963 - val_loss: 0.2059 - val_mae: 0.1160\n",
            "Epoch 1088/2000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.1638 - mae: 0.0971 - val_loss: 0.2067 - val_mae: 0.1174\n",
            "Epoch 1089/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2254 - mae: 0.1072 - val_loss: 0.2080 - val_mae: 0.1176\n",
            "Epoch 1090/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1673 - mae: 0.1015 - val_loss: 0.2076 - val_mae: 0.1181\n",
            "Epoch 1091/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2349 - mae: 0.1052 - val_loss: 0.2084 - val_mae: 0.1157\n",
            "Epoch 1092/2000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2165 - mae: 0.0993 - val_loss: 0.2123 - val_mae: 0.1183\n",
            "Epoch 1093/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1189 - mae: 0.0856 - val_loss: 0.2022 - val_mae: 0.1148\n",
            "Epoch 1094/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1879 - mae: 0.1030 - val_loss: 0.2133 - val_mae: 0.1236\n",
            "Epoch 1095/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2621 - mae: 0.1112 - val_loss: 0.1991 - val_mae: 0.1165\n",
            "Epoch 1096/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1375 - mae: 0.0930 - val_loss: 0.2119 - val_mae: 0.1503\n",
            "Epoch 1097/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2927 - mae: 0.1563 - val_loss: 0.2196 - val_mae: 0.1529\n",
            "Epoch 1098/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1964 - mae: 0.1326 - val_loss: 0.1977 - val_mae: 0.1239\n",
            "Epoch 1099/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1807 - mae: 0.1054 - val_loss: 0.2151 - val_mae: 0.1255\n",
            "Epoch 1100/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1691 - mae: 0.1073 - val_loss: 0.1989 - val_mae: 0.1163\n",
            "Epoch 1101/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2686 - mae: 0.1133 - val_loss: 0.2159 - val_mae: 0.1214\n",
            "Epoch 1102/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2197 - mae: 0.1058 - val_loss: 0.2112 - val_mae: 0.1195\n",
            "Epoch 1103/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2502 - mae: 0.1040 - val_loss: 0.2119 - val_mae: 0.1177\n",
            "Epoch 1104/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2417 - mae: 0.1060 - val_loss: 0.2029 - val_mae: 0.1156\n",
            "Epoch 1105/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2132 - mae: 0.1053 - val_loss: 0.2059 - val_mae: 0.1160\n",
            "Epoch 1106/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2019 - mae: 0.0995 - val_loss: 0.2072 - val_mae: 0.1168\n",
            "Epoch 1107/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1490 - mae: 0.0887 - val_loss: 0.2107 - val_mae: 0.1173\n",
            "Epoch 1108/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3267 - mae: 0.1161 - val_loss: 0.2070 - val_mae: 0.1160\n",
            "Epoch 1109/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1697 - mae: 0.0911 - val_loss: 0.2088 - val_mae: 0.1169\n",
            "Epoch 1110/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1486 - mae: 0.0910 - val_loss: 0.2047 - val_mae: 0.1173\n",
            "Epoch 1111/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3182 - mae: 0.1109 - val_loss: 0.2145 - val_mae: 0.1203\n",
            "Epoch 1112/2000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2282 - mae: 0.1016 - val_loss: 0.2069 - val_mae: 0.1176\n",
            "Epoch 1113/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3756 - mae: 0.1244 - val_loss: 0.2127 - val_mae: 0.1185\n",
            "Epoch 1114/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1717 - mae: 0.0954 - val_loss: 0.2063 - val_mae: 0.1168\n",
            "Epoch 1115/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1653 - mae: 0.0934 - val_loss: 0.2046 - val_mae: 0.1155\n",
            "Epoch 1116/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1743 - mae: 0.0947 - val_loss: 0.2081 - val_mae: 0.1163\n",
            "Epoch 1117/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1569 - mae: 0.0877 - val_loss: 0.2086 - val_mae: 0.1165\n",
            "Epoch 1118/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2362 - mae: 0.1092 - val_loss: 0.2157 - val_mae: 0.1197\n",
            "Epoch 1119/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2653 - mae: 0.1097 - val_loss: 0.2113 - val_mae: 0.1169\n",
            "Epoch 1120/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1612 - mae: 0.0951 - val_loss: 0.2071 - val_mae: 0.1169\n",
            "Epoch 1121/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2744 - mae: 0.1079 - val_loss: 0.2112 - val_mae: 0.1191\n",
            "Epoch 1122/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3566 - mae: 0.1277 - val_loss: 0.2077 - val_mae: 0.1169\n",
            "Epoch 1123/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1700 - mae: 0.0973 - val_loss: 0.2029 - val_mae: 0.1151\n",
            "Epoch 1124/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1624 - mae: 0.0964 - val_loss: 0.2050 - val_mae: 0.1157\n",
            "Epoch 1125/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.2551 - mae: 0.1149 - val_loss: 0.2133 - val_mae: 0.1177\n",
            "Epoch 1126/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1843 - mae: 0.1014 - val_loss: 0.2086 - val_mae: 0.1156\n",
            "Epoch 1127/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2099 - mae: 0.0925 - val_loss: 0.2116 - val_mae: 0.1188\n",
            "Epoch 1128/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3084 - mae: 0.1180 - val_loss: 0.2114 - val_mae: 0.1167\n",
            "Epoch 1129/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1943 - mae: 0.1045 - val_loss: 0.2055 - val_mae: 0.1159\n",
            "Epoch 1130/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1915 - mae: 0.0993 - val_loss: 0.2064 - val_mae: 0.1154\n",
            "Epoch 1131/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2050 - mae: 0.0995 - val_loss: 0.2038 - val_mae: 0.1142\n",
            "Epoch 1132/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2115 - mae: 0.1017 - val_loss: 0.2075 - val_mae: 0.1175\n",
            "Epoch 1133/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2083 - mae: 0.1001 - val_loss: 0.2097 - val_mae: 0.1169\n",
            "Epoch 1134/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3728 - mae: 0.1257 - val_loss: 0.2128 - val_mae: 0.1212\n",
            "Epoch 1135/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1750 - mae: 0.0994 - val_loss: 0.2075 - val_mae: 0.1165\n",
            "Epoch 1136/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1909 - mae: 0.0959 - val_loss: 0.2077 - val_mae: 0.1162\n",
            "Epoch 1137/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2265 - mae: 0.1008 - val_loss: 0.2119 - val_mae: 0.1163\n",
            "Epoch 1138/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2712 - mae: 0.1141 - val_loss: 0.2116 - val_mae: 0.1175\n",
            "Epoch 1139/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1963 - mae: 0.0981 - val_loss: 0.2042 - val_mae: 0.1152\n",
            "Epoch 1140/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1568 - mae: 0.0909 - val_loss: 0.2069 - val_mae: 0.1153\n",
            "Epoch 1141/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1730 - mae: 0.0923 - val_loss: 0.2085 - val_mae: 0.1164\n",
            "Epoch 1142/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2417 - mae: 0.1147 - val_loss: 0.2113 - val_mae: 0.1204\n",
            "Epoch 1143/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2589 - mae: 0.1092 - val_loss: 0.2058 - val_mae: 0.1155\n",
            "Epoch 1144/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3530 - mae: 0.1124 - val_loss: 0.2140 - val_mae: 0.1179\n",
            "Epoch 1145/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2726 - mae: 0.1122 - val_loss: 0.2098 - val_mae: 0.1167\n",
            "Epoch 1146/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1620 - mae: 0.0952 - val_loss: 0.2031 - val_mae: 0.1146\n",
            "Epoch 1147/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1969 - mae: 0.1072 - val_loss: 0.2070 - val_mae: 0.1173\n",
            "Epoch 1148/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3662 - mae: 0.1281 - val_loss: 0.2123 - val_mae: 0.1226\n",
            "Epoch 1149/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1857 - mae: 0.1001 - val_loss: 0.2082 - val_mae: 0.1210\n",
            "Epoch 1150/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3374 - mae: 0.1134 - val_loss: 0.2084 - val_mae: 0.1184\n",
            "Epoch 1151/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2489 - mae: 0.1080 - val_loss: 0.2088 - val_mae: 0.1176\n",
            "Epoch 1152/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2251 - mae: 0.0970 - val_loss: 0.2128 - val_mae: 0.1183\n",
            "Epoch 1153/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2094 - mae: 0.1057 - val_loss: 0.2055 - val_mae: 0.1163\n",
            "Epoch 1154/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3761 - mae: 0.1171 - val_loss: 0.2094 - val_mae: 0.1166\n",
            "Epoch 1155/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1947 - mae: 0.1017 - val_loss: 0.2028 - val_mae: 0.1143\n",
            "Epoch 1156/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1826 - mae: 0.1000 - val_loss: 0.2046 - val_mae: 0.1155\n",
            "Epoch 1157/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2286 - mae: 0.1018 - val_loss: 0.2100 - val_mae: 0.1162\n",
            "Epoch 1158/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1577 - mae: 0.0979 - val_loss: 0.2033 - val_mae: 0.1144\n",
            "Epoch 1159/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1588 - mae: 0.0963 - val_loss: 0.2098 - val_mae: 0.1166\n",
            "Epoch 1160/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1377 - mae: 0.0890 - val_loss: 0.2114 - val_mae: 0.1175\n",
            "Epoch 1161/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2480 - mae: 0.0984 - val_loss: 0.2128 - val_mae: 0.1183\n",
            "Epoch 1162/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1985 - mae: 0.1005 - val_loss: 0.2081 - val_mae: 0.1155\n",
            "Epoch 1163/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2536 - mae: 0.1072 - val_loss: 0.2064 - val_mae: 0.1166\n",
            "Epoch 1164/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1834 - mae: 0.1004 - val_loss: 0.2048 - val_mae: 0.1142\n",
            "Epoch 1165/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1529 - mae: 0.0986 - val_loss: 0.2049 - val_mae: 0.1178\n",
            "Epoch 1166/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2401 - mae: 0.1035 - val_loss: 0.2153 - val_mae: 0.1195\n",
            "Epoch 1167/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2449 - mae: 0.1118 - val_loss: 0.2111 - val_mae: 0.1185\n",
            "Epoch 1168/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3342 - mae: 0.1196 - val_loss: 0.2076 - val_mae: 0.1169\n",
            "Epoch 1169/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3443 - mae: 0.1253 - val_loss: 0.2112 - val_mae: 0.1168\n",
            "Epoch 1170/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1940 - mae: 0.0906 - val_loss: 0.2073 - val_mae: 0.1159\n",
            "Epoch 1171/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1977 - mae: 0.0995 - val_loss: 0.2076 - val_mae: 0.1163\n",
            "Epoch 1172/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1585 - mae: 0.0920 - val_loss: 0.2092 - val_mae: 0.1182\n",
            "Epoch 1173/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2066 - mae: 0.1028 - val_loss: 0.2082 - val_mae: 0.1180\n",
            "Epoch 1174/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2223 - mae: 0.1044 - val_loss: 0.2104 - val_mae: 0.1182\n",
            "Epoch 1175/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1929 - mae: 0.1001 - val_loss: 0.2038 - val_mae: 0.1156\n",
            "Epoch 1176/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1513 - mae: 0.0897 - val_loss: 0.2107 - val_mae: 0.1168\n",
            "Epoch 1177/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2388 - mae: 0.1039 - val_loss: 0.2139 - val_mae: 0.1183\n",
            "Epoch 1178/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2365 - mae: 0.1009 - val_loss: 0.2072 - val_mae: 0.1156\n",
            "Epoch 1179/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3162 - mae: 0.1229 - val_loss: 0.2121 - val_mae: 0.1190\n",
            "Epoch 1180/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2561 - mae: 0.1049 - val_loss: 0.2097 - val_mae: 0.1166\n",
            "Epoch 1181/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2011 - mae: 0.0961 - val_loss: 0.2076 - val_mae: 0.1173\n",
            "Epoch 1182/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2385 - mae: 0.1096 - val_loss: 0.2109 - val_mae: 0.1170\n",
            "Epoch 1183/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1903 - mae: 0.1035 - val_loss: 0.2043 - val_mae: 0.1173\n",
            "Epoch 1184/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2354 - mae: 0.1098 - val_loss: 0.2079 - val_mae: 0.1156\n",
            "Epoch 1185/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3471 - mae: 0.1160 - val_loss: 0.2088 - val_mae: 0.1181\n",
            "Epoch 1186/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1819 - mae: 0.0978 - val_loss: 0.2076 - val_mae: 0.1167\n",
            "Epoch 1187/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2189 - mae: 0.1060 - val_loss: 0.2061 - val_mae: 0.1157\n",
            "Epoch 1188/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2365 - mae: 0.0980 - val_loss: 0.2124 - val_mae: 0.1181\n",
            "Epoch 1189/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1805 - mae: 0.1004 - val_loss: 0.2084 - val_mae: 0.1157\n",
            "Epoch 1190/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2643 - mae: 0.1007 - val_loss: 0.2095 - val_mae: 0.1159\n",
            "Epoch 1191/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2008 - mae: 0.0990 - val_loss: 0.2088 - val_mae: 0.1161\n",
            "Epoch 1192/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1828 - mae: 0.1012 - val_loss: 0.2045 - val_mae: 0.1163\n",
            "Epoch 1193/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2179 - mae: 0.0984 - val_loss: 0.2052 - val_mae: 0.1173\n",
            "Epoch 1194/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2336 - mae: 0.1100 - val_loss: 0.2084 - val_mae: 0.1167\n",
            "Epoch 1195/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2677 - mae: 0.1079 - val_loss: 0.2105 - val_mae: 0.1169\n",
            "Epoch 1196/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1260 - mae: 0.0871 - val_loss: 0.2067 - val_mae: 0.1163\n",
            "Epoch 1197/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2221 - mae: 0.1046 - val_loss: 0.2137 - val_mae: 0.1200\n",
            "Epoch 1198/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3160 - mae: 0.1051 - val_loss: 0.2102 - val_mae: 0.1163\n",
            "Epoch 1199/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1617 - mae: 0.0960 - val_loss: 0.2069 - val_mae: 0.1165\n",
            "Epoch 1200/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2126 - mae: 0.1004 - val_loss: 0.2117 - val_mae: 0.1169\n",
            "Epoch 1201/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2321 - mae: 0.1081 - val_loss: 0.2050 - val_mae: 0.1159\n",
            "Epoch 1202/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2785 - mae: 0.1116 - val_loss: 0.2100 - val_mae: 0.1165\n",
            "Epoch 1203/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2007 - mae: 0.1046 - val_loss: 0.2071 - val_mae: 0.1167\n",
            "Epoch 1204/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3066 - mae: 0.1074 - val_loss: 0.2093 - val_mae: 0.1173\n",
            "Epoch 1205/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2138 - mae: 0.1013 - val_loss: 0.2076 - val_mae: 0.1156\n",
            "Epoch 1206/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1699 - mae: 0.0931 - val_loss: 0.2087 - val_mae: 0.1163\n",
            "Epoch 1207/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2165 - mae: 0.1113 - val_loss: 0.2102 - val_mae: 0.1167\n",
            "Epoch 1208/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2637 - mae: 0.1144 - val_loss: 0.2095 - val_mae: 0.1166\n",
            "Epoch 1209/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1691 - mae: 0.1009 - val_loss: 0.2053 - val_mae: 0.1168\n",
            "Epoch 1210/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2911 - mae: 0.1117 - val_loss: 0.2141 - val_mae: 0.1181\n",
            "Epoch 1211/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2724 - mae: 0.1096 - val_loss: 0.2116 - val_mae: 0.1168\n",
            "Epoch 1212/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2396 - mae: 0.1080 - val_loss: 0.2073 - val_mae: 0.1163\n",
            "Epoch 1213/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1949 - mae: 0.1017 - val_loss: 0.2052 - val_mae: 0.1157\n",
            "Epoch 1214/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1884 - mae: 0.0971 - val_loss: 0.2104 - val_mae: 0.1173\n",
            "Epoch 1215/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1622 - mae: 0.0970 - val_loss: 0.2057 - val_mae: 0.1161\n",
            "Epoch 1216/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1859 - mae: 0.0893 - val_loss: 0.2116 - val_mae: 0.1173\n",
            "Epoch 1217/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3415 - mae: 0.1148 - val_loss: 0.2058 - val_mae: 0.1158\n",
            "Epoch 1218/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2423 - mae: 0.1057 - val_loss: 0.2082 - val_mae: 0.1181\n",
            "Epoch 1219/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2807 - mae: 0.1131 - val_loss: 0.2089 - val_mae: 0.1168\n",
            "Epoch 1220/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1965 - mae: 0.1016 - val_loss: 0.2009 - val_mae: 0.1131\n",
            "Epoch 1221/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1268 - mae: 0.0823 - val_loss: 0.2054 - val_mae: 0.1174\n",
            "Epoch 1222/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2097 - mae: 0.1034 - val_loss: 0.2103 - val_mae: 0.1171\n",
            "Epoch 1223/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2808 - mae: 0.1152 - val_loss: 0.2113 - val_mae: 0.1214\n",
            "Epoch 1224/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1626 - mae: 0.0964 - val_loss: 0.2041 - val_mae: 0.1160\n",
            "Epoch 1225/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.4066 - mae: 0.1316 - val_loss: 0.2109 - val_mae: 0.1187\n",
            "Epoch 1226/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3380 - mae: 0.1124 - val_loss: 0.2041 - val_mae: 0.1159\n",
            "Epoch 1227/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2738 - mae: 0.1166 - val_loss: 0.2080 - val_mae: 0.1168\n",
            "Epoch 1228/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2971 - mae: 0.1070 - val_loss: 0.2080 - val_mae: 0.1166\n",
            "Epoch 1229/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2056 - mae: 0.1069 - val_loss: 0.2080 - val_mae: 0.1170\n",
            "Epoch 1230/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1942 - mae: 0.1051 - val_loss: 0.2044 - val_mae: 0.1146\n",
            "Epoch 1231/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2245 - mae: 0.1031 - val_loss: 0.2111 - val_mae: 0.1197\n",
            "Epoch 1232/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1825 - mae: 0.0991 - val_loss: 0.2083 - val_mae: 0.1171\n",
            "Epoch 1233/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1993 - mae: 0.1019 - val_loss: 0.2068 - val_mae: 0.1155\n",
            "Epoch 1234/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2091 - mae: 0.1031 - val_loss: 0.2092 - val_mae: 0.1176\n",
            "Epoch 1235/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3066 - mae: 0.1165 - val_loss: 0.2101 - val_mae: 0.1174\n",
            "Epoch 1236/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2126 - mae: 0.1023 - val_loss: 0.2062 - val_mae: 0.1160\n",
            "Epoch 1237/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1858 - mae: 0.0931 - val_loss: 0.2095 - val_mae: 0.1171\n",
            "Epoch 1238/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1823 - mae: 0.1009 - val_loss: 0.2075 - val_mae: 0.1169\n",
            "Epoch 1239/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1830 - mae: 0.0995 - val_loss: 0.2100 - val_mae: 0.1195\n",
            "Epoch 1240/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2705 - mae: 0.1147 - val_loss: 0.2108 - val_mae: 0.1203\n",
            "Epoch 1241/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2358 - mae: 0.1009 - val_loss: 0.2103 - val_mae: 0.1163\n",
            "Epoch 1242/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1891 - mae: 0.0970 - val_loss: 0.2089 - val_mae: 0.1163\n",
            "Epoch 1243/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1874 - mae: 0.0927 - val_loss: 0.2119 - val_mae: 0.1169\n",
            "Epoch 1244/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2188 - mae: 0.0980 - val_loss: 0.2120 - val_mae: 0.1163\n",
            "Epoch 1245/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2989 - mae: 0.1125 - val_loss: 0.2101 - val_mae: 0.1173\n",
            "Epoch 1246/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2904 - mae: 0.1158 - val_loss: 0.2041 - val_mae: 0.1157\n",
            "Epoch 1247/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.2014 - mae: 0.0937 - val_loss: 0.2082 - val_mae: 0.1169\n",
            "Epoch 1248/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1661 - mae: 0.0973 - val_loss: 0.2050 - val_mae: 0.1161\n",
            "Epoch 1249/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1670 - mae: 0.0955 - val_loss: 0.2099 - val_mae: 0.1183\n",
            "Epoch 1250/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1642 - mae: 0.0928 - val_loss: 0.2120 - val_mae: 0.1226\n",
            "Epoch 1251/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3986 - mae: 0.1236 - val_loss: 0.2087 - val_mae: 0.1192\n",
            "Epoch 1252/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2256 - mae: 0.1046 - val_loss: 0.2090 - val_mae: 0.1157\n",
            "Epoch 1253/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2808 - mae: 0.1075 - val_loss: 0.2124 - val_mae: 0.1164\n",
            "Epoch 1254/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2548 - mae: 0.1096 - val_loss: 0.2070 - val_mae: 0.1157\n",
            "Epoch 1255/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1969 - mae: 0.0995 - val_loss: 0.2081 - val_mae: 0.1187\n",
            "Epoch 1256/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2533 - mae: 0.1085 - val_loss: 0.2026 - val_mae: 0.1154\n",
            "Epoch 1257/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1518 - mae: 0.0929 - val_loss: 0.2042 - val_mae: 0.1154\n",
            "Epoch 1258/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2087 - mae: 0.1051 - val_loss: 0.2108 - val_mae: 0.1175\n",
            "Epoch 1259/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2464 - mae: 0.1069 - val_loss: 0.2129 - val_mae: 0.1197\n",
            "Epoch 1260/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1472 - mae: 0.0925 - val_loss: 0.2060 - val_mae: 0.1174\n",
            "Epoch 1261/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1657 - mae: 0.0910 - val_loss: 0.2082 - val_mae: 0.1174\n",
            "Epoch 1262/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3788 - mae: 0.1234 - val_loss: 0.2158 - val_mae: 0.1192\n",
            "Epoch 1263/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3420 - mae: 0.1174 - val_loss: 0.2038 - val_mae: 0.1144\n",
            "Epoch 1264/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1897 - mae: 0.1005 - val_loss: 0.2054 - val_mae: 0.1160\n",
            "Epoch 1265/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3130 - mae: 0.1138 - val_loss: 0.2132 - val_mae: 0.1256\n",
            "Epoch 1266/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1743 - mae: 0.0964 - val_loss: 0.2097 - val_mae: 0.1179\n",
            "Epoch 1267/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1969 - mae: 0.1059 - val_loss: 0.2069 - val_mae: 0.1154\n",
            "Epoch 1268/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1716 - mae: 0.0947 - val_loss: 0.2024 - val_mae: 0.1166\n",
            "Epoch 1269/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2229 - mae: 0.1071 - val_loss: 0.2119 - val_mae: 0.1196\n",
            "Epoch 1270/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1512 - mae: 0.0960 - val_loss: 0.2056 - val_mae: 0.1185\n",
            "Epoch 1271/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1921 - mae: 0.0964 - val_loss: 0.2052 - val_mae: 0.1205\n",
            "Epoch 1272/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1466 - mae: 0.0942 - val_loss: 0.2077 - val_mae: 0.1204\n",
            "Epoch 1273/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2466 - mae: 0.1037 - val_loss: 0.2106 - val_mae: 0.1206\n",
            "Epoch 1274/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2018 - mae: 0.0955 - val_loss: 0.2132 - val_mae: 0.1185\n",
            "Epoch 1275/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3090 - mae: 0.1139 - val_loss: 0.2095 - val_mae: 0.1182\n",
            "Epoch 1276/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1451 - mae: 0.0903 - val_loss: 0.2044 - val_mae: 0.1144\n",
            "Epoch 1277/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3000 - mae: 0.1161 - val_loss: 0.2112 - val_mae: 0.1172\n",
            "Epoch 1278/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2114 - mae: 0.1042 - val_loss: 0.2073 - val_mae: 0.1161\n",
            "Epoch 1279/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2400 - mae: 0.1027 - val_loss: 0.2106 - val_mae: 0.1176\n",
            "Epoch 1280/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2250 - mae: 0.0987 - val_loss: 0.2073 - val_mae: 0.1151\n",
            "Epoch 1281/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1766 - mae: 0.0881 - val_loss: 0.2062 - val_mae: 0.1164\n",
            "Epoch 1282/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1449 - mae: 0.0868 - val_loss: 0.2042 - val_mae: 0.1141\n",
            "Epoch 1283/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2327 - mae: 0.1006 - val_loss: 0.2106 - val_mae: 0.1173\n",
            "Epoch 1284/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1975 - mae: 0.1031 - val_loss: 0.2082 - val_mae: 0.1165\n",
            "Epoch 1285/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3266 - mae: 0.1142 - val_loss: 0.2087 - val_mae: 0.1165\n",
            "Epoch 1286/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2033 - mae: 0.1013 - val_loss: 0.2049 - val_mae: 0.1165\n",
            "Epoch 1287/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1691 - mae: 0.0943 - val_loss: 0.2103 - val_mae: 0.1181\n",
            "Epoch 1288/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1205 - mae: 0.0829 - val_loss: 0.2052 - val_mae: 0.1167\n",
            "Epoch 1289/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1746 - mae: 0.0958 - val_loss: 0.2092 - val_mae: 0.1184\n",
            "Epoch 1290/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3330 - mae: 0.1219 - val_loss: 0.2095 - val_mae: 0.1228\n",
            "Epoch 1291/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2017 - mae: 0.1106 - val_loss: 0.2099 - val_mae: 0.1256\n",
            "Epoch 1292/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1953 - mae: 0.1034 - val_loss: 0.2029 - val_mae: 0.1295\n",
            "Epoch 1293/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1502 - mae: 0.1032 - val_loss: 0.2380 - val_mae: 0.1520\n",
            "Epoch 1294/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1686 - mae: 0.1152 - val_loss: 0.1878 - val_mae: 0.1203\n",
            "Epoch 1295/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2299 - mae: 0.1123 - val_loss: 0.2080 - val_mae: 0.1278\n",
            "Epoch 1296/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2346 - mae: 0.1157 - val_loss: 0.1954 - val_mae: 0.1137\n",
            "Epoch 1297/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2065 - mae: 0.0992 - val_loss: 0.2072 - val_mae: 0.1218\n",
            "Epoch 1298/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1340 - mae: 0.0949 - val_loss: 0.1981 - val_mae: 0.1136\n",
            "Epoch 1299/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1741 - mae: 0.0930 - val_loss: 0.2111 - val_mae: 0.1178\n",
            "Epoch 1300/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2457 - mae: 0.1072 - val_loss: 0.2094 - val_mae: 0.1169\n",
            "Epoch 1301/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2989 - mae: 0.1086 - val_loss: 0.2094 - val_mae: 0.1171\n",
            "Epoch 1302/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2307 - mae: 0.1038 - val_loss: 0.2066 - val_mae: 0.1155\n",
            "Epoch 1303/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1863 - mae: 0.0953 - val_loss: 0.2055 - val_mae: 0.1161\n",
            "Epoch 1304/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2123 - mae: 0.0994 - val_loss: 0.2095 - val_mae: 0.1172\n",
            "Epoch 1305/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2160 - mae: 0.1021 - val_loss: 0.2097 - val_mae: 0.1172\n",
            "Epoch 1306/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3021 - mae: 0.1117 - val_loss: 0.2018 - val_mae: 0.1143\n",
            "Epoch 1307/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2516 - mae: 0.1032 - val_loss: 0.2049 - val_mae: 0.1149\n",
            "Epoch 1308/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1487 - mae: 0.0903 - val_loss: 0.2070 - val_mae: 0.1167\n",
            "Epoch 1309/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2493 - mae: 0.1168 - val_loss: 0.2069 - val_mae: 0.1166\n",
            "Epoch 1310/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2352 - mae: 0.1072 - val_loss: 0.2143 - val_mae: 0.1184\n",
            "Epoch 1311/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2340 - mae: 0.1065 - val_loss: 0.2085 - val_mae: 0.1164\n",
            "Epoch 1312/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2304 - mae: 0.1096 - val_loss: 0.2035 - val_mae: 0.1154\n",
            "Epoch 1313/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2387 - mae: 0.1084 - val_loss: 0.2102 - val_mae: 0.1176\n",
            "Epoch 1314/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1980 - mae: 0.0940 - val_loss: 0.2115 - val_mae: 0.1180\n",
            "Epoch 1315/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1347 - mae: 0.0870 - val_loss: 0.2041 - val_mae: 0.1145\n",
            "Epoch 1316/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1682 - mae: 0.0944 - val_loss: 0.2094 - val_mae: 0.1164\n",
            "Epoch 1317/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1875 - mae: 0.0954 - val_loss: 0.2120 - val_mae: 0.1177\n",
            "Epoch 1318/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3172 - mae: 0.1219 - val_loss: 0.2115 - val_mae: 0.1172\n",
            "Epoch 1319/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1563 - mae: 0.0837 - val_loss: 0.2055 - val_mae: 0.1145\n",
            "Epoch 1320/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2114 - mae: 0.1044 - val_loss: 0.2084 - val_mae: 0.1171\n",
            "Epoch 1321/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1923 - mae: 0.0982 - val_loss: 0.2108 - val_mae: 0.1178\n",
            "Epoch 1322/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.4104 - mae: 0.1311 - val_loss: 0.2151 - val_mae: 0.1190\n",
            "Epoch 1323/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2356 - mae: 0.0997 - val_loss: 0.2063 - val_mae: 0.1158\n",
            "Epoch 1324/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1494 - mae: 0.0926 - val_loss: 0.2008 - val_mae: 0.1146\n",
            "Epoch 1325/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2796 - mae: 0.1049 - val_loss: 0.2093 - val_mae: 0.1177\n",
            "Epoch 1326/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1955 - mae: 0.0964 - val_loss: 0.2068 - val_mae: 0.1176\n",
            "Epoch 1327/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3932 - mae: 0.1307 - val_loss: 0.2085 - val_mae: 0.1177\n",
            "Epoch 1328/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2659 - mae: 0.1111 - val_loss: 0.2082 - val_mae: 0.1174\n",
            "Epoch 1329/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2396 - mae: 0.1054 - val_loss: 0.2039 - val_mae: 0.1153\n",
            "Epoch 1330/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1788 - mae: 0.0958 - val_loss: 0.2084 - val_mae: 0.1153\n",
            "Epoch 1331/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1800 - mae: 0.0932 - val_loss: 0.2085 - val_mae: 0.1165\n",
            "Epoch 1332/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1750 - mae: 0.0936 - val_loss: 0.2093 - val_mae: 0.1179\n",
            "Epoch 1333/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2205 - mae: 0.1122 - val_loss: 0.2054 - val_mae: 0.1150\n",
            "Epoch 1334/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2545 - mae: 0.1063 - val_loss: 0.2102 - val_mae: 0.1162\n",
            "Epoch 1335/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2055 - mae: 0.1018 - val_loss: 0.2049 - val_mae: 0.1150\n",
            "Epoch 1336/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2250 - mae: 0.1041 - val_loss: 0.2131 - val_mae: 0.1183\n",
            "Epoch 1337/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1931 - mae: 0.0976 - val_loss: 0.2113 - val_mae: 0.1184\n",
            "Epoch 1338/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1714 - mae: 0.0944 - val_loss: 0.2048 - val_mae: 0.1154\n",
            "Epoch 1339/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2402 - mae: 0.1014 - val_loss: 0.2136 - val_mae: 0.1180\n",
            "Epoch 1340/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1953 - mae: 0.1039 - val_loss: 0.2058 - val_mae: 0.1159\n",
            "Epoch 1341/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2741 - mae: 0.1078 - val_loss: 0.2077 - val_mae: 0.1171\n",
            "Epoch 1342/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2898 - mae: 0.1152 - val_loss: 0.2157 - val_mae: 0.1181\n",
            "Epoch 1343/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2517 - mae: 0.1103 - val_loss: 0.2061 - val_mae: 0.1165\n",
            "Epoch 1344/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2161 - mae: 0.1069 - val_loss: 0.2055 - val_mae: 0.1155\n",
            "Epoch 1345/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2122 - mae: 0.1016 - val_loss: 0.2100 - val_mae: 0.1176\n",
            "Epoch 1346/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2238 - mae: 0.1117 - val_loss: 0.2078 - val_mae: 0.1171\n",
            "Epoch 1347/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2158 - mae: 0.1009 - val_loss: 0.2113 - val_mae: 0.1187\n",
            "Epoch 1348/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2710 - mae: 0.1105 - val_loss: 0.2066 - val_mae: 0.1177\n",
            "Epoch 1349/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1656 - mae: 0.0979 - val_loss: 0.2067 - val_mae: 0.1185\n",
            "Epoch 1350/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1631 - mae: 0.0947 - val_loss: 0.2095 - val_mae: 0.1180\n",
            "Epoch 1351/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1744 - mae: 0.0956 - val_loss: 0.2063 - val_mae: 0.1162\n",
            "Epoch 1352/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1842 - mae: 0.0927 - val_loss: 0.2128 - val_mae: 0.1185\n",
            "Epoch 1353/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2951 - mae: 0.1058 - val_loss: 0.2122 - val_mae: 0.1166\n",
            "Epoch 1354/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2029 - mae: 0.0978 - val_loss: 0.2072 - val_mae: 0.1152\n",
            "Epoch 1355/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2114 - mae: 0.1044 - val_loss: 0.2076 - val_mae: 0.1162\n",
            "Epoch 1356/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3451 - mae: 0.1136 - val_loss: 0.2096 - val_mae: 0.1165\n",
            "Epoch 1357/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2182 - mae: 0.0952 - val_loss: 0.2075 - val_mae: 0.1161\n",
            "Epoch 1358/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1988 - mae: 0.1004 - val_loss: 0.2055 - val_mae: 0.1175\n",
            "Epoch 1359/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2969 - mae: 0.1124 - val_loss: 0.2078 - val_mae: 0.1180\n",
            "Epoch 1360/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2184 - mae: 0.1060 - val_loss: 0.2070 - val_mae: 0.1171\n",
            "Epoch 1361/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2376 - mae: 0.1055 - val_loss: 0.2169 - val_mae: 0.1226\n",
            "Epoch 1362/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2285 - mae: 0.1034 - val_loss: 0.2076 - val_mae: 0.1197\n",
            "Epoch 1363/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2067 - mae: 0.1035 - val_loss: 0.2103 - val_mae: 0.1183\n",
            "Epoch 1364/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2240 - mae: 0.1063 - val_loss: 0.2096 - val_mae: 0.1164\n",
            "Epoch 1365/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2190 - mae: 0.1022 - val_loss: 0.2093 - val_mae: 0.1165\n",
            "Epoch 1366/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2120 - mae: 0.1011 - val_loss: 0.2076 - val_mae: 0.1157\n",
            "Epoch 1367/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1912 - mae: 0.1023 - val_loss: 0.2065 - val_mae: 0.1164\n",
            "Epoch 1368/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.2811 - mae: 0.1074 - val_loss: 0.2111 - val_mae: 0.1177\n",
            "Epoch 1369/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2604 - mae: 0.1113 - val_loss: 0.2095 - val_mae: 0.1159\n",
            "Epoch 1370/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1986 - mae: 0.0995 - val_loss: 0.2076 - val_mae: 0.1159\n",
            "Epoch 1371/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1955 - mae: 0.1019 - val_loss: 0.2080 - val_mae: 0.1157\n",
            "Epoch 1372/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1902 - mae: 0.0914 - val_loss: 0.2078 - val_mae: 0.1157\n",
            "Epoch 1373/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2087 - mae: 0.0956 - val_loss: 0.2088 - val_mae: 0.1166\n",
            "Epoch 1374/2000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2436 - mae: 0.1015 - val_loss: 0.2084 - val_mae: 0.1164\n",
            "Epoch 1375/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2409 - mae: 0.1016 - val_loss: 0.2089 - val_mae: 0.1168\n",
            "Epoch 1376/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1712 - mae: 0.0929 - val_loss: 0.2066 - val_mae: 0.1160\n",
            "Epoch 1377/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2583 - mae: 0.1083 - val_loss: 0.2087 - val_mae: 0.1163\n",
            "Epoch 1378/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2912 - mae: 0.1110 - val_loss: 0.2133 - val_mae: 0.1184\n",
            "Epoch 1379/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2242 - mae: 0.1015 - val_loss: 0.2068 - val_mae: 0.1163\n",
            "Epoch 1380/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2054 - mae: 0.1041 - val_loss: 0.2083 - val_mae: 0.1190\n",
            "Epoch 1381/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2397 - mae: 0.1055 - val_loss: 0.2108 - val_mae: 0.1170\n",
            "Epoch 1382/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2257 - mae: 0.1054 - val_loss: 0.2037 - val_mae: 0.1164\n",
            "Epoch 1383/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3600 - mae: 0.1208 - val_loss: 0.2089 - val_mae: 0.1174\n",
            "Epoch 1384/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1709 - mae: 0.0918 - val_loss: 0.2107 - val_mae: 0.1190\n",
            "Epoch 1385/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1530 - mae: 0.0913 - val_loss: 0.2055 - val_mae: 0.1194\n",
            "Epoch 1386/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1944 - mae: 0.1051 - val_loss: 0.2088 - val_mae: 0.1187\n",
            "Epoch 1387/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1675 - mae: 0.0915 - val_loss: 0.2088 - val_mae: 0.1164\n",
            "Epoch 1388/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1743 - mae: 0.0999 - val_loss: 0.2050 - val_mae: 0.1162\n",
            "Epoch 1389/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1568 - mae: 0.0934 - val_loss: 0.2108 - val_mae: 0.1178\n",
            "Epoch 1390/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1932 - mae: 0.1046 - val_loss: 0.2049 - val_mae: 0.1153\n",
            "Epoch 1391/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2739 - mae: 0.1117 - val_loss: 0.2135 - val_mae: 0.1201\n",
            "Epoch 1392/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1578 - mae: 0.0926 - val_loss: 0.2101 - val_mae: 0.1176\n",
            "Epoch 1393/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2741 - mae: 0.1145 - val_loss: 0.2090 - val_mae: 0.1168\n",
            "Epoch 1394/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1928 - mae: 0.0947 - val_loss: 0.2141 - val_mae: 0.1202\n",
            "Epoch 1395/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2771 - mae: 0.1117 - val_loss: 0.2077 - val_mae: 0.1151\n",
            "Epoch 1396/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2756 - mae: 0.1080 - val_loss: 0.2092 - val_mae: 0.1163\n",
            "Epoch 1397/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1561 - mae: 0.0916 - val_loss: 0.2034 - val_mae: 0.1143\n",
            "Epoch 1398/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1759 - mae: 0.1044 - val_loss: 0.2031 - val_mae: 0.1143\n",
            "Epoch 1399/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3207 - mae: 0.1236 - val_loss: 0.2117 - val_mae: 0.1175\n",
            "Epoch 1400/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1718 - mae: 0.0928 - val_loss: 0.2075 - val_mae: 0.1162\n",
            "Epoch 1401/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2213 - mae: 0.1006 - val_loss: 0.2076 - val_mae: 0.1158\n",
            "Epoch 1402/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1916 - mae: 0.1006 - val_loss: 0.2076 - val_mae: 0.1157\n",
            "Epoch 1403/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2093 - mae: 0.0942 - val_loss: 0.2122 - val_mae: 0.1173\n",
            "Epoch 1404/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2493 - mae: 0.1029 - val_loss: 0.2138 - val_mae: 0.1185\n",
            "Epoch 1405/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1538 - mae: 0.0913 - val_loss: 0.2084 - val_mae: 0.1166\n",
            "Epoch 1406/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2457 - mae: 0.1012 - val_loss: 0.2100 - val_mae: 0.1179\n",
            "Epoch 1407/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1767 - mae: 0.0946 - val_loss: 0.2080 - val_mae: 0.1190\n",
            "Epoch 1408/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1820 - mae: 0.1040 - val_loss: 0.2027 - val_mae: 0.1162\n",
            "Epoch 1409/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2541 - mae: 0.1079 - val_loss: 0.2131 - val_mae: 0.1235\n",
            "Epoch 1410/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2412 - mae: 0.1166 - val_loss: 0.2130 - val_mae: 0.1236\n",
            "Epoch 1411/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1961 - mae: 0.1054 - val_loss: 0.2079 - val_mae: 0.1189\n",
            "Epoch 1412/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2063 - mae: 0.1036 - val_loss: 0.2157 - val_mae: 0.1220\n",
            "Epoch 1413/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2748 - mae: 0.1091 - val_loss: 0.2084 - val_mae: 0.1171\n",
            "Epoch 1414/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3457 - mae: 0.1151 - val_loss: 0.2090 - val_mae: 0.1170\n",
            "Epoch 1415/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2281 - mae: 0.1093 - val_loss: 0.2066 - val_mae: 0.1172\n",
            "Epoch 1416/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3622 - mae: 0.1210 - val_loss: 0.2112 - val_mae: 0.1173\n",
            "Epoch 1417/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3334 - mae: 0.1238 - val_loss: 0.2075 - val_mae: 0.1170\n",
            "Epoch 1418/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1746 - mae: 0.1005 - val_loss: 0.2053 - val_mae: 0.1192\n",
            "Epoch 1419/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2160 - mae: 0.1096 - val_loss: 0.2136 - val_mae: 0.1204\n",
            "Epoch 1420/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2059 - mae: 0.0993 - val_loss: 0.2102 - val_mae: 0.1178\n",
            "Epoch 1421/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1574 - mae: 0.0941 - val_loss: 0.2037 - val_mae: 0.1150\n",
            "Epoch 1422/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2986 - mae: 0.1142 - val_loss: 0.2091 - val_mae: 0.1178\n",
            "Epoch 1423/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1856 - mae: 0.1028 - val_loss: 0.2060 - val_mae: 0.1154\n",
            "Epoch 1424/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2662 - mae: 0.1159 - val_loss: 0.2137 - val_mae: 0.1178\n",
            "Epoch 1425/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2560 - mae: 0.1047 - val_loss: 0.2083 - val_mae: 0.1182\n",
            "Epoch 1426/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1625 - mae: 0.0947 - val_loss: 0.2050 - val_mae: 0.1146\n",
            "Epoch 1427/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1477 - mae: 0.0924 - val_loss: 0.2074 - val_mae: 0.1162\n",
            "Epoch 1428/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2444 - mae: 0.1065 - val_loss: 0.2149 - val_mae: 0.1185\n",
            "Epoch 1429/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1717 - mae: 0.0951 - val_loss: 0.2076 - val_mae: 0.1152\n",
            "Epoch 1430/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1685 - mae: 0.0900 - val_loss: 0.2095 - val_mae: 0.1175\n",
            "Epoch 1431/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1696 - mae: 0.0993 - val_loss: 0.2066 - val_mae: 0.1155\n",
            "Epoch 1432/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3272 - mae: 0.1200 - val_loss: 0.2148 - val_mae: 0.1188\n",
            "Epoch 1433/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1799 - mae: 0.0958 - val_loss: 0.2072 - val_mae: 0.1165\n",
            "Epoch 1434/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2446 - mae: 0.1034 - val_loss: 0.2098 - val_mae: 0.1201\n",
            "Epoch 1435/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.2067 - mae: 0.0987 - val_loss: 0.2099 - val_mae: 0.1190\n",
            "Epoch 1436/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1883 - mae: 0.0975 - val_loss: 0.2079 - val_mae: 0.1164\n",
            "Epoch 1437/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1717 - mae: 0.1003 - val_loss: 0.2056 - val_mae: 0.1167\n",
            "Epoch 1438/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1966 - mae: 0.0929 - val_loss: 0.2125 - val_mae: 0.1179\n",
            "Epoch 1439/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2490 - mae: 0.1063 - val_loss: 0.2107 - val_mae: 0.1173\n",
            "Epoch 1440/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1732 - mae: 0.0955 - val_loss: 0.2081 - val_mae: 0.1153\n",
            "Epoch 1441/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2374 - mae: 0.1009 - val_loss: 0.2095 - val_mae: 0.1176\n",
            "Epoch 1442/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2005 - mae: 0.1027 - val_loss: 0.2078 - val_mae: 0.1156\n",
            "Epoch 1443/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1827 - mae: 0.0923 - val_loss: 0.2108 - val_mae: 0.1170\n",
            "Epoch 1444/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1978 - mae: 0.1017 - val_loss: 0.2099 - val_mae: 0.1172\n",
            "Epoch 1445/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1909 - mae: 0.0966 - val_loss: 0.2132 - val_mae: 0.1180\n",
            "Epoch 1446/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2207 - mae: 0.0938 - val_loss: 0.2104 - val_mae: 0.1154\n",
            "Epoch 1447/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3205 - mae: 0.1142 - val_loss: 0.2082 - val_mae: 0.1159\n",
            "Epoch 1448/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2031 - mae: 0.0903 - val_loss: 0.2098 - val_mae: 0.1161\n",
            "Epoch 1449/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1351 - mae: 0.0911 - val_loss: 0.1995 - val_mae: 0.1128\n",
            "Epoch 1450/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1970 - mae: 0.1019 - val_loss: 0.2106 - val_mae: 0.1172\n",
            "Epoch 1451/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1994 - mae: 0.0955 - val_loss: 0.2105 - val_mae: 0.1166\n",
            "Epoch 1452/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1973 - mae: 0.0939 - val_loss: 0.2110 - val_mae: 0.1179\n",
            "Epoch 1453/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1908 - mae: 0.1021 - val_loss: 0.2075 - val_mae: 0.1154\n",
            "Epoch 1454/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1625 - mae: 0.0936 - val_loss: 0.2077 - val_mae: 0.1188\n",
            "Epoch 1455/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2073 - mae: 0.1009 - val_loss: 0.2101 - val_mae: 0.1180\n",
            "Epoch 1456/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1777 - mae: 0.0990 - val_loss: 0.2082 - val_mae: 0.1167\n",
            "Epoch 1457/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2817 - mae: 0.1051 - val_loss: 0.2105 - val_mae: 0.1206\n",
            "Epoch 1458/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3017 - mae: 0.1136 - val_loss: 0.2090 - val_mae: 0.1174\n",
            "Epoch 1459/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2237 - mae: 0.1027 - val_loss: 0.2093 - val_mae: 0.1160\n",
            "Epoch 1460/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2411 - mae: 0.1050 - val_loss: 0.2071 - val_mae: 0.1153\n",
            "Epoch 1461/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1865 - mae: 0.0999 - val_loss: 0.2084 - val_mae: 0.1187\n",
            "Epoch 1462/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2664 - mae: 0.1176 - val_loss: 0.2108 - val_mae: 0.1228\n",
            "Epoch 1463/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1677 - mae: 0.1019 - val_loss: 0.2059 - val_mae: 0.1194\n",
            "Epoch 1464/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2704 - mae: 0.1140 - val_loss: 0.2130 - val_mae: 0.1185\n",
            "Epoch 1465/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1830 - mae: 0.0978 - val_loss: 0.2068 - val_mae: 0.1160\n",
            "Epoch 1466/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2526 - mae: 0.1088 - val_loss: 0.2117 - val_mae: 0.1181\n",
            "Epoch 1467/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2014 - mae: 0.1018 - val_loss: 0.2071 - val_mae: 0.1161\n",
            "Epoch 1468/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2881 - mae: 0.1140 - val_loss: 0.2136 - val_mae: 0.1186\n",
            "Epoch 1469/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2674 - mae: 0.1035 - val_loss: 0.2116 - val_mae: 0.1177\n",
            "Epoch 1470/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2143 - mae: 0.1006 - val_loss: 0.2052 - val_mae: 0.1148\n",
            "Epoch 1471/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1937 - mae: 0.1002 - val_loss: 0.2037 - val_mae: 0.1158\n",
            "Epoch 1472/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3507 - mae: 0.1267 - val_loss: 0.2132 - val_mae: 0.1195\n",
            "Epoch 1473/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2821 - mae: 0.1128 - val_loss: 0.2100 - val_mae: 0.1159\n",
            "Epoch 1474/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3052 - mae: 0.1112 - val_loss: 0.2085 - val_mae: 0.1160\n",
            "Epoch 1475/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1731 - mae: 0.0938 - val_loss: 0.2034 - val_mae: 0.1165\n",
            "Epoch 1476/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2165 - mae: 0.1094 - val_loss: 0.2065 - val_mae: 0.1162\n",
            "Epoch 1477/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1730 - mae: 0.0935 - val_loss: 0.2102 - val_mae: 0.1167\n",
            "Epoch 1478/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1238 - mae: 0.0859 - val_loss: 0.2063 - val_mae: 0.1154\n",
            "Epoch 1479/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3366 - mae: 0.1149 - val_loss: 0.2138 - val_mae: 0.1185\n",
            "Epoch 1480/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1908 - mae: 0.0954 - val_loss: 0.2080 - val_mae: 0.1207\n",
            "Epoch 1481/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2602 - mae: 0.1167 - val_loss: 0.1978 - val_mae: 0.1136\n",
            "Epoch 1482/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2597 - mae: 0.1100 - val_loss: 0.1973 - val_mae: 0.1324\n",
            "Epoch 1483/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2992 - mae: 0.1412 - val_loss: 0.2108 - val_mae: 0.1482\n",
            "Epoch 1484/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3216 - mae: 0.1387 - val_loss: 0.2061 - val_mae: 0.1241\n",
            "Epoch 1485/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3180 - mae: 0.1166 - val_loss: 0.2000 - val_mae: 0.1185\n",
            "Epoch 1486/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2463 - mae: 0.1085 - val_loss: 0.2066 - val_mae: 0.1198\n",
            "Epoch 1487/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1461 - mae: 0.0912 - val_loss: 0.2073 - val_mae: 0.1180\n",
            "Epoch 1488/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3294 - mae: 0.1184 - val_loss: 0.2082 - val_mae: 0.1169\n",
            "Epoch 1489/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1814 - mae: 0.0956 - val_loss: 0.2063 - val_mae: 0.1165\n",
            "Epoch 1490/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1822 - mae: 0.0939 - val_loss: 0.2115 - val_mae: 0.1186\n",
            "Epoch 1491/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3419 - mae: 0.1240 - val_loss: 0.2084 - val_mae: 0.1169\n",
            "Epoch 1492/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1762 - mae: 0.0931 - val_loss: 0.2094 - val_mae: 0.1178\n",
            "Epoch 1493/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2071 - mae: 0.0967 - val_loss: 0.2108 - val_mae: 0.1204\n",
            "Epoch 1494/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1594 - mae: 0.0924 - val_loss: 0.2041 - val_mae: 0.1158\n",
            "Epoch 1495/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3008 - mae: 0.1138 - val_loss: 0.2102 - val_mae: 0.1184\n",
            "Epoch 1496/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2579 - mae: 0.1096 - val_loss: 0.2083 - val_mae: 0.1164\n",
            "Epoch 1497/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2028 - mae: 0.0962 - val_loss: 0.2122 - val_mae: 0.1178\n",
            "Epoch 1498/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1684 - mae: 0.0903 - val_loss: 0.2056 - val_mae: 0.1173\n",
            "Epoch 1499/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2534 - mae: 0.1079 - val_loss: 0.2096 - val_mae: 0.1169\n",
            "Epoch 1500/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1685 - mae: 0.0924 - val_loss: 0.2064 - val_mae: 0.1154\n",
            "Epoch 1501/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2116 - mae: 0.1036 - val_loss: 0.2089 - val_mae: 0.1162\n",
            "Epoch 1502/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2330 - mae: 0.1057 - val_loss: 0.2096 - val_mae: 0.1183\n",
            "Epoch 1503/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2473 - mae: 0.1038 - val_loss: 0.2101 - val_mae: 0.1169\n",
            "Epoch 1504/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2484 - mae: 0.1038 - val_loss: 0.2087 - val_mae: 0.1172\n",
            "Epoch 1505/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1504 - mae: 0.0947 - val_loss: 0.2115 - val_mae: 0.1179\n",
            "Epoch 1506/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1568 - mae: 0.0931 - val_loss: 0.2057 - val_mae: 0.1158\n",
            "Epoch 1507/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2200 - mae: 0.1033 - val_loss: 0.2110 - val_mae: 0.1166\n",
            "Epoch 1508/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2201 - mae: 0.1007 - val_loss: 0.2086 - val_mae: 0.1169\n",
            "Epoch 1509/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1800 - mae: 0.0965 - val_loss: 0.2080 - val_mae: 0.1163\n",
            "Epoch 1510/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3095 - mae: 0.1113 - val_loss: 0.2144 - val_mae: 0.1186\n",
            "Epoch 1511/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1465 - mae: 0.0901 - val_loss: 0.2030 - val_mae: 0.1143\n",
            "Epoch 1512/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1796 - mae: 0.0943 - val_loss: 0.2088 - val_mae: 0.1162\n",
            "Epoch 1513/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1778 - mae: 0.0928 - val_loss: 0.2070 - val_mae: 0.1157\n",
            "Epoch 1514/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2809 - mae: 0.1051 - val_loss: 0.2136 - val_mae: 0.1176\n",
            "Epoch 1515/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1490 - mae: 0.0905 - val_loss: 0.2084 - val_mae: 0.1158\n",
            "Epoch 1516/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2749 - mae: 0.1092 - val_loss: 0.2097 - val_mae: 0.1172\n",
            "Epoch 1517/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2517 - mae: 0.1054 - val_loss: 0.2086 - val_mae: 0.1168\n",
            "Epoch 1518/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1409 - mae: 0.0892 - val_loss: 0.2045 - val_mae: 0.1150\n",
            "Epoch 1519/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1972 - mae: 0.1071 - val_loss: 0.2066 - val_mae: 0.1159\n",
            "Epoch 1520/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3004 - mae: 0.1029 - val_loss: 0.2135 - val_mae: 0.1183\n",
            "Epoch 1521/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2101 - mae: 0.0961 - val_loss: 0.2082 - val_mae: 0.1161\n",
            "Epoch 1522/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2629 - mae: 0.1071 - val_loss: 0.2089 - val_mae: 0.1152\n",
            "Epoch 1523/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2507 - mae: 0.1103 - val_loss: 0.2107 - val_mae: 0.1168\n",
            "Epoch 1524/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1778 - mae: 0.0838 - val_loss: 0.2078 - val_mae: 0.1162\n",
            "Epoch 1525/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3139 - mae: 0.1127 - val_loss: 0.2044 - val_mae: 0.1146\n",
            "Epoch 1526/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1809 - mae: 0.1034 - val_loss: 0.2054 - val_mae: 0.1152\n",
            "Epoch 1527/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2484 - mae: 0.1091 - val_loss: 0.2095 - val_mae: 0.1159\n",
            "Epoch 1528/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1950 - mae: 0.0972 - val_loss: 0.2084 - val_mae: 0.1164\n",
            "Epoch 1529/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2124 - mae: 0.1039 - val_loss: 0.2080 - val_mae: 0.1170\n",
            "Epoch 1530/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1693 - mae: 0.0948 - val_loss: 0.2107 - val_mae: 0.1184\n",
            "Epoch 1531/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2868 - mae: 0.1126 - val_loss: 0.2108 - val_mae: 0.1190\n",
            "Epoch 1532/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1796 - mae: 0.1032 - val_loss: 0.2011 - val_mae: 0.1141\n",
            "Epoch 1533/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2452 - mae: 0.1044 - val_loss: 0.2101 - val_mae: 0.1173\n",
            "Epoch 1534/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1839 - mae: 0.1032 - val_loss: 0.2039 - val_mae: 0.1157\n",
            "Epoch 1535/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1832 - mae: 0.0906 - val_loss: 0.2151 - val_mae: 0.1185\n",
            "Epoch 1536/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1807 - mae: 0.0990 - val_loss: 0.2106 - val_mae: 0.1171\n",
            "Epoch 1537/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2340 - mae: 0.1029 - val_loss: 0.2100 - val_mae: 0.1172\n",
            "Epoch 1538/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2641 - mae: 0.1067 - val_loss: 0.2108 - val_mae: 0.1176\n",
            "Epoch 1539/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1792 - mae: 0.0994 - val_loss: 0.2051 - val_mae: 0.1149\n",
            "Epoch 1540/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1596 - mae: 0.0926 - val_loss: 0.2055 - val_mae: 0.1150\n",
            "Epoch 1541/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2572 - mae: 0.1049 - val_loss: 0.2113 - val_mae: 0.1171\n",
            "Epoch 1542/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2058 - mae: 0.1028 - val_loss: 0.2094 - val_mae: 0.1160\n",
            "Epoch 1543/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2770 - mae: 0.1112 - val_loss: 0.2091 - val_mae: 0.1169\n",
            "Epoch 1544/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2892 - mae: 0.1110 - val_loss: 0.2080 - val_mae: 0.1158\n",
            "Epoch 1545/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1627 - mae: 0.0922 - val_loss: 0.2046 - val_mae: 0.1166\n",
            "Epoch 1546/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2118 - mae: 0.1078 - val_loss: 0.2113 - val_mae: 0.1180\n",
            "Epoch 1547/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1707 - mae: 0.0944 - val_loss: 0.2071 - val_mae: 0.1153\n",
            "Epoch 1548/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3638 - mae: 0.1193 - val_loss: 0.2091 - val_mae: 0.1157\n",
            "Epoch 1549/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1930 - mae: 0.0957 - val_loss: 0.2114 - val_mae: 0.1169\n",
            "Epoch 1550/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2190 - mae: 0.1040 - val_loss: 0.2068 - val_mae: 0.1143\n",
            "Epoch 1551/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2608 - mae: 0.1092 - val_loss: 0.2060 - val_mae: 0.1156\n",
            "Epoch 1552/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2775 - mae: 0.1121 - val_loss: 0.2112 - val_mae: 0.1178\n",
            "Epoch 1553/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2832 - mae: 0.1208 - val_loss: 0.2070 - val_mae: 0.1161\n",
            "Epoch 1554/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2248 - mae: 0.0961 - val_loss: 0.2077 - val_mae: 0.1166\n",
            "Epoch 1555/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3649 - mae: 0.1260 - val_loss: 0.2067 - val_mae: 0.1154\n",
            "Epoch 1556/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1754 - mae: 0.0959 - val_loss: 0.2068 - val_mae: 0.1164\n",
            "Epoch 1557/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2427 - mae: 0.1019 - val_loss: 0.2082 - val_mae: 0.1164\n",
            "Epoch 1558/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1440 - mae: 0.0920 - val_loss: 0.2032 - val_mae: 0.1138\n",
            "Epoch 1559/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2474 - mae: 0.1044 - val_loss: 0.2123 - val_mae: 0.1184\n",
            "Epoch 1560/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2619 - mae: 0.1057 - val_loss: 0.2089 - val_mae: 0.1171\n",
            "Epoch 1561/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1606 - mae: 0.0902 - val_loss: 0.2020 - val_mae: 0.1139\n",
            "Epoch 1562/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1782 - mae: 0.0951 - val_loss: 0.2078 - val_mae: 0.1172\n",
            "Epoch 1563/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1921 - mae: 0.1004 - val_loss: 0.2082 - val_mae: 0.1159\n",
            "Epoch 1564/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1953 - mae: 0.1015 - val_loss: 0.2087 - val_mae: 0.1180\n",
            "Epoch 1565/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1494 - mae: 0.0950 - val_loss: 0.2052 - val_mae: 0.1154\n",
            "Epoch 1566/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1398 - mae: 0.0912 - val_loss: 0.2094 - val_mae: 0.1177\n",
            "Epoch 1567/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1704 - mae: 0.0954 - val_loss: 0.2094 - val_mae: 0.1169\n",
            "Epoch 1568/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2145 - mae: 0.1048 - val_loss: 0.2119 - val_mae: 0.1171\n",
            "Epoch 1569/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1604 - mae: 0.0943 - val_loss: 0.2106 - val_mae: 0.1172\n",
            "Epoch 1570/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2225 - mae: 0.1065 - val_loss: 0.2130 - val_mae: 0.1188\n",
            "Epoch 1571/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2526 - mae: 0.1023 - val_loss: 0.2110 - val_mae: 0.1187\n",
            "Epoch 1572/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1924 - mae: 0.0985 - val_loss: 0.2087 - val_mae: 0.1169\n",
            "Epoch 1573/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2759 - mae: 0.1153 - val_loss: 0.2053 - val_mae: 0.1153\n",
            "Epoch 1574/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2174 - mae: 0.0942 - val_loss: 0.2112 - val_mae: 0.1175\n",
            "Epoch 1575/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1862 - mae: 0.0978 - val_loss: 0.2096 - val_mae: 0.1159\n",
            "Epoch 1576/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3116 - mae: 0.1092 - val_loss: 0.2056 - val_mae: 0.1152\n",
            "Epoch 1577/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1768 - mae: 0.0985 - val_loss: 0.2073 - val_mae: 0.1170\n",
            "Epoch 1578/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2451 - mae: 0.1066 - val_loss: 0.2097 - val_mae: 0.1167\n",
            "Epoch 1579/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1648 - mae: 0.0944 - val_loss: 0.2050 - val_mae: 0.1143\n",
            "Epoch 1580/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2300 - mae: 0.1075 - val_loss: 0.2114 - val_mae: 0.1180\n",
            "Epoch 1581/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3142 - mae: 0.1126 - val_loss: 0.2121 - val_mae: 0.1189\n",
            "Epoch 1582/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2476 - mae: 0.1090 - val_loss: 0.2109 - val_mae: 0.1195\n",
            "Epoch 1583/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1456 - mae: 0.0907 - val_loss: 0.2060 - val_mae: 0.1160\n",
            "Epoch 1584/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2535 - mae: 0.1076 - val_loss: 0.2109 - val_mae: 0.1179\n",
            "Epoch 1585/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1625 - mae: 0.1017 - val_loss: 0.2049 - val_mae: 0.1155\n",
            "Epoch 1586/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2799 - mae: 0.1130 - val_loss: 0.2081 - val_mae: 0.1172\n",
            "Epoch 1587/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1474 - mae: 0.0924 - val_loss: 0.2046 - val_mae: 0.1152\n",
            "Epoch 1588/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2294 - mae: 0.1005 - val_loss: 0.2090 - val_mae: 0.1172\n",
            "Epoch 1589/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1970 - mae: 0.0983 - val_loss: 0.2116 - val_mae: 0.1183\n",
            "Epoch 1590/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1729 - mae: 0.0923 - val_loss: 0.2094 - val_mae: 0.1159\n",
            "Epoch 1591/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2076 - mae: 0.1002 - val_loss: 0.2093 - val_mae: 0.1172\n",
            "Epoch 1592/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1467 - mae: 0.0872 - val_loss: 0.2074 - val_mae: 0.1178\n",
            "Epoch 1593/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1970 - mae: 0.1008 - val_loss: 0.2124 - val_mae: 0.1191\n",
            "Epoch 1594/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2357 - mae: 0.0993 - val_loss: 0.2088 - val_mae: 0.1174\n",
            "Epoch 1595/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2366 - mae: 0.1051 - val_loss: 0.2110 - val_mae: 0.1171\n",
            "Epoch 1596/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1644 - mae: 0.0941 - val_loss: 0.2069 - val_mae: 0.1152\n",
            "Epoch 1597/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1590 - mae: 0.0919 - val_loss: 0.2099 - val_mae: 0.1173\n",
            "Epoch 1598/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2440 - mae: 0.1125 - val_loss: 0.2097 - val_mae: 0.1172\n",
            "Epoch 1599/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1623 - mae: 0.0914 - val_loss: 0.2071 - val_mae: 0.1160\n",
            "Epoch 1600/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1381 - mae: 0.0870 - val_loss: 0.2081 - val_mae: 0.1162\n",
            "Epoch 1601/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2886 - mae: 0.1072 - val_loss: 0.2082 - val_mae: 0.1160\n",
            "Epoch 1602/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1944 - mae: 0.1086 - val_loss: 0.2077 - val_mae: 0.1162\n",
            "Epoch 1603/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2606 - mae: 0.1062 - val_loss: 0.2115 - val_mae: 0.1170\n",
            "Epoch 1604/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3319 - mae: 0.1158 - val_loss: 0.2066 - val_mae: 0.1158\n",
            "Epoch 1605/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1866 - mae: 0.0922 - val_loss: 0.2090 - val_mae: 0.1157\n",
            "Epoch 1606/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2308 - mae: 0.1004 - val_loss: 0.2084 - val_mae: 0.1154\n",
            "Epoch 1607/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2418 - mae: 0.1111 - val_loss: 0.2075 - val_mae: 0.1160\n",
            "Epoch 1608/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3961 - mae: 0.1214 - val_loss: 0.2098 - val_mae: 0.1159\n",
            "Epoch 1609/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2259 - mae: 0.0997 - val_loss: 0.2078 - val_mae: 0.1152\n",
            "Epoch 1610/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2073 - mae: 0.1047 - val_loss: 0.2068 - val_mae: 0.1154\n",
            "Epoch 1611/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1878 - mae: 0.0886 - val_loss: 0.2114 - val_mae: 0.1175\n",
            "Epoch 1612/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1928 - mae: 0.0917 - val_loss: 0.2078 - val_mae: 0.1167\n",
            "Epoch 1613/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2332 - mae: 0.1061 - val_loss: 0.2076 - val_mae: 0.1166\n",
            "Epoch 1614/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3227 - mae: 0.1255 - val_loss: 0.2059 - val_mae: 0.1173\n",
            "Epoch 1615/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2673 - mae: 0.1057 - val_loss: 0.2081 - val_mae: 0.1207\n",
            "Epoch 1616/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1955 - mae: 0.1068 - val_loss: 0.2103 - val_mae: 0.1185\n",
            "Epoch 1617/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2107 - mae: 0.1020 - val_loss: 0.2097 - val_mae: 0.1167\n",
            "Epoch 1618/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1801 - mae: 0.0948 - val_loss: 0.2108 - val_mae: 0.1170\n",
            "Epoch 1619/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1841 - mae: 0.0943 - val_loss: 0.2111 - val_mae: 0.1164\n",
            "Epoch 1620/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2940 - mae: 0.1101 - val_loss: 0.2099 - val_mae: 0.1167\n",
            "Epoch 1621/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1711 - mae: 0.0930 - val_loss: 0.2063 - val_mae: 0.1153\n",
            "Epoch 1622/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2277 - mae: 0.1045 - val_loss: 0.2067 - val_mae: 0.1165\n",
            "Epoch 1623/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1858 - mae: 0.0995 - val_loss: 0.2105 - val_mae: 0.1240\n",
            "Epoch 1624/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1826 - mae: 0.1013 - val_loss: 0.2081 - val_mae: 0.1204\n",
            "Epoch 1625/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3016 - mae: 0.1128 - val_loss: 0.2119 - val_mae: 0.1222\n",
            "Epoch 1626/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1995 - mae: 0.1033 - val_loss: 0.2100 - val_mae: 0.1605\n",
            "Epoch 1627/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2632 - mae: 0.1516 - val_loss: 0.2144 - val_mae: 0.1373\n",
            "Epoch 1628/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1931 - mae: 0.1128 - val_loss: 0.2128 - val_mae: 0.1241\n",
            "Epoch 1629/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.3100 - mae: 0.1179 - val_loss: 0.2082 - val_mae: 0.1211\n",
            "Epoch 1630/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1375 - mae: 0.0888 - val_loss: 0.2005 - val_mae: 0.1168\n",
            "Epoch 1631/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2457 - mae: 0.1090 - val_loss: 0.2073 - val_mae: 0.1172\n",
            "Epoch 1632/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2314 - mae: 0.1080 - val_loss: 0.2076 - val_mae: 0.1173\n",
            "Epoch 1633/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1874 - mae: 0.0990 - val_loss: 0.2097 - val_mae: 0.1170\n",
            "Epoch 1634/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2202 - mae: 0.0975 - val_loss: 0.2108 - val_mae: 0.1164\n",
            "Epoch 1635/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1690 - mae: 0.1002 - val_loss: 0.2055 - val_mae: 0.1152\n",
            "Epoch 1636/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2269 - mae: 0.1092 - val_loss: 0.2089 - val_mae: 0.1176\n",
            "Epoch 1637/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2786 - mae: 0.1090 - val_loss: 0.2112 - val_mae: 0.1172\n",
            "Epoch 1638/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2804 - mae: 0.1092 - val_loss: 0.2091 - val_mae: 0.1150\n",
            "Epoch 1639/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2067 - mae: 0.1046 - val_loss: 0.2073 - val_mae: 0.1162\n",
            "Epoch 1640/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1999 - mae: 0.0962 - val_loss: 0.2102 - val_mae: 0.1164\n",
            "Epoch 1641/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2290 - mae: 0.1038 - val_loss: 0.2094 - val_mae: 0.1162\n",
            "Epoch 1642/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2230 - mae: 0.1011 - val_loss: 0.2122 - val_mae: 0.1183\n",
            "Epoch 1643/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2182 - mae: 0.1043 - val_loss: 0.2091 - val_mae: 0.1160\n",
            "Epoch 1644/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2302 - mae: 0.1032 - val_loss: 0.2099 - val_mae: 0.1173\n",
            "Epoch 1645/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2438 - mae: 0.1068 - val_loss: 0.2102 - val_mae: 0.1158\n",
            "Epoch 1646/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3055 - mae: 0.1020 - val_loss: 0.2071 - val_mae: 0.1147\n",
            "Epoch 1647/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2700 - mae: 0.1118 - val_loss: 0.2091 - val_mae: 0.1170\n",
            "Epoch 1648/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3221 - mae: 0.1156 - val_loss: 0.2061 - val_mae: 0.1145\n",
            "Epoch 1649/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1849 - mae: 0.0994 - val_loss: 0.2052 - val_mae: 0.1147\n",
            "Epoch 1650/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3373 - mae: 0.1292 - val_loss: 0.2103 - val_mae: 0.1167\n",
            "Epoch 1651/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1856 - mae: 0.1011 - val_loss: 0.2060 - val_mae: 0.1163\n",
            "Epoch 1652/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2517 - mae: 0.1057 - val_loss: 0.2136 - val_mae: 0.1174\n",
            "Epoch 1653/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2329 - mae: 0.1074 - val_loss: 0.2087 - val_mae: 0.1158\n",
            "Epoch 1654/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3605 - mae: 0.1276 - val_loss: 0.2141 - val_mae: 0.1222\n",
            "Epoch 1655/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2437 - mae: 0.1228 - val_loss: 0.2020 - val_mae: 0.1156\n",
            "Epoch 1656/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1883 - mae: 0.1078 - val_loss: 0.2050 - val_mae: 0.1174\n",
            "Epoch 1657/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2750 - mae: 0.1113 - val_loss: 0.2130 - val_mae: 0.1190\n",
            "Epoch 1658/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2854 - mae: 0.1117 - val_loss: 0.2086 - val_mae: 0.1171\n",
            "Epoch 1659/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1795 - mae: 0.0964 - val_loss: 0.2090 - val_mae: 0.1199\n",
            "Epoch 1660/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2048 - mae: 0.1001 - val_loss: 0.2071 - val_mae: 0.1175\n",
            "Epoch 1661/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2385 - mae: 0.0985 - val_loss: 0.2135 - val_mae: 0.1179\n",
            "Epoch 1662/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2842 - mae: 0.1087 - val_loss: 0.2093 - val_mae: 0.1160\n",
            "Epoch 1663/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1274 - mae: 0.0903 - val_loss: 0.2031 - val_mae: 0.1150\n",
            "Epoch 1664/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3307 - mae: 0.1167 - val_loss: 0.2099 - val_mae: 0.1173\n",
            "Epoch 1665/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2334 - mae: 0.1063 - val_loss: 0.2096 - val_mae: 0.1182\n",
            "Epoch 1666/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3261 - mae: 0.1265 - val_loss: 0.2062 - val_mae: 0.1144\n",
            "Epoch 1667/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.2353 - mae: 0.1015 - val_loss: 0.2061 - val_mae: 0.1146\n",
            "Epoch 1668/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1754 - mae: 0.0929 - val_loss: 0.2095 - val_mae: 0.1162\n",
            "Epoch 1669/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1694 - mae: 0.0930 - val_loss: 0.2080 - val_mae: 0.1167\n",
            "Epoch 1670/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2117 - mae: 0.1044 - val_loss: 0.2097 - val_mae: 0.1161\n",
            "Epoch 1671/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1769 - mae: 0.0949 - val_loss: 0.2075 - val_mae: 0.1152\n",
            "Epoch 1672/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2347 - mae: 0.1031 - val_loss: 0.2097 - val_mae: 0.1167\n",
            "Epoch 1673/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1869 - mae: 0.0962 - val_loss: 0.2101 - val_mae: 0.1158\n",
            "Epoch 1674/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1939 - mae: 0.0934 - val_loss: 0.2103 - val_mae: 0.1178\n",
            "Epoch 1675/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1973 - mae: 0.1050 - val_loss: 0.2070 - val_mae: 0.1157\n",
            "Epoch 1676/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1932 - mae: 0.1010 - val_loss: 0.2060 - val_mae: 0.1149\n",
            "Epoch 1677/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2920 - mae: 0.1103 - val_loss: 0.2114 - val_mae: 0.1176\n",
            "Epoch 1678/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2021 - mae: 0.0976 - val_loss: 0.2099 - val_mae: 0.1159\n",
            "Epoch 1679/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1470 - mae: 0.0900 - val_loss: 0.2060 - val_mae: 0.1158\n",
            "Epoch 1680/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2109 - mae: 0.1054 - val_loss: 0.2091 - val_mae: 0.1179\n",
            "Epoch 1681/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2120 - mae: 0.0957 - val_loss: 0.2066 - val_mae: 0.1150\n",
            "Epoch 1682/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2311 - mae: 0.1020 - val_loss: 0.2088 - val_mae: 0.1155\n",
            "Epoch 1683/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2442 - mae: 0.1035 - val_loss: 0.2082 - val_mae: 0.1155\n",
            "Epoch 1684/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2513 - mae: 0.1040 - val_loss: 0.2116 - val_mae: 0.1164\n",
            "Epoch 1685/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1983 - mae: 0.0928 - val_loss: 0.2071 - val_mae: 0.1152\n",
            "Epoch 1686/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1988 - mae: 0.0961 - val_loss: 0.2093 - val_mae: 0.1172\n",
            "Epoch 1687/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2958 - mae: 0.1180 - val_loss: 0.2086 - val_mae: 0.1159\n",
            "Epoch 1688/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1765 - mae: 0.0969 - val_loss: 0.2078 - val_mae: 0.1154\n",
            "Epoch 1689/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2453 - mae: 0.1103 - val_loss: 0.2095 - val_mae: 0.1167\n",
            "Epoch 1690/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1893 - mae: 0.0949 - val_loss: 0.2135 - val_mae: 0.1182\n",
            "Epoch 1691/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2610 - mae: 0.1065 - val_loss: 0.2099 - val_mae: 0.1164\n",
            "Epoch 1692/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1518 - mae: 0.0915 - val_loss: 0.2032 - val_mae: 0.1130\n",
            "Epoch 1693/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3108 - mae: 0.1051 - val_loss: 0.2085 - val_mae: 0.1168\n",
            "Epoch 1694/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1902 - mae: 0.1010 - val_loss: 0.2072 - val_mae: 0.1165\n",
            "Epoch 1695/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2168 - mae: 0.0998 - val_loss: 0.2092 - val_mae: 0.1159\n",
            "Epoch 1696/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1465 - mae: 0.0883 - val_loss: 0.2063 - val_mae: 0.1163\n",
            "Epoch 1697/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1964 - mae: 0.1006 - val_loss: 0.2060 - val_mae: 0.1155\n",
            "Epoch 1698/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1936 - mae: 0.0990 - val_loss: 0.2094 - val_mae: 0.1162\n",
            "Epoch 1699/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1774 - mae: 0.0933 - val_loss: 0.2106 - val_mae: 0.1185\n",
            "Epoch 1700/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2219 - mae: 0.1045 - val_loss: 0.2079 - val_mae: 0.1157\n",
            "Epoch 1701/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1975 - mae: 0.1045 - val_loss: 0.2065 - val_mae: 0.1152\n",
            "Epoch 1702/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2436 - mae: 0.1020 - val_loss: 0.2120 - val_mae: 0.1177\n",
            "Epoch 1703/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1878 - mae: 0.0983 - val_loss: 0.2057 - val_mae: 0.1150\n",
            "Epoch 1704/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2798 - mae: 0.1120 - val_loss: 0.2114 - val_mae: 0.1189\n",
            "Epoch 1705/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1756 - mae: 0.0961 - val_loss: 0.2080 - val_mae: 0.1158\n",
            "Epoch 1706/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2735 - mae: 0.1118 - val_loss: 0.2087 - val_mae: 0.1162\n",
            "Epoch 1707/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1892 - mae: 0.1005 - val_loss: 0.2078 - val_mae: 0.1155\n",
            "Epoch 1708/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2349 - mae: 0.1042 - val_loss: 0.2087 - val_mae: 0.1186\n",
            "Epoch 1709/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2512 - mae: 0.1012 - val_loss: 0.2117 - val_mae: 0.1174\n",
            "Epoch 1710/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1653 - mae: 0.0951 - val_loss: 0.2037 - val_mae: 0.1152\n",
            "Epoch 1711/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2743 - mae: 0.1083 - val_loss: 0.2120 - val_mae: 0.1167\n",
            "Epoch 1712/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1765 - mae: 0.0903 - val_loss: 0.2072 - val_mae: 0.1149\n",
            "Epoch 1713/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1736 - mae: 0.0989 - val_loss: 0.2069 - val_mae: 0.1160\n",
            "Epoch 1714/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2515 - mae: 0.1120 - val_loss: 0.2109 - val_mae: 0.1164\n",
            "Epoch 1715/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2604 - mae: 0.1079 - val_loss: 0.2060 - val_mae: 0.1152\n",
            "Epoch 1716/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2169 - mae: 0.1024 - val_loss: 0.2067 - val_mae: 0.1152\n",
            "Epoch 1717/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2654 - mae: 0.1102 - val_loss: 0.2104 - val_mae: 0.1162\n",
            "Epoch 1718/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2327 - mae: 0.1057 - val_loss: 0.2094 - val_mae: 0.1172\n",
            "Epoch 1719/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3661 - mae: 0.1210 - val_loss: 0.2041 - val_mae: 0.1145\n",
            "Epoch 1720/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2121 - mae: 0.1027 - val_loss: 0.2103 - val_mae: 0.1335\n",
            "Epoch 1721/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2865 - mae: 0.1188 - val_loss: 0.2077 - val_mae: 0.1239\n",
            "Epoch 1722/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2247 - mae: 0.1145 - val_loss: 0.2024 - val_mae: 0.1215\n",
            "Epoch 1723/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2824 - mae: 0.1255 - val_loss: 0.2069 - val_mae: 0.1195\n",
            "Epoch 1724/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2831 - mae: 0.1142 - val_loss: 0.2068 - val_mae: 0.1173\n",
            "Epoch 1725/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2382 - mae: 0.1024 - val_loss: 0.2049 - val_mae: 0.1191\n",
            "Epoch 1726/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2235 - mae: 0.1034 - val_loss: 0.2048 - val_mae: 0.1171\n",
            "Epoch 1727/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2018 - mae: 0.1010 - val_loss: 0.2090 - val_mae: 0.1162\n",
            "Epoch 1728/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2103 - mae: 0.1040 - val_loss: 0.2059 - val_mae: 0.1149\n",
            "Epoch 1729/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2836 - mae: 0.1132 - val_loss: 0.2083 - val_mae: 0.1156\n",
            "Epoch 1730/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2208 - mae: 0.0993 - val_loss: 0.2053 - val_mae: 0.1145\n",
            "Epoch 1731/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1921 - mae: 0.0981 - val_loss: 0.2049 - val_mae: 0.1156\n",
            "Epoch 1732/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2369 - mae: 0.1035 - val_loss: 0.2112 - val_mae: 0.1186\n",
            "Epoch 1733/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1492 - mae: 0.0903 - val_loss: 0.2068 - val_mae: 0.1161\n",
            "Epoch 1734/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2746 - mae: 0.1146 - val_loss: 0.2095 - val_mae: 0.1159\n",
            "Epoch 1735/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2702 - mae: 0.1103 - val_loss: 0.2101 - val_mae: 0.1162\n",
            "Epoch 1736/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2176 - mae: 0.1029 - val_loss: 0.2075 - val_mae: 0.1157\n",
            "Epoch 1737/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2251 - mae: 0.1016 - val_loss: 0.2089 - val_mae: 0.1161\n",
            "Epoch 1738/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3133 - mae: 0.1173 - val_loss: 0.2111 - val_mae: 0.1162\n",
            "Epoch 1739/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1865 - mae: 0.1024 - val_loss: 0.2048 - val_mae: 0.1150\n",
            "Epoch 1740/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1815 - mae: 0.0988 - val_loss: 0.2101 - val_mae: 0.1164\n",
            "Epoch 1741/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1867 - mae: 0.0961 - val_loss: 0.2118 - val_mae: 0.1174\n",
            "Epoch 1742/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2545 - mae: 0.1059 - val_loss: 0.2151 - val_mae: 0.1182\n",
            "Epoch 1743/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2133 - mae: 0.1025 - val_loss: 0.2054 - val_mae: 0.1150\n",
            "Epoch 1744/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1378 - mae: 0.0834 - val_loss: 0.2040 - val_mae: 0.1140\n",
            "Epoch 1745/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2329 - mae: 0.1094 - val_loss: 0.2083 - val_mae: 0.1158\n",
            "Epoch 1746/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2090 - mae: 0.1043 - val_loss: 0.2106 - val_mae: 0.1200\n",
            "Epoch 1747/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2919 - mae: 0.1203 - val_loss: 0.2086 - val_mae: 0.1168\n",
            "Epoch 1748/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1902 - mae: 0.0960 - val_loss: 0.2084 - val_mae: 0.1165\n",
            "Epoch 1749/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1779 - mae: 0.0985 - val_loss: 0.2080 - val_mae: 0.1162\n",
            "Epoch 1750/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1596 - mae: 0.0919 - val_loss: 0.2054 - val_mae: 0.1152\n",
            "Epoch 1751/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1611 - mae: 0.0908 - val_loss: 0.2107 - val_mae: 0.1163\n",
            "Epoch 1752/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2406 - mae: 0.1102 - val_loss: 0.2124 - val_mae: 0.1198\n",
            "Epoch 1753/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2726 - mae: 0.1178 - val_loss: 0.2102 - val_mae: 0.1171\n",
            "Epoch 1754/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1873 - mae: 0.1030 - val_loss: 0.2026 - val_mae: 0.1133\n",
            "Epoch 1755/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2446 - mae: 0.1094 - val_loss: 0.2114 - val_mae: 0.1164\n",
            "Epoch 1756/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2826 - mae: 0.1049 - val_loss: 0.2113 - val_mae: 0.1161\n",
            "Epoch 1757/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2291 - mae: 0.0995 - val_loss: 0.2082 - val_mae: 0.1155\n",
            "Epoch 1758/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2356 - mae: 0.1098 - val_loss: 0.2084 - val_mae: 0.1153\n",
            "Epoch 1759/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1847 - mae: 0.0939 - val_loss: 0.2083 - val_mae: 0.1160\n",
            "Epoch 1760/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3498 - mae: 0.1225 - val_loss: 0.2111 - val_mae: 0.1165\n",
            "Epoch 1761/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2151 - mae: 0.1078 - val_loss: 0.2093 - val_mae: 0.1176\n",
            "Epoch 1762/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1417 - mae: 0.0932 - val_loss: 0.2015 - val_mae: 0.1150\n",
            "Epoch 1763/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2112 - mae: 0.1029 - val_loss: 0.2106 - val_mae: 0.1240\n",
            "Epoch 1764/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2524 - mae: 0.1116 - val_loss: 0.2137 - val_mae: 0.1207\n",
            "Epoch 1765/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2129 - mae: 0.1079 - val_loss: 0.2092 - val_mae: 0.1190\n",
            "Epoch 1766/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1856 - mae: 0.1023 - val_loss: 0.2015 - val_mae: 0.1134\n",
            "Epoch 1767/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1671 - mae: 0.0924 - val_loss: 0.2078 - val_mae: 0.1156\n",
            "Epoch 1768/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2131 - mae: 0.1033 - val_loss: 0.2071 - val_mae: 0.1152\n",
            "Epoch 1769/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1963 - mae: 0.0983 - val_loss: 0.2122 - val_mae: 0.1173\n",
            "Epoch 1770/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2036 - mae: 0.1049 - val_loss: 0.2088 - val_mae: 0.1159\n",
            "Epoch 1771/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2034 - mae: 0.0977 - val_loss: 0.2069 - val_mae: 0.1149\n",
            "Epoch 1772/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2119 - mae: 0.1076 - val_loss: 0.2089 - val_mae: 0.1172\n",
            "Epoch 1773/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1870 - mae: 0.0964 - val_loss: 0.2090 - val_mae: 0.1171\n",
            "Epoch 1774/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1987 - mae: 0.0946 - val_loss: 0.2103 - val_mae: 0.1169\n",
            "Epoch 1775/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1760 - mae: 0.0923 - val_loss: 0.2108 - val_mae: 0.1175\n",
            "Epoch 1776/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2024 - mae: 0.1049 - val_loss: 0.2089 - val_mae: 0.1158\n",
            "Epoch 1777/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3034 - mae: 0.1153 - val_loss: 0.2118 - val_mae: 0.1163\n",
            "Epoch 1778/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2763 - mae: 0.1078 - val_loss: 0.2084 - val_mae: 0.1157\n",
            "Epoch 1779/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2837 - mae: 0.1104 - val_loss: 0.2130 - val_mae: 0.1172\n",
            "Epoch 1780/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2385 - mae: 0.1082 - val_loss: 0.2087 - val_mae: 0.1158\n",
            "Epoch 1781/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1882 - mae: 0.0945 - val_loss: 0.2066 - val_mae: 0.1145\n",
            "Epoch 1782/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1635 - mae: 0.0899 - val_loss: 0.2038 - val_mae: 0.1136\n",
            "Epoch 1783/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2310 - mae: 0.1069 - val_loss: 0.2114 - val_mae: 0.1168\n",
            "Epoch 1784/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2794 - mae: 0.1107 - val_loss: 0.2080 - val_mae: 0.1164\n",
            "Epoch 1785/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2411 - mae: 0.1062 - val_loss: 0.2106 - val_mae: 0.1168\n",
            "Epoch 1786/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2281 - mae: 0.1053 - val_loss: 0.2081 - val_mae: 0.1173\n",
            "Epoch 1787/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1921 - mae: 0.1038 - val_loss: 0.2062 - val_mae: 0.1144\n",
            "Epoch 1788/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1951 - mae: 0.0933 - val_loss: 0.2112 - val_mae: 0.1176\n",
            "Epoch 1789/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2689 - mae: 0.1084 - val_loss: 0.2075 - val_mae: 0.1170\n",
            "Epoch 1790/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.2406 - mae: 0.1048 - val_loss: 0.2123 - val_mae: 0.1172\n",
            "Epoch 1791/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2328 - mae: 0.0965 - val_loss: 0.2081 - val_mae: 0.1154\n",
            "Epoch 1792/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2060 - mae: 0.1035 - val_loss: 0.2035 - val_mae: 0.1138\n",
            "Epoch 1793/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2960 - mae: 0.1120 - val_loss: 0.2106 - val_mae: 0.1163\n",
            "Epoch 1794/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2054 - mae: 0.0992 - val_loss: 0.2057 - val_mae: 0.1147\n",
            "Epoch 1795/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1480 - mae: 0.0925 - val_loss: 0.2037 - val_mae: 0.1150\n",
            "Epoch 1796/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2882 - mae: 0.1064 - val_loss: 0.2133 - val_mae: 0.1183\n",
            "Epoch 1797/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2482 - mae: 0.1047 - val_loss: 0.2087 - val_mae: 0.1178\n",
            "Epoch 1798/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1947 - mae: 0.0962 - val_loss: 0.2105 - val_mae: 0.1171\n",
            "Epoch 1799/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2416 - mae: 0.1086 - val_loss: 0.2085 - val_mae: 0.1152\n",
            "Epoch 1800/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3034 - mae: 0.1081 - val_loss: 0.2101 - val_mae: 0.1163\n",
            "Epoch 1801/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2251 - mae: 0.1022 - val_loss: 0.2069 - val_mae: 0.1170\n",
            "Epoch 1802/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2713 - mae: 0.1070 - val_loss: 0.2062 - val_mae: 0.1154\n",
            "Epoch 1803/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2072 - mae: 0.0952 - val_loss: 0.2071 - val_mae: 0.1158\n",
            "Epoch 1804/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1892 - mae: 0.0962 - val_loss: 0.2097 - val_mae: 0.1163\n",
            "Epoch 1805/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2012 - mae: 0.1028 - val_loss: 0.2081 - val_mae: 0.1167\n",
            "Epoch 1806/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1592 - mae: 0.0942 - val_loss: 0.2078 - val_mae: 0.1161\n",
            "Epoch 1807/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3418 - mae: 0.1197 - val_loss: 0.2112 - val_mae: 0.1183\n",
            "Epoch 1808/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1414 - mae: 0.0927 - val_loss: 0.2042 - val_mae: 0.1166\n",
            "Epoch 1809/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2038 - mae: 0.1061 - val_loss: 0.2113 - val_mae: 0.1193\n",
            "Epoch 1810/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1334 - mae: 0.0939 - val_loss: 0.2078 - val_mae: 0.1161\n",
            "Epoch 1811/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2029 - mae: 0.1018 - val_loss: 0.2091 - val_mae: 0.1174\n",
            "Epoch 1812/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3512 - mae: 0.1204 - val_loss: 0.2103 - val_mae: 0.1178\n",
            "Epoch 1813/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2347 - mae: 0.1013 - val_loss: 0.2132 - val_mae: 0.1185\n",
            "Epoch 1814/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1839 - mae: 0.0960 - val_loss: 0.2065 - val_mae: 0.1150\n",
            "Epoch 1815/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1875 - mae: 0.0934 - val_loss: 0.2094 - val_mae: 0.1164\n",
            "Epoch 1816/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1872 - mae: 0.1022 - val_loss: 0.2058 - val_mae: 0.1158\n",
            "Epoch 1817/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2067 - mae: 0.1072 - val_loss: 0.2058 - val_mae: 0.1146\n",
            "Epoch 1818/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2182 - mae: 0.0969 - val_loss: 0.2118 - val_mae: 0.1174\n",
            "Epoch 1819/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2642 - mae: 0.1080 - val_loss: 0.2086 - val_mae: 0.1160\n",
            "Epoch 1820/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1897 - mae: 0.1018 - val_loss: 0.2070 - val_mae: 0.1152\n",
            "Epoch 1821/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1902 - mae: 0.0914 - val_loss: 0.2115 - val_mae: 0.1187\n",
            "Epoch 1822/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1637 - mae: 0.0921 - val_loss: 0.2085 - val_mae: 0.1174\n",
            "Epoch 1823/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2205 - mae: 0.1048 - val_loss: 0.2088 - val_mae: 0.1151\n",
            "Epoch 1824/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2311 - mae: 0.1036 - val_loss: 0.2131 - val_mae: 0.1190\n",
            "Epoch 1825/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1837 - mae: 0.1005 - val_loss: 0.2107 - val_mae: 0.1188\n",
            "Epoch 1826/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2279 - mae: 0.1081 - val_loss: 0.2078 - val_mae: 0.1153\n",
            "Epoch 1827/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1629 - mae: 0.0929 - val_loss: 0.2073 - val_mae: 0.1198\n",
            "Epoch 1828/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2093 - mae: 0.1035 - val_loss: 0.2062 - val_mae: 0.1169\n",
            "Epoch 1829/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1385 - mae: 0.0894 - val_loss: 0.2100 - val_mae: 0.1183\n",
            "Epoch 1830/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2219 - mae: 0.1089 - val_loss: 0.2099 - val_mae: 0.1177\n",
            "Epoch 1831/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2211 - mae: 0.1093 - val_loss: 0.2070 - val_mae: 0.1170\n",
            "Epoch 1832/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2156 - mae: 0.1066 - val_loss: 0.2095 - val_mae: 0.1175\n",
            "Epoch 1833/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2729 - mae: 0.1030 - val_loss: 0.1969 - val_mae: 0.1147\n",
            "Epoch 1834/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2457 - mae: 0.1117 - val_loss: 0.2086 - val_mae: 0.1201\n",
            "Epoch 1835/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1353 - mae: 0.0952 - val_loss: 0.2101 - val_mae: 0.1306\n",
            "Epoch 1836/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2619 - mae: 0.1201 - val_loss: 0.2157 - val_mae: 0.1215\n",
            "Epoch 1837/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1990 - mae: 0.0998 - val_loss: 0.2122 - val_mae: 0.1214\n",
            "Epoch 1838/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3364 - mae: 0.1220 - val_loss: 0.2146 - val_mae: 0.1202\n",
            "Epoch 1839/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2220 - mae: 0.1067 - val_loss: 0.2058 - val_mae: 0.1142\n",
            "Epoch 1840/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3146 - mae: 0.1099 - val_loss: 0.2135 - val_mae: 0.1180\n",
            "Epoch 1841/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1699 - mae: 0.0939 - val_loss: 0.2048 - val_mae: 0.1152\n",
            "Epoch 1842/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1835 - mae: 0.0921 - val_loss: 0.2112 - val_mae: 0.1178\n",
            "Epoch 1843/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3067 - mae: 0.1178 - val_loss: 0.2104 - val_mae: 0.1168\n",
            "Epoch 1844/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2524 - mae: 0.1091 - val_loss: 0.2093 - val_mae: 0.1156\n",
            "Epoch 1845/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2989 - mae: 0.1103 - val_loss: 0.2127 - val_mae: 0.1162\n",
            "Epoch 1846/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2533 - mae: 0.1047 - val_loss: 0.2084 - val_mae: 0.1162\n",
            "Epoch 1847/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1499 - mae: 0.0883 - val_loss: 0.2058 - val_mae: 0.1149\n",
            "Epoch 1848/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.1783 - mae: 0.0935 - val_loss: 0.2085 - val_mae: 0.1155\n",
            "Epoch 1849/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.4178 - mae: 0.1328 - val_loss: 0.2094 - val_mae: 0.1158\n",
            "Epoch 1850/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2311 - mae: 0.1016 - val_loss: 0.2123 - val_mae: 0.1164\n",
            "Epoch 1851/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2194 - mae: 0.1073 - val_loss: 0.2032 - val_mae: 0.1132\n",
            "Epoch 1852/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.4353 - mae: 0.1275 - val_loss: 0.2071 - val_mae: 0.1154\n",
            "Epoch 1853/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2177 - mae: 0.1023 - val_loss: 0.2121 - val_mae: 0.1169\n",
            "Epoch 1854/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1785 - mae: 0.0963 - val_loss: 0.2020 - val_mae: 0.1130\n",
            "Epoch 1855/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1860 - mae: 0.0873 - val_loss: 0.2100 - val_mae: 0.1174\n",
            "Epoch 1856/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3005 - mae: 0.1096 - val_loss: 0.2075 - val_mae: 0.1152\n",
            "Epoch 1857/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1605 - mae: 0.0985 - val_loss: 0.2040 - val_mae: 0.1145\n",
            "Epoch 1858/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2108 - mae: 0.0989 - val_loss: 0.2077 - val_mae: 0.1156\n",
            "Epoch 1859/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1862 - mae: 0.0942 - val_loss: 0.2140 - val_mae: 0.1187\n",
            "Epoch 1860/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1632 - mae: 0.0930 - val_loss: 0.2066 - val_mae: 0.1147\n",
            "Epoch 1861/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1803 - mae: 0.0934 - val_loss: 0.2073 - val_mae: 0.1151\n",
            "Epoch 1862/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3061 - mae: 0.1087 - val_loss: 0.2053 - val_mae: 0.1151\n",
            "Epoch 1863/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2124 - mae: 0.0971 - val_loss: 0.2060 - val_mae: 0.1143\n",
            "Epoch 1864/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2252 - mae: 0.1024 - val_loss: 0.2111 - val_mae: 0.1167\n",
            "Epoch 1865/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1391 - mae: 0.0858 - val_loss: 0.2077 - val_mae: 0.1154\n",
            "Epoch 1866/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3285 - mae: 0.1132 - val_loss: 0.2143 - val_mae: 0.1171\n",
            "Epoch 1867/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2471 - mae: 0.1071 - val_loss: 0.2091 - val_mae: 0.1164\n",
            "Epoch 1868/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2197 - mae: 0.1034 - val_loss: 0.2058 - val_mae: 0.1154\n",
            "Epoch 1869/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1776 - mae: 0.0930 - val_loss: 0.2087 - val_mae: 0.1159\n",
            "Epoch 1870/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1919 - mae: 0.0981 - val_loss: 0.2081 - val_mae: 0.1165\n",
            "Epoch 1871/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2121 - mae: 0.1060 - val_loss: 0.2083 - val_mae: 0.1157\n",
            "Epoch 1872/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3479 - mae: 0.1170 - val_loss: 0.2135 - val_mae: 0.1172\n",
            "Epoch 1873/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2098 - mae: 0.1001 - val_loss: 0.2082 - val_mae: 0.1160\n",
            "Epoch 1874/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1707 - mae: 0.0887 - val_loss: 0.2085 - val_mae: 0.1152\n",
            "Epoch 1875/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3371 - mae: 0.1135 - val_loss: 0.2106 - val_mae: 0.1176\n",
            "Epoch 1876/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2013 - mae: 0.1078 - val_loss: 0.2062 - val_mae: 0.1152\n",
            "Epoch 1877/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1688 - mae: 0.0958 - val_loss: 0.2041 - val_mae: 0.1136\n",
            "Epoch 1878/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2126 - mae: 0.0993 - val_loss: 0.2085 - val_mae: 0.1162\n",
            "Epoch 1879/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2115 - mae: 0.1017 - val_loss: 0.2104 - val_mae: 0.1172\n",
            "Epoch 1880/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2256 - mae: 0.1005 - val_loss: 0.2154 - val_mae: 0.1181\n",
            "Epoch 1881/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2997 - mae: 0.1156 - val_loss: 0.2075 - val_mae: 0.1150\n",
            "Epoch 1882/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2137 - mae: 0.0970 - val_loss: 0.2069 - val_mae: 0.1145\n",
            "Epoch 1883/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2153 - mae: 0.0907 - val_loss: 0.2092 - val_mae: 0.1186\n",
            "Epoch 1884/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1504 - mae: 0.0924 - val_loss: 0.2084 - val_mae: 0.1170\n",
            "Epoch 1885/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2772 - mae: 0.1049 - val_loss: 0.2080 - val_mae: 0.1176\n",
            "Epoch 1886/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2071 - mae: 0.0976 - val_loss: 0.2098 - val_mae: 0.1190\n",
            "Epoch 1887/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2372 - mae: 0.1082 - val_loss: 0.2062 - val_mae: 0.1162\n",
            "Epoch 1888/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1809 - mae: 0.1021 - val_loss: 0.2077 - val_mae: 0.1156\n",
            "Epoch 1889/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2369 - mae: 0.1019 - val_loss: 0.2131 - val_mae: 0.1172\n",
            "Epoch 1890/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2830 - mae: 0.1073 - val_loss: 0.2065 - val_mae: 0.1161\n",
            "Epoch 1891/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2907 - mae: 0.1200 - val_loss: 0.2109 - val_mae: 0.1176\n",
            "Epoch 1892/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2244 - mae: 0.1035 - val_loss: 0.2073 - val_mae: 0.1156\n",
            "Epoch 1893/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1508 - mae: 0.0920 - val_loss: 0.2035 - val_mae: 0.1159\n",
            "Epoch 1894/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2172 - mae: 0.0983 - val_loss: 0.2042 - val_mae: 0.1140\n",
            "Epoch 1895/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2314 - mae: 0.1050 - val_loss: 0.2106 - val_mae: 0.1165\n",
            "Epoch 1896/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2479 - mae: 0.1110 - val_loss: 0.2132 - val_mae: 0.1207\n",
            "Epoch 1897/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1806 - mae: 0.1062 - val_loss: 0.2044 - val_mae: 0.1180\n",
            "Epoch 1898/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3120 - mae: 0.1273 - val_loss: 0.2129 - val_mae: 0.1186\n",
            "Epoch 1899/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2680 - mae: 0.1104 - val_loss: 0.2109 - val_mae: 0.1174\n",
            "Epoch 1900/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2819 - mae: 0.1059 - val_loss: 0.2097 - val_mae: 0.1163\n",
            "Epoch 1901/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2690 - mae: 0.1120 - val_loss: 0.2108 - val_mae: 0.1164\n",
            "Epoch 1902/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2625 - mae: 0.1148 - val_loss: 0.2029 - val_mae: 0.1134\n",
            "Epoch 1903/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2140 - mae: 0.1057 - val_loss: 0.2066 - val_mae: 0.1154\n",
            "Epoch 1904/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2574 - mae: 0.1062 - val_loss: 0.2135 - val_mae: 0.1181\n",
            "Epoch 1905/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1862 - mae: 0.0962 - val_loss: 0.2087 - val_mae: 0.1171\n",
            "Epoch 1906/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3333 - mae: 0.1117 - val_loss: 0.2084 - val_mae: 0.1147\n",
            "Epoch 1907/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2339 - mae: 0.1060 - val_loss: 0.2085 - val_mae: 0.1158\n",
            "Epoch 1908/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1392 - mae: 0.0921 - val_loss: 0.2022 - val_mae: 0.1137\n",
            "Epoch 1909/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2354 - mae: 0.1019 - val_loss: 0.2100 - val_mae: 0.1165\n",
            "Epoch 1910/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2352 - mae: 0.1025 - val_loss: 0.2074 - val_mae: 0.1157\n",
            "Epoch 1911/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1569 - mae: 0.0925 - val_loss: 0.2066 - val_mae: 0.1146\n",
            "Epoch 1912/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2755 - mae: 0.1082 - val_loss: 0.2101 - val_mae: 0.1161\n",
            "Epoch 1913/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3746 - mae: 0.1249 - val_loss: 0.2078 - val_mae: 0.1147\n",
            "Epoch 1914/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1704 - mae: 0.0909 - val_loss: 0.2085 - val_mae: 0.1163\n",
            "Epoch 1915/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1715 - mae: 0.0928 - val_loss: 0.2101 - val_mae: 0.1177\n",
            "Epoch 1916/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.3144 - mae: 0.1200 - val_loss: 0.2104 - val_mae: 0.1169\n",
            "Epoch 1917/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1660 - mae: 0.0994 - val_loss: 0.2033 - val_mae: 0.1144\n",
            "Epoch 1918/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2475 - mae: 0.1093 - val_loss: 0.2076 - val_mae: 0.1154\n",
            "Epoch 1919/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2029 - mae: 0.0981 - val_loss: 0.2070 - val_mae: 0.1153\n",
            "Epoch 1920/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2228 - mae: 0.0971 - val_loss: 0.2100 - val_mae: 0.1162\n",
            "Epoch 1921/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2113 - mae: 0.0993 - val_loss: 0.2114 - val_mae: 0.1168\n",
            "Epoch 1922/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2771 - mae: 0.1095 - val_loss: 0.2097 - val_mae: 0.1162\n",
            "Epoch 1923/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1996 - mae: 0.0986 - val_loss: 0.2077 - val_mae: 0.1156\n",
            "Epoch 1924/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2095 - mae: 0.0969 - val_loss: 0.2084 - val_mae: 0.1165\n",
            "Epoch 1925/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3675 - mae: 0.1231 - val_loss: 0.2049 - val_mae: 0.1152\n",
            "Epoch 1926/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1868 - mae: 0.0905 - val_loss: 0.2125 - val_mae: 0.1176\n",
            "Epoch 1927/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1685 - mae: 0.0878 - val_loss: 0.2127 - val_mae: 0.1182\n",
            "Epoch 1928/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3100 - mae: 0.1138 - val_loss: 0.2110 - val_mae: 0.1182\n",
            "Epoch 1929/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2789 - mae: 0.1102 - val_loss: 0.2064 - val_mae: 0.1176\n",
            "Epoch 1930/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3318 - mae: 0.1164 - val_loss: 0.2031 - val_mae: 0.1205\n",
            "Epoch 1931/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2588 - mae: 0.1109 - val_loss: 0.2105 - val_mae: 0.1185\n",
            "Epoch 1932/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1743 - mae: 0.0934 - val_loss: 0.2108 - val_mae: 0.1233\n",
            "Epoch 1933/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2122 - mae: 0.1063 - val_loss: 0.2085 - val_mae: 0.1177\n",
            "Epoch 1934/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2503 - mae: 0.1070 - val_loss: 0.2066 - val_mae: 0.1157\n",
            "Epoch 1935/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1579 - mae: 0.0917 - val_loss: 0.2074 - val_mae: 0.1151\n",
            "Epoch 1936/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1776 - mae: 0.0902 - val_loss: 0.2094 - val_mae: 0.1159\n",
            "Epoch 1937/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2896 - mae: 0.1080 - val_loss: 0.2100 - val_mae: 0.1175\n",
            "Epoch 1938/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2013 - mae: 0.1074 - val_loss: 0.2076 - val_mae: 0.1162\n",
            "Epoch 1939/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2405 - mae: 0.1048 - val_loss: 0.2102 - val_mae: 0.1168\n",
            "Epoch 1940/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2067 - mae: 0.0991 - val_loss: 0.2074 - val_mae: 0.1169\n",
            "Epoch 1941/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2344 - mae: 0.1066 - val_loss: 0.2130 - val_mae: 0.1179\n",
            "Epoch 1942/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2795 - mae: 0.1104 - val_loss: 0.2092 - val_mae: 0.1159\n",
            "Epoch 1943/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2074 - mae: 0.1040 - val_loss: 0.2081 - val_mae: 0.1159\n",
            "Epoch 1944/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1901 - mae: 0.0952 - val_loss: 0.2092 - val_mae: 0.1162\n",
            "Epoch 1945/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1585 - mae: 0.0955 - val_loss: 0.2062 - val_mae: 0.1146\n",
            "Epoch 1946/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1788 - mae: 0.1041 - val_loss: 0.2064 - val_mae: 0.1148\n",
            "Epoch 1947/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2349 - mae: 0.1071 - val_loss: 0.2106 - val_mae: 0.1178\n",
            "Epoch 1948/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1792 - mae: 0.1001 - val_loss: 0.2119 - val_mae: 0.1188\n",
            "Epoch 1949/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2341 - mae: 0.0981 - val_loss: 0.2141 - val_mae: 0.1174\n",
            "Epoch 1950/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1820 - mae: 0.1007 - val_loss: 0.2068 - val_mae: 0.1157\n",
            "Epoch 1951/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1813 - mae: 0.0997 - val_loss: 0.2087 - val_mae: 0.1161\n",
            "Epoch 1952/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2296 - mae: 0.1063 - val_loss: 0.2102 - val_mae: 0.1166\n",
            "Epoch 1953/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3638 - mae: 0.1230 - val_loss: 0.2118 - val_mae: 0.1168\n",
            "Epoch 1954/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1830 - mae: 0.0958 - val_loss: 0.2092 - val_mae: 0.1175\n",
            "Epoch 1955/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1958 - mae: 0.0875 - val_loss: 0.2140 - val_mae: 0.1174\n",
            "Epoch 1956/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1503 - mae: 0.0979 - val_loss: 0.2021 - val_mae: 0.1155\n",
            "Epoch 1957/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1984 - mae: 0.0980 - val_loss: 0.2083 - val_mae: 0.1161\n",
            "Epoch 1958/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2675 - mae: 0.1017 - val_loss: 0.2113 - val_mae: 0.1166\n",
            "Epoch 1959/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3094 - mae: 0.1045 - val_loss: 0.2102 - val_mae: 0.1163\n",
            "Epoch 1960/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1895 - mae: 0.0950 - val_loss: 0.2057 - val_mae: 0.1148\n",
            "Epoch 1961/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1947 - mae: 0.0985 - val_loss: 0.2085 - val_mae: 0.1152\n",
            "Epoch 1962/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1680 - mae: 0.0972 - val_loss: 0.2043 - val_mae: 0.1151\n",
            "Epoch 1963/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2920 - mae: 0.1165 - val_loss: 0.2077 - val_mae: 0.1160\n",
            "Epoch 1964/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2585 - mae: 0.1129 - val_loss: 0.2088 - val_mae: 0.1159\n",
            "Epoch 1965/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1583 - mae: 0.0966 - val_loss: 0.2034 - val_mae: 0.1144\n",
            "Epoch 1966/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2088 - mae: 0.0985 - val_loss: 0.2121 - val_mae: 0.1172\n",
            "Epoch 1967/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2016 - mae: 0.0999 - val_loss: 0.2089 - val_mae: 0.1167\n",
            "Epoch 1968/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3933 - mae: 0.1231 - val_loss: 0.2129 - val_mae: 0.1172\n",
            "Epoch 1969/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1746 - mae: 0.0942 - val_loss: 0.2102 - val_mae: 0.1163\n",
            "Epoch 1970/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2645 - mae: 0.1097 - val_loss: 0.2103 - val_mae: 0.1162\n",
            "Epoch 1971/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1448 - mae: 0.0878 - val_loss: 0.2078 - val_mae: 0.1149\n",
            "Epoch 1972/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3260 - mae: 0.1187 - val_loss: 0.2101 - val_mae: 0.1156\n",
            "Epoch 1973/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1647 - mae: 0.0903 - val_loss: 0.2056 - val_mae: 0.1152\n",
            "Epoch 1974/2000\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.2360 - mae: 0.1091 - val_loss: 0.2056 - val_mae: 0.1152\n",
            "Epoch 1975/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2203 - mae: 0.0967 - val_loss: 0.2088 - val_mae: 0.1156\n",
            "Epoch 1976/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1675 - mae: 0.0963 - val_loss: 0.2095 - val_mae: 0.1156\n",
            "Epoch 1977/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2040 - mae: 0.1030 - val_loss: 0.2127 - val_mae: 0.1167\n",
            "Epoch 1978/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1831 - mae: 0.0965 - val_loss: 0.2112 - val_mae: 0.1167\n",
            "Epoch 1979/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2345 - mae: 0.1043 - val_loss: 0.2089 - val_mae: 0.1165\n",
            "Epoch 1980/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2809 - mae: 0.1177 - val_loss: 0.2084 - val_mae: 0.1167\n",
            "Epoch 1981/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2498 - mae: 0.1039 - val_loss: 0.2077 - val_mae: 0.1164\n",
            "Epoch 1982/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2503 - mae: 0.1141 - val_loss: 0.2070 - val_mae: 0.1152\n",
            "Epoch 1983/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1842 - mae: 0.0996 - val_loss: 0.2044 - val_mae: 0.1138\n",
            "Epoch 1984/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1937 - mae: 0.0912 - val_loss: 0.2109 - val_mae: 0.1171\n",
            "Epoch 1985/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1600 - mae: 0.0923 - val_loss: 0.2083 - val_mae: 0.1153\n",
            "Epoch 1986/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2060 - mae: 0.1077 - val_loss: 0.2090 - val_mae: 0.1159\n",
            "Epoch 1987/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2702 - mae: 0.1111 - val_loss: 0.2153 - val_mae: 0.1197\n",
            "Epoch 1988/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2039 - mae: 0.0987 - val_loss: 0.2052 - val_mae: 0.1136\n",
            "Epoch 1989/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1784 - mae: 0.0937 - val_loss: 0.2091 - val_mae: 0.1171\n",
            "Epoch 1990/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1802 - mae: 0.0915 - val_loss: 0.2079 - val_mae: 0.1165\n",
            "Epoch 1991/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2667 - mae: 0.1073 - val_loss: 0.2100 - val_mae: 0.1163\n",
            "Epoch 1992/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2114 - mae: 0.0984 - val_loss: 0.2115 - val_mae: 0.1193\n",
            "Epoch 1993/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2927 - mae: 0.1140 - val_loss: 0.2085 - val_mae: 0.1154\n",
            "Epoch 1994/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1623 - mae: 0.0966 - val_loss: 0.2071 - val_mae: 0.1149\n",
            "Epoch 1995/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3469 - mae: 0.1147 - val_loss: 0.2093 - val_mae: 0.1160\n",
            "Epoch 1996/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2371 - mae: 0.1070 - val_loss: 0.2074 - val_mae: 0.1161\n",
            "Epoch 1997/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3400 - mae: 0.1141 - val_loss: 0.2088 - val_mae: 0.1175\n",
            "Epoch 1998/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1828 - mae: 0.1011 - val_loss: 0.2076 - val_mae: 0.1150\n",
            "Epoch 1999/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1654 - mae: 0.0916 - val_loss: 0.2093 - val_mae: 0.1160\n",
            "Epoch 2000/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1857 - mae: 0.0981 - val_loss: 0.2108 - val_mae: 0.1178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOL4lk4_RlT1",
        "outputId": "ba18e5ab-6b57-4c1e-d4d1-9dc8e7655b16"
      },
      "source": [
        "# モデルの評価\n",
        "score = model_1.evaluate([x_fs_test_n, x_fp_test_n], y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test mae:', score[1])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255/255 [==============================] - 0s 2ms/step - loss: 0.2243 - mae: 0.1106\n",
            "Test loss: 0.2242625504732132\n",
            "Test mae: 0.11060714721679688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Q4owGizfRe-Z",
        "outputId": "530c0ca5-c102-44d0-8d12-f64609d1736f"
      },
      "source": [
        "# 学習経過の可視化\n",
        "loss     = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "nb_epoch = len(loss)\n",
        "for i in range(900):\n",
        "  if max(loss)>2: \n",
        "    loss = loss[1:]\n",
        "    val_loss = val_loss[1:]\n",
        "  else:\n",
        "    plt.plot(range(i,nb_epoch), loss, marker='.', label='loss')\n",
        "    plt.plot(range(i,nb_epoch), val_loss, marker='.', label='val_loss')\n",
        "    break\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "_bCV9O2WRmzS",
        "outputId": "13932d96-6668-4067-ec1a-58e87781a12c"
      },
      "source": [
        "# 学習経過の可視化\n",
        "mae     = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "nb_epoch = len(mae)\n",
        "for i in range(900):\n",
        "  if max(mae)>2: \n",
        "    mae = mae[1:]\n",
        "    val_mae = val_mae[1:]\n",
        "  else:\n",
        "    plt.plot(range(i,nb_epoch), mae,     marker='.', label='mae')\n",
        "    plt.plot(range(i,nb_epoch), val_mae, marker='.', label='val_mae')\n",
        "    break\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('mae')\n",
        "plt.show()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDtbbPWoQ71s"
      },
      "source": [
        "# 学習モデルの保存\n",
        "model_1.save(str(n)+\"_random.seed(\"+str(seed)+\")_train\"+str(train)+\".h5\")"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq0JDC0XjZO_"
      },
      "source": [
        "# model_2\n",
        "\n",
        "# データの前処理\n",
        "\n",
        "\n",
        "## 変数設定(各条件を変えてたくさん試すため)\n",
        "train = 0.5                 #train:validのtrainデータの割合\n",
        "seed = 0                       \n",
        "random.seed(seed)           #乱数seed固定\n",
        "\n",
        "\n",
        "## データ加工\n",
        "\n",
        "### データ抽出(各データをランダムにシャッフル→train,valid,testに分割。各大きさのデータが同じ数だけ抽出される。)\n",
        "for i in range (1,6):\n",
        "  exec(\"lst_fs\"+str(i)+\"_shuffle = random.sample(lst_fs\"+str(i)+\", len(lst_fs\"+str(i)+\"))\")  \n",
        "  exec(\"lst_fs\"+str(i)+\"_train = lst_fs\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")       \n",
        "  exec(\"lst_fs\"+str(i)+\"_valid = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\")          \n",
        "  exec(\"lst_fs\"+str(i)+\"_test = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_shuffle = random.sample(lst_fp\"+str(i)+\", len(lst_fp\"+str(i)+\"))\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_train = lst_fp\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_valid = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\") \n",
        "  exec(\"lst_fp\"+str(i)+\"_test = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "\n",
        "### train,valid,testの各々について、大きさ、位置、表面温度分布データに分割\n",
        "for i in range (1,6):\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_train = [r[0] for r in lst_fs\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_train = [r[0] for r in lst_fp\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_train = [r[1:-1] for r in lst_fp\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_valid = [r[0] for r in lst_fs\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_valid = [r[0] for r in lst_fp\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_valid = [r[1:-1] for r in lst_fp\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_test = [r[0] for r in lst_fs\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_test = [r[0] for r in lst_fp\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_test = [r[1:-1] for r in lst_fp\"+str(i)+\"_test]\")\n",
        "\n",
        "### データを結合(入力データ・正解データの大枠完成)\n",
        "lst_x_fs_train = lst_x_fs1_train + lst_x_fs2_train + lst_x_fs3_train + lst_x_fs4_train + lst_x_fs5_train\n",
        "lst_x_fp_train = lst_x_fp1_train + lst_x_fp2_train + lst_x_fp3_train + lst_x_fp4_train + lst_x_fp5_train\n",
        "lst_y_train = lst_y1_train + lst_y2_train + lst_y3_train + lst_y4_train + lst_y5_train\n",
        "\n",
        "lst_x_fs_valid = lst_x_fs1_valid + lst_x_fs2_valid + lst_x_fs3_valid + lst_x_fs4_valid + lst_x_fs5_valid\n",
        "lst_x_fp_valid = lst_x_fp1_valid + lst_x_fp2_valid + lst_x_fp3_valid + lst_x_fp4_valid + lst_x_fp5_valid\n",
        "lst_y_valid = lst_y1_valid + lst_y2_valid + lst_y3_valid + lst_y4_valid + lst_y5_valid\n",
        "\n",
        "lst_x_fs_test = lst_x_fs1_test + lst_x_fs2_test + lst_x_fs3_test + lst_x_fs4_test + lst_x_fs5_test\n",
        "lst_x_fp_test = lst_x_fp1_test + lst_x_fp2_test + lst_x_fp3_test + lst_x_fp4_test + lst_x_fp5_test\n",
        "lst_y_test = lst_y1_test + lst_y2_test + lst_y3_test + lst_y4_test + lst_y5_test\n",
        "\n",
        "### np.arrayで変換\n",
        "lst_f0 = np.array(lst_f0, dtype=float)\n",
        "lst_x_fs_train = np.array(lst_x_fs_train, dtype=int)\n",
        "lst_x_fp_train = np.array(lst_x_fp_train, dtype=int)\n",
        "lst_x_fs_valid = np.array(lst_x_fs_valid, dtype=int)\n",
        "lst_x_fp_valid = np.array(lst_x_fp_valid, dtype=int)\n",
        "lst_x_fs_test = np.array(lst_x_fs_test, dtype=int)\n",
        "lst_x_fp_test = np.array(lst_x_fp_test, dtype=int)\n",
        "lst_y_train = np.array(lst_y_train, dtype=float)\n",
        "lst_y_valid = np.array(lst_y_valid, dtype=float)\n",
        "lst_y_test = np.array(lst_y_test, dtype=float)\n",
        "\n",
        "### 入力データを二次元化\n",
        "x_fs_train = lst_x_fs_train.reshape(-1, 1)\n",
        "x_fs_valid = lst_x_fs_valid.reshape(-1, 1)\n",
        "x_fs_test = lst_x_fs_test.reshape(-1, 1)\n",
        "x_fp_train = lst_x_fp_train.reshape(-1, 1)\n",
        "x_fp_valid = lst_x_fp_valid.reshape(-1, 1)\n",
        "x_fp_test = lst_x_fp_test.reshape(-1, 1)\n",
        "\n",
        "### 温度分布データを、穴なし温度分布データとの差に変換\n",
        "y_train = lst_y_train - lst_f0\n",
        "y_valid = lst_y_valid - lst_f0\n",
        "y_test = lst_y_test - lst_f0\n",
        "\n",
        "### 入力データの正規化\n",
        "scaler_x = MinMaxScaler()\n",
        "x_fs_train_n = scaler_x.fit_transform(x_fs_train)\n",
        "x_fs_valid_n = scaler_x.fit_transform(x_fs_valid)\n",
        "x_fs_test_n = scaler_x.fit_transform(x_fs_test) \n",
        "x_fp_train_n = scaler_x.fit_transform(x_fp_train)\n",
        "x_fp_valid_n = scaler_x.fit_transform(x_fp_valid)\n",
        "x_fp_test_n = scaler_x.fit_transform(x_fp_test) "
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C531QEtBjZPA"
      },
      "source": [
        "# NN\n",
        "\n",
        "## 入力を定義\n",
        "input1 = Input(shape=(1,))\n",
        "input2 = Input(shape=(1,))\n",
        "\n",
        "## 入力1から結合前まで\n",
        "x = Dense(1, activation=\"linear\")(input1)\n",
        "x = Model(inputs=input1, outputs=x)\n",
        "\n",
        "## 入力2から結合前まで\n",
        "y = Dense(1, activation=\"linear\")(input2)\n",
        "y = Model(inputs=input2, outputs=y)\n",
        "\n",
        "## 結合\n",
        "combined = concatenate([x.output, y.output])\n",
        "\n",
        "## 密結合\n",
        "z = Dense(32, activation=\"relu\")(combined)\n",
        "z = Dense(512, activation=\"relu\")(z)\n",
        "z = Dense(256, activation=\"relu\")(z)\n",
        "z = Dense(128, activation=\"relu\")(z)\n",
        "z = Dense(50)(z)\n",
        "\n",
        "## モデル定義とコンパイル\n",
        "model_2 = Model(inputs=[x.input, y.input], outputs=z)\n",
        "model_2.compile(loss='mse', optimizer='adam', metrics=['mae'])"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GSImBBLjZPA",
        "outputId": "39b6fa94-4ee1-41b0-fd21-3434927cdf64"
      },
      "source": [
        "# 学習\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "history = model_2.fit([x_fs_train_n, x_fp_train_n], y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=([x_fs_valid_n, x_fp_valid_n], y_valid))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "16/16 [==============================] - 1s 20ms/step - loss: 0.2543 - mae: 0.2368 - val_loss: 0.5548 - val_mae: 0.2318\n",
            "Epoch 2/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2867 - mae: 0.1922 - val_loss: 0.5462 - val_mae: 0.2011\n",
            "Epoch 3/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1976 - mae: 0.1623 - val_loss: 0.5346 - val_mae: 0.1945\n",
            "Epoch 4/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3696 - mae: 0.1909 - val_loss: 0.5367 - val_mae: 0.2047\n",
            "Epoch 5/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2020 - mae: 0.1609 - val_loss: 0.5213 - val_mae: 0.1956\n",
            "Epoch 6/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2218 - mae: 0.1611 - val_loss: 0.5003 - val_mae: 0.1876\n",
            "Epoch 7/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1291 - mae: 0.1318 - val_loss: 0.4879 - val_mae: 0.1981\n",
            "Epoch 8/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1521 - mae: 0.1474 - val_loss: 0.4734 - val_mae: 0.1964\n",
            "Epoch 9/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1588 - mae: 0.1527 - val_loss: 0.4673 - val_mae: 0.1872\n",
            "Epoch 10/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1471 - mae: 0.1440 - val_loss: 0.4660 - val_mae: 0.2010\n",
            "Epoch 11/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1435 - mae: 0.1448 - val_loss: 0.4700 - val_mae: 0.2141\n",
            "Epoch 12/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2001 - mae: 0.1620 - val_loss: 0.4641 - val_mae: 0.1870\n",
            "Epoch 13/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2071 - mae: 0.1519 - val_loss: 0.4623 - val_mae: 0.1840\n",
            "Epoch 14/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.1367 - mae: 0.1310 - val_loss: 0.4520 - val_mae: 0.1915\n",
            "Epoch 15/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2036 - mae: 0.1519 - val_loss: 0.4561 - val_mae: 0.1973\n",
            "Epoch 16/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1616 - mae: 0.1525 - val_loss: 0.4519 - val_mae: 0.1909\n",
            "Epoch 17/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1370 - mae: 0.1393 - val_loss: 0.4511 - val_mae: 0.2006\n",
            "Epoch 18/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1903 - mae: 0.1535 - val_loss: 0.4736 - val_mae: 0.1915\n",
            "Epoch 19/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1314 - mae: 0.1529 - val_loss: 0.4568 - val_mae: 0.1867\n",
            "Epoch 20/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1282 - mae: 0.1427 - val_loss: 0.4495 - val_mae: 0.1897\n",
            "Epoch 21/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2113 - mae: 0.1561 - val_loss: 0.4544 - val_mae: 0.1867\n",
            "Epoch 22/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1086 - mae: 0.1282 - val_loss: 0.4436 - val_mae: 0.1982\n",
            "Epoch 23/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1511 - mae: 0.1498 - val_loss: 0.4662 - val_mae: 0.2182\n",
            "Epoch 24/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1690 - mae: 0.1586 - val_loss: 0.4449 - val_mae: 0.1918\n",
            "Epoch 25/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1268 - mae: 0.1447 - val_loss: 0.4553 - val_mae: 0.1856\n",
            "Epoch 26/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1077 - mae: 0.1272 - val_loss: 0.4433 - val_mae: 0.1922\n",
            "Epoch 27/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1838 - mae: 0.1518 - val_loss: 0.4370 - val_mae: 0.1918\n",
            "Epoch 28/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1357 - mae: 0.1369 - val_loss: 0.4379 - val_mae: 0.1947\n",
            "Epoch 29/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1453 - mae: 0.1415 - val_loss: 0.4351 - val_mae: 0.1828\n",
            "Epoch 30/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1311 - mae: 0.1357 - val_loss: 0.4460 - val_mae: 0.1793\n",
            "Epoch 31/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1169 - mae: 0.1338 - val_loss: 0.4348 - val_mae: 0.1859\n",
            "Epoch 32/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1503 - mae: 0.1448 - val_loss: 0.4392 - val_mae: 0.1764\n",
            "Epoch 33/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1800 - mae: 0.1371 - val_loss: 0.4424 - val_mae: 0.1793\n",
            "Epoch 34/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1197 - mae: 0.1266 - val_loss: 0.4221 - val_mae: 0.1856\n",
            "Epoch 35/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1879 - mae: 0.1500 - val_loss: 0.4161 - val_mae: 0.1822\n",
            "Epoch 36/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1265 - mae: 0.1410 - val_loss: 0.4266 - val_mae: 0.1865\n",
            "Epoch 37/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1326 - mae: 0.1443 - val_loss: 0.4167 - val_mae: 0.1793\n",
            "Epoch 38/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1049 - mae: 0.1278 - val_loss: 0.4373 - val_mae: 0.1889\n",
            "Epoch 39/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1358 - mae: 0.1432 - val_loss: 0.4438 - val_mae: 0.1750\n",
            "Epoch 40/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1604 - mae: 0.1348 - val_loss: 0.4337 - val_mae: 0.1788\n",
            "Epoch 41/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1008 - mae: 0.1232 - val_loss: 0.4211 - val_mae: 0.1971\n",
            "Epoch 42/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1260 - mae: 0.1397 - val_loss: 0.4170 - val_mae: 0.1820\n",
            "Epoch 43/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1389 - mae: 0.1447 - val_loss: 0.4262 - val_mae: 0.1722\n",
            "Epoch 44/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1089 - mae: 0.1262 - val_loss: 0.4093 - val_mae: 0.1835\n",
            "Epoch 45/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1211 - mae: 0.1288 - val_loss: 0.4090 - val_mae: 0.1760\n",
            "Epoch 46/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1591 - mae: 0.1454 - val_loss: 0.4433 - val_mae: 0.1773\n",
            "Epoch 47/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1305 - mae: 0.1351 - val_loss: 0.4155 - val_mae: 0.1791\n",
            "Epoch 48/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1440 - mae: 0.1353 - val_loss: 0.4154 - val_mae: 0.1729\n",
            "Epoch 49/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1317 - mae: 0.1353 - val_loss: 0.4139 - val_mae: 0.1721\n",
            "Epoch 50/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1061 - mae: 0.1266 - val_loss: 0.4137 - val_mae: 0.1782\n",
            "Epoch 51/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1374 - mae: 0.1331 - val_loss: 0.4224 - val_mae: 0.1692\n",
            "Epoch 52/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1429 - mae: 0.1348 - val_loss: 0.4044 - val_mae: 0.1795\n",
            "Epoch 53/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1023 - mae: 0.1269 - val_loss: 0.4118 - val_mae: 0.1842\n",
            "Epoch 54/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0908 - mae: 0.1261 - val_loss: 0.4068 - val_mae: 0.1731\n",
            "Epoch 55/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1557 - mae: 0.1456 - val_loss: 0.4177 - val_mae: 0.1733\n",
            "Epoch 56/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1488 - mae: 0.1461 - val_loss: 0.4414 - val_mae: 0.1734\n",
            "Epoch 57/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1344 - mae: 0.1395 - val_loss: 0.4111 - val_mae: 0.1706\n",
            "Epoch 58/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1335 - mae: 0.1376 - val_loss: 0.4034 - val_mae: 0.1722\n",
            "Epoch 59/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1496 - mae: 0.1451 - val_loss: 0.4157 - val_mae: 0.1675\n",
            "Epoch 60/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1016 - mae: 0.1224 - val_loss: 0.4030 - val_mae: 0.1740\n",
            "Epoch 61/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1351 - mae: 0.1375 - val_loss: 0.4070 - val_mae: 0.1697\n",
            "Epoch 62/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1104 - mae: 0.1301 - val_loss: 0.4094 - val_mae: 0.1692\n",
            "Epoch 63/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1295 - mae: 0.1319 - val_loss: 0.4106 - val_mae: 0.1673\n",
            "Epoch 64/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1177 - mae: 0.1278 - val_loss: 0.4070 - val_mae: 0.1697\n",
            "Epoch 65/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1329 - mae: 0.1294 - val_loss: 0.4028 - val_mae: 0.1704\n",
            "Epoch 66/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1287 - mae: 0.1282 - val_loss: 0.3984 - val_mae: 0.1673\n",
            "Epoch 67/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1428 - mae: 0.1365 - val_loss: 0.4088 - val_mae: 0.1668\n",
            "Epoch 68/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1590 - mae: 0.1415 - val_loss: 0.4240 - val_mae: 0.1643\n",
            "Epoch 69/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1069 - mae: 0.1186 - val_loss: 0.3980 - val_mae: 0.1709\n",
            "Epoch 70/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1661 - mae: 0.1393 - val_loss: 0.4134 - val_mae: 0.1630\n",
            "Epoch 71/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1652 - mae: 0.1368 - val_loss: 0.4314 - val_mae: 0.1679\n",
            "Epoch 72/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1205 - mae: 0.1257 - val_loss: 0.4035 - val_mae: 0.1759\n",
            "Epoch 73/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1331 - mae: 0.1366 - val_loss: 0.4152 - val_mae: 0.1663\n",
            "Epoch 74/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1123 - mae: 0.1239 - val_loss: 0.3989 - val_mae: 0.1745\n",
            "Epoch 75/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1194 - mae: 0.1297 - val_loss: 0.4133 - val_mae: 0.1677\n",
            "Epoch 76/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1372 - mae: 0.1407 - val_loss: 0.4265 - val_mae: 0.1640\n",
            "Epoch 77/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1499 - mae: 0.1365 - val_loss: 0.4324 - val_mae: 0.1759\n",
            "Epoch 78/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1320 - mae: 0.1409 - val_loss: 0.3995 - val_mae: 0.1682\n",
            "Epoch 79/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1311 - mae: 0.1287 - val_loss: 0.4082 - val_mae: 0.1634\n",
            "Epoch 80/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1361 - mae: 0.1302 - val_loss: 0.3977 - val_mae: 0.1646\n",
            "Epoch 81/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1440 - mae: 0.1329 - val_loss: 0.4435 - val_mae: 0.1672\n",
            "Epoch 82/2000\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0970 - mae: 0.1206 - val_loss: 0.4016 - val_mae: 0.1789\n",
            "Epoch 83/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1308 - mae: 0.1356 - val_loss: 0.3960 - val_mae: 0.1646\n",
            "Epoch 84/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1890 - mae: 0.1449 - val_loss: 0.4139 - val_mae: 0.1644\n",
            "Epoch 85/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1108 - mae: 0.1184 - val_loss: 0.4043 - val_mae: 0.1679\n",
            "Epoch 86/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0854 - mae: 0.1171 - val_loss: 0.3946 - val_mae: 0.1656\n",
            "Epoch 87/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1140 - mae: 0.1245 - val_loss: 0.4044 - val_mae: 0.1651\n",
            "Epoch 88/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1012 - mae: 0.1170 - val_loss: 0.4018 - val_mae: 0.1636\n",
            "Epoch 89/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0926 - mae: 0.1137 - val_loss: 0.4012 - val_mae: 0.1612\n",
            "Epoch 90/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1359 - mae: 0.1234 - val_loss: 0.4118 - val_mae: 0.1634\n",
            "Epoch 91/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1400 - mae: 0.1271 - val_loss: 0.3978 - val_mae: 0.1647\n",
            "Epoch 92/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1276 - mae: 0.1252 - val_loss: 0.3998 - val_mae: 0.1601\n",
            "Epoch 93/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1002 - mae: 0.1173 - val_loss: 0.4092 - val_mae: 0.1737\n",
            "Epoch 94/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1706 - mae: 0.1441 - val_loss: 0.4441 - val_mae: 0.1706\n",
            "Epoch 95/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2168 - mae: 0.1560 - val_loss: 0.4013 - val_mae: 0.1659\n",
            "Epoch 96/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1048 - mae: 0.1212 - val_loss: 0.3989 - val_mae: 0.1598\n",
            "Epoch 97/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1362 - mae: 0.1316 - val_loss: 0.4129 - val_mae: 0.1647\n",
            "Epoch 98/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1221 - mae: 0.1285 - val_loss: 0.3910 - val_mae: 0.1651\n",
            "Epoch 99/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1158 - mae: 0.1239 - val_loss: 0.4092 - val_mae: 0.1601\n",
            "Epoch 100/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1023 - mae: 0.1202 - val_loss: 0.3949 - val_mae: 0.1630\n",
            "Epoch 101/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1193 - mae: 0.1232 - val_loss: 0.4001 - val_mae: 0.1592\n",
            "Epoch 102/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1297 - mae: 0.1228 - val_loss: 0.3942 - val_mae: 0.1588\n",
            "Epoch 103/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1255 - mae: 0.1134 - val_loss: 0.4043 - val_mae: 0.1589\n",
            "Epoch 104/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1922 - mae: 0.1415 - val_loss: 0.3987 - val_mae: 0.1590\n",
            "Epoch 105/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1388 - mae: 0.1306 - val_loss: 0.4060 - val_mae: 0.1602\n",
            "Epoch 106/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0766 - mae: 0.1029 - val_loss: 0.3976 - val_mae: 0.1599\n",
            "Epoch 107/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1261 - mae: 0.1173 - val_loss: 0.3959 - val_mae: 0.1593\n",
            "Epoch 108/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0847 - mae: 0.1083 - val_loss: 0.3966 - val_mae: 0.1578\n",
            "Epoch 109/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0884 - mae: 0.1094 - val_loss: 0.3996 - val_mae: 0.1570\n",
            "Epoch 110/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1083 - mae: 0.1092 - val_loss: 0.3908 - val_mae: 0.1610\n",
            "Epoch 111/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1226 - mae: 0.1242 - val_loss: 0.4052 - val_mae: 0.1598\n",
            "Epoch 112/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1365 - mae: 0.1285 - val_loss: 0.3923 - val_mae: 0.1573\n",
            "Epoch 113/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0946 - mae: 0.1128 - val_loss: 0.3940 - val_mae: 0.1579\n",
            "Epoch 114/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1309 - mae: 0.1238 - val_loss: 0.3951 - val_mae: 0.1572\n",
            "Epoch 115/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0769 - mae: 0.1055 - val_loss: 0.4019 - val_mae: 0.1586\n",
            "Epoch 116/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1512 - mae: 0.1246 - val_loss: 0.4041 - val_mae: 0.1569\n",
            "Epoch 117/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1028 - mae: 0.1107 - val_loss: 0.3935 - val_mae: 0.1609\n",
            "Epoch 118/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1112 - mae: 0.1161 - val_loss: 0.3908 - val_mae: 0.1581\n",
            "Epoch 119/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1162 - mae: 0.1182 - val_loss: 0.3940 - val_mae: 0.1571\n",
            "Epoch 120/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1279 - mae: 0.1212 - val_loss: 0.3892 - val_mae: 0.1573\n",
            "Epoch 121/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1147 - mae: 0.1175 - val_loss: 0.4083 - val_mae: 0.1571\n",
            "Epoch 122/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1353 - mae: 0.1188 - val_loss: 0.3889 - val_mae: 0.1561\n",
            "Epoch 123/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1189 - mae: 0.1242 - val_loss: 0.3896 - val_mae: 0.1583\n",
            "Epoch 124/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1061 - mae: 0.1190 - val_loss: 0.3919 - val_mae: 0.1555\n",
            "Epoch 125/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1358 - mae: 0.1180 - val_loss: 0.3882 - val_mae: 0.1560\n",
            "Epoch 126/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1009 - mae: 0.1106 - val_loss: 0.4004 - val_mae: 0.1601\n",
            "Epoch 127/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1220 - mae: 0.1244 - val_loss: 0.4041 - val_mae: 0.1611\n",
            "Epoch 128/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1145 - mae: 0.1164 - val_loss: 0.3980 - val_mae: 0.1600\n",
            "Epoch 129/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0803 - mae: 0.1059 - val_loss: 0.3971 - val_mae: 0.1612\n",
            "Epoch 130/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1030 - mae: 0.1178 - val_loss: 0.4064 - val_mae: 0.1557\n",
            "Epoch 131/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1088 - mae: 0.1138 - val_loss: 0.4046 - val_mae: 0.1545\n",
            "Epoch 132/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1041 - mae: 0.1156 - val_loss: 0.3982 - val_mae: 0.1582\n",
            "Epoch 133/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1020 - mae: 0.1158 - val_loss: 0.3985 - val_mae: 0.1534\n",
            "Epoch 134/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1070 - mae: 0.1142 - val_loss: 0.3917 - val_mae: 0.1551\n",
            "Epoch 135/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1272 - mae: 0.1185 - val_loss: 0.3952 - val_mae: 0.1538\n",
            "Epoch 136/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0882 - mae: 0.1056 - val_loss: 0.4096 - val_mae: 0.1532\n",
            "Epoch 137/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1016 - mae: 0.1132 - val_loss: 0.3921 - val_mae: 0.1551\n",
            "Epoch 138/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1514 - mae: 0.1236 - val_loss: 0.4252 - val_mae: 0.1557\n",
            "Epoch 139/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0924 - mae: 0.1101 - val_loss: 0.3930 - val_mae: 0.1605\n",
            "Epoch 140/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1182 - mae: 0.1190 - val_loss: 0.3971 - val_mae: 0.1571\n",
            "Epoch 141/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1024 - mae: 0.1208 - val_loss: 0.4015 - val_mae: 0.1512\n",
            "Epoch 142/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1309 - mae: 0.1126 - val_loss: 0.3932 - val_mae: 0.1553\n",
            "Epoch 143/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1199 - mae: 0.1200 - val_loss: 0.3895 - val_mae: 0.1576\n",
            "Epoch 144/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0902 - mae: 0.1085 - val_loss: 0.3966 - val_mae: 0.1545\n",
            "Epoch 145/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1451 - mae: 0.1284 - val_loss: 0.4128 - val_mae: 0.1551\n",
            "Epoch 146/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1436 - mae: 0.1200 - val_loss: 0.4012 - val_mae: 0.1525\n",
            "Epoch 147/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1132 - mae: 0.1146 - val_loss: 0.3888 - val_mae: 0.1565\n",
            "Epoch 148/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1047 - mae: 0.1155 - val_loss: 0.3896 - val_mae: 0.1528\n",
            "Epoch 149/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0933 - mae: 0.1137 - val_loss: 0.4046 - val_mae: 0.1546\n",
            "Epoch 150/2000\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.1096 - mae: 0.1145 - val_loss: 0.3921 - val_mae: 0.1542\n",
            "Epoch 151/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1302 - mae: 0.1213 - val_loss: 0.3983 - val_mae: 0.1516\n",
            "Epoch 152/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0922 - mae: 0.1123 - val_loss: 0.3986 - val_mae: 0.1519\n",
            "Epoch 153/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0952 - mae: 0.1081 - val_loss: 0.3944 - val_mae: 0.1522\n",
            "Epoch 154/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1178 - mae: 0.1140 - val_loss: 0.3966 - val_mae: 0.1484\n",
            "Epoch 155/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1418 - mae: 0.1137 - val_loss: 0.4075 - val_mae: 0.1505\n",
            "Epoch 156/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1172 - mae: 0.1178 - val_loss: 0.3933 - val_mae: 0.1528\n",
            "Epoch 157/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1369 - mae: 0.1133 - val_loss: 0.4117 - val_mae: 0.1496\n",
            "Epoch 158/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1079 - mae: 0.1103 - val_loss: 0.3959 - val_mae: 0.1479\n",
            "Epoch 159/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1154 - mae: 0.1120 - val_loss: 0.3961 - val_mae: 0.1496\n",
            "Epoch 160/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1004 - mae: 0.1083 - val_loss: 0.3909 - val_mae: 0.1529\n",
            "Epoch 161/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1109 - mae: 0.1174 - val_loss: 0.3915 - val_mae: 0.1509\n",
            "Epoch 162/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1432 - mae: 0.1212 - val_loss: 0.3960 - val_mae: 0.1487\n",
            "Epoch 163/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0854 - mae: 0.1039 - val_loss: 0.3921 - val_mae: 0.1537\n",
            "Epoch 164/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1159 - mae: 0.1140 - val_loss: 0.4052 - val_mae: 0.1502\n",
            "Epoch 165/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1238 - mae: 0.1108 - val_loss: 0.3981 - val_mae: 0.1561\n",
            "Epoch 166/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1029 - mae: 0.1110 - val_loss: 0.3921 - val_mae: 0.1582\n",
            "Epoch 167/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1717 - mae: 0.1299 - val_loss: 0.3930 - val_mae: 0.1468\n",
            "Epoch 168/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1585 - mae: 0.1186 - val_loss: 0.3865 - val_mae: 0.1458\n",
            "Epoch 169/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0927 - mae: 0.1010 - val_loss: 0.3945 - val_mae: 0.1429\n",
            "Epoch 170/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1378 - mae: 0.1153 - val_loss: 0.4180 - val_mae: 0.1507\n",
            "Epoch 171/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0988 - mae: 0.1066 - val_loss: 0.3978 - val_mae: 0.1675\n",
            "Epoch 172/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1303 - mae: 0.1265 - val_loss: 0.4006 - val_mae: 0.1517\n",
            "Epoch 173/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0909 - mae: 0.1111 - val_loss: 0.3873 - val_mae: 0.1454\n",
            "Epoch 174/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1224 - mae: 0.1121 - val_loss: 0.3891 - val_mae: 0.1439\n",
            "Epoch 175/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0748 - mae: 0.0919 - val_loss: 0.3942 - val_mae: 0.1428\n",
            "Epoch 176/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1529 - mae: 0.1283 - val_loss: 0.4535 - val_mae: 0.1644\n",
            "Epoch 177/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1229 - mae: 0.1204 - val_loss: 0.3907 - val_mae: 0.1613\n",
            "Epoch 178/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1390 - mae: 0.1267 - val_loss: 0.4179 - val_mae: 0.1564\n",
            "Epoch 179/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1267 - mae: 0.1122 - val_loss: 0.3915 - val_mae: 0.1437\n",
            "Epoch 180/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0878 - mae: 0.0958 - val_loss: 0.3941 - val_mae: 0.1446\n",
            "Epoch 181/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0950 - mae: 0.1008 - val_loss: 0.3863 - val_mae: 0.1450\n",
            "Epoch 182/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0907 - mae: 0.0987 - val_loss: 0.3848 - val_mae: 0.1445\n",
            "Epoch 183/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1072 - mae: 0.0983 - val_loss: 0.3916 - val_mae: 0.1436\n",
            "Epoch 184/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1176 - mae: 0.1106 - val_loss: 0.3959 - val_mae: 0.1414\n",
            "Epoch 185/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1153 - mae: 0.1084 - val_loss: 0.3911 - val_mae: 0.1465\n",
            "Epoch 186/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1305 - mae: 0.1113 - val_loss: 0.3997 - val_mae: 0.1424\n",
            "Epoch 187/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1027 - mae: 0.0967 - val_loss: 0.3850 - val_mae: 0.1496\n",
            "Epoch 188/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1766 - mae: 0.1230 - val_loss: 0.4080 - val_mae: 0.1431\n",
            "Epoch 189/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0875 - mae: 0.0937 - val_loss: 0.3882 - val_mae: 0.1429\n",
            "Epoch 190/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1146 - mae: 0.1081 - val_loss: 0.4040 - val_mae: 0.1432\n",
            "Epoch 191/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1144 - mae: 0.1021 - val_loss: 0.3974 - val_mae: 0.1441\n",
            "Epoch 192/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1340 - mae: 0.1113 - val_loss: 0.3973 - val_mae: 0.1390\n",
            "Epoch 193/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1259 - mae: 0.1075 - val_loss: 0.3976 - val_mae: 0.1427\n",
            "Epoch 194/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0981 - mae: 0.1056 - val_loss: 0.3973 - val_mae: 0.1474\n",
            "Epoch 195/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0958 - mae: 0.0995 - val_loss: 0.3889 - val_mae: 0.1458\n",
            "Epoch 196/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1547 - mae: 0.1181 - val_loss: 0.4053 - val_mae: 0.1476\n",
            "Epoch 197/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1089 - mae: 0.1082 - val_loss: 0.3858 - val_mae: 0.1452\n",
            "Epoch 198/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0954 - mae: 0.1063 - val_loss: 0.3907 - val_mae: 0.1402\n",
            "Epoch 199/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0937 - mae: 0.1019 - val_loss: 0.3939 - val_mae: 0.1376\n",
            "Epoch 200/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0842 - mae: 0.0942 - val_loss: 0.3895 - val_mae: 0.1407\n",
            "Epoch 201/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1002 - mae: 0.1043 - val_loss: 0.3834 - val_mae: 0.1402\n",
            "Epoch 202/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0942 - mae: 0.0982 - val_loss: 0.3955 - val_mae: 0.1386\n",
            "Epoch 203/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1038 - mae: 0.0987 - val_loss: 0.3907 - val_mae: 0.1380\n",
            "Epoch 204/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0927 - mae: 0.0930 - val_loss: 0.3873 - val_mae: 0.1410\n",
            "Epoch 205/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1320 - mae: 0.1105 - val_loss: 0.3895 - val_mae: 0.1384\n",
            "Epoch 206/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0978 - mae: 0.0973 - val_loss: 0.3943 - val_mae: 0.1397\n",
            "Epoch 207/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0849 - mae: 0.0933 - val_loss: 0.3909 - val_mae: 0.1376\n",
            "Epoch 208/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0805 - mae: 0.0889 - val_loss: 0.3882 - val_mae: 0.1388\n",
            "Epoch 209/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1231 - mae: 0.1105 - val_loss: 0.4016 - val_mae: 0.1378\n",
            "Epoch 210/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0995 - mae: 0.0935 - val_loss: 0.3851 - val_mae: 0.1426\n",
            "Epoch 211/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1125 - mae: 0.1054 - val_loss: 0.3994 - val_mae: 0.1396\n",
            "Epoch 212/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1069 - mae: 0.0994 - val_loss: 0.3843 - val_mae: 0.1390\n",
            "Epoch 213/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1273 - mae: 0.1093 - val_loss: 0.3944 - val_mae: 0.1364\n",
            "Epoch 214/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1337 - mae: 0.1070 - val_loss: 0.3929 - val_mae: 0.1372\n",
            "Epoch 215/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0825 - mae: 0.0911 - val_loss: 0.3893 - val_mae: 0.1372\n",
            "Epoch 216/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0983 - mae: 0.0954 - val_loss: 0.3928 - val_mae: 0.1389\n",
            "Epoch 217/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1090 - mae: 0.0990 - val_loss: 0.3879 - val_mae: 0.1438\n",
            "Epoch 218/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1022 - mae: 0.1034 - val_loss: 0.3907 - val_mae: 0.1534\n",
            "Epoch 219/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1655 - mae: 0.1184 - val_loss: 0.3925 - val_mae: 0.1414\n",
            "Epoch 220/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1506 - mae: 0.1142 - val_loss: 0.3964 - val_mae: 0.1368\n",
            "Epoch 221/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0945 - mae: 0.0923 - val_loss: 0.3863 - val_mae: 0.1465\n",
            "Epoch 222/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1460 - mae: 0.1256 - val_loss: 0.4064 - val_mae: 0.1476\n",
            "Epoch 223/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1072 - mae: 0.1083 - val_loss: 0.3836 - val_mae: 0.1412\n",
            "Epoch 224/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0924 - mae: 0.0967 - val_loss: 0.3872 - val_mae: 0.1366\n",
            "Epoch 225/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0828 - mae: 0.0917 - val_loss: 0.3821 - val_mae: 0.1411\n",
            "Epoch 226/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1081 - mae: 0.1030 - val_loss: 0.3928 - val_mae: 0.1348\n",
            "Epoch 227/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1284 - mae: 0.1017 - val_loss: 0.3944 - val_mae: 0.1362\n",
            "Epoch 228/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1107 - mae: 0.1023 - val_loss: 0.3927 - val_mae: 0.1363\n",
            "Epoch 229/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0877 - mae: 0.0969 - val_loss: 0.3904 - val_mae: 0.1373\n",
            "Epoch 230/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1264 - mae: 0.1035 - val_loss: 0.3919 - val_mae: 0.1348\n",
            "Epoch 231/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1024 - mae: 0.0982 - val_loss: 0.3903 - val_mae: 0.1378\n",
            "Epoch 232/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0810 - mae: 0.0915 - val_loss: 0.3888 - val_mae: 0.1432\n",
            "Epoch 233/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0874 - mae: 0.0921 - val_loss: 0.3909 - val_mae: 0.1361\n",
            "Epoch 234/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1054 - mae: 0.0996 - val_loss: 0.3866 - val_mae: 0.1346\n",
            "Epoch 235/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0927 - mae: 0.0944 - val_loss: 0.3867 - val_mae: 0.1400\n",
            "Epoch 236/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0938 - mae: 0.0963 - val_loss: 0.3918 - val_mae: 0.1349\n",
            "Epoch 237/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0868 - mae: 0.0931 - val_loss: 0.3909 - val_mae: 0.1411\n",
            "Epoch 238/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1238 - mae: 0.1094 - val_loss: 0.3951 - val_mae: 0.1373\n",
            "Epoch 239/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0791 - mae: 0.0913 - val_loss: 0.3891 - val_mae: 0.1340\n",
            "Epoch 240/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0986 - mae: 0.0953 - val_loss: 0.3921 - val_mae: 0.1351\n",
            "Epoch 241/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0989 - mae: 0.0932 - val_loss: 0.3908 - val_mae: 0.1358\n",
            "Epoch 242/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1267 - mae: 0.1066 - val_loss: 0.3851 - val_mae: 0.1346\n",
            "Epoch 243/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1171 - mae: 0.0956 - val_loss: 0.3887 - val_mae: 0.1339\n",
            "Epoch 244/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0942 - mae: 0.0930 - val_loss: 0.3850 - val_mae: 0.1340\n",
            "Epoch 245/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0812 - mae: 0.0878 - val_loss: 0.3867 - val_mae: 0.1350\n",
            "Epoch 246/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1190 - mae: 0.0973 - val_loss: 0.3920 - val_mae: 0.1331\n",
            "Epoch 247/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1085 - mae: 0.0966 - val_loss: 0.3959 - val_mae: 0.1339\n",
            "Epoch 248/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0994 - mae: 0.0972 - val_loss: 0.3902 - val_mae: 0.1358\n",
            "Epoch 249/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1363 - mae: 0.1087 - val_loss: 0.3873 - val_mae: 0.1413\n",
            "Epoch 250/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1103 - mae: 0.0975 - val_loss: 0.3931 - val_mae: 0.1335\n",
            "Epoch 251/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1078 - mae: 0.0994 - val_loss: 0.3823 - val_mae: 0.1371\n",
            "Epoch 252/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0809 - mae: 0.0953 - val_loss: 0.3901 - val_mae: 0.1353\n",
            "Epoch 253/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1162 - mae: 0.0953 - val_loss: 0.3917 - val_mae: 0.1333\n",
            "Epoch 254/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1380 - mae: 0.1125 - val_loss: 0.3840 - val_mae: 0.1346\n",
            "Epoch 255/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1195 - mae: 0.1001 - val_loss: 0.3935 - val_mae: 0.1325\n",
            "Epoch 256/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1093 - mae: 0.0944 - val_loss: 0.3913 - val_mae: 0.1347\n",
            "Epoch 257/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1189 - mae: 0.1012 - val_loss: 0.3894 - val_mae: 0.1329\n",
            "Epoch 258/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1430 - mae: 0.1050 - val_loss: 0.3958 - val_mae: 0.1325\n",
            "Epoch 259/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1274 - mae: 0.1042 - val_loss: 0.3964 - val_mae: 0.1302\n",
            "Epoch 260/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0948 - mae: 0.0901 - val_loss: 0.3872 - val_mae: 0.1335\n",
            "Epoch 261/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0832 - mae: 0.0891 - val_loss: 0.3881 - val_mae: 0.1334\n",
            "Epoch 262/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0869 - mae: 0.0903 - val_loss: 0.3905 - val_mae: 0.1335\n",
            "Epoch 263/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1144 - mae: 0.0993 - val_loss: 0.4003 - val_mae: 0.1360\n",
            "Epoch 264/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1487 - mae: 0.1159 - val_loss: 0.4066 - val_mae: 0.1381\n",
            "Epoch 265/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1249 - mae: 0.1077 - val_loss: 0.3916 - val_mae: 0.1372\n",
            "Epoch 266/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0865 - mae: 0.0926 - val_loss: 0.3935 - val_mae: 0.1341\n",
            "Epoch 267/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0925 - mae: 0.0901 - val_loss: 0.3937 - val_mae: 0.1345\n",
            "Epoch 268/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1064 - mae: 0.0933 - val_loss: 0.3961 - val_mae: 0.1337\n",
            "Epoch 269/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1224 - mae: 0.0955 - val_loss: 0.3914 - val_mae: 0.1313\n",
            "Epoch 270/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1088 - mae: 0.0960 - val_loss: 0.3969 - val_mae: 0.1363\n",
            "Epoch 271/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1255 - mae: 0.1012 - val_loss: 0.3863 - val_mae: 0.1340\n",
            "Epoch 272/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1149 - mae: 0.1027 - val_loss: 0.4020 - val_mae: 0.1389\n",
            "Epoch 273/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0970 - mae: 0.0955 - val_loss: 0.3857 - val_mae: 0.1342\n",
            "Epoch 274/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0994 - mae: 0.0949 - val_loss: 0.3946 - val_mae: 0.1319\n",
            "Epoch 275/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0947 - mae: 0.0926 - val_loss: 0.3937 - val_mae: 0.1342\n",
            "Epoch 276/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0766 - mae: 0.0835 - val_loss: 0.3913 - val_mae: 0.1330\n",
            "Epoch 277/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0869 - mae: 0.0939 - val_loss: 0.3929 - val_mae: 0.1361\n",
            "Epoch 278/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1369 - mae: 0.1059 - val_loss: 0.3851 - val_mae: 0.1337\n",
            "Epoch 279/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1006 - mae: 0.0970 - val_loss: 0.3980 - val_mae: 0.1429\n",
            "Epoch 280/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1411 - mae: 0.1169 - val_loss: 0.3980 - val_mae: 0.1398\n",
            "Epoch 281/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0885 - mae: 0.1001 - val_loss: 0.3961 - val_mae: 0.1368\n",
            "Epoch 282/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1287 - mae: 0.1041 - val_loss: 0.3862 - val_mae: 0.1348\n",
            "Epoch 283/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1213 - mae: 0.0983 - val_loss: 0.3878 - val_mae: 0.1314\n",
            "Epoch 284/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1317 - mae: 0.0965 - val_loss: 0.3865 - val_mae: 0.1350\n",
            "Epoch 285/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1440 - mae: 0.1045 - val_loss: 0.3916 - val_mae: 0.1296\n",
            "Epoch 286/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0688 - mae: 0.0782 - val_loss: 0.3831 - val_mae: 0.1326\n",
            "Epoch 287/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0747 - mae: 0.0858 - val_loss: 0.3919 - val_mae: 0.1405\n",
            "Epoch 288/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0992 - mae: 0.0978 - val_loss: 0.3836 - val_mae: 0.1371\n",
            "Epoch 289/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0849 - mae: 0.0887 - val_loss: 0.3863 - val_mae: 0.1302\n",
            "Epoch 290/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0936 - mae: 0.0860 - val_loss: 0.3884 - val_mae: 0.1319\n",
            "Epoch 291/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1033 - mae: 0.0966 - val_loss: 0.3837 - val_mae: 0.1372\n",
            "Epoch 292/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1264 - mae: 0.1069 - val_loss: 0.3884 - val_mae: 0.1332\n",
            "Epoch 293/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1285 - mae: 0.1015 - val_loss: 0.3916 - val_mae: 0.1305\n",
            "Epoch 294/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0764 - mae: 0.0844 - val_loss: 0.3884 - val_mae: 0.1294\n",
            "Epoch 295/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0941 - mae: 0.0889 - val_loss: 0.3887 - val_mae: 0.1325\n",
            "Epoch 296/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1055 - mae: 0.0972 - val_loss: 0.3932 - val_mae: 0.1308\n",
            "Epoch 297/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1523 - mae: 0.0994 - val_loss: 0.3894 - val_mae: 0.1337\n",
            "Epoch 298/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0899 - mae: 0.0931 - val_loss: 0.4016 - val_mae: 0.1324\n",
            "Epoch 299/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1161 - mae: 0.1013 - val_loss: 0.3791 - val_mae: 0.1395\n",
            "Epoch 300/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1093 - mae: 0.1005 - val_loss: 0.3884 - val_mae: 0.1298\n",
            "Epoch 301/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1020 - mae: 0.0960 - val_loss: 0.3901 - val_mae: 0.1303\n",
            "Epoch 302/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0911 - mae: 0.0869 - val_loss: 0.3822 - val_mae: 0.1354\n",
            "Epoch 303/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1061 - mae: 0.0970 - val_loss: 0.4027 - val_mae: 0.1340\n",
            "Epoch 304/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0780 - mae: 0.0884 - val_loss: 0.3926 - val_mae: 0.1352\n",
            "Epoch 305/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1628 - mae: 0.1094 - val_loss: 0.4038 - val_mae: 0.1310\n",
            "Epoch 306/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0880 - mae: 0.0926 - val_loss: 0.3927 - val_mae: 0.1322\n",
            "Epoch 307/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0798 - mae: 0.0838 - val_loss: 0.3932 - val_mae: 0.1354\n",
            "Epoch 308/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0828 - mae: 0.0887 - val_loss: 0.3828 - val_mae: 0.1331\n",
            "Epoch 309/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1119 - mae: 0.0997 - val_loss: 0.3880 - val_mae: 0.1316\n",
            "Epoch 310/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1223 - mae: 0.0939 - val_loss: 0.3915 - val_mae: 0.1301\n",
            "Epoch 311/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1098 - mae: 0.0957 - val_loss: 0.3873 - val_mae: 0.1293\n",
            "Epoch 312/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1335 - mae: 0.1013 - val_loss: 0.3930 - val_mae: 0.1313\n",
            "Epoch 313/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0966 - mae: 0.0908 - val_loss: 0.3878 - val_mae: 0.1291\n",
            "Epoch 314/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1234 - mae: 0.0994 - val_loss: 0.3873 - val_mae: 0.1304\n",
            "Epoch 315/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1370 - mae: 0.1026 - val_loss: 0.3892 - val_mae: 0.1295\n",
            "Epoch 316/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1196 - mae: 0.0952 - val_loss: 0.3865 - val_mae: 0.1309\n",
            "Epoch 317/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0883 - mae: 0.0914 - val_loss: 0.3987 - val_mae: 0.1368\n",
            "Epoch 318/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1204 - mae: 0.1024 - val_loss: 0.3853 - val_mae: 0.1357\n",
            "Epoch 319/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0988 - mae: 0.1008 - val_loss: 0.3955 - val_mae: 0.1320\n",
            "Epoch 320/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1422 - mae: 0.1065 - val_loss: 0.3921 - val_mae: 0.1310\n",
            "Epoch 321/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1299 - mae: 0.1010 - val_loss: 0.3882 - val_mae: 0.1319\n",
            "Epoch 322/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0921 - mae: 0.0947 - val_loss: 0.3958 - val_mae: 0.1303\n",
            "Epoch 323/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0810 - mae: 0.0876 - val_loss: 0.3910 - val_mae: 0.1314\n",
            "Epoch 324/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1303 - mae: 0.1081 - val_loss: 0.3875 - val_mae: 0.1293\n",
            "Epoch 325/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0847 - mae: 0.0893 - val_loss: 0.3895 - val_mae: 0.1337\n",
            "Epoch 326/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0920 - mae: 0.0916 - val_loss: 0.3862 - val_mae: 0.1339\n",
            "Epoch 327/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0925 - mae: 0.0912 - val_loss: 0.3854 - val_mae: 0.1319\n",
            "Epoch 328/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1263 - mae: 0.1028 - val_loss: 0.3889 - val_mae: 0.1311\n",
            "Epoch 329/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1325 - mae: 0.0983 - val_loss: 0.3953 - val_mae: 0.1350\n",
            "Epoch 330/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0888 - mae: 0.0941 - val_loss: 0.3862 - val_mae: 0.1323\n",
            "Epoch 331/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0913 - mae: 0.0930 - val_loss: 0.3930 - val_mae: 0.1285\n",
            "Epoch 332/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1069 - mae: 0.0977 - val_loss: 0.3874 - val_mae: 0.1308\n",
            "Epoch 333/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1258 - mae: 0.0986 - val_loss: 0.3944 - val_mae: 0.1305\n",
            "Epoch 334/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1254 - mae: 0.0959 - val_loss: 0.3901 - val_mae: 0.1334\n",
            "Epoch 335/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1380 - mae: 0.1044 - val_loss: 0.3924 - val_mae: 0.1299\n",
            "Epoch 336/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1245 - mae: 0.0985 - val_loss: 0.3839 - val_mae: 0.1321\n",
            "Epoch 337/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1236 - mae: 0.0973 - val_loss: 0.3959 - val_mae: 0.1291\n",
            "Epoch 338/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0832 - mae: 0.0863 - val_loss: 0.3815 - val_mae: 0.1348\n",
            "Epoch 339/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1596 - mae: 0.1134 - val_loss: 0.3898 - val_mae: 0.1287\n",
            "Epoch 340/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1475 - mae: 0.1018 - val_loss: 0.3888 - val_mae: 0.1292\n",
            "Epoch 341/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0716 - mae: 0.0824 - val_loss: 0.3900 - val_mae: 0.1307\n",
            "Epoch 342/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0738 - mae: 0.0861 - val_loss: 0.3859 - val_mae: 0.1302\n",
            "Epoch 343/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0979 - mae: 0.0924 - val_loss: 0.3866 - val_mae: 0.1301\n",
            "Epoch 344/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0922 - mae: 0.0898 - val_loss: 0.3893 - val_mae: 0.1271\n",
            "Epoch 345/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1101 - mae: 0.0920 - val_loss: 0.3910 - val_mae: 0.1316\n",
            "Epoch 346/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0949 - mae: 0.0936 - val_loss: 0.3901 - val_mae: 0.1316\n",
            "Epoch 347/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1121 - mae: 0.1024 - val_loss: 0.3828 - val_mae: 0.1347\n",
            "Epoch 348/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1024 - mae: 0.0939 - val_loss: 0.3917 - val_mae: 0.1290\n",
            "Epoch 349/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1109 - mae: 0.0932 - val_loss: 0.3861 - val_mae: 0.1280\n",
            "Epoch 350/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1169 - mae: 0.0959 - val_loss: 0.3920 - val_mae: 0.1295\n",
            "Epoch 351/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1234 - mae: 0.1032 - val_loss: 0.3844 - val_mae: 0.1307\n",
            "Epoch 352/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1350 - mae: 0.1028 - val_loss: 0.4022 - val_mae: 0.1338\n",
            "Epoch 353/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1118 - mae: 0.0942 - val_loss: 0.3880 - val_mae: 0.1314\n",
            "Epoch 354/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0816 - mae: 0.0889 - val_loss: 0.3883 - val_mae: 0.1302\n",
            "Epoch 355/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1183 - mae: 0.0926 - val_loss: 0.3999 - val_mae: 0.1290\n",
            "Epoch 356/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0794 - mae: 0.0852 - val_loss: 0.3885 - val_mae: 0.1274\n",
            "Epoch 357/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0854 - mae: 0.0882 - val_loss: 0.3880 - val_mae: 0.1290\n",
            "Epoch 358/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1128 - mae: 0.0917 - val_loss: 0.3913 - val_mae: 0.1310\n",
            "Epoch 359/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0917 - mae: 0.0911 - val_loss: 0.3838 - val_mae: 0.1289\n",
            "Epoch 360/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0757 - mae: 0.0854 - val_loss: 0.3872 - val_mae: 0.1285\n",
            "Epoch 361/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1312 - mae: 0.0994 - val_loss: 0.4010 - val_mae: 0.1322\n",
            "Epoch 362/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0960 - mae: 0.0885 - val_loss: 0.3868 - val_mae: 0.1284\n",
            "Epoch 363/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1326 - mae: 0.1012 - val_loss: 0.3936 - val_mae: 0.1290\n",
            "Epoch 364/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0934 - mae: 0.0924 - val_loss: 0.3894 - val_mae: 0.1364\n",
            "Epoch 365/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0936 - mae: 0.0937 - val_loss: 0.3878 - val_mae: 0.1337\n",
            "Epoch 366/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1240 - mae: 0.0957 - val_loss: 0.3916 - val_mae: 0.1298\n",
            "Epoch 367/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1036 - mae: 0.0924 - val_loss: 0.3876 - val_mae: 0.1318\n",
            "Epoch 368/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0863 - mae: 0.0875 - val_loss: 0.3876 - val_mae: 0.1276\n",
            "Epoch 369/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1404 - mae: 0.0994 - val_loss: 0.3936 - val_mae: 0.1301\n",
            "Epoch 370/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0934 - mae: 0.0898 - val_loss: 0.3924 - val_mae: 0.1277\n",
            "Epoch 371/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1011 - mae: 0.0893 - val_loss: 0.3881 - val_mae: 0.1308\n",
            "Epoch 372/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1227 - mae: 0.0950 - val_loss: 0.3866 - val_mae: 0.1304\n",
            "Epoch 373/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1359 - mae: 0.0992 - val_loss: 0.3922 - val_mae: 0.1272\n",
            "Epoch 374/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1456 - mae: 0.1016 - val_loss: 0.3933 - val_mae: 0.1268\n",
            "Epoch 375/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0951 - mae: 0.0908 - val_loss: 0.3873 - val_mae: 0.1283\n",
            "Epoch 376/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1424 - mae: 0.1069 - val_loss: 0.4081 - val_mae: 0.1320\n",
            "Epoch 377/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1103 - mae: 0.0937 - val_loss: 0.3882 - val_mae: 0.1451\n",
            "Epoch 378/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1642 - mae: 0.1209 - val_loss: 0.4022 - val_mae: 0.1407\n",
            "Epoch 379/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0915 - mae: 0.0952 - val_loss: 0.3916 - val_mae: 0.1458\n",
            "Epoch 380/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1699 - mae: 0.1133 - val_loss: 0.3919 - val_mae: 0.1339\n",
            "Epoch 381/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1000 - mae: 0.0962 - val_loss: 0.3952 - val_mae: 0.1290\n",
            "Epoch 382/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1325 - mae: 0.1005 - val_loss: 0.3882 - val_mae: 0.1279\n",
            "Epoch 383/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1051 - mae: 0.0914 - val_loss: 0.3857 - val_mae: 0.1287\n",
            "Epoch 384/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0959 - mae: 0.0909 - val_loss: 0.3934 - val_mae: 0.1282\n",
            "Epoch 385/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1230 - mae: 0.1013 - val_loss: 0.3833 - val_mae: 0.1332\n",
            "Epoch 386/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1060 - mae: 0.0892 - val_loss: 0.3873 - val_mae: 0.1282\n",
            "Epoch 387/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1069 - mae: 0.0913 - val_loss: 0.3874 - val_mae: 0.1283\n",
            "Epoch 388/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0847 - mae: 0.0862 - val_loss: 0.3914 - val_mae: 0.1270\n",
            "Epoch 389/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1477 - mae: 0.0996 - val_loss: 0.4115 - val_mae: 0.1332\n",
            "Epoch 390/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1278 - mae: 0.0934 - val_loss: 0.3839 - val_mae: 0.1350\n",
            "Epoch 391/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0791 - mae: 0.0868 - val_loss: 0.3907 - val_mae: 0.1300\n",
            "Epoch 392/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0971 - mae: 0.0885 - val_loss: 0.3859 - val_mae: 0.1275\n",
            "Epoch 393/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0927 - mae: 0.0900 - val_loss: 0.3876 - val_mae: 0.1279\n",
            "Epoch 394/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1222 - mae: 0.0954 - val_loss: 0.3942 - val_mae: 0.1275\n",
            "Epoch 395/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1050 - mae: 0.0893 - val_loss: 0.3898 - val_mae: 0.1339\n",
            "Epoch 396/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0897 - mae: 0.0895 - val_loss: 0.3869 - val_mae: 0.1293\n",
            "Epoch 397/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1006 - mae: 0.0959 - val_loss: 0.3848 - val_mae: 0.1282\n",
            "Epoch 398/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0837 - mae: 0.0868 - val_loss: 0.3867 - val_mae: 0.1284\n",
            "Epoch 399/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0849 - mae: 0.0863 - val_loss: 0.3871 - val_mae: 0.1285\n",
            "Epoch 400/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0955 - mae: 0.0887 - val_loss: 0.3895 - val_mae: 0.1339\n",
            "Epoch 401/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1088 - mae: 0.0967 - val_loss: 0.3881 - val_mae: 0.1279\n",
            "Epoch 402/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1389 - mae: 0.1027 - val_loss: 0.3889 - val_mae: 0.1262\n",
            "Epoch 403/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0939 - mae: 0.0887 - val_loss: 0.3910 - val_mae: 0.1292\n",
            "Epoch 404/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0881 - mae: 0.0886 - val_loss: 0.3833 - val_mae: 0.1298\n",
            "Epoch 405/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0850 - mae: 0.0852 - val_loss: 0.3868 - val_mae: 0.1276\n",
            "Epoch 406/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1157 - mae: 0.0990 - val_loss: 0.3878 - val_mae: 0.1254\n",
            "Epoch 407/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1058 - mae: 0.0883 - val_loss: 0.3943 - val_mae: 0.1296\n",
            "Epoch 408/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1041 - mae: 0.0915 - val_loss: 0.3855 - val_mae: 0.1262\n",
            "Epoch 409/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1347 - mae: 0.0986 - val_loss: 0.3877 - val_mae: 0.1281\n",
            "Epoch 410/2000\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.0958 - mae: 0.0881 - val_loss: 0.3882 - val_mae: 0.1249\n",
            "Epoch 411/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1123 - mae: 0.0920 - val_loss: 0.3917 - val_mae: 0.1289\n",
            "Epoch 412/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1485 - mae: 0.1068 - val_loss: 0.3975 - val_mae: 0.1308\n",
            "Epoch 413/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1237 - mae: 0.1030 - val_loss: 0.3830 - val_mae: 0.1298\n",
            "Epoch 414/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0856 - mae: 0.0834 - val_loss: 0.3918 - val_mae: 0.1281\n",
            "Epoch 415/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0874 - mae: 0.0855 - val_loss: 0.3840 - val_mae: 0.1282\n",
            "Epoch 416/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1342 - mae: 0.1031 - val_loss: 0.3934 - val_mae: 0.1271\n",
            "Epoch 417/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1212 - mae: 0.0870 - val_loss: 0.3847 - val_mae: 0.1257\n",
            "Epoch 418/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1418 - mae: 0.1008 - val_loss: 0.3903 - val_mae: 0.1265\n",
            "Epoch 419/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1173 - mae: 0.0949 - val_loss: 0.3830 - val_mae: 0.1275\n",
            "Epoch 420/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1073 - mae: 0.0919 - val_loss: 0.3998 - val_mae: 0.1275\n",
            "Epoch 421/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1181 - mae: 0.0965 - val_loss: 0.3857 - val_mae: 0.1255\n",
            "Epoch 422/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0982 - mae: 0.0904 - val_loss: 0.3866 - val_mae: 0.1262\n",
            "Epoch 423/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1096 - mae: 0.0955 - val_loss: 0.3944 - val_mae: 0.1249\n",
            "Epoch 424/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0927 - mae: 0.0864 - val_loss: 0.3890 - val_mae: 0.1261\n",
            "Epoch 425/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1241 - mae: 0.0951 - val_loss: 0.3864 - val_mae: 0.1256\n",
            "Epoch 426/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1061 - mae: 0.0908 - val_loss: 0.3883 - val_mae: 0.1270\n",
            "Epoch 427/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1191 - mae: 0.0949 - val_loss: 0.3895 - val_mae: 0.1266\n",
            "Epoch 428/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1051 - mae: 0.0895 - val_loss: 0.3903 - val_mae: 0.1281\n",
            "Epoch 429/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0986 - mae: 0.0831 - val_loss: 0.3869 - val_mae: 0.1268\n",
            "Epoch 430/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0768 - mae: 0.0818 - val_loss: 0.3874 - val_mae: 0.1292\n",
            "Epoch 431/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0998 - mae: 0.0864 - val_loss: 0.3891 - val_mae: 0.1298\n",
            "Epoch 432/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1273 - mae: 0.0964 - val_loss: 0.3889 - val_mae: 0.1278\n",
            "Epoch 433/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1389 - mae: 0.1017 - val_loss: 0.3888 - val_mae: 0.1309\n",
            "Epoch 434/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0915 - mae: 0.0905 - val_loss: 0.3891 - val_mae: 0.1301\n",
            "Epoch 435/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0932 - mae: 0.0893 - val_loss: 0.3898 - val_mae: 0.1320\n",
            "Epoch 436/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0806 - mae: 0.0890 - val_loss: 0.3885 - val_mae: 0.1293\n",
            "Epoch 437/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1276 - mae: 0.0962 - val_loss: 0.3979 - val_mae: 0.1296\n",
            "Epoch 438/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0991 - mae: 0.0913 - val_loss: 0.3814 - val_mae: 0.1295\n",
            "Epoch 439/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1261 - mae: 0.1009 - val_loss: 0.3920 - val_mae: 0.1319\n",
            "Epoch 440/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0874 - mae: 0.0898 - val_loss: 0.3852 - val_mae: 0.1378\n",
            "Epoch 441/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0827 - mae: 0.0896 - val_loss: 0.3873 - val_mae: 0.1270\n",
            "Epoch 442/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0853 - mae: 0.0839 - val_loss: 0.3820 - val_mae: 0.1271\n",
            "Epoch 443/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1388 - mae: 0.0970 - val_loss: 0.3826 - val_mae: 0.1264\n",
            "Epoch 444/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1248 - mae: 0.0991 - val_loss: 0.3930 - val_mae: 0.1245\n",
            "Epoch 445/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0973 - mae: 0.0878 - val_loss: 0.3909 - val_mae: 0.1248\n",
            "Epoch 446/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1605 - mae: 0.1041 - val_loss: 0.3966 - val_mae: 0.1272\n",
            "Epoch 447/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1134 - mae: 0.0909 - val_loss: 0.3941 - val_mae: 0.1371\n",
            "Epoch 448/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1108 - mae: 0.0983 - val_loss: 0.3937 - val_mae: 0.1280\n",
            "Epoch 449/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1197 - mae: 0.0987 - val_loss: 0.3889 - val_mae: 0.1265\n",
            "Epoch 450/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1111 - mae: 0.0892 - val_loss: 0.3915 - val_mae: 0.1245\n",
            "Epoch 451/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1180 - mae: 0.0928 - val_loss: 0.3828 - val_mae: 0.1278\n",
            "Epoch 452/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1143 - mae: 0.0918 - val_loss: 0.3871 - val_mae: 0.1265\n",
            "Epoch 453/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1001 - mae: 0.0865 - val_loss: 0.3870 - val_mae: 0.1267\n",
            "Epoch 454/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0796 - mae: 0.0822 - val_loss: 0.3852 - val_mae: 0.1266\n",
            "Epoch 455/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1127 - mae: 0.0917 - val_loss: 0.3898 - val_mae: 0.1254\n",
            "Epoch 456/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1139 - mae: 0.0923 - val_loss: 0.3883 - val_mae: 0.1240\n",
            "Epoch 457/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0918 - mae: 0.0838 - val_loss: 0.3893 - val_mae: 0.1255\n",
            "Epoch 458/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1025 - mae: 0.0927 - val_loss: 0.3847 - val_mae: 0.1271\n",
            "Epoch 459/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1443 - mae: 0.0958 - val_loss: 0.3958 - val_mae: 0.1247\n",
            "Epoch 460/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0837 - mae: 0.0837 - val_loss: 0.3908 - val_mae: 0.1244\n",
            "Epoch 461/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1029 - mae: 0.0912 - val_loss: 0.3865 - val_mae: 0.1268\n",
            "Epoch 462/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1475 - mae: 0.1048 - val_loss: 0.3916 - val_mae: 0.1241\n",
            "Epoch 463/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1154 - mae: 0.0899 - val_loss: 0.3876 - val_mae: 0.1246\n",
            "Epoch 464/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0967 - mae: 0.0899 - val_loss: 0.3892 - val_mae: 0.1256\n",
            "Epoch 465/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0968 - mae: 0.0904 - val_loss: 0.3861 - val_mae: 0.1268\n",
            "Epoch 466/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1187 - mae: 0.0966 - val_loss: 0.3849 - val_mae: 0.1258\n",
            "Epoch 467/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0765 - mae: 0.0866 - val_loss: 0.3888 - val_mae: 0.1236\n",
            "Epoch 468/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1059 - mae: 0.0841 - val_loss: 0.3904 - val_mae: 0.1283\n",
            "Epoch 469/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1043 - mae: 0.0884 - val_loss: 0.3881 - val_mae: 0.1255\n",
            "Epoch 470/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0913 - mae: 0.0861 - val_loss: 0.3927 - val_mae: 0.1286\n",
            "Epoch 471/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1305 - mae: 0.0974 - val_loss: 0.3839 - val_mae: 0.1331\n",
            "Epoch 472/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1283 - mae: 0.0989 - val_loss: 0.4027 - val_mae: 0.1330\n",
            "Epoch 473/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0860 - mae: 0.0896 - val_loss: 0.3873 - val_mae: 0.1263\n",
            "Epoch 474/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0812 - mae: 0.0815 - val_loss: 0.3884 - val_mae: 0.1244\n",
            "Epoch 475/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1506 - mae: 0.1017 - val_loss: 0.3937 - val_mae: 0.1280\n",
            "Epoch 476/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1075 - mae: 0.0898 - val_loss: 0.3870 - val_mae: 0.1261\n",
            "Epoch 477/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1273 - mae: 0.0953 - val_loss: 0.3940 - val_mae: 0.1261\n",
            "Epoch 478/2000\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1312 - mae: 0.1005 - val_loss: 0.3889 - val_mae: 0.1260\n",
            "Epoch 479/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0669 - mae: 0.0741 - val_loss: 0.3885 - val_mae: 0.1247\n",
            "Epoch 480/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0842 - mae: 0.0820 - val_loss: 0.3849 - val_mae: 0.1268\n",
            "Epoch 481/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1020 - mae: 0.0873 - val_loss: 0.3865 - val_mae: 0.1269\n",
            "Epoch 482/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1029 - mae: 0.0881 - val_loss: 0.3908 - val_mae: 0.1272\n",
            "Epoch 483/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1110 - mae: 0.0985 - val_loss: 0.3832 - val_mae: 0.1293\n",
            "Epoch 484/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1021 - mae: 0.0907 - val_loss: 0.3848 - val_mae: 0.1273\n",
            "Epoch 485/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0917 - mae: 0.0882 - val_loss: 0.3888 - val_mae: 0.1271\n",
            "Epoch 486/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0805 - mae: 0.0850 - val_loss: 0.3875 - val_mae: 0.1274\n",
            "Epoch 487/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1003 - mae: 0.0894 - val_loss: 0.3899 - val_mae: 0.1269\n",
            "Epoch 488/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1031 - mae: 0.0865 - val_loss: 0.3860 - val_mae: 0.1256\n",
            "Epoch 489/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1320 - mae: 0.0995 - val_loss: 0.3809 - val_mae: 0.1268\n",
            "Epoch 490/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0912 - mae: 0.0871 - val_loss: 0.3913 - val_mae: 0.1231\n",
            "Epoch 491/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1309 - mae: 0.0980 - val_loss: 0.3818 - val_mae: 0.1279\n",
            "Epoch 492/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0931 - mae: 0.0814 - val_loss: 0.3915 - val_mae: 0.1252\n",
            "Epoch 493/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0996 - mae: 0.0919 - val_loss: 0.3864 - val_mae: 0.1242\n",
            "Epoch 494/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0983 - mae: 0.0863 - val_loss: 0.3828 - val_mae: 0.1264\n",
            "Epoch 495/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1437 - mae: 0.1070 - val_loss: 0.3895 - val_mae: 0.1278\n",
            "Epoch 496/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0893 - mae: 0.0844 - val_loss: 0.3858 - val_mae: 0.1274\n",
            "Epoch 497/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1158 - mae: 0.0932 - val_loss: 0.3873 - val_mae: 0.1278\n",
            "Epoch 498/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0952 - mae: 0.0890 - val_loss: 0.3905 - val_mae: 0.1247\n",
            "Epoch 499/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0718 - mae: 0.0787 - val_loss: 0.3879 - val_mae: 0.1238\n",
            "Epoch 500/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1342 - mae: 0.0947 - val_loss: 0.3853 - val_mae: 0.1265\n",
            "Epoch 501/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0806 - mae: 0.0834 - val_loss: 0.3919 - val_mae: 0.1255\n",
            "Epoch 502/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1203 - mae: 0.0969 - val_loss: 0.3888 - val_mae: 0.1291\n",
            "Epoch 503/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1096 - mae: 0.0898 - val_loss: 0.3854 - val_mae: 0.1291\n",
            "Epoch 504/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0927 - mae: 0.0865 - val_loss: 0.3966 - val_mae: 0.1254\n",
            "Epoch 505/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0915 - mae: 0.0853 - val_loss: 0.3912 - val_mae: 0.1266\n",
            "Epoch 506/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0753 - mae: 0.0772 - val_loss: 0.3901 - val_mae: 0.1244\n",
            "Epoch 507/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1201 - mae: 0.0906 - val_loss: 0.3876 - val_mae: 0.1261\n",
            "Epoch 508/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0972 - mae: 0.0851 - val_loss: 0.3890 - val_mae: 0.1247\n",
            "Epoch 509/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1001 - mae: 0.0847 - val_loss: 0.3909 - val_mae: 0.1254\n",
            "Epoch 510/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1007 - mae: 0.0879 - val_loss: 0.3856 - val_mae: 0.1264\n",
            "Epoch 511/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1021 - mae: 0.0869 - val_loss: 0.3915 - val_mae: 0.1248\n",
            "Epoch 512/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1148 - mae: 0.0967 - val_loss: 0.3868 - val_mae: 0.1243\n",
            "Epoch 513/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1247 - mae: 0.0933 - val_loss: 0.3923 - val_mae: 0.1256\n",
            "Epoch 514/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1385 - mae: 0.0957 - val_loss: 0.3854 - val_mae: 0.1244\n",
            "Epoch 515/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1168 - mae: 0.0933 - val_loss: 0.3919 - val_mae: 0.1253\n",
            "Epoch 516/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0934 - mae: 0.0884 - val_loss: 0.3888 - val_mae: 0.1278\n",
            "Epoch 517/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1032 - mae: 0.0859 - val_loss: 0.3935 - val_mae: 0.1255\n",
            "Epoch 518/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1459 - mae: 0.0977 - val_loss: 0.3925 - val_mae: 0.1260\n",
            "Epoch 519/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1192 - mae: 0.0906 - val_loss: 0.3843 - val_mae: 0.1247\n",
            "Epoch 520/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0799 - mae: 0.0813 - val_loss: 0.3830 - val_mae: 0.1249\n",
            "Epoch 521/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0872 - mae: 0.0823 - val_loss: 0.3822 - val_mae: 0.1301\n",
            "Epoch 522/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1064 - mae: 0.0910 - val_loss: 0.3849 - val_mae: 0.1308\n",
            "Epoch 523/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1120 - mae: 0.0945 - val_loss: 0.3844 - val_mae: 0.1256\n",
            "Epoch 524/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1132 - mae: 0.0894 - val_loss: 0.3854 - val_mae: 0.1263\n",
            "Epoch 525/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0726 - mae: 0.0829 - val_loss: 0.3867 - val_mae: 0.1267\n",
            "Epoch 526/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1072 - mae: 0.0903 - val_loss: 0.3862 - val_mae: 0.1257\n",
            "Epoch 527/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0893 - mae: 0.0823 - val_loss: 0.3863 - val_mae: 0.1247\n",
            "Epoch 528/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1386 - mae: 0.0949 - val_loss: 0.3932 - val_mae: 0.1241\n",
            "Epoch 529/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1085 - mae: 0.0847 - val_loss: 0.3857 - val_mae: 0.1273\n",
            "Epoch 530/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1113 - mae: 0.0936 - val_loss: 0.3909 - val_mae: 0.1239\n",
            "Epoch 531/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0916 - mae: 0.0852 - val_loss: 0.3874 - val_mae: 0.1250\n",
            "Epoch 532/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1047 - mae: 0.0899 - val_loss: 0.3899 - val_mae: 0.1252\n",
            "Epoch 533/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1395 - mae: 0.0984 - val_loss: 0.3865 - val_mae: 0.1253\n",
            "Epoch 534/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0970 - mae: 0.0858 - val_loss: 0.3883 - val_mae: 0.1231\n",
            "Epoch 535/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0873 - mae: 0.0889 - val_loss: 0.3825 - val_mae: 0.1253\n",
            "Epoch 536/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1561 - mae: 0.1046 - val_loss: 0.3966 - val_mae: 0.1252\n",
            "Epoch 537/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1027 - mae: 0.0886 - val_loss: 0.3884 - val_mae: 0.1236\n",
            "Epoch 538/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0842 - mae: 0.0810 - val_loss: 0.3926 - val_mae: 0.1239\n",
            "Epoch 539/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0919 - mae: 0.0857 - val_loss: 0.3840 - val_mae: 0.1249\n",
            "Epoch 540/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0948 - mae: 0.0828 - val_loss: 0.3924 - val_mae: 0.1245\n",
            "Epoch 541/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1035 - mae: 0.0924 - val_loss: 0.3845 - val_mae: 0.1245\n",
            "Epoch 542/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1297 - mae: 0.0937 - val_loss: 0.3921 - val_mae: 0.1227\n",
            "Epoch 543/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1006 - mae: 0.0884 - val_loss: 0.3833 - val_mae: 0.1246\n",
            "Epoch 544/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0836 - mae: 0.0878 - val_loss: 0.3850 - val_mae: 0.1275\n",
            "Epoch 545/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0838 - mae: 0.0882 - val_loss: 0.3858 - val_mae: 0.1260\n",
            "Epoch 546/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0938 - mae: 0.0872 - val_loss: 0.3873 - val_mae: 0.1272\n",
            "Epoch 547/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1090 - mae: 0.0865 - val_loss: 0.3913 - val_mae: 0.1237\n",
            "Epoch 548/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1420 - mae: 0.0957 - val_loss: 0.3848 - val_mae: 0.1258\n",
            "Epoch 549/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1043 - mae: 0.0901 - val_loss: 0.3874 - val_mae: 0.1239\n",
            "Epoch 550/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0896 - mae: 0.0878 - val_loss: 0.3849 - val_mae: 0.1244\n",
            "Epoch 551/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0925 - mae: 0.0860 - val_loss: 0.3894 - val_mae: 0.1231\n",
            "Epoch 552/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0932 - mae: 0.0863 - val_loss: 0.3852 - val_mae: 0.1243\n",
            "Epoch 553/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1461 - mae: 0.0991 - val_loss: 0.3867 - val_mae: 0.1249\n",
            "Epoch 554/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1062 - mae: 0.0873 - val_loss: 0.3892 - val_mae: 0.1220\n",
            "Epoch 555/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1215 - mae: 0.0893 - val_loss: 0.3853 - val_mae: 0.1241\n",
            "Epoch 556/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0952 - mae: 0.0859 - val_loss: 0.3898 - val_mae: 0.1232\n",
            "Epoch 557/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1099 - mae: 0.0897 - val_loss: 0.3868 - val_mae: 0.1243\n",
            "Epoch 558/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1220 - mae: 0.0946 - val_loss: 0.3874 - val_mae: 0.1240\n",
            "Epoch 559/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1076 - mae: 0.0903 - val_loss: 0.3882 - val_mae: 0.1224\n",
            "Epoch 560/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0903 - mae: 0.0803 - val_loss: 0.3908 - val_mae: 0.1241\n",
            "Epoch 561/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0911 - mae: 0.0825 - val_loss: 0.3879 - val_mae: 0.1223\n",
            "Epoch 562/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1068 - mae: 0.0844 - val_loss: 0.3966 - val_mae: 0.1265\n",
            "Epoch 563/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0986 - mae: 0.0900 - val_loss: 0.3843 - val_mae: 0.1265\n",
            "Epoch 564/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0940 - mae: 0.0877 - val_loss: 0.3958 - val_mae: 0.1230\n",
            "Epoch 565/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1008 - mae: 0.0856 - val_loss: 0.3835 - val_mae: 0.1252\n",
            "Epoch 566/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1122 - mae: 0.0850 - val_loss: 0.3910 - val_mae: 0.1245\n",
            "Epoch 567/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1171 - mae: 0.0926 - val_loss: 0.3834 - val_mae: 0.1268\n",
            "Epoch 568/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1108 - mae: 0.0900 - val_loss: 0.3904 - val_mae: 0.1265\n",
            "Epoch 569/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0869 - mae: 0.0853 - val_loss: 0.4018 - val_mae: 0.1314\n",
            "Epoch 570/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0842 - mae: 0.0871 - val_loss: 0.3865 - val_mae: 0.1290\n",
            "Epoch 571/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1256 - mae: 0.0969 - val_loss: 0.3924 - val_mae: 0.1342\n",
            "Epoch 572/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1254 - mae: 0.1080 - val_loss: 0.3969 - val_mae: 0.1326\n",
            "Epoch 573/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1330 - mae: 0.0993 - val_loss: 0.3871 - val_mae: 0.1307\n",
            "Epoch 574/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1012 - mae: 0.0889 - val_loss: 0.3858 - val_mae: 0.1246\n",
            "Epoch 575/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0853 - mae: 0.0832 - val_loss: 0.3885 - val_mae: 0.1231\n",
            "Epoch 576/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1431 - mae: 0.0944 - val_loss: 0.3879 - val_mae: 0.1241\n",
            "Epoch 577/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1147 - mae: 0.0979 - val_loss: 0.3913 - val_mae: 0.1254\n",
            "Epoch 578/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1377 - mae: 0.1017 - val_loss: 0.3857 - val_mae: 0.1252\n",
            "Epoch 579/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1007 - mae: 0.0874 - val_loss: 0.3879 - val_mae: 0.1251\n",
            "Epoch 580/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1216 - mae: 0.0933 - val_loss: 0.3913 - val_mae: 0.1224\n",
            "Epoch 581/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1090 - mae: 0.0877 - val_loss: 0.3858 - val_mae: 0.1228\n",
            "Epoch 582/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1008 - mae: 0.0847 - val_loss: 0.3870 - val_mae: 0.1229\n",
            "Epoch 583/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1001 - mae: 0.0801 - val_loss: 0.3940 - val_mae: 0.1223\n",
            "Epoch 584/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1312 - mae: 0.0983 - val_loss: 0.3933 - val_mae: 0.1281\n",
            "Epoch 585/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0971 - mae: 0.0892 - val_loss: 0.3898 - val_mae: 0.1262\n",
            "Epoch 586/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0946 - mae: 0.0879 - val_loss: 0.3901 - val_mae: 0.1230\n",
            "Epoch 587/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1130 - mae: 0.0920 - val_loss: 0.3842 - val_mae: 0.1262\n",
            "Epoch 588/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1038 - mae: 0.0878 - val_loss: 0.3872 - val_mae: 0.1219\n",
            "Epoch 589/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1020 - mae: 0.0869 - val_loss: 0.3829 - val_mae: 0.1266\n",
            "Epoch 590/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0924 - mae: 0.0823 - val_loss: 0.3906 - val_mae: 0.1222\n",
            "Epoch 591/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0997 - mae: 0.0807 - val_loss: 0.3861 - val_mae: 0.1242\n",
            "Epoch 592/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0947 - mae: 0.0900 - val_loss: 0.3869 - val_mae: 0.1229\n",
            "Epoch 593/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1332 - mae: 0.0954 - val_loss: 0.3890 - val_mae: 0.1227\n",
            "Epoch 594/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1431 - mae: 0.0974 - val_loss: 0.3880 - val_mae: 0.1258\n",
            "Epoch 595/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1324 - mae: 0.0896 - val_loss: 0.3935 - val_mae: 0.1241\n",
            "Epoch 596/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1206 - mae: 0.0941 - val_loss: 0.3913 - val_mae: 0.1233\n",
            "Epoch 597/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0852 - mae: 0.0831 - val_loss: 0.3841 - val_mae: 0.1238\n",
            "Epoch 598/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0810 - mae: 0.0760 - val_loss: 0.3926 - val_mae: 0.1244\n",
            "Epoch 599/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1070 - mae: 0.0881 - val_loss: 0.3834 - val_mae: 0.1255\n",
            "Epoch 600/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1005 - mae: 0.0808 - val_loss: 0.3874 - val_mae: 0.1220\n",
            "Epoch 601/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1321 - mae: 0.0897 - val_loss: 0.3875 - val_mae: 0.1220\n",
            "Epoch 602/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0943 - mae: 0.0859 - val_loss: 0.3943 - val_mae: 0.1215\n",
            "Epoch 603/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0750 - mae: 0.0767 - val_loss: 0.3873 - val_mae: 0.1248\n",
            "Epoch 604/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0882 - mae: 0.0843 - val_loss: 0.3888 - val_mae: 0.1245\n",
            "Epoch 605/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0740 - mae: 0.0792 - val_loss: 0.3862 - val_mae: 0.1274\n",
            "Epoch 606/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0967 - mae: 0.0915 - val_loss: 0.3823 - val_mae: 0.1244\n",
            "Epoch 607/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1153 - mae: 0.0959 - val_loss: 0.3871 - val_mae: 0.1259\n",
            "Epoch 608/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1180 - mae: 0.0962 - val_loss: 0.3883 - val_mae: 0.1269\n",
            "Epoch 609/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0882 - mae: 0.0824 - val_loss: 0.3875 - val_mae: 0.1234\n",
            "Epoch 610/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0852 - mae: 0.0800 - val_loss: 0.3883 - val_mae: 0.1237\n",
            "Epoch 611/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0860 - mae: 0.0805 - val_loss: 0.3842 - val_mae: 0.1237\n",
            "Epoch 612/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1017 - mae: 0.0857 - val_loss: 0.3864 - val_mae: 0.1231\n",
            "Epoch 613/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0947 - mae: 0.0858 - val_loss: 0.3954 - val_mae: 0.1221\n",
            "Epoch 614/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1300 - mae: 0.0904 - val_loss: 0.3825 - val_mae: 0.1239\n",
            "Epoch 615/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1506 - mae: 0.1035 - val_loss: 0.3898 - val_mae: 0.1257\n",
            "Epoch 616/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1477 - mae: 0.1009 - val_loss: 0.3888 - val_mae: 0.1224\n",
            "Epoch 617/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1029 - mae: 0.0862 - val_loss: 0.3902 - val_mae: 0.1248\n",
            "Epoch 618/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1112 - mae: 0.0895 - val_loss: 0.3908 - val_mae: 0.1247\n",
            "Epoch 619/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1385 - mae: 0.0974 - val_loss: 0.3873 - val_mae: 0.1239\n",
            "Epoch 620/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0785 - mae: 0.0794 - val_loss: 0.3936 - val_mae: 0.1225\n",
            "Epoch 621/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0803 - mae: 0.0851 - val_loss: 0.3869 - val_mae: 0.1224\n",
            "Epoch 622/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1010 - mae: 0.0829 - val_loss: 0.3830 - val_mae: 0.1243\n",
            "Epoch 623/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0988 - mae: 0.0818 - val_loss: 0.3893 - val_mae: 0.1228\n",
            "Epoch 624/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0886 - mae: 0.0809 - val_loss: 0.3882 - val_mae: 0.1211\n",
            "Epoch 625/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1398 - mae: 0.0951 - val_loss: 0.3881 - val_mae: 0.1238\n",
            "Epoch 626/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1466 - mae: 0.1024 - val_loss: 0.3889 - val_mae: 0.1216\n",
            "Epoch 627/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1395 - mae: 0.0925 - val_loss: 0.3915 - val_mae: 0.1242\n",
            "Epoch 628/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1008 - mae: 0.0842 - val_loss: 0.3910 - val_mae: 0.1256\n",
            "Epoch 629/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1058 - mae: 0.0868 - val_loss: 0.3858 - val_mae: 0.1236\n",
            "Epoch 630/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1313 - mae: 0.0971 - val_loss: 0.3882 - val_mae: 0.1234\n",
            "Epoch 631/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1746 - mae: 0.1058 - val_loss: 0.3935 - val_mae: 0.1217\n",
            "Epoch 632/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1335 - mae: 0.0895 - val_loss: 0.3917 - val_mae: 0.1213\n",
            "Epoch 633/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0946 - mae: 0.0820 - val_loss: 0.3933 - val_mae: 0.1265\n",
            "Epoch 634/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0943 - mae: 0.0842 - val_loss: 0.3864 - val_mae: 0.1304\n",
            "Epoch 635/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0985 - mae: 0.0889 - val_loss: 0.3814 - val_mae: 0.1247\n",
            "Epoch 636/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1075 - mae: 0.0889 - val_loss: 0.4021 - val_mae: 0.1265\n",
            "Epoch 637/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0926 - mae: 0.0796 - val_loss: 0.3778 - val_mae: 0.1323\n",
            "Epoch 638/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0918 - mae: 0.0944 - val_loss: 0.3826 - val_mae: 0.1333\n",
            "Epoch 639/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0983 - mae: 0.0900 - val_loss: 0.3945 - val_mae: 0.1354\n",
            "Epoch 640/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1359 - mae: 0.1052 - val_loss: 0.3912 - val_mae: 0.1240\n",
            "Epoch 641/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0714 - mae: 0.0809 - val_loss: 0.3866 - val_mae: 0.1274\n",
            "Epoch 642/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0825 - mae: 0.0827 - val_loss: 0.3865 - val_mae: 0.1264\n",
            "Epoch 643/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0723 - mae: 0.0749 - val_loss: 0.3858 - val_mae: 0.1235\n",
            "Epoch 644/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1132 - mae: 0.0956 - val_loss: 0.3850 - val_mae: 0.1243\n",
            "Epoch 645/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0863 - mae: 0.0812 - val_loss: 0.3884 - val_mae: 0.1237\n",
            "Epoch 646/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1149 - mae: 0.0915 - val_loss: 0.3866 - val_mae: 0.1253\n",
            "Epoch 647/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1168 - mae: 0.0860 - val_loss: 0.3905 - val_mae: 0.1211\n",
            "Epoch 648/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1294 - mae: 0.0921 - val_loss: 0.3893 - val_mae: 0.1237\n",
            "Epoch 649/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1173 - mae: 0.0930 - val_loss: 0.3872 - val_mae: 0.1231\n",
            "Epoch 650/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1041 - mae: 0.0839 - val_loss: 0.3872 - val_mae: 0.1234\n",
            "Epoch 651/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0958 - mae: 0.0850 - val_loss: 0.3836 - val_mae: 0.1225\n",
            "Epoch 652/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1309 - mae: 0.0901 - val_loss: 0.3890 - val_mae: 0.1211\n",
            "Epoch 653/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1004 - mae: 0.0828 - val_loss: 0.3897 - val_mae: 0.1219\n",
            "Epoch 654/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0746 - mae: 0.0785 - val_loss: 0.3876 - val_mae: 0.1206\n",
            "Epoch 655/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0653 - mae: 0.0691 - val_loss: 0.3862 - val_mae: 0.1232\n",
            "Epoch 656/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1343 - mae: 0.0885 - val_loss: 0.3887 - val_mae: 0.1237\n",
            "Epoch 657/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0933 - mae: 0.0861 - val_loss: 0.3865 - val_mae: 0.1210\n",
            "Epoch 658/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1270 - mae: 0.0978 - val_loss: 0.3890 - val_mae: 0.1230\n",
            "Epoch 659/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0797 - mae: 0.0731 - val_loss: 0.3894 - val_mae: 0.1222\n",
            "Epoch 660/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1081 - mae: 0.0857 - val_loss: 0.3852 - val_mae: 0.1235\n",
            "Epoch 661/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1026 - mae: 0.0891 - val_loss: 0.3909 - val_mae: 0.1253\n",
            "Epoch 662/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1144 - mae: 0.0874 - val_loss: 0.3873 - val_mae: 0.1231\n",
            "Epoch 663/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1289 - mae: 0.0871 - val_loss: 0.3915 - val_mae: 0.1208\n",
            "Epoch 664/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1092 - mae: 0.0914 - val_loss: 0.3892 - val_mae: 0.1256\n",
            "Epoch 665/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1060 - mae: 0.0851 - val_loss: 0.3894 - val_mae: 0.1229\n",
            "Epoch 666/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1206 - mae: 0.0895 - val_loss: 0.3888 - val_mae: 0.1214\n",
            "Epoch 667/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1409 - mae: 0.0964 - val_loss: 0.3916 - val_mae: 0.1215\n",
            "Epoch 668/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1042 - mae: 0.0828 - val_loss: 0.3882 - val_mae: 0.1220\n",
            "Epoch 669/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1101 - mae: 0.0933 - val_loss: 0.3905 - val_mae: 0.1225\n",
            "Epoch 670/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0956 - mae: 0.0831 - val_loss: 0.3910 - val_mae: 0.1228\n",
            "Epoch 671/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0855 - mae: 0.0827 - val_loss: 0.3881 - val_mae: 0.1217\n",
            "Epoch 672/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1097 - mae: 0.0889 - val_loss: 0.3877 - val_mae: 0.1248\n",
            "Epoch 673/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1119 - mae: 0.0915 - val_loss: 0.3880 - val_mae: 0.1221\n",
            "Epoch 674/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1181 - mae: 0.0912 - val_loss: 0.3872 - val_mae: 0.1244\n",
            "Epoch 675/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0888 - mae: 0.0812 - val_loss: 0.3875 - val_mae: 0.1232\n",
            "Epoch 676/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1173 - mae: 0.0867 - val_loss: 0.3914 - val_mae: 0.1272\n",
            "Epoch 677/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1066 - mae: 0.0876 - val_loss: 0.3870 - val_mae: 0.1230\n",
            "Epoch 678/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0930 - mae: 0.0800 - val_loss: 0.3912 - val_mae: 0.1222\n",
            "Epoch 679/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0868 - mae: 0.0821 - val_loss: 0.3869 - val_mae: 0.1216\n",
            "Epoch 680/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0925 - mae: 0.0866 - val_loss: 0.3867 - val_mae: 0.1204\n",
            "Epoch 681/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1251 - mae: 0.0940 - val_loss: 0.3870 - val_mae: 0.1232\n",
            "Epoch 682/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1319 - mae: 0.0862 - val_loss: 0.3958 - val_mae: 0.1198\n",
            "Epoch 683/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0781 - mae: 0.0755 - val_loss: 0.3860 - val_mae: 0.1260\n",
            "Epoch 684/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1372 - mae: 0.1008 - val_loss: 0.3874 - val_mae: 0.1219\n",
            "Epoch 685/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1555 - mae: 0.0944 - val_loss: 0.3967 - val_mae: 0.1225\n",
            "Epoch 686/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0789 - mae: 0.0781 - val_loss: 0.3861 - val_mae: 0.1235\n",
            "Epoch 687/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0876 - mae: 0.0887 - val_loss: 0.3845 - val_mae: 0.1280\n",
            "Epoch 688/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0877 - mae: 0.0852 - val_loss: 0.3905 - val_mae: 0.1239\n",
            "Epoch 689/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0746 - mae: 0.0759 - val_loss: 0.3864 - val_mae: 0.1226\n",
            "Epoch 690/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1131 - mae: 0.0920 - val_loss: 0.3921 - val_mae: 0.1226\n",
            "Epoch 691/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1344 - mae: 0.0908 - val_loss: 0.3923 - val_mae: 0.1236\n",
            "Epoch 692/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0952 - mae: 0.0825 - val_loss: 0.3833 - val_mae: 0.1255\n",
            "Epoch 693/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1169 - mae: 0.0919 - val_loss: 0.3836 - val_mae: 0.1229\n",
            "Epoch 694/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1251 - mae: 0.0921 - val_loss: 0.3872 - val_mae: 0.1223\n",
            "Epoch 695/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1126 - mae: 0.0880 - val_loss: 0.3867 - val_mae: 0.1214\n",
            "Epoch 696/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0913 - mae: 0.0836 - val_loss: 0.3901 - val_mae: 0.1235\n",
            "Epoch 697/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1262 - mae: 0.0964 - val_loss: 0.3873 - val_mae: 0.1256\n",
            "Epoch 698/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1477 - mae: 0.0928 - val_loss: 0.3915 - val_mae: 0.1232\n",
            "Epoch 699/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1303 - mae: 0.0928 - val_loss: 0.3873 - val_mae: 0.1213\n",
            "Epoch 700/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1282 - mae: 0.0889 - val_loss: 0.3864 - val_mae: 0.1223\n",
            "Epoch 701/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1203 - mae: 0.0860 - val_loss: 0.3861 - val_mae: 0.1201\n",
            "Epoch 702/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0745 - mae: 0.0771 - val_loss: 0.3869 - val_mae: 0.1221\n",
            "Epoch 703/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1119 - mae: 0.0883 - val_loss: 0.3873 - val_mae: 0.1224\n",
            "Epoch 704/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1312 - mae: 0.0905 - val_loss: 0.3878 - val_mae: 0.1212\n",
            "Epoch 705/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1172 - mae: 0.0919 - val_loss: 0.3872 - val_mae: 0.1217\n",
            "Epoch 706/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1026 - mae: 0.0781 - val_loss: 0.3889 - val_mae: 0.1210\n",
            "Epoch 707/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1134 - mae: 0.0874 - val_loss: 0.3898 - val_mae: 0.1225\n",
            "Epoch 708/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1249 - mae: 0.0933 - val_loss: 0.3911 - val_mae: 0.1226\n",
            "Epoch 709/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1005 - mae: 0.0859 - val_loss: 0.3901 - val_mae: 0.1207\n",
            "Epoch 710/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1068 - mae: 0.0866 - val_loss: 0.3892 - val_mae: 0.1231\n",
            "Epoch 711/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1277 - mae: 0.0959 - val_loss: 0.3920 - val_mae: 0.1217\n",
            "Epoch 712/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1375 - mae: 0.1006 - val_loss: 0.3834 - val_mae: 0.1234\n",
            "Epoch 713/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1427 - mae: 0.0982 - val_loss: 0.3854 - val_mae: 0.1233\n",
            "Epoch 714/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1040 - mae: 0.0872 - val_loss: 0.3846 - val_mae: 0.1214\n",
            "Epoch 715/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0948 - mae: 0.0831 - val_loss: 0.3871 - val_mae: 0.1209\n",
            "Epoch 716/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1008 - mae: 0.0824 - val_loss: 0.3881 - val_mae: 0.1218\n",
            "Epoch 717/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0923 - mae: 0.0868 - val_loss: 0.3856 - val_mae: 0.1241\n",
            "Epoch 718/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1132 - mae: 0.0946 - val_loss: 0.3864 - val_mae: 0.1267\n",
            "Epoch 719/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0686 - mae: 0.0742 - val_loss: 0.3848 - val_mae: 0.1229\n",
            "Epoch 720/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1025 - mae: 0.0870 - val_loss: 0.3897 - val_mae: 0.1240\n",
            "Epoch 721/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0957 - mae: 0.0868 - val_loss: 0.3845 - val_mae: 0.1228\n",
            "Epoch 722/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1382 - mae: 0.0873 - val_loss: 0.3914 - val_mae: 0.1231\n",
            "Epoch 723/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1382 - mae: 0.0963 - val_loss: 0.3917 - val_mae: 0.1205\n",
            "Epoch 724/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1153 - mae: 0.0847 - val_loss: 0.3844 - val_mae: 0.1202\n",
            "Epoch 725/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0911 - mae: 0.0820 - val_loss: 0.3855 - val_mae: 0.1195\n",
            "Epoch 726/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1394 - mae: 0.0920 - val_loss: 0.3838 - val_mae: 0.1250\n",
            "Epoch 727/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0941 - mae: 0.0853 - val_loss: 0.3901 - val_mae: 0.1227\n",
            "Epoch 728/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0946 - mae: 0.0887 - val_loss: 0.3873 - val_mae: 0.1213\n",
            "Epoch 729/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1113 - mae: 0.0845 - val_loss: 0.3884 - val_mae: 0.1226\n",
            "Epoch 730/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1221 - mae: 0.0919 - val_loss: 0.3899 - val_mae: 0.1233\n",
            "Epoch 731/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1101 - mae: 0.0873 - val_loss: 0.3892 - val_mae: 0.1232\n",
            "Epoch 732/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1043 - mae: 0.0917 - val_loss: 0.3854 - val_mae: 0.1244\n",
            "Epoch 733/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1005 - mae: 0.0887 - val_loss: 0.3838 - val_mae: 0.1216\n",
            "Epoch 734/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1457 - mae: 0.0975 - val_loss: 0.3883 - val_mae: 0.1220\n",
            "Epoch 735/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1201 - mae: 0.0874 - val_loss: 0.3907 - val_mae: 0.1215\n",
            "Epoch 736/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1386 - mae: 0.0942 - val_loss: 0.3868 - val_mae: 0.1238\n",
            "Epoch 737/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0917 - mae: 0.0888 - val_loss: 0.3893 - val_mae: 0.1219\n",
            "Epoch 738/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0989 - mae: 0.0869 - val_loss: 0.3842 - val_mae: 0.1209\n",
            "Epoch 739/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0714 - mae: 0.0757 - val_loss: 0.3932 - val_mae: 0.1209\n",
            "Epoch 740/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1168 - mae: 0.0899 - val_loss: 0.3921 - val_mae: 0.1243\n",
            "Epoch 741/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1426 - mae: 0.0948 - val_loss: 0.3846 - val_mae: 0.1270\n",
            "Epoch 742/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0917 - mae: 0.0883 - val_loss: 0.4038 - val_mae: 0.1355\n",
            "Epoch 743/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1245 - mae: 0.0951 - val_loss: 0.3799 - val_mae: 0.1251\n",
            "Epoch 744/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1423 - mae: 0.0987 - val_loss: 0.3931 - val_mae: 0.1259\n",
            "Epoch 745/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1375 - mae: 0.0947 - val_loss: 0.3830 - val_mae: 0.1246\n",
            "Epoch 746/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0979 - mae: 0.0824 - val_loss: 0.3886 - val_mae: 0.1211\n",
            "Epoch 747/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1219 - mae: 0.0910 - val_loss: 0.3837 - val_mae: 0.1230\n",
            "Epoch 748/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1028 - mae: 0.0882 - val_loss: 0.3866 - val_mae: 0.1211\n",
            "Epoch 749/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1718 - mae: 0.1005 - val_loss: 0.3864 - val_mae: 0.1212\n",
            "Epoch 750/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0955 - mae: 0.0828 - val_loss: 0.3879 - val_mae: 0.1203\n",
            "Epoch 751/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0745 - mae: 0.0737 - val_loss: 0.3880 - val_mae: 0.1208\n",
            "Epoch 752/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0809 - mae: 0.0798 - val_loss: 0.3854 - val_mae: 0.1218\n",
            "Epoch 753/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1346 - mae: 0.0963 - val_loss: 0.3898 - val_mae: 0.1227\n",
            "Epoch 754/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1051 - mae: 0.0849 - val_loss: 0.3874 - val_mae: 0.1202\n",
            "Epoch 755/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0942 - mae: 0.0810 - val_loss: 0.3846 - val_mae: 0.1256\n",
            "Epoch 756/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0919 - mae: 0.0828 - val_loss: 0.3853 - val_mae: 0.1227\n",
            "Epoch 757/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1213 - mae: 0.0900 - val_loss: 0.3937 - val_mae: 0.1215\n",
            "Epoch 758/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0865 - mae: 0.0788 - val_loss: 0.3832 - val_mae: 0.1217\n",
            "Epoch 759/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0968 - mae: 0.0890 - val_loss: 0.3880 - val_mae: 0.1236\n",
            "Epoch 760/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0864 - mae: 0.0795 - val_loss: 0.3839 - val_mae: 0.1240\n",
            "Epoch 761/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1470 - mae: 0.1000 - val_loss: 0.3951 - val_mae: 0.1217\n",
            "Epoch 762/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1083 - mae: 0.0869 - val_loss: 0.3898 - val_mae: 0.1198\n",
            "Epoch 763/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0922 - mae: 0.0879 - val_loss: 0.3903 - val_mae: 0.1220\n",
            "Epoch 764/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0966 - mae: 0.0810 - val_loss: 0.3859 - val_mae: 0.1237\n",
            "Epoch 765/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0895 - mae: 0.0901 - val_loss: 0.3889 - val_mae: 0.1214\n",
            "Epoch 766/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0995 - mae: 0.0848 - val_loss: 0.3878 - val_mae: 0.1231\n",
            "Epoch 767/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1166 - mae: 0.0890 - val_loss: 0.3854 - val_mae: 0.1213\n",
            "Epoch 768/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0756 - mae: 0.0781 - val_loss: 0.3925 - val_mae: 0.1217\n",
            "Epoch 769/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1186 - mae: 0.0916 - val_loss: 0.3873 - val_mae: 0.1230\n",
            "Epoch 770/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1494 - mae: 0.0999 - val_loss: 0.3868 - val_mae: 0.1229\n",
            "Epoch 771/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1334 - mae: 0.0915 - val_loss: 0.3907 - val_mae: 0.1211\n",
            "Epoch 772/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1186 - mae: 0.0880 - val_loss: 0.3927 - val_mae: 0.1217\n",
            "Epoch 773/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0944 - mae: 0.0851 - val_loss: 0.3856 - val_mae: 0.1212\n",
            "Epoch 774/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0932 - mae: 0.0808 - val_loss: 0.3873 - val_mae: 0.1212\n",
            "Epoch 775/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1009 - mae: 0.0854 - val_loss: 0.3897 - val_mae: 0.1221\n",
            "Epoch 776/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1150 - mae: 0.0913 - val_loss: 0.3821 - val_mae: 0.1221\n",
            "Epoch 777/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0809 - mae: 0.0745 - val_loss: 0.3910 - val_mae: 0.1215\n",
            "Epoch 778/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1187 - mae: 0.0849 - val_loss: 0.3864 - val_mae: 0.1211\n",
            "Epoch 779/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1139 - mae: 0.0896 - val_loss: 0.3912 - val_mae: 0.1278\n",
            "Epoch 780/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1170 - mae: 0.0974 - val_loss: 0.3903 - val_mae: 0.1210\n",
            "Epoch 781/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1365 - mae: 0.0946 - val_loss: 0.3891 - val_mae: 0.1220\n",
            "Epoch 782/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0920 - mae: 0.0822 - val_loss: 0.3829 - val_mae: 0.1220\n",
            "Epoch 783/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1198 - mae: 0.0837 - val_loss: 0.3885 - val_mae: 0.1219\n",
            "Epoch 784/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1026 - mae: 0.0856 - val_loss: 0.3867 - val_mae: 0.1245\n",
            "Epoch 785/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1205 - mae: 0.0963 - val_loss: 0.3905 - val_mae: 0.1235\n",
            "Epoch 786/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1429 - mae: 0.0981 - val_loss: 0.3900 - val_mae: 0.1243\n",
            "Epoch 787/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1514 - mae: 0.0975 - val_loss: 0.3922 - val_mae: 0.1215\n",
            "Epoch 788/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0874 - mae: 0.0849 - val_loss: 0.3869 - val_mae: 0.1212\n",
            "Epoch 789/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0673 - mae: 0.0697 - val_loss: 0.3891 - val_mae: 0.1219\n",
            "Epoch 790/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0894 - mae: 0.0781 - val_loss: 0.3875 - val_mae: 0.1208\n",
            "Epoch 791/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0902 - mae: 0.0831 - val_loss: 0.3866 - val_mae: 0.1209\n",
            "Epoch 792/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0846 - mae: 0.0803 - val_loss: 0.3868 - val_mae: 0.1216\n",
            "Epoch 793/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0829 - mae: 0.0759 - val_loss: 0.3902 - val_mae: 0.1215\n",
            "Epoch 794/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1347 - mae: 0.0895 - val_loss: 0.3861 - val_mae: 0.1226\n",
            "Epoch 795/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1127 - mae: 0.0894 - val_loss: 0.3911 - val_mae: 0.1244\n",
            "Epoch 796/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1255 - mae: 0.0947 - val_loss: 0.3946 - val_mae: 0.1399\n",
            "Epoch 797/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0914 - mae: 0.0925 - val_loss: 0.3871 - val_mae: 0.1237\n",
            "Epoch 798/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1004 - mae: 0.0819 - val_loss: 0.3891 - val_mae: 0.1224\n",
            "Epoch 799/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0948 - mae: 0.0800 - val_loss: 0.3879 - val_mae: 0.1219\n",
            "Epoch 800/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0819 - mae: 0.0765 - val_loss: 0.3902 - val_mae: 0.1195\n",
            "Epoch 801/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0913 - mae: 0.0837 - val_loss: 0.3853 - val_mae: 0.1221\n",
            "Epoch 802/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1071 - mae: 0.0895 - val_loss: 0.3892 - val_mae: 0.1208\n",
            "Epoch 803/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1485 - mae: 0.0916 - val_loss: 0.3886 - val_mae: 0.1220\n",
            "Epoch 804/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0997 - mae: 0.0789 - val_loss: 0.3924 - val_mae: 0.1201\n",
            "Epoch 805/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0841 - mae: 0.0771 - val_loss: 0.3855 - val_mae: 0.1207\n",
            "Epoch 806/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0964 - mae: 0.0833 - val_loss: 0.3873 - val_mae: 0.1207\n",
            "Epoch 807/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0770 - mae: 0.0749 - val_loss: 0.3883 - val_mae: 0.1215\n",
            "Epoch 808/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1099 - mae: 0.0913 - val_loss: 0.3893 - val_mae: 0.1211\n",
            "Epoch 809/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0865 - mae: 0.0799 - val_loss: 0.3892 - val_mae: 0.1219\n",
            "Epoch 810/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1011 - mae: 0.0874 - val_loss: 0.3848 - val_mae: 0.1218\n",
            "Epoch 811/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1009 - mae: 0.0813 - val_loss: 0.3889 - val_mae: 0.1204\n",
            "Epoch 812/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1290 - mae: 0.0907 - val_loss: 0.3886 - val_mae: 0.1228\n",
            "Epoch 813/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0759 - mae: 0.0775 - val_loss: 0.3889 - val_mae: 0.1206\n",
            "Epoch 814/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1099 - mae: 0.0878 - val_loss: 0.3920 - val_mae: 0.1236\n",
            "Epoch 815/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1312 - mae: 0.0942 - val_loss: 0.3848 - val_mae: 0.1217\n",
            "Epoch 816/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0938 - mae: 0.0838 - val_loss: 0.3906 - val_mae: 0.1221\n",
            "Epoch 817/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1031 - mae: 0.0878 - val_loss: 0.3862 - val_mae: 0.1215\n",
            "Epoch 818/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0963 - mae: 0.0822 - val_loss: 0.3874 - val_mae: 0.1204\n",
            "Epoch 819/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0830 - mae: 0.0740 - val_loss: 0.3880 - val_mae: 0.1217\n",
            "Epoch 820/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1060 - mae: 0.0856 - val_loss: 0.3868 - val_mae: 0.1211\n",
            "Epoch 821/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0862 - mae: 0.0800 - val_loss: 0.3911 - val_mae: 0.1224\n",
            "Epoch 822/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1237 - mae: 0.0901 - val_loss: 0.3863 - val_mae: 0.1211\n",
            "Epoch 823/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1426 - mae: 0.0966 - val_loss: 0.3896 - val_mae: 0.1224\n",
            "Epoch 824/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0834 - mae: 0.0795 - val_loss: 0.3893 - val_mae: 0.1215\n",
            "Epoch 825/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1048 - mae: 0.0838 - val_loss: 0.3866 - val_mae: 0.1229\n",
            "Epoch 826/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1155 - mae: 0.0918 - val_loss: 0.3958 - val_mae: 0.1275\n",
            "Epoch 827/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0917 - mae: 0.0878 - val_loss: 0.3932 - val_mae: 0.1279\n",
            "Epoch 828/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1128 - mae: 0.0995 - val_loss: 0.3862 - val_mae: 0.1423\n",
            "Epoch 829/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1431 - mae: 0.1055 - val_loss: 0.3983 - val_mae: 0.1454\n",
            "Epoch 830/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1054 - mae: 0.0973 - val_loss: 0.3877 - val_mae: 0.1281\n",
            "Epoch 831/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1100 - mae: 0.1013 - val_loss: 0.3858 - val_mae: 0.1290\n",
            "Epoch 832/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0941 - mae: 0.0854 - val_loss: 0.3872 - val_mae: 0.1279\n",
            "Epoch 833/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0909 - mae: 0.0849 - val_loss: 0.3899 - val_mae: 0.1310\n",
            "Epoch 834/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1012 - mae: 0.0893 - val_loss: 0.3887 - val_mae: 0.1262\n",
            "Epoch 835/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1024 - mae: 0.0885 - val_loss: 0.3861 - val_mae: 0.1248\n",
            "Epoch 836/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1200 - mae: 0.0881 - val_loss: 0.3881 - val_mae: 0.1209\n",
            "Epoch 837/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1230 - mae: 0.0877 - val_loss: 0.3879 - val_mae: 0.1209\n",
            "Epoch 838/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1281 - mae: 0.0903 - val_loss: 0.3848 - val_mae: 0.1211\n",
            "Epoch 839/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0810 - mae: 0.0793 - val_loss: 0.3904 - val_mae: 0.1195\n",
            "Epoch 840/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0814 - mae: 0.0784 - val_loss: 0.3850 - val_mae: 0.1217\n",
            "Epoch 841/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1012 - mae: 0.0817 - val_loss: 0.3840 - val_mae: 0.1238\n",
            "Epoch 842/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1008 - mae: 0.0889 - val_loss: 0.3899 - val_mae: 0.1212\n",
            "Epoch 843/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1393 - mae: 0.0926 - val_loss: 0.3862 - val_mae: 0.1218\n",
            "Epoch 844/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0776 - mae: 0.0795 - val_loss: 0.3887 - val_mae: 0.1192\n",
            "Epoch 845/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0937 - mae: 0.0833 - val_loss: 0.3849 - val_mae: 0.1228\n",
            "Epoch 846/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1310 - mae: 0.0902 - val_loss: 0.3864 - val_mae: 0.1205\n",
            "Epoch 847/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0889 - mae: 0.0816 - val_loss: 0.3898 - val_mae: 0.1200\n",
            "Epoch 848/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0765 - mae: 0.0789 - val_loss: 0.3868 - val_mae: 0.1201\n",
            "Epoch 849/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1240 - mae: 0.0859 - val_loss: 0.3861 - val_mae: 0.1226\n",
            "Epoch 850/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0996 - mae: 0.0875 - val_loss: 0.3921 - val_mae: 0.1218\n",
            "Epoch 851/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1062 - mae: 0.0880 - val_loss: 0.3849 - val_mae: 0.1231\n",
            "Epoch 852/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1190 - mae: 0.0925 - val_loss: 0.3868 - val_mae: 0.1198\n",
            "Epoch 853/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1068 - mae: 0.0872 - val_loss: 0.3869 - val_mae: 0.1200\n",
            "Epoch 854/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0955 - mae: 0.0872 - val_loss: 0.3877 - val_mae: 0.1219\n",
            "Epoch 855/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0711 - mae: 0.0735 - val_loss: 0.3845 - val_mae: 0.1206\n",
            "Epoch 856/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1223 - mae: 0.0824 - val_loss: 0.3884 - val_mae: 0.1210\n",
            "Epoch 857/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1359 - mae: 0.0881 - val_loss: 0.3925 - val_mae: 0.1194\n",
            "Epoch 858/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0891 - mae: 0.0788 - val_loss: 0.3868 - val_mae: 0.1227\n",
            "Epoch 859/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0941 - mae: 0.0828 - val_loss: 0.3841 - val_mae: 0.1227\n",
            "Epoch 860/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1157 - mae: 0.0891 - val_loss: 0.3902 - val_mae: 0.1207\n",
            "Epoch 861/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1604 - mae: 0.0950 - val_loss: 0.3891 - val_mae: 0.1218\n",
            "Epoch 862/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1165 - mae: 0.0859 - val_loss: 0.3847 - val_mae: 0.1205\n",
            "Epoch 863/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0832 - mae: 0.0778 - val_loss: 0.3854 - val_mae: 0.1199\n",
            "Epoch 864/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0807 - mae: 0.0795 - val_loss: 0.3917 - val_mae: 0.1191\n",
            "Epoch 865/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1414 - mae: 0.0944 - val_loss: 0.3848 - val_mae: 0.1238\n",
            "Epoch 866/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1235 - mae: 0.0959 - val_loss: 0.3867 - val_mae: 0.1208\n",
            "Epoch 867/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1225 - mae: 0.0873 - val_loss: 0.3854 - val_mae: 0.1206\n",
            "Epoch 868/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0943 - mae: 0.0849 - val_loss: 0.3923 - val_mae: 0.1195\n",
            "Epoch 869/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0885 - mae: 0.0814 - val_loss: 0.3872 - val_mae: 0.1204\n",
            "Epoch 870/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0871 - mae: 0.0794 - val_loss: 0.3864 - val_mae: 0.1247\n",
            "Epoch 871/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0922 - mae: 0.0831 - val_loss: 0.3859 - val_mae: 0.1212\n",
            "Epoch 872/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0883 - mae: 0.0845 - val_loss: 0.3858 - val_mae: 0.1220\n",
            "Epoch 873/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1278 - mae: 0.0890 - val_loss: 0.3907 - val_mae: 0.1213\n",
            "Epoch 874/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1049 - mae: 0.0794 - val_loss: 0.3926 - val_mae: 0.1206\n",
            "Epoch 875/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1221 - mae: 0.0956 - val_loss: 0.3892 - val_mae: 0.1224\n",
            "Epoch 876/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0969 - mae: 0.0809 - val_loss: 0.3867 - val_mae: 0.1213\n",
            "Epoch 877/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0901 - mae: 0.0826 - val_loss: 0.3907 - val_mae: 0.1189\n",
            "Epoch 878/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0982 - mae: 0.0867 - val_loss: 0.3837 - val_mae: 0.1214\n",
            "Epoch 879/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1050 - mae: 0.0881 - val_loss: 0.3848 - val_mae: 0.1205\n",
            "Epoch 880/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0890 - mae: 0.0805 - val_loss: 0.3911 - val_mae: 0.1202\n",
            "Epoch 881/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1090 - mae: 0.0903 - val_loss: 0.3864 - val_mae: 0.1198\n",
            "Epoch 882/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1184 - mae: 0.0900 - val_loss: 0.3870 - val_mae: 0.1216\n",
            "Epoch 883/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0874 - mae: 0.0807 - val_loss: 0.3878 - val_mae: 0.1213\n",
            "Epoch 884/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1232 - mae: 0.0873 - val_loss: 0.3893 - val_mae: 0.1213\n",
            "Epoch 885/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0984 - mae: 0.0814 - val_loss: 0.3907 - val_mae: 0.1206\n",
            "Epoch 886/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1166 - mae: 0.0916 - val_loss: 0.3864 - val_mae: 0.1230\n",
            "Epoch 887/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0990 - mae: 0.0867 - val_loss: 0.3919 - val_mae: 0.1207\n",
            "Epoch 888/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1256 - mae: 0.0836 - val_loss: 0.3883 - val_mae: 0.1237\n",
            "Epoch 889/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1185 - mae: 0.0880 - val_loss: 0.3901 - val_mae: 0.1212\n",
            "Epoch 890/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1090 - mae: 0.0891 - val_loss: 0.3886 - val_mae: 0.1218\n",
            "Epoch 891/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0948 - mae: 0.0868 - val_loss: 0.3890 - val_mae: 0.1199\n",
            "Epoch 892/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1261 - mae: 0.0889 - val_loss: 0.3893 - val_mae: 0.1241\n",
            "Epoch 893/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0808 - mae: 0.0805 - val_loss: 0.3885 - val_mae: 0.1208\n",
            "Epoch 894/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1059 - mae: 0.0833 - val_loss: 0.3866 - val_mae: 0.1215\n",
            "Epoch 895/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0869 - mae: 0.0815 - val_loss: 0.3881 - val_mae: 0.1214\n",
            "Epoch 896/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0891 - mae: 0.0787 - val_loss: 0.3877 - val_mae: 0.1202\n",
            "Epoch 897/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0877 - mae: 0.0769 - val_loss: 0.3869 - val_mae: 0.1204\n",
            "Epoch 898/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1245 - mae: 0.0861 - val_loss: 0.3845 - val_mae: 0.1211\n",
            "Epoch 899/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0874 - mae: 0.0785 - val_loss: 0.3899 - val_mae: 0.1202\n",
            "Epoch 900/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1110 - mae: 0.0814 - val_loss: 0.3881 - val_mae: 0.1209\n",
            "Epoch 901/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0781 - mae: 0.0736 - val_loss: 0.3893 - val_mae: 0.1211\n",
            "Epoch 902/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1017 - mae: 0.0906 - val_loss: 0.3847 - val_mae: 0.1221\n",
            "Epoch 903/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0941 - mae: 0.0865 - val_loss: 0.3866 - val_mae: 0.1215\n",
            "Epoch 904/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1499 - mae: 0.0977 - val_loss: 0.3870 - val_mae: 0.1222\n",
            "Epoch 905/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1318 - mae: 0.0894 - val_loss: 0.3878 - val_mae: 0.1210\n",
            "Epoch 906/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1047 - mae: 0.0837 - val_loss: 0.3940 - val_mae: 0.1184\n",
            "Epoch 907/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0984 - mae: 0.0831 - val_loss: 0.3895 - val_mae: 0.1211\n",
            "Epoch 908/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1029 - mae: 0.0866 - val_loss: 0.3880 - val_mae: 0.1225\n",
            "Epoch 909/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1357 - mae: 0.0952 - val_loss: 0.3899 - val_mae: 0.1216\n",
            "Epoch 910/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1277 - mae: 0.0918 - val_loss: 0.3866 - val_mae: 0.1198\n",
            "Epoch 911/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1518 - mae: 0.0956 - val_loss: 0.3912 - val_mae: 0.1240\n",
            "Epoch 912/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1014 - mae: 0.0836 - val_loss: 0.3937 - val_mae: 0.1196\n",
            "Epoch 913/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1242 - mae: 0.0896 - val_loss: 0.3879 - val_mae: 0.1227\n",
            "Epoch 914/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.0837 - val_loss: 0.3925 - val_mae: 0.1216\n",
            "Epoch 915/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1037 - mae: 0.0865 - val_loss: 0.3816 - val_mae: 0.1266\n",
            "Epoch 916/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0972 - mae: 0.0894 - val_loss: 0.3891 - val_mae: 0.1224\n",
            "Epoch 917/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0806 - mae: 0.0770 - val_loss: 0.3850 - val_mae: 0.1216\n",
            "Epoch 918/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1063 - mae: 0.0850 - val_loss: 0.3861 - val_mae: 0.1205\n",
            "Epoch 919/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1231 - mae: 0.0956 - val_loss: 0.3887 - val_mae: 0.1212\n",
            "Epoch 920/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1311 - mae: 0.0899 - val_loss: 0.3932 - val_mae: 0.1206\n",
            "Epoch 921/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0890 - mae: 0.0795 - val_loss: 0.3898 - val_mae: 0.1210\n",
            "Epoch 922/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1059 - mae: 0.0907 - val_loss: 0.3855 - val_mae: 0.1220\n",
            "Epoch 923/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0835 - mae: 0.0787 - val_loss: 0.3938 - val_mae: 0.1223\n",
            "Epoch 924/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1187 - mae: 0.0936 - val_loss: 0.3873 - val_mae: 0.1226\n",
            "Epoch 925/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1016 - mae: 0.0876 - val_loss: 0.3848 - val_mae: 0.1223\n",
            "Epoch 926/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1020 - mae: 0.0866 - val_loss: 0.3882 - val_mae: 0.1209\n",
            "Epoch 927/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1031 - mae: 0.0865 - val_loss: 0.3880 - val_mae: 0.1232\n",
            "Epoch 928/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0925 - mae: 0.0882 - val_loss: 0.3879 - val_mae: 0.1224\n",
            "Epoch 929/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1134 - mae: 0.0857 - val_loss: 0.3896 - val_mae: 0.1258\n",
            "Epoch 930/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0782 - mae: 0.0811 - val_loss: 0.3854 - val_mae: 0.1247\n",
            "Epoch 931/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1060 - mae: 0.0947 - val_loss: 0.3871 - val_mae: 0.1208\n",
            "Epoch 932/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1379 - mae: 0.0909 - val_loss: 0.3902 - val_mae: 0.1209\n",
            "Epoch 933/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1179 - mae: 0.0896 - val_loss: 0.3886 - val_mae: 0.1202\n",
            "Epoch 934/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1268 - mae: 0.0934 - val_loss: 0.3836 - val_mae: 0.1219\n",
            "Epoch 935/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1234 - mae: 0.0941 - val_loss: 0.3895 - val_mae: 0.1196\n",
            "Epoch 936/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1285 - mae: 0.0899 - val_loss: 0.3897 - val_mae: 0.1206\n",
            "Epoch 937/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1262 - mae: 0.0867 - val_loss: 0.3910 - val_mae: 0.1203\n",
            "Epoch 938/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0697 - mae: 0.0749 - val_loss: 0.3892 - val_mae: 0.1207\n",
            "Epoch 939/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0910 - mae: 0.0778 - val_loss: 0.3837 - val_mae: 0.1230\n",
            "Epoch 940/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1363 - mae: 0.0945 - val_loss: 0.3919 - val_mae: 0.1230\n",
            "Epoch 941/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1274 - mae: 0.0916 - val_loss: 0.3862 - val_mae: 0.1228\n",
            "Epoch 942/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0839 - mae: 0.0814 - val_loss: 0.3871 - val_mae: 0.1224\n",
            "Epoch 943/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1074 - mae: 0.0935 - val_loss: 0.3863 - val_mae: 0.1245\n",
            "Epoch 944/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1212 - mae: 0.0939 - val_loss: 0.3848 - val_mae: 0.1211\n",
            "Epoch 945/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0878 - mae: 0.0797 - val_loss: 0.3893 - val_mae: 0.1221\n",
            "Epoch 946/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0854 - mae: 0.0824 - val_loss: 0.3905 - val_mae: 0.1208\n",
            "Epoch 947/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.1140 - mae: 0.0870 - val_loss: 0.3864 - val_mae: 0.1213\n",
            "Epoch 948/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1322 - mae: 0.0888 - val_loss: 0.3912 - val_mae: 0.1202\n",
            "Epoch 949/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1029 - mae: 0.0862 - val_loss: 0.3876 - val_mae: 0.1217\n",
            "Epoch 950/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1098 - mae: 0.0858 - val_loss: 0.3897 - val_mae: 0.1208\n",
            "Epoch 951/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1009 - mae: 0.0817 - val_loss: 0.3869 - val_mae: 0.1204\n",
            "Epoch 952/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0729 - mae: 0.0743 - val_loss: 0.3894 - val_mae: 0.1202\n",
            "Epoch 953/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0812 - mae: 0.0777 - val_loss: 0.3854 - val_mae: 0.1225\n",
            "Epoch 954/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1060 - mae: 0.0868 - val_loss: 0.3892 - val_mae: 0.1208\n",
            "Epoch 955/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1112 - mae: 0.0872 - val_loss: 0.3844 - val_mae: 0.1222\n",
            "Epoch 956/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0994 - mae: 0.0857 - val_loss: 0.3853 - val_mae: 0.1200\n",
            "Epoch 957/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0864 - mae: 0.0750 - val_loss: 0.3877 - val_mae: 0.1213\n",
            "Epoch 958/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1048 - mae: 0.0875 - val_loss: 0.3874 - val_mae: 0.1190\n",
            "Epoch 959/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0912 - mae: 0.0841 - val_loss: 0.3864 - val_mae: 0.1204\n",
            "Epoch 960/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1083 - mae: 0.0895 - val_loss: 0.3838 - val_mae: 0.1207\n",
            "Epoch 961/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0997 - mae: 0.0828 - val_loss: 0.3876 - val_mae: 0.1209\n",
            "Epoch 962/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1135 - mae: 0.0839 - val_loss: 0.3894 - val_mae: 0.1195\n",
            "Epoch 963/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0740 - mae: 0.0720 - val_loss: 0.3891 - val_mae: 0.1195\n",
            "Epoch 964/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0809 - mae: 0.0794 - val_loss: 0.3847 - val_mae: 0.1199\n",
            "Epoch 965/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0858 - mae: 0.0792 - val_loss: 0.3838 - val_mae: 0.1220\n",
            "Epoch 966/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1009 - mae: 0.0820 - val_loss: 0.3857 - val_mae: 0.1214\n",
            "Epoch 967/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1024 - mae: 0.0835 - val_loss: 0.3890 - val_mae: 0.1194\n",
            "Epoch 968/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0801 - mae: 0.0780 - val_loss: 0.3879 - val_mae: 0.1207\n",
            "Epoch 969/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1094 - mae: 0.0880 - val_loss: 0.3873 - val_mae: 0.1208\n",
            "Epoch 970/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0794 - mae: 0.0754 - val_loss: 0.3857 - val_mae: 0.1195\n",
            "Epoch 971/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1138 - mae: 0.0902 - val_loss: 0.3842 - val_mae: 0.1208\n",
            "Epoch 972/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1161 - mae: 0.0923 - val_loss: 0.3893 - val_mae: 0.1216\n",
            "Epoch 973/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0925 - mae: 0.0786 - val_loss: 0.3910 - val_mae: 0.1260\n",
            "Epoch 974/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0828 - mae: 0.0798 - val_loss: 0.3940 - val_mae: 0.1265\n",
            "Epoch 975/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0900 - mae: 0.0875 - val_loss: 0.3851 - val_mae: 0.1249\n",
            "Epoch 976/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1188 - mae: 0.0893 - val_loss: 0.4327 - val_mae: 0.1300\n",
            "Epoch 977/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1330 - mae: 0.1026 - val_loss: 0.4028 - val_mae: 0.1296\n",
            "Epoch 978/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0971 - mae: 0.0926 - val_loss: 0.3908 - val_mae: 0.1352\n",
            "Epoch 979/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1258 - mae: 0.1001 - val_loss: 0.3972 - val_mae: 0.1278\n",
            "Epoch 980/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1470 - mae: 0.0974 - val_loss: 0.3883 - val_mae: 0.1261\n",
            "Epoch 981/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1300 - mae: 0.0953 - val_loss: 0.3919 - val_mae: 0.1204\n",
            "Epoch 982/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1220 - mae: 0.0831 - val_loss: 0.3896 - val_mae: 0.1207\n",
            "Epoch 983/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0887 - mae: 0.0842 - val_loss: 0.3919 - val_mae: 0.1213\n",
            "Epoch 984/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1315 - mae: 0.0936 - val_loss: 0.3870 - val_mae: 0.1236\n",
            "Epoch 985/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1060 - mae: 0.0830 - val_loss: 0.3929 - val_mae: 0.1218\n",
            "Epoch 986/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1113 - mae: 0.0854 - val_loss: 0.3879 - val_mae: 0.1219\n",
            "Epoch 987/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1812 - mae: 0.1101 - val_loss: 0.3888 - val_mae: 0.1216\n",
            "Epoch 988/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1151 - mae: 0.0889 - val_loss: 0.3869 - val_mae: 0.1199\n",
            "Epoch 989/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1396 - mae: 0.0915 - val_loss: 0.3902 - val_mae: 0.1195\n",
            "Epoch 990/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0869 - mae: 0.0780 - val_loss: 0.3848 - val_mae: 0.1204\n",
            "Epoch 991/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1199 - mae: 0.0920 - val_loss: 0.3866 - val_mae: 0.1221\n",
            "Epoch 992/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0994 - mae: 0.0798 - val_loss: 0.3914 - val_mae: 0.1217\n",
            "Epoch 993/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1057 - mae: 0.0877 - val_loss: 0.3845 - val_mae: 0.1221\n",
            "Epoch 994/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1109 - mae: 0.0866 - val_loss: 0.3909 - val_mae: 0.1207\n",
            "Epoch 995/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1176 - mae: 0.0917 - val_loss: 0.3885 - val_mae: 0.1210\n",
            "Epoch 996/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1497 - mae: 0.1016 - val_loss: 0.3871 - val_mae: 0.1208\n",
            "Epoch 997/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0929 - mae: 0.0803 - val_loss: 0.3928 - val_mae: 0.1194\n",
            "Epoch 998/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0792 - mae: 0.0797 - val_loss: 0.3887 - val_mae: 0.1201\n",
            "Epoch 999/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1185 - mae: 0.0857 - val_loss: 0.3860 - val_mae: 0.1211\n",
            "Epoch 1000/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1426 - mae: 0.0973 - val_loss: 0.3872 - val_mae: 0.1200\n",
            "Epoch 1001/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0745 - mae: 0.0738 - val_loss: 0.3880 - val_mae: 0.1199\n",
            "Epoch 1002/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1090 - mae: 0.0914 - val_loss: 0.3875 - val_mae: 0.1230\n",
            "Epoch 1003/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0934 - mae: 0.0793 - val_loss: 0.3871 - val_mae: 0.1209\n",
            "Epoch 1004/2000\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0914 - mae: 0.0817 - val_loss: 0.3874 - val_mae: 0.1208\n",
            "Epoch 1005/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1216 - mae: 0.0870 - val_loss: 0.3867 - val_mae: 0.1230\n",
            "Epoch 1006/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0997 - mae: 0.0816 - val_loss: 0.3940 - val_mae: 0.1195\n",
            "Epoch 1007/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0811 - mae: 0.0778 - val_loss: 0.3887 - val_mae: 0.1195\n",
            "Epoch 1008/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0629 - mae: 0.0713 - val_loss: 0.3857 - val_mae: 0.1201\n",
            "Epoch 1009/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0905 - mae: 0.0792 - val_loss: 0.3847 - val_mae: 0.1223\n",
            "Epoch 1010/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1052 - mae: 0.0864 - val_loss: 0.3892 - val_mae: 0.1206\n",
            "Epoch 1011/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0987 - mae: 0.0780 - val_loss: 0.3908 - val_mae: 0.1195\n",
            "Epoch 1012/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1195 - mae: 0.0866 - val_loss: 0.3866 - val_mae: 0.1203\n",
            "Epoch 1013/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1193 - mae: 0.0875 - val_loss: 0.3879 - val_mae: 0.1211\n",
            "Epoch 1014/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1322 - mae: 0.0880 - val_loss: 0.3885 - val_mae: 0.1205\n",
            "Epoch 1015/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0867 - mae: 0.0837 - val_loss: 0.3909 - val_mae: 0.1197\n",
            "Epoch 1016/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0958 - mae: 0.0832 - val_loss: 0.3864 - val_mae: 0.1215\n",
            "Epoch 1017/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0903 - mae: 0.0791 - val_loss: 0.3870 - val_mae: 0.1207\n",
            "Epoch 1018/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1227 - mae: 0.0891 - val_loss: 0.3859 - val_mae: 0.1216\n",
            "Epoch 1019/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0970 - mae: 0.0849 - val_loss: 0.3932 - val_mae: 0.1230\n",
            "Epoch 1020/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0887 - mae: 0.0837 - val_loss: 0.3882 - val_mae: 0.1245\n",
            "Epoch 1021/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0871 - mae: 0.0799 - val_loss: 0.3914 - val_mae: 0.1242\n",
            "Epoch 1022/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1090 - mae: 0.0910 - val_loss: 0.3872 - val_mae: 0.1219\n",
            "Epoch 1023/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0983 - mae: 0.0809 - val_loss: 0.3865 - val_mae: 0.1204\n",
            "Epoch 1024/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0987 - mae: 0.0870 - val_loss: 0.3877 - val_mae: 0.1195\n",
            "Epoch 1025/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0959 - mae: 0.0803 - val_loss: 0.3853 - val_mae: 0.1213\n",
            "Epoch 1026/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0937 - mae: 0.0818 - val_loss: 0.3906 - val_mae: 0.1204\n",
            "Epoch 1027/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1261 - mae: 0.0799 - val_loss: 0.3887 - val_mae: 0.1193\n",
            "Epoch 1028/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0736 - mae: 0.0711 - val_loss: 0.3899 - val_mae: 0.1200\n",
            "Epoch 1029/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1317 - mae: 0.0899 - val_loss: 0.3860 - val_mae: 0.1209\n",
            "Epoch 1030/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0879 - mae: 0.0819 - val_loss: 0.3848 - val_mae: 0.1199\n",
            "Epoch 1031/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0949 - mae: 0.0820 - val_loss: 0.3903 - val_mae: 0.1200\n",
            "Epoch 1032/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1145 - mae: 0.0933 - val_loss: 0.3869 - val_mae: 0.1216\n",
            "Epoch 1033/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1243 - mae: 0.0857 - val_loss: 0.3870 - val_mae: 0.1210\n",
            "Epoch 1034/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1403 - mae: 0.0935 - val_loss: 0.3916 - val_mae: 0.1196\n",
            "Epoch 1035/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1535 - mae: 0.0930 - val_loss: 0.3901 - val_mae: 0.1191\n",
            "Epoch 1036/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0969 - mae: 0.0846 - val_loss: 0.3882 - val_mae: 0.1210\n",
            "Epoch 1037/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0923 - mae: 0.0835 - val_loss: 0.3878 - val_mae: 0.1218\n",
            "Epoch 1038/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1334 - mae: 0.0961 - val_loss: 0.3878 - val_mae: 0.1212\n",
            "Epoch 1039/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0902 - mae: 0.0830 - val_loss: 0.3900 - val_mae: 0.1200\n",
            "Epoch 1040/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1303 - mae: 0.0890 - val_loss: 0.3872 - val_mae: 0.1201\n",
            "Epoch 1041/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1587 - mae: 0.0965 - val_loss: 0.3895 - val_mae: 0.1203\n",
            "Epoch 1042/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0804 - mae: 0.0800 - val_loss: 0.3928 - val_mae: 0.1199\n",
            "Epoch 1043/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0872 - mae: 0.0831 - val_loss: 0.3866 - val_mae: 0.1199\n",
            "Epoch 1044/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0871 - mae: 0.0837 - val_loss: 0.3848 - val_mae: 0.1225\n",
            "Epoch 1045/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0984 - mae: 0.0805 - val_loss: 0.3915 - val_mae: 0.1206\n",
            "Epoch 1046/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0910 - mae: 0.0821 - val_loss: 0.3863 - val_mae: 0.1199\n",
            "Epoch 1047/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1449 - mae: 0.0956 - val_loss: 0.3852 - val_mae: 0.1216\n",
            "Epoch 1048/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1051 - mae: 0.0858 - val_loss: 0.3899 - val_mae: 0.1214\n",
            "Epoch 1049/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0862 - mae: 0.0783 - val_loss: 0.3865 - val_mae: 0.1211\n",
            "Epoch 1050/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0779 - mae: 0.0797 - val_loss: 0.3865 - val_mae: 0.1193\n",
            "Epoch 1051/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0864 - mae: 0.0776 - val_loss: 0.3861 - val_mae: 0.1205\n",
            "Epoch 1052/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0819 - mae: 0.0769 - val_loss: 0.3840 - val_mae: 0.1230\n",
            "Epoch 1053/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1442 - mae: 0.0971 - val_loss: 0.3897 - val_mae: 0.1212\n",
            "Epoch 1054/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0954 - mae: 0.0803 - val_loss: 0.3895 - val_mae: 0.1208\n",
            "Epoch 1055/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1411 - mae: 0.0980 - val_loss: 0.3866 - val_mae: 0.1201\n",
            "Epoch 1056/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0964 - mae: 0.0822 - val_loss: 0.3919 - val_mae: 0.1197\n",
            "Epoch 1057/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1186 - mae: 0.0823 - val_loss: 0.3908 - val_mae: 0.1198\n",
            "Epoch 1058/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1123 - mae: 0.0845 - val_loss: 0.3871 - val_mae: 0.1212\n",
            "Epoch 1059/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0994 - mae: 0.0841 - val_loss: 0.3903 - val_mae: 0.1189\n",
            "Epoch 1060/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1048 - mae: 0.0839 - val_loss: 0.3892 - val_mae: 0.1203\n",
            "Epoch 1061/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.1118 - mae: 0.0852 - val_loss: 0.3883 - val_mae: 0.1227\n",
            "Epoch 1062/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1155 - mae: 0.0896 - val_loss: 0.3890 - val_mae: 0.1206\n",
            "Epoch 1063/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1312 - mae: 0.0912 - val_loss: 0.3866 - val_mae: 0.1209\n",
            "Epoch 1064/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0986 - mae: 0.0829 - val_loss: 0.3900 - val_mae: 0.1213\n",
            "Epoch 1065/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1246 - mae: 0.0865 - val_loss: 0.3899 - val_mae: 0.1214\n",
            "Epoch 1066/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1084 - mae: 0.0879 - val_loss: 0.3901 - val_mae: 0.1190\n",
            "Epoch 1067/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0974 - mae: 0.0807 - val_loss: 0.3895 - val_mae: 0.1204\n",
            "Epoch 1068/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1246 - mae: 0.0901 - val_loss: 0.3857 - val_mae: 0.1217\n",
            "Epoch 1069/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0949 - mae: 0.0822 - val_loss: 0.3926 - val_mae: 0.1205\n",
            "Epoch 1070/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1072 - mae: 0.0874 - val_loss: 0.3909 - val_mae: 0.1207\n",
            "Epoch 1071/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1068 - mae: 0.0859 - val_loss: 0.3901 - val_mae: 0.1205\n",
            "Epoch 1072/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1007 - mae: 0.0826 - val_loss: 0.3874 - val_mae: 0.1229\n",
            "Epoch 1073/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1412 - mae: 0.0972 - val_loss: 0.3906 - val_mae: 0.1208\n",
            "Epoch 1074/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0993 - mae: 0.0825 - val_loss: 0.3917 - val_mae: 0.1211\n",
            "Epoch 1075/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0944 - mae: 0.0850 - val_loss: 0.3909 - val_mae: 0.1203\n",
            "Epoch 1076/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1487 - mae: 0.0942 - val_loss: 0.3896 - val_mae: 0.1207\n",
            "Epoch 1077/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1039 - mae: 0.0852 - val_loss: 0.3892 - val_mae: 0.1216\n",
            "Epoch 1078/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0931 - mae: 0.0797 - val_loss: 0.3866 - val_mae: 0.1215\n",
            "Epoch 1079/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0947 - mae: 0.0863 - val_loss: 0.3861 - val_mae: 0.1255\n",
            "Epoch 1080/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1219 - mae: 0.0929 - val_loss: 0.3849 - val_mae: 0.1212\n",
            "Epoch 1081/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1107 - mae: 0.0934 - val_loss: 0.3873 - val_mae: 0.1212\n",
            "Epoch 1082/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1148 - mae: 0.0830 - val_loss: 0.3875 - val_mae: 0.1194\n",
            "Epoch 1083/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0997 - mae: 0.0880 - val_loss: 0.3853 - val_mae: 0.1219\n",
            "Epoch 1084/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0795 - mae: 0.0764 - val_loss: 0.3881 - val_mae: 0.1207\n",
            "Epoch 1085/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1261 - mae: 0.0890 - val_loss: 0.3893 - val_mae: 0.1205\n",
            "Epoch 1086/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1101 - mae: 0.0857 - val_loss: 0.3868 - val_mae: 0.1200\n",
            "Epoch 1087/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1451 - mae: 0.0947 - val_loss: 0.3864 - val_mae: 0.1201\n",
            "Epoch 1088/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0947 - mae: 0.0847 - val_loss: 0.3908 - val_mae: 0.1201\n",
            "Epoch 1089/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1167 - mae: 0.0867 - val_loss: 0.3923 - val_mae: 0.1211\n",
            "Epoch 1090/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0776 - mae: 0.0771 - val_loss: 0.3869 - val_mae: 0.1213\n",
            "Epoch 1091/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0940 - mae: 0.0835 - val_loss: 0.3867 - val_mae: 0.1231\n",
            "Epoch 1092/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0969 - mae: 0.0822 - val_loss: 0.3854 - val_mae: 0.1204\n",
            "Epoch 1093/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1002 - mae: 0.0820 - val_loss: 0.3886 - val_mae: 0.1200\n",
            "Epoch 1094/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0894 - mae: 0.0794 - val_loss: 0.3936 - val_mae: 0.1205\n",
            "Epoch 1095/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0896 - mae: 0.0821 - val_loss: 0.3869 - val_mae: 0.1197\n",
            "Epoch 1096/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0787 - mae: 0.0754 - val_loss: 0.3855 - val_mae: 0.1214\n",
            "Epoch 1097/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1340 - mae: 0.0923 - val_loss: 0.3894 - val_mae: 0.1213\n",
            "Epoch 1098/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1060 - mae: 0.0781 - val_loss: 0.3909 - val_mae: 0.1222\n",
            "Epoch 1099/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0983 - mae: 0.0883 - val_loss: 0.3880 - val_mae: 0.1208\n",
            "Epoch 1100/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1195 - mae: 0.0843 - val_loss: 0.3888 - val_mae: 0.1223\n",
            "Epoch 1101/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1153 - mae: 0.0886 - val_loss: 0.3890 - val_mae: 0.1205\n",
            "Epoch 1102/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1034 - mae: 0.0813 - val_loss: 0.3874 - val_mae: 0.1205\n",
            "Epoch 1103/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1234 - mae: 0.0863 - val_loss: 0.3903 - val_mae: 0.1214\n",
            "Epoch 1104/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0907 - mae: 0.0863 - val_loss: 0.3883 - val_mae: 0.1205\n",
            "Epoch 1105/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1031 - mae: 0.0880 - val_loss: 0.3869 - val_mae: 0.1212\n",
            "Epoch 1106/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1105 - mae: 0.0906 - val_loss: 0.3907 - val_mae: 0.1213\n",
            "Epoch 1107/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0922 - mae: 0.0786 - val_loss: 0.3892 - val_mae: 0.1204\n",
            "Epoch 1108/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0968 - mae: 0.0819 - val_loss: 0.3875 - val_mae: 0.1221\n",
            "Epoch 1109/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0938 - mae: 0.0833 - val_loss: 0.3922 - val_mae: 0.1203\n",
            "Epoch 1110/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0869 - mae: 0.0768 - val_loss: 0.3882 - val_mae: 0.1229\n",
            "Epoch 1111/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1116 - mae: 0.0850 - val_loss: 0.3922 - val_mae: 0.1226\n",
            "Epoch 1112/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0930 - mae: 0.0793 - val_loss: 0.3919 - val_mae: 0.1208\n",
            "Epoch 1113/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0951 - mae: 0.0788 - val_loss: 0.3926 - val_mae: 0.1203\n",
            "Epoch 1114/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1232 - mae: 0.0866 - val_loss: 0.3891 - val_mae: 0.1198\n",
            "Epoch 1115/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1343 - mae: 0.0973 - val_loss: 0.3908 - val_mae: 0.1210\n",
            "Epoch 1116/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0851 - mae: 0.0784 - val_loss: 0.3912 - val_mae: 0.1201\n",
            "Epoch 1117/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1114 - mae: 0.0807 - val_loss: 0.3893 - val_mae: 0.1210\n",
            "Epoch 1118/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0804 - mae: 0.0739 - val_loss: 0.3875 - val_mae: 0.1193\n",
            "Epoch 1119/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0676 - mae: 0.0701 - val_loss: 0.3920 - val_mae: 0.1204\n",
            "Epoch 1120/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1014 - mae: 0.0907 - val_loss: 0.3864 - val_mae: 0.1238\n",
            "Epoch 1121/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1076 - mae: 0.0866 - val_loss: 0.3868 - val_mae: 0.1203\n",
            "Epoch 1122/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1063 - mae: 0.0803 - val_loss: 0.3877 - val_mae: 0.1201\n",
            "Epoch 1123/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0825 - mae: 0.0742 - val_loss: 0.3884 - val_mae: 0.1206\n",
            "Epoch 1124/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1062 - mae: 0.0848 - val_loss: 0.3890 - val_mae: 0.1201\n",
            "Epoch 1125/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1750 - mae: 0.1050 - val_loss: 0.3909 - val_mae: 0.1198\n",
            "Epoch 1126/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0952 - mae: 0.0778 - val_loss: 0.3930 - val_mae: 0.1196\n",
            "Epoch 1127/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1341 - mae: 0.0906 - val_loss: 0.3850 - val_mae: 0.1211\n",
            "Epoch 1128/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1398 - mae: 0.0948 - val_loss: 0.3910 - val_mae: 0.1202\n",
            "Epoch 1129/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.1260 - mae: 0.0869 - val_loss: 0.3884 - val_mae: 0.1212\n",
            "Epoch 1130/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1210 - mae: 0.0939 - val_loss: 0.3874 - val_mae: 0.1213\n",
            "Epoch 1131/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1164 - mae: 0.0854 - val_loss: 0.3905 - val_mae: 0.1200\n",
            "Epoch 1132/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1002 - mae: 0.0811 - val_loss: 0.3877 - val_mae: 0.1205\n",
            "Epoch 1133/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0841 - mae: 0.0779 - val_loss: 0.3919 - val_mae: 0.1209\n",
            "Epoch 1134/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0994 - mae: 0.0884 - val_loss: 0.3885 - val_mae: 0.1216\n",
            "Epoch 1135/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1212 - mae: 0.0901 - val_loss: 0.3860 - val_mae: 0.1220\n",
            "Epoch 1136/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1023 - mae: 0.0844 - val_loss: 0.3926 - val_mae: 0.1203\n",
            "Epoch 1137/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0951 - mae: 0.0821 - val_loss: 0.3935 - val_mae: 0.1205\n",
            "Epoch 1138/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1123 - mae: 0.0859 - val_loss: 0.3880 - val_mae: 0.1237\n",
            "Epoch 1139/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0885 - mae: 0.0828 - val_loss: 0.3906 - val_mae: 0.1244\n",
            "Epoch 1140/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0954 - mae: 0.0846 - val_loss: 0.3890 - val_mae: 0.1219\n",
            "Epoch 1141/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1163 - mae: 0.0933 - val_loss: 0.3883 - val_mae: 0.1241\n",
            "Epoch 1142/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1112 - mae: 0.0871 - val_loss: 0.3931 - val_mae: 0.1221\n",
            "Epoch 1143/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0873 - mae: 0.0801 - val_loss: 0.3944 - val_mae: 0.1227\n",
            "Epoch 1144/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0793 - mae: 0.0801 - val_loss: 0.3847 - val_mae: 0.1209\n",
            "Epoch 1145/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1102 - mae: 0.0871 - val_loss: 0.3839 - val_mae: 0.1216\n",
            "Epoch 1146/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1167 - mae: 0.0900 - val_loss: 0.3911 - val_mae: 0.1195\n",
            "Epoch 1147/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1405 - mae: 0.0930 - val_loss: 0.3892 - val_mae: 0.1205\n",
            "Epoch 1148/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1581 - mae: 0.1008 - val_loss: 0.3899 - val_mae: 0.1209\n",
            "Epoch 1149/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1049 - mae: 0.0834 - val_loss: 0.3928 - val_mae: 0.1200\n",
            "Epoch 1150/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1293 - mae: 0.0888 - val_loss: 0.3893 - val_mae: 0.1197\n",
            "Epoch 1151/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1068 - mae: 0.0814 - val_loss: 0.3900 - val_mae: 0.1209\n",
            "Epoch 1152/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1476 - mae: 0.0971 - val_loss: 0.3905 - val_mae: 0.1200\n",
            "Epoch 1153/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1356 - mae: 0.0961 - val_loss: 0.3873 - val_mae: 0.1200\n",
            "Epoch 1154/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0919 - mae: 0.0824 - val_loss: 0.3877 - val_mae: 0.1205\n",
            "Epoch 1155/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0994 - mae: 0.0842 - val_loss: 0.3875 - val_mae: 0.1204\n",
            "Epoch 1156/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1097 - mae: 0.0840 - val_loss: 0.3890 - val_mae: 0.1202\n",
            "Epoch 1157/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0756 - mae: 0.0747 - val_loss: 0.3928 - val_mae: 0.1192\n",
            "Epoch 1158/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0689 - mae: 0.0744 - val_loss: 0.3883 - val_mae: 0.1199\n",
            "Epoch 1159/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1828 - mae: 0.1020 - val_loss: 0.3956 - val_mae: 0.1299\n",
            "Epoch 1160/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1335 - mae: 0.1007 - val_loss: 0.3875 - val_mae: 0.1251\n",
            "Epoch 1161/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1221 - mae: 0.0966 - val_loss: 0.3889 - val_mae: 0.1277\n",
            "Epoch 1162/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1379 - mae: 0.0993 - val_loss: 0.3880 - val_mae: 0.1247\n",
            "Epoch 1163/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0854 - mae: 0.0854 - val_loss: 0.3869 - val_mae: 0.1220\n",
            "Epoch 1164/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0956 - mae: 0.0883 - val_loss: 0.3872 - val_mae: 0.1209\n",
            "Epoch 1165/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0722 - mae: 0.0749 - val_loss: 0.3889 - val_mae: 0.1220\n",
            "Epoch 1166/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0790 - mae: 0.0770 - val_loss: 0.3854 - val_mae: 0.1220\n",
            "Epoch 1167/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0935 - mae: 0.0818 - val_loss: 0.3884 - val_mae: 0.1197\n",
            "Epoch 1168/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1076 - mae: 0.0875 - val_loss: 0.3913 - val_mae: 0.1210\n",
            "Epoch 1169/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0856 - mae: 0.0783 - val_loss: 0.3869 - val_mae: 0.1223\n",
            "Epoch 1170/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1001 - mae: 0.0813 - val_loss: 0.3894 - val_mae: 0.1210\n",
            "Epoch 1171/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1430 - mae: 0.0966 - val_loss: 0.3903 - val_mae: 0.1200\n",
            "Epoch 1172/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0855 - mae: 0.0776 - val_loss: 0.3876 - val_mae: 0.1203\n",
            "Epoch 1173/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0986 - mae: 0.0854 - val_loss: 0.3868 - val_mae: 0.1197\n",
            "Epoch 1174/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0891 - mae: 0.0840 - val_loss: 0.3877 - val_mae: 0.1241\n",
            "Epoch 1175/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1037 - mae: 0.0866 - val_loss: 0.3859 - val_mae: 0.1226\n",
            "Epoch 1176/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1549 - mae: 0.1018 - val_loss: 0.3878 - val_mae: 0.1209\n",
            "Epoch 1177/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1221 - mae: 0.0893 - val_loss: 0.3915 - val_mae: 0.1202\n",
            "Epoch 1178/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0878 - mae: 0.0750 - val_loss: 0.3883 - val_mae: 0.1199\n",
            "Epoch 1179/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0978 - mae: 0.0813 - val_loss: 0.3867 - val_mae: 0.1200\n",
            "Epoch 1180/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0938 - mae: 0.0786 - val_loss: 0.3900 - val_mae: 0.1191\n",
            "Epoch 1181/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0898 - mae: 0.0819 - val_loss: 0.3843 - val_mae: 0.1209\n",
            "Epoch 1182/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0944 - mae: 0.0837 - val_loss: 0.3871 - val_mae: 0.1200\n",
            "Epoch 1183/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1457 - mae: 0.0945 - val_loss: 0.3897 - val_mae: 0.1216\n",
            "Epoch 1184/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1228 - mae: 0.0890 - val_loss: 0.3905 - val_mae: 0.1199\n",
            "Epoch 1185/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0928 - mae: 0.0843 - val_loss: 0.3903 - val_mae: 0.1201\n",
            "Epoch 1186/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1293 - mae: 0.0890 - val_loss: 0.3894 - val_mae: 0.1196\n",
            "Epoch 1187/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1125 - mae: 0.0823 - val_loss: 0.3891 - val_mae: 0.1206\n",
            "Epoch 1188/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0749 - mae: 0.0740 - val_loss: 0.3881 - val_mae: 0.1213\n",
            "Epoch 1189/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0814 - mae: 0.0790 - val_loss: 0.3876 - val_mae: 0.1209\n",
            "Epoch 1190/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1085 - mae: 0.0847 - val_loss: 0.3884 - val_mae: 0.1203\n",
            "Epoch 1191/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0931 - mae: 0.0820 - val_loss: 0.3883 - val_mae: 0.1207\n",
            "Epoch 1192/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1052 - mae: 0.0827 - val_loss: 0.3856 - val_mae: 0.1226\n",
            "Epoch 1193/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1212 - mae: 0.0899 - val_loss: 0.3916 - val_mae: 0.1293\n",
            "Epoch 1194/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1270 - mae: 0.0975 - val_loss: 0.3891 - val_mae: 0.1242\n",
            "Epoch 1195/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0933 - mae: 0.0826 - val_loss: 0.3883 - val_mae: 0.1230\n",
            "Epoch 1196/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0781 - mae: 0.0788 - val_loss: 0.3850 - val_mae: 0.1213\n",
            "Epoch 1197/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0918 - mae: 0.0815 - val_loss: 0.3868 - val_mae: 0.1207\n",
            "Epoch 1198/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0802 - mae: 0.0763 - val_loss: 0.3852 - val_mae: 0.1229\n",
            "Epoch 1199/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1063 - mae: 0.0887 - val_loss: 0.3923 - val_mae: 0.1249\n",
            "Epoch 1200/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1057 - mae: 0.0905 - val_loss: 0.3889 - val_mae: 0.1203\n",
            "Epoch 1201/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1303 - mae: 0.0929 - val_loss: 0.3857 - val_mae: 0.1248\n",
            "Epoch 1202/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0928 - mae: 0.0848 - val_loss: 0.3875 - val_mae: 0.1267\n",
            "Epoch 1203/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1225 - mae: 0.0904 - val_loss: 0.3925 - val_mae: 0.1281\n",
            "Epoch 1204/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1268 - mae: 0.0991 - val_loss: 0.3885 - val_mae: 0.1261\n",
            "Epoch 1205/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1232 - mae: 0.0991 - val_loss: 0.3897 - val_mae: 0.1208\n",
            "Epoch 1206/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0882 - mae: 0.0795 - val_loss: 0.3916 - val_mae: 0.1209\n",
            "Epoch 1207/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0926 - mae: 0.0833 - val_loss: 0.3852 - val_mae: 0.1220\n",
            "Epoch 1208/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1052 - mae: 0.0872 - val_loss: 0.3939 - val_mae: 0.1216\n",
            "Epoch 1209/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1022 - mae: 0.0841 - val_loss: 0.3881 - val_mae: 0.1211\n",
            "Epoch 1210/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0883 - mae: 0.0749 - val_loss: 0.3867 - val_mae: 0.1221\n",
            "Epoch 1211/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0947 - mae: 0.0824 - val_loss: 0.3893 - val_mae: 0.1198\n",
            "Epoch 1212/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1256 - mae: 0.0843 - val_loss: 0.3900 - val_mae: 0.1205\n",
            "Epoch 1213/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0872 - mae: 0.0811 - val_loss: 0.3903 - val_mae: 0.1197\n",
            "Epoch 1214/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0835 - mae: 0.0746 - val_loss: 0.3901 - val_mae: 0.1194\n",
            "Epoch 1215/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1211 - mae: 0.0844 - val_loss: 0.3882 - val_mae: 0.1202\n",
            "Epoch 1216/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0968 - mae: 0.0872 - val_loss: 0.3873 - val_mae: 0.1197\n",
            "Epoch 1217/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0938 - mae: 0.0774 - val_loss: 0.3872 - val_mae: 0.1203\n",
            "Epoch 1218/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1136 - mae: 0.0841 - val_loss: 0.3869 - val_mae: 0.1208\n",
            "Epoch 1219/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1325 - mae: 0.0850 - val_loss: 0.3901 - val_mae: 0.1213\n",
            "Epoch 1220/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0986 - mae: 0.0826 - val_loss: 0.3879 - val_mae: 0.1200\n",
            "Epoch 1221/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1268 - mae: 0.0920 - val_loss: 0.3867 - val_mae: 0.1204\n",
            "Epoch 1222/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0932 - mae: 0.0832 - val_loss: 0.3906 - val_mae: 0.1198\n",
            "Epoch 1223/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1065 - mae: 0.0830 - val_loss: 0.3885 - val_mae: 0.1218\n",
            "Epoch 1224/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0971 - mae: 0.0814 - val_loss: 0.3882 - val_mae: 0.1207\n",
            "Epoch 1225/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0953 - mae: 0.0818 - val_loss: 0.3887 - val_mae: 0.1203\n",
            "Epoch 1226/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1008 - mae: 0.0808 - val_loss: 0.3901 - val_mae: 0.1201\n",
            "Epoch 1227/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0845 - mae: 0.0764 - val_loss: 0.3909 - val_mae: 0.1199\n",
            "Epoch 1228/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0740 - mae: 0.0773 - val_loss: 0.3897 - val_mae: 0.1210\n",
            "Epoch 1229/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0789 - mae: 0.0798 - val_loss: 0.3878 - val_mae: 0.1216\n",
            "Epoch 1230/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0876 - mae: 0.0783 - val_loss: 0.3840 - val_mae: 0.1215\n",
            "Epoch 1231/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1164 - mae: 0.0941 - val_loss: 0.3865 - val_mae: 0.1208\n",
            "Epoch 1232/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1077 - mae: 0.0820 - val_loss: 0.3909 - val_mae: 0.1195\n",
            "Epoch 1233/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1084 - mae: 0.0853 - val_loss: 0.3886 - val_mae: 0.1207\n",
            "Epoch 1234/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1124 - mae: 0.0912 - val_loss: 0.3864 - val_mae: 0.1200\n",
            "Epoch 1235/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1568 - mae: 0.0999 - val_loss: 0.3878 - val_mae: 0.1215\n",
            "Epoch 1236/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0839 - mae: 0.0803 - val_loss: 0.3894 - val_mae: 0.1209\n",
            "Epoch 1237/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1031 - mae: 0.0823 - val_loss: 0.3885 - val_mae: 0.1200\n",
            "Epoch 1238/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0894 - mae: 0.0803 - val_loss: 0.3867 - val_mae: 0.1201\n",
            "Epoch 1239/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0871 - mae: 0.0823 - val_loss: 0.3882 - val_mae: 0.1207\n",
            "Epoch 1240/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1023 - mae: 0.0844 - val_loss: 0.3846 - val_mae: 0.1216\n",
            "Epoch 1241/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0935 - mae: 0.0799 - val_loss: 0.3898 - val_mae: 0.1209\n",
            "Epoch 1242/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0767 - mae: 0.0738 - val_loss: 0.3906 - val_mae: 0.1199\n",
            "Epoch 1243/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0888 - mae: 0.0746 - val_loss: 0.3877 - val_mae: 0.1203\n",
            "Epoch 1244/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1212 - mae: 0.0889 - val_loss: 0.3890 - val_mae: 0.1208\n",
            "Epoch 1245/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1545 - mae: 0.1031 - val_loss: 0.3894 - val_mae: 0.1193\n",
            "Epoch 1246/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1102 - mae: 0.0832 - val_loss: 0.3888 - val_mae: 0.1201\n",
            "Epoch 1247/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0888 - mae: 0.0831 - val_loss: 0.3877 - val_mae: 0.1195\n",
            "Epoch 1248/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1215 - mae: 0.0856 - val_loss: 0.3875 - val_mae: 0.1208\n",
            "Epoch 1249/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1133 - mae: 0.0831 - val_loss: 0.3924 - val_mae: 0.1195\n",
            "Epoch 1250/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1349 - mae: 0.0831 - val_loss: 0.3919 - val_mae: 0.1230\n",
            "Epoch 1251/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1081 - mae: 0.0904 - val_loss: 0.3900 - val_mae: 0.1208\n",
            "Epoch 1252/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1244 - mae: 0.1017 - val_loss: 0.3869 - val_mae: 0.1198\n",
            "Epoch 1253/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1062 - mae: 0.0857 - val_loss: 0.3916 - val_mae: 0.1192\n",
            "Epoch 1254/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0937 - mae: 0.0771 - val_loss: 0.3858 - val_mae: 0.1210\n",
            "Epoch 1255/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1034 - mae: 0.0833 - val_loss: 0.3861 - val_mae: 0.1204\n",
            "Epoch 1256/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1406 - mae: 0.0955 - val_loss: 0.3900 - val_mae: 0.1195\n",
            "Epoch 1257/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0903 - mae: 0.0787 - val_loss: 0.3883 - val_mae: 0.1193\n",
            "Epoch 1258/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0919 - mae: 0.0814 - val_loss: 0.3892 - val_mae: 0.1201\n",
            "Epoch 1259/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1049 - mae: 0.0806 - val_loss: 0.3867 - val_mae: 0.1207\n",
            "Epoch 1260/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0920 - mae: 0.0807 - val_loss: 0.3894 - val_mae: 0.1200\n",
            "Epoch 1261/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0931 - mae: 0.0802 - val_loss: 0.3896 - val_mae: 0.1198\n",
            "Epoch 1262/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0953 - mae: 0.0820 - val_loss: 0.3867 - val_mae: 0.1204\n",
            "Epoch 1263/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0888 - mae: 0.0802 - val_loss: 0.3887 - val_mae: 0.1209\n",
            "Epoch 1264/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1024 - mae: 0.0808 - val_loss: 0.3901 - val_mae: 0.1218\n",
            "Epoch 1265/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0993 - mae: 0.0825 - val_loss: 0.3917 - val_mae: 0.1201\n",
            "Epoch 1266/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1388 - mae: 0.0876 - val_loss: 0.3924 - val_mae: 0.1206\n",
            "Epoch 1267/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1745 - mae: 0.1014 - val_loss: 0.3879 - val_mae: 0.1213\n",
            "Epoch 1268/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0912 - mae: 0.0805 - val_loss: 0.3933 - val_mae: 0.1187\n",
            "Epoch 1269/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1178 - mae: 0.0888 - val_loss: 0.3886 - val_mae: 0.1223\n",
            "Epoch 1270/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0727 - mae: 0.0768 - val_loss: 0.3904 - val_mae: 0.1200\n",
            "Epoch 1271/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0926 - mae: 0.0810 - val_loss: 0.3857 - val_mae: 0.1222\n",
            "Epoch 1272/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0958 - mae: 0.0812 - val_loss: 0.3897 - val_mae: 0.1210\n",
            "Epoch 1273/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0963 - mae: 0.0807 - val_loss: 0.3860 - val_mae: 0.1206\n",
            "Epoch 1274/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1200 - mae: 0.0943 - val_loss: 0.3911 - val_mae: 0.1202\n",
            "Epoch 1275/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0858 - mae: 0.0733 - val_loss: 0.3875 - val_mae: 0.1215\n",
            "Epoch 1276/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1154 - mae: 0.0949 - val_loss: 0.3876 - val_mae: 0.1206\n",
            "Epoch 1277/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1095 - mae: 0.0822 - val_loss: 0.3897 - val_mae: 0.1206\n",
            "Epoch 1278/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1263 - mae: 0.0887 - val_loss: 0.3890 - val_mae: 0.1203\n",
            "Epoch 1279/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1191 - mae: 0.0848 - val_loss: 0.3924 - val_mae: 0.1200\n",
            "Epoch 1280/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1281 - mae: 0.0987 - val_loss: 0.3850 - val_mae: 0.1208\n",
            "Epoch 1281/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1027 - mae: 0.0850 - val_loss: 0.3870 - val_mae: 0.1227\n",
            "Epoch 1282/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1162 - mae: 0.0867 - val_loss: 0.3897 - val_mae: 0.1220\n",
            "Epoch 1283/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0861 - mae: 0.0801 - val_loss: 0.3905 - val_mae: 0.1220\n",
            "Epoch 1284/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1428 - mae: 0.1036 - val_loss: 0.3905 - val_mae: 0.1282\n",
            "Epoch 1285/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1375 - mae: 0.1014 - val_loss: 0.3880 - val_mae: 0.1234\n",
            "Epoch 1286/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0989 - mae: 0.0883 - val_loss: 0.3884 - val_mae: 0.1204\n",
            "Epoch 1287/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1025 - mae: 0.0856 - val_loss: 0.3919 - val_mae: 0.1203\n",
            "Epoch 1288/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0785 - mae: 0.0787 - val_loss: 0.3921 - val_mae: 0.1210\n",
            "Epoch 1289/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0820 - mae: 0.0762 - val_loss: 0.3867 - val_mae: 0.1200\n",
            "Epoch 1290/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1215 - mae: 0.0891 - val_loss: 0.3862 - val_mae: 0.1216\n",
            "Epoch 1291/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0963 - mae: 0.0792 - val_loss: 0.3921 - val_mae: 0.1192\n",
            "Epoch 1292/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0843 - mae: 0.0735 - val_loss: 0.3880 - val_mae: 0.1211\n",
            "Epoch 1293/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1024 - mae: 0.0823 - val_loss: 0.3862 - val_mae: 0.1202\n",
            "Epoch 1294/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0723 - mae: 0.0760 - val_loss: 0.3898 - val_mae: 0.1203\n",
            "Epoch 1295/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1320 - mae: 0.0908 - val_loss: 0.3864 - val_mae: 0.1212\n",
            "Epoch 1296/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0968 - mae: 0.0846 - val_loss: 0.3914 - val_mae: 0.1188\n",
            "Epoch 1297/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0874 - mae: 0.0808 - val_loss: 0.3876 - val_mae: 0.1196\n",
            "Epoch 1298/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1001 - mae: 0.0815 - val_loss: 0.3881 - val_mae: 0.1216\n",
            "Epoch 1299/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0717 - mae: 0.0711 - val_loss: 0.3892 - val_mae: 0.1200\n",
            "Epoch 1300/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0773 - mae: 0.0763 - val_loss: 0.3863 - val_mae: 0.1214\n",
            "Epoch 1301/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0837 - mae: 0.0794 - val_loss: 0.3905 - val_mae: 0.1201\n",
            "Epoch 1302/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0727 - mae: 0.0750 - val_loss: 0.3894 - val_mae: 0.1204\n",
            "Epoch 1303/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0945 - mae: 0.0776 - val_loss: 0.3882 - val_mae: 0.1215\n",
            "Epoch 1304/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1144 - mae: 0.0865 - val_loss: 0.3886 - val_mae: 0.1201\n",
            "Epoch 1305/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1070 - mae: 0.0778 - val_loss: 0.3956 - val_mae: 0.1201\n",
            "Epoch 1306/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0678 - mae: 0.0751 - val_loss: 0.3868 - val_mae: 0.1211\n",
            "Epoch 1307/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1036 - mae: 0.0878 - val_loss: 0.3858 - val_mae: 0.1237\n",
            "Epoch 1308/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0975 - mae: 0.0832 - val_loss: 0.3872 - val_mae: 0.1212\n",
            "Epoch 1309/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1127 - mae: 0.0942 - val_loss: 0.3879 - val_mae: 0.1206\n",
            "Epoch 1310/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1136 - mae: 0.0855 - val_loss: 0.3911 - val_mae: 0.1232\n",
            "Epoch 1311/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0821 - mae: 0.0838 - val_loss: 0.3887 - val_mae: 0.1212\n",
            "Epoch 1312/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1202 - mae: 0.0906 - val_loss: 0.3868 - val_mae: 0.1212\n",
            "Epoch 1313/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1115 - mae: 0.0862 - val_loss: 0.3908 - val_mae: 0.1197\n",
            "Epoch 1314/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0987 - mae: 0.0823 - val_loss: 0.3897 - val_mae: 0.1182\n",
            "Epoch 1315/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0937 - mae: 0.0824 - val_loss: 0.3869 - val_mae: 0.1192\n",
            "Epoch 1316/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0940 - mae: 0.0776 - val_loss: 0.3875 - val_mae: 0.1198\n",
            "Epoch 1317/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1105 - mae: 0.0883 - val_loss: 0.3884 - val_mae: 0.1198\n",
            "Epoch 1318/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0904 - mae: 0.0760 - val_loss: 0.3893 - val_mae: 0.1206\n",
            "Epoch 1319/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0871 - mae: 0.0827 - val_loss: 0.3895 - val_mae: 0.1185\n",
            "Epoch 1320/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0749 - mae: 0.0750 - val_loss: 0.3897 - val_mae: 0.1199\n",
            "Epoch 1321/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1251 - mae: 0.0874 - val_loss: 0.3894 - val_mae: 0.1203\n",
            "Epoch 1322/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0916 - mae: 0.0825 - val_loss: 0.3855 - val_mae: 0.1218\n",
            "Epoch 1323/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1108 - mae: 0.0870 - val_loss: 0.3895 - val_mae: 0.1203\n",
            "Epoch 1324/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0958 - mae: 0.0788 - val_loss: 0.3887 - val_mae: 0.1208\n",
            "Epoch 1325/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0996 - mae: 0.0830 - val_loss: 0.3875 - val_mae: 0.1198\n",
            "Epoch 1326/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1265 - mae: 0.0894 - val_loss: 0.3881 - val_mae: 0.1213\n",
            "Epoch 1327/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0918 - mae: 0.0829 - val_loss: 0.3891 - val_mae: 0.1202\n",
            "Epoch 1328/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1294 - mae: 0.0898 - val_loss: 0.3888 - val_mae: 0.1201\n",
            "Epoch 1329/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1276 - mae: 0.0894 - val_loss: 0.3892 - val_mae: 0.1190\n",
            "Epoch 1330/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1044 - mae: 0.0814 - val_loss: 0.3882 - val_mae: 0.1190\n",
            "Epoch 1331/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0902 - mae: 0.0765 - val_loss: 0.3880 - val_mae: 0.1207\n",
            "Epoch 1332/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0924 - mae: 0.0800 - val_loss: 0.3862 - val_mae: 0.1210\n",
            "Epoch 1333/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0917 - mae: 0.0816 - val_loss: 0.3879 - val_mae: 0.1205\n",
            "Epoch 1334/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0963 - mae: 0.0832 - val_loss: 0.3878 - val_mae: 0.1212\n",
            "Epoch 1335/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1340 - mae: 0.0906 - val_loss: 0.3895 - val_mae: 0.1206\n",
            "Epoch 1336/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1412 - mae: 0.0966 - val_loss: 0.3908 - val_mae: 0.1202\n",
            "Epoch 1337/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1457 - mae: 0.0984 - val_loss: 0.3885 - val_mae: 0.1211\n",
            "Epoch 1338/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0808 - mae: 0.0758 - val_loss: 0.3906 - val_mae: 0.1198\n",
            "Epoch 1339/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1241 - mae: 0.0826 - val_loss: 0.3911 - val_mae: 0.1191\n",
            "Epoch 1340/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1295 - mae: 0.0933 - val_loss: 0.3887 - val_mae: 0.1199\n",
            "Epoch 1341/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0990 - mae: 0.0852 - val_loss: 0.3881 - val_mae: 0.1188\n",
            "Epoch 1342/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1420 - mae: 0.0971 - val_loss: 0.3875 - val_mae: 0.1197\n",
            "Epoch 1343/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0828 - mae: 0.0796 - val_loss: 0.3891 - val_mae: 0.1224\n",
            "Epoch 1344/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1140 - mae: 0.0869 - val_loss: 0.3903 - val_mae: 0.1204\n",
            "Epoch 1345/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1418 - mae: 0.0907 - val_loss: 0.3872 - val_mae: 0.1209\n",
            "Epoch 1346/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1168 - mae: 0.0838 - val_loss: 0.3894 - val_mae: 0.1197\n",
            "Epoch 1347/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0844 - mae: 0.0770 - val_loss: 0.3889 - val_mae: 0.1188\n",
            "Epoch 1348/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1093 - mae: 0.0848 - val_loss: 0.3874 - val_mae: 0.1205\n",
            "Epoch 1349/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1215 - mae: 0.0918 - val_loss: 0.3869 - val_mae: 0.1206\n",
            "Epoch 1350/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0953 - mae: 0.0850 - val_loss: 0.3873 - val_mae: 0.1195\n",
            "Epoch 1351/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1137 - mae: 0.0848 - val_loss: 0.3875 - val_mae: 0.1212\n",
            "Epoch 1352/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0966 - mae: 0.0770 - val_loss: 0.3900 - val_mae: 0.1204\n",
            "Epoch 1353/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1231 - mae: 0.0915 - val_loss: 0.3873 - val_mae: 0.1211\n",
            "Epoch 1354/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1314 - mae: 0.0903 - val_loss: 0.3888 - val_mae: 0.1207\n",
            "Epoch 1355/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1211 - mae: 0.0917 - val_loss: 0.3891 - val_mae: 0.1191\n",
            "Epoch 1356/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0983 - mae: 0.0851 - val_loss: 0.3893 - val_mae: 0.1189\n",
            "Epoch 1357/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1150 - mae: 0.0901 - val_loss: 0.3882 - val_mae: 0.1200\n",
            "Epoch 1358/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0798 - mae: 0.0809 - val_loss: 0.3878 - val_mae: 0.1202\n",
            "Epoch 1359/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1075 - mae: 0.0833 - val_loss: 0.3885 - val_mae: 0.1203\n",
            "Epoch 1360/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0987 - mae: 0.0867 - val_loss: 0.3873 - val_mae: 0.1210\n",
            "Epoch 1361/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0893 - mae: 0.0772 - val_loss: 0.3862 - val_mae: 0.1204\n",
            "Epoch 1362/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0837 - mae: 0.0772 - val_loss: 0.3868 - val_mae: 0.1195\n",
            "Epoch 1363/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1582 - mae: 0.0970 - val_loss: 0.3888 - val_mae: 0.1214\n",
            "Epoch 1364/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1200 - mae: 0.0849 - val_loss: 0.3904 - val_mae: 0.1192\n",
            "Epoch 1365/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1356 - mae: 0.0971 - val_loss: 0.3875 - val_mae: 0.1220\n",
            "Epoch 1366/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1164 - mae: 0.0896 - val_loss: 0.3908 - val_mae: 0.1203\n",
            "Epoch 1367/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0951 - mae: 0.0821 - val_loss: 0.3865 - val_mae: 0.1199\n",
            "Epoch 1368/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0785 - mae: 0.0783 - val_loss: 0.3882 - val_mae: 0.1207\n",
            "Epoch 1369/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1053 - mae: 0.0897 - val_loss: 0.3862 - val_mae: 0.1205\n",
            "Epoch 1370/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1132 - mae: 0.0824 - val_loss: 0.3895 - val_mae: 0.1198\n",
            "Epoch 1371/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0895 - mae: 0.0778 - val_loss: 0.3869 - val_mae: 0.1198\n",
            "Epoch 1372/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1300 - mae: 0.0957 - val_loss: 0.3884 - val_mae: 0.1198\n",
            "Epoch 1373/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1258 - mae: 0.0834 - val_loss: 0.3888 - val_mae: 0.1207\n",
            "Epoch 1374/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0864 - mae: 0.0807 - val_loss: 0.3912 - val_mae: 0.1199\n",
            "Epoch 1375/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0916 - mae: 0.0773 - val_loss: 0.3858 - val_mae: 0.1208\n",
            "Epoch 1376/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1156 - mae: 0.0884 - val_loss: 0.3829 - val_mae: 0.1174\n",
            "Epoch 1377/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1215 - mae: 0.0784 - val_loss: 0.4095 - val_mae: 0.1260\n",
            "Epoch 1378/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1250 - mae: 0.0939 - val_loss: 0.3913 - val_mae: 0.1413\n",
            "Epoch 1379/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0939 - mae: 0.0868 - val_loss: 0.3987 - val_mae: 0.1403\n",
            "Epoch 1380/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1204 - mae: 0.1025 - val_loss: 0.3879 - val_mae: 0.1327\n",
            "Epoch 1381/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0703 - mae: 0.0803 - val_loss: 0.3876 - val_mae: 0.1264\n",
            "Epoch 1382/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0806 - mae: 0.0784 - val_loss: 0.3865 - val_mae: 0.1259\n",
            "Epoch 1383/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1007 - mae: 0.0830 - val_loss: 0.3817 - val_mae: 0.1229\n",
            "Epoch 1384/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1374 - mae: 0.0949 - val_loss: 0.3817 - val_mae: 0.1219\n",
            "Epoch 1385/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0877 - mae: 0.0785 - val_loss: 0.3897 - val_mae: 0.1256\n",
            "Epoch 1386/2000\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0831 - mae: 0.0863 - val_loss: 0.3949 - val_mae: 0.1467\n",
            "Epoch 1387/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1128 - mae: 0.1031 - val_loss: 0.3898 - val_mae: 0.1397\n",
            "Epoch 1388/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1427 - mae: 0.1148 - val_loss: 0.3895 - val_mae: 0.1261\n",
            "Epoch 1389/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1099 - mae: 0.0917 - val_loss: 0.3872 - val_mae: 0.1265\n",
            "Epoch 1390/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0999 - mae: 0.0866 - val_loss: 0.3858 - val_mae: 0.1224\n",
            "Epoch 1391/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1098 - mae: 0.0866 - val_loss: 0.3873 - val_mae: 0.1223\n",
            "Epoch 1392/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1499 - mae: 0.1065 - val_loss: 0.3875 - val_mae: 0.1221\n",
            "Epoch 1393/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0928 - mae: 0.0842 - val_loss: 0.3900 - val_mae: 0.1211\n",
            "Epoch 1394/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1543 - mae: 0.0921 - val_loss: 0.3875 - val_mae: 0.1217\n",
            "Epoch 1395/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1018 - mae: 0.0870 - val_loss: 0.3847 - val_mae: 0.1203\n",
            "Epoch 1396/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1084 - mae: 0.0820 - val_loss: 0.3906 - val_mae: 0.1227\n",
            "Epoch 1397/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0894 - mae: 0.0793 - val_loss: 0.3857 - val_mae: 0.1223\n",
            "Epoch 1398/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0822 - mae: 0.0823 - val_loss: 0.3918 - val_mae: 0.1204\n",
            "Epoch 1399/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0704 - mae: 0.0730 - val_loss: 0.3879 - val_mae: 0.1219\n",
            "Epoch 1400/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1041 - mae: 0.0882 - val_loss: 0.3886 - val_mae: 0.1209\n",
            "Epoch 1401/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1121 - mae: 0.0877 - val_loss: 0.3872 - val_mae: 0.1204\n",
            "Epoch 1402/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0689 - mae: 0.0705 - val_loss: 0.3896 - val_mae: 0.1206\n",
            "Epoch 1403/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0924 - mae: 0.0862 - val_loss: 0.3858 - val_mae: 0.1219\n",
            "Epoch 1404/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1538 - mae: 0.1028 - val_loss: 0.3880 - val_mae: 0.1217\n",
            "Epoch 1405/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0975 - mae: 0.0858 - val_loss: 0.3889 - val_mae: 0.1205\n",
            "Epoch 1406/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1269 - mae: 0.0924 - val_loss: 0.3895 - val_mae: 0.1209\n",
            "Epoch 1407/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0800 - mae: 0.0762 - val_loss: 0.3906 - val_mae: 0.1190\n",
            "Epoch 1408/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0820 - mae: 0.0751 - val_loss: 0.3887 - val_mae: 0.1195\n",
            "Epoch 1409/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0924 - mae: 0.0799 - val_loss: 0.3860 - val_mae: 0.1216\n",
            "Epoch 1410/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0802 - mae: 0.0773 - val_loss: 0.3913 - val_mae: 0.1209\n",
            "Epoch 1411/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0792 - mae: 0.0801 - val_loss: 0.3882 - val_mae: 0.1223\n",
            "Epoch 1412/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0969 - mae: 0.0792 - val_loss: 0.3878 - val_mae: 0.1245\n",
            "Epoch 1413/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1013 - mae: 0.0826 - val_loss: 0.3905 - val_mae: 0.1211\n",
            "Epoch 1414/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1151 - mae: 0.0838 - val_loss: 0.3877 - val_mae: 0.1202\n",
            "Epoch 1415/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0909 - mae: 0.0825 - val_loss: 0.3884 - val_mae: 0.1197\n",
            "Epoch 1416/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0754 - mae: 0.0728 - val_loss: 0.3914 - val_mae: 0.1198\n",
            "Epoch 1417/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0671 - mae: 0.0704 - val_loss: 0.3864 - val_mae: 0.1200\n",
            "Epoch 1418/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0670 - mae: 0.0734 - val_loss: 0.3860 - val_mae: 0.1204\n",
            "Epoch 1419/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0882 - mae: 0.0773 - val_loss: 0.3888 - val_mae: 0.1203\n",
            "Epoch 1420/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1299 - mae: 0.0970 - val_loss: 0.3882 - val_mae: 0.1205\n",
            "Epoch 1421/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0882 - mae: 0.0742 - val_loss: 0.3897 - val_mae: 0.1200\n",
            "Epoch 1422/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1013 - mae: 0.0854 - val_loss: 0.3887 - val_mae: 0.1230\n",
            "Epoch 1423/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0965 - mae: 0.0846 - val_loss: 0.3867 - val_mae: 0.1219\n",
            "Epoch 1424/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1261 - mae: 0.0911 - val_loss: 0.3883 - val_mae: 0.1211\n",
            "Epoch 1425/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0865 - mae: 0.0844 - val_loss: 0.3883 - val_mae: 0.1187\n",
            "Epoch 1426/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0970 - mae: 0.0837 - val_loss: 0.3864 - val_mae: 0.1211\n",
            "Epoch 1427/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1210 - mae: 0.0841 - val_loss: 0.3891 - val_mae: 0.1219\n",
            "Epoch 1428/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0817 - mae: 0.0724 - val_loss: 0.3911 - val_mae: 0.1206\n",
            "Epoch 1429/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1115 - mae: 0.0855 - val_loss: 0.3890 - val_mae: 0.1204\n",
            "Epoch 1430/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1237 - mae: 0.0887 - val_loss: 0.3875 - val_mae: 0.1197\n",
            "Epoch 1431/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1175 - mae: 0.0870 - val_loss: 0.3890 - val_mae: 0.1195\n",
            "Epoch 1432/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1094 - mae: 0.0827 - val_loss: 0.3870 - val_mae: 0.1199\n",
            "Epoch 1433/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1304 - mae: 0.0913 - val_loss: 0.3873 - val_mae: 0.1197\n",
            "Epoch 1434/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1243 - mae: 0.0889 - val_loss: 0.3903 - val_mae: 0.1202\n",
            "Epoch 1435/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0863 - mae: 0.0757 - val_loss: 0.3895 - val_mae: 0.1193\n",
            "Epoch 1436/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1099 - mae: 0.0849 - val_loss: 0.3856 - val_mae: 0.1212\n",
            "Epoch 1437/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1428 - mae: 0.0910 - val_loss: 0.3919 - val_mae: 0.1200\n",
            "Epoch 1438/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0845 - mae: 0.0755 - val_loss: 0.3906 - val_mae: 0.1204\n",
            "Epoch 1439/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1517 - mae: 0.0944 - val_loss: 0.3870 - val_mae: 0.1203\n",
            "Epoch 1440/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1093 - mae: 0.0867 - val_loss: 0.3895 - val_mae: 0.1208\n",
            "Epoch 1441/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1004 - mae: 0.0809 - val_loss: 0.3890 - val_mae: 0.1201\n",
            "Epoch 1442/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0981 - mae: 0.0839 - val_loss: 0.3866 - val_mae: 0.1210\n",
            "Epoch 1443/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0874 - mae: 0.0809 - val_loss: 0.3898 - val_mae: 0.1190\n",
            "Epoch 1444/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1031 - mae: 0.0852 - val_loss: 0.3863 - val_mae: 0.1212\n",
            "Epoch 1445/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0883 - mae: 0.0789 - val_loss: 0.3862 - val_mae: 0.1207\n",
            "Epoch 1446/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0773 - mae: 0.0757 - val_loss: 0.3887 - val_mae: 0.1198\n",
            "Epoch 1447/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1121 - mae: 0.0843 - val_loss: 0.3905 - val_mae: 0.1194\n",
            "Epoch 1448/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0723 - mae: 0.0771 - val_loss: 0.3883 - val_mae: 0.1197\n",
            "Epoch 1449/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1233 - mae: 0.0888 - val_loss: 0.3835 - val_mae: 0.1211\n",
            "Epoch 1450/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1074 - mae: 0.0910 - val_loss: 0.3882 - val_mae: 0.1200\n",
            "Epoch 1451/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1365 - mae: 0.0926 - val_loss: 0.3887 - val_mae: 0.1207\n",
            "Epoch 1452/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0988 - mae: 0.0878 - val_loss: 0.3921 - val_mae: 0.1203\n",
            "Epoch 1453/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0904 - mae: 0.0805 - val_loss: 0.3877 - val_mae: 0.1210\n",
            "Epoch 1454/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1017 - mae: 0.0821 - val_loss: 0.3885 - val_mae: 0.1197\n",
            "Epoch 1455/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0914 - mae: 0.0827 - val_loss: 0.3876 - val_mae: 0.1202\n",
            "Epoch 1456/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0792 - mae: 0.0757 - val_loss: 0.3873 - val_mae: 0.1199\n",
            "Epoch 1457/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1175 - mae: 0.0911 - val_loss: 0.3890 - val_mae: 0.1199\n",
            "Epoch 1458/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0858 - mae: 0.0798 - val_loss: 0.3884 - val_mae: 0.1189\n",
            "Epoch 1459/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1230 - mae: 0.0864 - val_loss: 0.3887 - val_mae: 0.1196\n",
            "Epoch 1460/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1103 - mae: 0.0854 - val_loss: 0.3864 - val_mae: 0.1198\n",
            "Epoch 1461/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1299 - mae: 0.0889 - val_loss: 0.3889 - val_mae: 0.1198\n",
            "Epoch 1462/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0748 - mae: 0.0767 - val_loss: 0.3908 - val_mae: 0.1194\n",
            "Epoch 1463/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1005 - mae: 0.0819 - val_loss: 0.3879 - val_mae: 0.1202\n",
            "Epoch 1464/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1108 - mae: 0.0868 - val_loss: 0.3874 - val_mae: 0.1215\n",
            "Epoch 1465/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1112 - mae: 0.0877 - val_loss: 0.3868 - val_mae: 0.1206\n",
            "Epoch 1466/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1180 - mae: 0.0881 - val_loss: 0.3896 - val_mae: 0.1190\n",
            "Epoch 1467/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0966 - mae: 0.0816 - val_loss: 0.3911 - val_mae: 0.1189\n",
            "Epoch 1468/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0798 - mae: 0.0774 - val_loss: 0.3886 - val_mae: 0.1194\n",
            "Epoch 1469/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0881 - mae: 0.0772 - val_loss: 0.3894 - val_mae: 0.1202\n",
            "Epoch 1470/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0916 - mae: 0.0779 - val_loss: 0.3884 - val_mae: 0.1215\n",
            "Epoch 1471/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0750 - mae: 0.0726 - val_loss: 0.3905 - val_mae: 0.1203\n",
            "Epoch 1472/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1012 - mae: 0.0836 - val_loss: 0.3888 - val_mae: 0.1193\n",
            "Epoch 1473/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0882 - mae: 0.0816 - val_loss: 0.3880 - val_mae: 0.1192\n",
            "Epoch 1474/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0703 - mae: 0.0737 - val_loss: 0.3867 - val_mae: 0.1229\n",
            "Epoch 1475/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1075 - mae: 0.0883 - val_loss: 0.3884 - val_mae: 0.1220\n",
            "Epoch 1476/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0888 - mae: 0.0812 - val_loss: 0.3928 - val_mae: 0.1403\n",
            "Epoch 1477/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1025 - mae: 0.0967 - val_loss: 0.3932 - val_mae: 0.1289\n",
            "Epoch 1478/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1295 - mae: 0.1016 - val_loss: 0.3920 - val_mae: 0.1301\n",
            "Epoch 1479/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0781 - mae: 0.0809 - val_loss: 0.3920 - val_mae: 0.1303\n",
            "Epoch 1480/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1024 - mae: 0.0948 - val_loss: 0.3907 - val_mae: 0.1242\n",
            "Epoch 1481/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0918 - mae: 0.0859 - val_loss: 0.3877 - val_mae: 0.1224\n",
            "Epoch 1482/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1247 - mae: 0.0930 - val_loss: 0.3893 - val_mae: 0.1218\n",
            "Epoch 1483/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0795 - mae: 0.0773 - val_loss: 0.3885 - val_mae: 0.1200\n",
            "Epoch 1484/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1002 - mae: 0.0828 - val_loss: 0.3889 - val_mae: 0.1207\n",
            "Epoch 1485/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0981 - mae: 0.0823 - val_loss: 0.3875 - val_mae: 0.1204\n",
            "Epoch 1486/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1033 - mae: 0.0851 - val_loss: 0.3872 - val_mae: 0.1201\n",
            "Epoch 1487/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0875 - mae: 0.0772 - val_loss: 0.3890 - val_mae: 0.1199\n",
            "Epoch 1488/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1251 - mae: 0.0916 - val_loss: 0.3871 - val_mae: 0.1201\n",
            "Epoch 1489/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1249 - mae: 0.0873 - val_loss: 0.3890 - val_mae: 0.1197\n",
            "Epoch 1490/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1478 - mae: 0.0940 - val_loss: 0.3924 - val_mae: 0.1195\n",
            "Epoch 1491/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1347 - mae: 0.0875 - val_loss: 0.3894 - val_mae: 0.1198\n",
            "Epoch 1492/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1173 - mae: 0.0832 - val_loss: 0.3901 - val_mae: 0.1206\n",
            "Epoch 1493/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1251 - mae: 0.0923 - val_loss: 0.3874 - val_mae: 0.1192\n",
            "Epoch 1494/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0829 - mae: 0.0785 - val_loss: 0.3893 - val_mae: 0.1199\n",
            "Epoch 1495/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1219 - mae: 0.0898 - val_loss: 0.3867 - val_mae: 0.1217\n",
            "Epoch 1496/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1148 - mae: 0.0838 - val_loss: 0.3875 - val_mae: 0.1204\n",
            "Epoch 1497/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0906 - mae: 0.0824 - val_loss: 0.3930 - val_mae: 0.1191\n",
            "Epoch 1498/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0992 - mae: 0.0801 - val_loss: 0.3856 - val_mae: 0.1202\n",
            "Epoch 1499/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1022 - mae: 0.0795 - val_loss: 0.3889 - val_mae: 0.1201\n",
            "Epoch 1500/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0970 - mae: 0.0798 - val_loss: 0.3889 - val_mae: 0.1200\n",
            "Epoch 1501/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1159 - mae: 0.0862 - val_loss: 0.3885 - val_mae: 0.1210\n",
            "Epoch 1502/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0991 - mae: 0.0851 - val_loss: 0.3892 - val_mae: 0.1193\n",
            "Epoch 1503/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1014 - mae: 0.0845 - val_loss: 0.3877 - val_mae: 0.1200\n",
            "Epoch 1504/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0756 - mae: 0.0739 - val_loss: 0.3890 - val_mae: 0.1194\n",
            "Epoch 1505/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1127 - mae: 0.0838 - val_loss: 0.3882 - val_mae: 0.1198\n",
            "Epoch 1506/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1222 - mae: 0.0881 - val_loss: 0.3879 - val_mae: 0.1199\n",
            "Epoch 1507/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0717 - mae: 0.0739 - val_loss: 0.3952 - val_mae: 0.1201\n",
            "Epoch 1508/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0736 - mae: 0.0753 - val_loss: 0.3893 - val_mae: 0.1202\n",
            "Epoch 1509/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0939 - mae: 0.0822 - val_loss: 0.3858 - val_mae: 0.1246\n",
            "Epoch 1510/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1173 - mae: 0.0888 - val_loss: 0.3882 - val_mae: 0.1202\n",
            "Epoch 1511/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1388 - mae: 0.0918 - val_loss: 0.3914 - val_mae: 0.1205\n",
            "Epoch 1512/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1077 - mae: 0.0820 - val_loss: 0.3892 - val_mae: 0.1199\n",
            "Epoch 1513/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1067 - mae: 0.0829 - val_loss: 0.3885 - val_mae: 0.1187\n",
            "Epoch 1514/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1298 - mae: 0.0864 - val_loss: 0.3888 - val_mae: 0.1217\n",
            "Epoch 1515/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1123 - mae: 0.0883 - val_loss: 0.3916 - val_mae: 0.1199\n",
            "Epoch 1516/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0876 - mae: 0.0772 - val_loss: 0.3917 - val_mae: 0.1197\n",
            "Epoch 1517/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0935 - mae: 0.0825 - val_loss: 0.3869 - val_mae: 0.1200\n",
            "Epoch 1518/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1265 - mae: 0.0852 - val_loss: 0.3876 - val_mae: 0.1217\n",
            "Epoch 1519/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0973 - mae: 0.0806 - val_loss: 0.3894 - val_mae: 0.1220\n",
            "Epoch 1520/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1195 - mae: 0.0915 - val_loss: 0.3901 - val_mae: 0.1190\n",
            "Epoch 1521/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1287 - mae: 0.0851 - val_loss: 0.3887 - val_mae: 0.1198\n",
            "Epoch 1522/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1097 - mae: 0.0839 - val_loss: 0.3883 - val_mae: 0.1201\n",
            "Epoch 1523/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1047 - mae: 0.0875 - val_loss: 0.3893 - val_mae: 0.1209\n",
            "Epoch 1524/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1313 - mae: 0.0895 - val_loss: 0.3884 - val_mae: 0.1215\n",
            "Epoch 1525/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1003 - mae: 0.0835 - val_loss: 0.3870 - val_mae: 0.1200\n",
            "Epoch 1526/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0902 - mae: 0.0810 - val_loss: 0.3882 - val_mae: 0.1195\n",
            "Epoch 1527/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0814 - mae: 0.0731 - val_loss: 0.3891 - val_mae: 0.1192\n",
            "Epoch 1528/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1109 - mae: 0.0820 - val_loss: 0.3875 - val_mae: 0.1194\n",
            "Epoch 1529/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1007 - mae: 0.0837 - val_loss: 0.3887 - val_mae: 0.1196\n",
            "Epoch 1530/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1293 - mae: 0.0914 - val_loss: 0.3910 - val_mae: 0.1192\n",
            "Epoch 1531/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0840 - mae: 0.0746 - val_loss: 0.3876 - val_mae: 0.1200\n",
            "Epoch 1532/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1114 - mae: 0.0869 - val_loss: 0.3881 - val_mae: 0.1199\n",
            "Epoch 1533/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1185 - mae: 0.0855 - val_loss: 0.3909 - val_mae: 0.1196\n",
            "Epoch 1534/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0765 - mae: 0.0773 - val_loss: 0.3875 - val_mae: 0.1194\n",
            "Epoch 1535/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1022 - mae: 0.0865 - val_loss: 0.3865 - val_mae: 0.1195\n",
            "Epoch 1536/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0848 - mae: 0.0792 - val_loss: 0.3865 - val_mae: 0.1204\n",
            "Epoch 1537/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0635 - mae: 0.0668 - val_loss: 0.3891 - val_mae: 0.1199\n",
            "Epoch 1538/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0940 - mae: 0.0838 - val_loss: 0.3878 - val_mae: 0.1208\n",
            "Epoch 1539/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0818 - mae: 0.0799 - val_loss: 0.3870 - val_mae: 0.1199\n",
            "Epoch 1540/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0856 - mae: 0.0781 - val_loss: 0.3887 - val_mae: 0.1193\n",
            "Epoch 1541/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1256 - mae: 0.0860 - val_loss: 0.3868 - val_mae: 0.1204\n",
            "Epoch 1542/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1242 - mae: 0.0941 - val_loss: 0.3893 - val_mae: 0.1193\n",
            "Epoch 1543/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0897 - mae: 0.0811 - val_loss: 0.3881 - val_mae: 0.1203\n",
            "Epoch 1544/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1043 - mae: 0.0867 - val_loss: 0.3876 - val_mae: 0.1191\n",
            "Epoch 1545/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0788 - mae: 0.0788 - val_loss: 0.3890 - val_mae: 0.1208\n",
            "Epoch 1546/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1104 - mae: 0.0847 - val_loss: 0.3862 - val_mae: 0.1209\n",
            "Epoch 1547/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0846 - mae: 0.0817 - val_loss: 0.3870 - val_mae: 0.1205\n",
            "Epoch 1548/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1057 - mae: 0.0904 - val_loss: 0.3881 - val_mae: 0.1192\n",
            "Epoch 1549/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1023 - mae: 0.0783 - val_loss: 0.3889 - val_mae: 0.1216\n",
            "Epoch 1550/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1109 - mae: 0.0824 - val_loss: 0.3895 - val_mae: 0.1201\n",
            "Epoch 1551/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0867 - mae: 0.0772 - val_loss: 0.3928 - val_mae: 0.1189\n",
            "Epoch 1552/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1167 - mae: 0.0852 - val_loss: 0.3880 - val_mae: 0.1201\n",
            "Epoch 1553/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0909 - mae: 0.0808 - val_loss: 0.3886 - val_mae: 0.1201\n",
            "Epoch 1554/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1191 - mae: 0.0910 - val_loss: 0.3892 - val_mae: 0.1201\n",
            "Epoch 1555/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1084 - mae: 0.0843 - val_loss: 0.3893 - val_mae: 0.1193\n",
            "Epoch 1556/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0740 - mae: 0.0742 - val_loss: 0.3891 - val_mae: 0.1190\n",
            "Epoch 1557/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0918 - mae: 0.0810 - val_loss: 0.3870 - val_mae: 0.1213\n",
            "Epoch 1558/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1120 - mae: 0.0874 - val_loss: 0.3886 - val_mae: 0.1219\n",
            "Epoch 1559/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1226 - mae: 0.0929 - val_loss: 0.3872 - val_mae: 0.1200\n",
            "Epoch 1560/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1069 - mae: 0.0841 - val_loss: 0.3893 - val_mae: 0.1210\n",
            "Epoch 1561/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0983 - mae: 0.0785 - val_loss: 0.3920 - val_mae: 0.1190\n",
            "Epoch 1562/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0767 - mae: 0.0759 - val_loss: 0.3892 - val_mae: 0.1193\n",
            "Epoch 1563/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1008 - mae: 0.0831 - val_loss: 0.3853 - val_mae: 0.1205\n",
            "Epoch 1564/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0905 - mae: 0.0836 - val_loss: 0.3923 - val_mae: 0.1196\n",
            "Epoch 1565/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0718 - mae: 0.0728 - val_loss: 0.3884 - val_mae: 0.1199\n",
            "Epoch 1566/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1261 - mae: 0.0874 - val_loss: 0.3883 - val_mae: 0.1220\n",
            "Epoch 1567/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0957 - mae: 0.0816 - val_loss: 0.3861 - val_mae: 0.1328\n",
            "Epoch 1568/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0888 - mae: 0.0891 - val_loss: 0.3915 - val_mae: 0.1259\n",
            "Epoch 1569/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1404 - mae: 0.1003 - val_loss: 0.3810 - val_mae: 0.1258\n",
            "Epoch 1570/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1409 - mae: 0.0960 - val_loss: 0.3854 - val_mae: 0.1226\n",
            "Epoch 1571/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1122 - mae: 0.0855 - val_loss: 0.3886 - val_mae: 0.1247\n",
            "Epoch 1572/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0826 - mae: 0.0790 - val_loss: 0.3871 - val_mae: 0.1214\n",
            "Epoch 1573/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0828 - mae: 0.0729 - val_loss: 0.3857 - val_mae: 0.1217\n",
            "Epoch 1574/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1139 - mae: 0.0871 - val_loss: 0.3909 - val_mae: 0.1214\n",
            "Epoch 1575/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0965 - mae: 0.0832 - val_loss: 0.3886 - val_mae: 0.1208\n",
            "Epoch 1576/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1126 - mae: 0.0787 - val_loss: 0.3902 - val_mae: 0.1201\n",
            "Epoch 1577/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1148 - mae: 0.0905 - val_loss: 0.3890 - val_mae: 0.1202\n",
            "Epoch 1578/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0693 - mae: 0.0751 - val_loss: 0.3873 - val_mae: 0.1210\n",
            "Epoch 1579/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1031 - mae: 0.0837 - val_loss: 0.3867 - val_mae: 0.1214\n",
            "Epoch 1580/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0990 - mae: 0.0847 - val_loss: 0.3904 - val_mae: 0.1199\n",
            "Epoch 1581/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1638 - mae: 0.0964 - val_loss: 0.3872 - val_mae: 0.1216\n",
            "Epoch 1582/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0858 - mae: 0.0789 - val_loss: 0.3914 - val_mae: 0.1199\n",
            "Epoch 1583/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0706 - mae: 0.0692 - val_loss: 0.3881 - val_mae: 0.1203\n",
            "Epoch 1584/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1273 - mae: 0.0884 - val_loss: 0.3866 - val_mae: 0.1206\n",
            "Epoch 1585/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1119 - mae: 0.0811 - val_loss: 0.3845 - val_mae: 0.1199\n",
            "Epoch 1586/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1021 - mae: 0.0862 - val_loss: 0.3904 - val_mae: 0.1197\n",
            "Epoch 1587/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1441 - mae: 0.0957 - val_loss: 0.3894 - val_mae: 0.1196\n",
            "Epoch 1588/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0885 - mae: 0.0775 - val_loss: 0.3868 - val_mae: 0.1193\n",
            "Epoch 1589/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1145 - mae: 0.0806 - val_loss: 0.3880 - val_mae: 0.1195\n",
            "Epoch 1590/2000\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1218 - mae: 0.0847 - val_loss: 0.3870 - val_mae: 0.1196\n",
            "Epoch 1591/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0916 - mae: 0.0791 - val_loss: 0.3890 - val_mae: 0.1197\n",
            "Epoch 1592/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0785 - mae: 0.0793 - val_loss: 0.3890 - val_mae: 0.1188\n",
            "Epoch 1593/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0992 - mae: 0.0830 - val_loss: 0.3877 - val_mae: 0.1218\n",
            "Epoch 1594/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1266 - mae: 0.0919 - val_loss: 0.3886 - val_mae: 0.1204\n",
            "Epoch 1595/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1140 - mae: 0.0858 - val_loss: 0.3884 - val_mae: 0.1203\n",
            "Epoch 1596/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0870 - mae: 0.0788 - val_loss: 0.3867 - val_mae: 0.1197\n",
            "Epoch 1597/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1078 - mae: 0.0873 - val_loss: 0.3879 - val_mae: 0.1197\n",
            "Epoch 1598/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0998 - mae: 0.0858 - val_loss: 0.3878 - val_mae: 0.1208\n",
            "Epoch 1599/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0933 - mae: 0.0828 - val_loss: 0.3890 - val_mae: 0.1200\n",
            "Epoch 1600/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0794 - mae: 0.0735 - val_loss: 0.3898 - val_mae: 0.1197\n",
            "Epoch 1601/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0893 - mae: 0.0765 - val_loss: 0.3872 - val_mae: 0.1207\n",
            "Epoch 1602/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0891 - mae: 0.0805 - val_loss: 0.3889 - val_mae: 0.1200\n",
            "Epoch 1603/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0906 - mae: 0.0831 - val_loss: 0.3876 - val_mae: 0.1191\n",
            "Epoch 1604/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0978 - mae: 0.0808 - val_loss: 0.3883 - val_mae: 0.1201\n",
            "Epoch 1605/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1011 - mae: 0.0859 - val_loss: 0.3884 - val_mae: 0.1195\n",
            "Epoch 1606/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1161 - mae: 0.0871 - val_loss: 0.3878 - val_mae: 0.1212\n",
            "Epoch 1607/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0922 - mae: 0.0841 - val_loss: 0.3879 - val_mae: 0.1196\n",
            "Epoch 1608/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0910 - mae: 0.0781 - val_loss: 0.3863 - val_mae: 0.1196\n",
            "Epoch 1609/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1220 - mae: 0.0863 - val_loss: 0.3876 - val_mae: 0.1201\n",
            "Epoch 1610/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1290 - mae: 0.0854 - val_loss: 0.3917 - val_mae: 0.1192\n",
            "Epoch 1611/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0856 - mae: 0.0722 - val_loss: 0.3889 - val_mae: 0.1192\n",
            "Epoch 1612/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1018 - mae: 0.0831 - val_loss: 0.3884 - val_mae: 0.1202\n",
            "Epoch 1613/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0794 - mae: 0.0763 - val_loss: 0.3894 - val_mae: 0.1195\n",
            "Epoch 1614/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1501 - mae: 0.0937 - val_loss: 0.3842 - val_mae: 0.1216\n",
            "Epoch 1615/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1297 - mae: 0.0959 - val_loss: 0.3921 - val_mae: 0.1207\n",
            "Epoch 1616/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1049 - mae: 0.0878 - val_loss: 0.3894 - val_mae: 0.1218\n",
            "Epoch 1617/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0777 - mae: 0.0740 - val_loss: 0.3899 - val_mae: 0.1208\n",
            "Epoch 1618/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0909 - mae: 0.0777 - val_loss: 0.3904 - val_mae: 0.1204\n",
            "Epoch 1619/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0952 - mae: 0.0819 - val_loss: 0.3881 - val_mae: 0.1196\n",
            "Epoch 1620/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0833 - mae: 0.0773 - val_loss: 0.3867 - val_mae: 0.1199\n",
            "Epoch 1621/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0797 - mae: 0.0770 - val_loss: 0.3888 - val_mae: 0.1191\n",
            "Epoch 1622/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1466 - mae: 0.0934 - val_loss: 0.3863 - val_mae: 0.1205\n",
            "Epoch 1623/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1147 - mae: 0.0883 - val_loss: 0.3912 - val_mae: 0.1184\n",
            "Epoch 1624/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1105 - mae: 0.0871 - val_loss: 0.3876 - val_mae: 0.1197\n",
            "Epoch 1625/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0819 - mae: 0.0771 - val_loss: 0.3875 - val_mae: 0.1193\n",
            "Epoch 1626/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1241 - mae: 0.0868 - val_loss: 0.3873 - val_mae: 0.1195\n",
            "Epoch 1627/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1197 - mae: 0.0853 - val_loss: 0.3912 - val_mae: 0.1198\n",
            "Epoch 1628/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1135 - mae: 0.0864 - val_loss: 0.3896 - val_mae: 0.1196\n",
            "Epoch 1629/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0962 - mae: 0.0848 - val_loss: 0.3887 - val_mae: 0.1187\n",
            "Epoch 1630/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1175 - mae: 0.0876 - val_loss: 0.3886 - val_mae: 0.1195\n",
            "Epoch 1631/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1085 - mae: 0.0864 - val_loss: 0.3862 - val_mae: 0.1210\n",
            "Epoch 1632/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0843 - mae: 0.0735 - val_loss: 0.3881 - val_mae: 0.1197\n",
            "Epoch 1633/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0787 - mae: 0.0717 - val_loss: 0.3886 - val_mae: 0.1189\n",
            "Epoch 1634/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0989 - mae: 0.0747 - val_loss: 0.3897 - val_mae: 0.1187\n",
            "Epoch 1635/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1139 - mae: 0.0876 - val_loss: 0.3861 - val_mae: 0.1198\n",
            "Epoch 1636/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1023 - mae: 0.0820 - val_loss: 0.3893 - val_mae: 0.1215\n",
            "Epoch 1637/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0892 - mae: 0.0829 - val_loss: 0.3902 - val_mae: 0.1193\n",
            "Epoch 1638/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0968 - mae: 0.0847 - val_loss: 0.3867 - val_mae: 0.1207\n",
            "Epoch 1639/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1003 - mae: 0.0859 - val_loss: 0.3897 - val_mae: 0.1201\n",
            "Epoch 1640/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0862 - mae: 0.0799 - val_loss: 0.3906 - val_mae: 0.1189\n",
            "Epoch 1641/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1270 - mae: 0.0905 - val_loss: 0.3893 - val_mae: 0.1224\n",
            "Epoch 1642/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1068 - mae: 0.0864 - val_loss: 0.3906 - val_mae: 0.1224\n",
            "Epoch 1643/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0828 - mae: 0.0748 - val_loss: 0.3923 - val_mae: 0.1203\n",
            "Epoch 1644/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1113 - mae: 0.0831 - val_loss: 0.3878 - val_mae: 0.1204\n",
            "Epoch 1645/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1118 - mae: 0.0882 - val_loss: 0.3878 - val_mae: 0.1212\n",
            "Epoch 1646/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1734 - mae: 0.1004 - val_loss: 0.3890 - val_mae: 0.1211\n",
            "Epoch 1647/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1081 - mae: 0.0799 - val_loss: 0.3906 - val_mae: 0.1193\n",
            "Epoch 1648/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1036 - mae: 0.0855 - val_loss: 0.3905 - val_mae: 0.1202\n",
            "Epoch 1649/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0735 - mae: 0.0724 - val_loss: 0.3885 - val_mae: 0.1203\n",
            "Epoch 1650/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1150 - mae: 0.0894 - val_loss: 0.3880 - val_mae: 0.1204\n",
            "Epoch 1651/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0911 - mae: 0.0827 - val_loss: 0.3892 - val_mae: 0.1215\n",
            "Epoch 1652/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0596 - mae: 0.0678 - val_loss: 0.3894 - val_mae: 0.1196\n",
            "Epoch 1653/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0870 - mae: 0.0767 - val_loss: 0.3890 - val_mae: 0.1193\n",
            "Epoch 1654/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0825 - mae: 0.0811 - val_loss: 0.3870 - val_mae: 0.1195\n",
            "Epoch 1655/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1038 - mae: 0.0825 - val_loss: 0.3846 - val_mae: 0.1226\n",
            "Epoch 1656/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0766 - mae: 0.0766 - val_loss: 0.3903 - val_mae: 0.1195\n",
            "Epoch 1657/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1102 - mae: 0.0830 - val_loss: 0.3888 - val_mae: 0.1223\n",
            "Epoch 1658/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0794 - mae: 0.0746 - val_loss: 0.3893 - val_mae: 0.1205\n",
            "Epoch 1659/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0955 - mae: 0.0831 - val_loss: 0.3879 - val_mae: 0.1202\n",
            "Epoch 1660/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1020 - mae: 0.0828 - val_loss: 0.3915 - val_mae: 0.1189\n",
            "Epoch 1661/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0943 - mae: 0.0800 - val_loss: 0.3888 - val_mae: 0.1201\n",
            "Epoch 1662/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0851 - mae: 0.0799 - val_loss: 0.3879 - val_mae: 0.1198\n",
            "Epoch 1663/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0808 - mae: 0.0742 - val_loss: 0.3874 - val_mae: 0.1214\n",
            "Epoch 1664/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0956 - mae: 0.0770 - val_loss: 0.3891 - val_mae: 0.1200\n",
            "Epoch 1665/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0774 - mae: 0.0753 - val_loss: 0.3879 - val_mae: 0.1206\n",
            "Epoch 1666/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0999 - mae: 0.0815 - val_loss: 0.3897 - val_mae: 0.1195\n",
            "Epoch 1667/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0820 - mae: 0.0748 - val_loss: 0.3891 - val_mae: 0.1189\n",
            "Epoch 1668/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0983 - mae: 0.0862 - val_loss: 0.3880 - val_mae: 0.1191\n",
            "Epoch 1669/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0786 - mae: 0.0760 - val_loss: 0.3859 - val_mae: 0.1206\n",
            "Epoch 1670/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1233 - mae: 0.0867 - val_loss: 0.3877 - val_mae: 0.1201\n",
            "Epoch 1671/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1035 - mae: 0.0839 - val_loss: 0.3883 - val_mae: 0.1186\n",
            "Epoch 1672/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0991 - mae: 0.0802 - val_loss: 0.3896 - val_mae: 0.1195\n",
            "Epoch 1673/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0964 - mae: 0.0816 - val_loss: 0.3879 - val_mae: 0.1197\n",
            "Epoch 1674/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0995 - mae: 0.0820 - val_loss: 0.3894 - val_mae: 0.1194\n",
            "Epoch 1675/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1008 - mae: 0.0797 - val_loss: 0.3886 - val_mae: 0.1225\n",
            "Epoch 1676/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0812 - mae: 0.0761 - val_loss: 0.3890 - val_mae: 0.1205\n",
            "Epoch 1677/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0968 - mae: 0.0834 - val_loss: 0.3913 - val_mae: 0.1190\n",
            "Epoch 1678/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.0783 - val_loss: 0.3863 - val_mae: 0.1194\n",
            "Epoch 1679/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1148 - mae: 0.0926 - val_loss: 0.3886 - val_mae: 0.1201\n",
            "Epoch 1680/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0823 - mae: 0.0782 - val_loss: 0.3872 - val_mae: 0.1208\n",
            "Epoch 1681/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1051 - mae: 0.0885 - val_loss: 0.3886 - val_mae: 0.1193\n",
            "Epoch 1682/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0926 - mae: 0.0799 - val_loss: 0.3887 - val_mae: 0.1203\n",
            "Epoch 1683/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1153 - mae: 0.0866 - val_loss: 0.3887 - val_mae: 0.1204\n",
            "Epoch 1684/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1016 - mae: 0.0849 - val_loss: 0.3887 - val_mae: 0.1204\n",
            "Epoch 1685/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0891 - mae: 0.0768 - val_loss: 0.3924 - val_mae: 0.1203\n",
            "Epoch 1686/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0775 - mae: 0.0754 - val_loss: 0.3892 - val_mae: 0.1190\n",
            "Epoch 1687/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0631 - mae: 0.0674 - val_loss: 0.3904 - val_mae: 0.1190\n",
            "Epoch 1688/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0760 - mae: 0.0781 - val_loss: 0.3853 - val_mae: 0.1213\n",
            "Epoch 1689/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1019 - mae: 0.0814 - val_loss: 0.3871 - val_mae: 0.1204\n",
            "Epoch 1690/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1132 - mae: 0.0914 - val_loss: 0.3878 - val_mae: 0.1194\n",
            "Epoch 1691/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1566 - mae: 0.0982 - val_loss: 0.3920 - val_mae: 0.1202\n",
            "Epoch 1692/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1063 - mae: 0.0849 - val_loss: 0.3915 - val_mae: 0.1210\n",
            "Epoch 1693/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0660 - mae: 0.0705 - val_loss: 0.3909 - val_mae: 0.1200\n",
            "Epoch 1694/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0878 - mae: 0.0783 - val_loss: 0.3848 - val_mae: 0.1207\n",
            "Epoch 1695/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1076 - mae: 0.0899 - val_loss: 0.3874 - val_mae: 0.1206\n",
            "Epoch 1696/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0911 - mae: 0.0819 - val_loss: 0.3905 - val_mae: 0.1191\n",
            "Epoch 1697/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0771 - mae: 0.0764 - val_loss: 0.3882 - val_mae: 0.1190\n",
            "Epoch 1698/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1225 - mae: 0.0905 - val_loss: 0.3851 - val_mae: 0.1212\n",
            "Epoch 1699/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0842 - mae: 0.0808 - val_loss: 0.3907 - val_mae: 0.1189\n",
            "Epoch 1700/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1121 - mae: 0.0884 - val_loss: 0.3890 - val_mae: 0.1203\n",
            "Epoch 1701/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0904 - mae: 0.0823 - val_loss: 0.3876 - val_mae: 0.1208\n",
            "Epoch 1702/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1009 - mae: 0.0837 - val_loss: 0.3922 - val_mae: 0.1188\n",
            "Epoch 1703/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0890 - mae: 0.0794 - val_loss: 0.3868 - val_mae: 0.1208\n",
            "Epoch 1704/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1363 - mae: 0.0908 - val_loss: 0.3864 - val_mae: 0.1206\n",
            "Epoch 1705/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1290 - mae: 0.0952 - val_loss: 0.3902 - val_mae: 0.1201\n",
            "Epoch 1706/2000\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0901 - mae: 0.0793 - val_loss: 0.3875 - val_mae: 0.1225\n",
            "Epoch 1707/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1124 - mae: 0.0924 - val_loss: 0.4129 - val_mae: 0.1325\n",
            "Epoch 1708/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1029 - mae: 0.0931 - val_loss: 0.3988 - val_mae: 0.1381\n",
            "Epoch 1709/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0920 - mae: 0.0964 - val_loss: 0.3921 - val_mae: 0.1346\n",
            "Epoch 1710/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1129 - mae: 0.1023 - val_loss: 0.3888 - val_mae: 0.1302\n",
            "Epoch 1711/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0874 - mae: 0.0901 - val_loss: 0.3873 - val_mae: 0.1293\n",
            "Epoch 1712/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1325 - mae: 0.0945 - val_loss: 0.3882 - val_mae: 0.1231\n",
            "Epoch 1713/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1068 - mae: 0.0872 - val_loss: 0.3915 - val_mae: 0.1193\n",
            "Epoch 1714/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1106 - mae: 0.0860 - val_loss: 0.3880 - val_mae: 0.1218\n",
            "Epoch 1715/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0799 - mae: 0.0776 - val_loss: 0.3894 - val_mae: 0.1207\n",
            "Epoch 1716/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0700 - mae: 0.0785 - val_loss: 0.3904 - val_mae: 0.1206\n",
            "Epoch 1717/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1075 - mae: 0.0882 - val_loss: 0.3872 - val_mae: 0.1228\n",
            "Epoch 1718/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1119 - mae: 0.0820 - val_loss: 0.3907 - val_mae: 0.1199\n",
            "Epoch 1719/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1429 - mae: 0.0961 - val_loss: 0.3900 - val_mae: 0.1227\n",
            "Epoch 1720/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0807 - mae: 0.0768 - val_loss: 0.3886 - val_mae: 0.1203\n",
            "Epoch 1721/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0960 - mae: 0.0827 - val_loss: 0.3894 - val_mae: 0.1195\n",
            "Epoch 1722/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0892 - mae: 0.0843 - val_loss: 0.3882 - val_mae: 0.1191\n",
            "Epoch 1723/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0999 - mae: 0.0838 - val_loss: 0.3859 - val_mae: 0.1211\n",
            "Epoch 1724/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1641 - mae: 0.0962 - val_loss: 0.3868 - val_mae: 0.1207\n",
            "Epoch 1725/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1121 - mae: 0.0820 - val_loss: 0.3924 - val_mae: 0.1192\n",
            "Epoch 1726/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1179 - mae: 0.0908 - val_loss: 0.3914 - val_mae: 0.1184\n",
            "Epoch 1727/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0803 - mae: 0.0732 - val_loss: 0.3886 - val_mae: 0.1188\n",
            "Epoch 1728/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1057 - mae: 0.0851 - val_loss: 0.3877 - val_mae: 0.1196\n",
            "Epoch 1729/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1200 - mae: 0.0945 - val_loss: 0.3881 - val_mae: 0.1199\n",
            "Epoch 1730/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0758 - mae: 0.0728 - val_loss: 0.3900 - val_mae: 0.1197\n",
            "Epoch 1731/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1061 - mae: 0.0811 - val_loss: 0.3879 - val_mae: 0.1202\n",
            "Epoch 1732/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1028 - mae: 0.0835 - val_loss: 0.3886 - val_mae: 0.1192\n",
            "Epoch 1733/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0793 - mae: 0.0755 - val_loss: 0.3889 - val_mae: 0.1190\n",
            "Epoch 1734/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1369 - mae: 0.0948 - val_loss: 0.3863 - val_mae: 0.1206\n",
            "Epoch 1735/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1409 - mae: 0.0945 - val_loss: 0.3899 - val_mae: 0.1187\n",
            "Epoch 1736/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1017 - mae: 0.0807 - val_loss: 0.3886 - val_mae: 0.1194\n",
            "Epoch 1737/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1417 - mae: 0.0915 - val_loss: 0.3885 - val_mae: 0.1196\n",
            "Epoch 1738/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0974 - mae: 0.0799 - val_loss: 0.3875 - val_mae: 0.1197\n",
            "Epoch 1739/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0833 - mae: 0.0787 - val_loss: 0.3903 - val_mae: 0.1181\n",
            "Epoch 1740/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1569 - mae: 0.0907 - val_loss: 0.3877 - val_mae: 0.1204\n",
            "Epoch 1741/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0716 - mae: 0.0697 - val_loss: 0.3902 - val_mae: 0.1188\n",
            "Epoch 1742/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0858 - mae: 0.0821 - val_loss: 0.3873 - val_mae: 0.1195\n",
            "Epoch 1743/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0739 - mae: 0.0750 - val_loss: 0.3882 - val_mae: 0.1195\n",
            "Epoch 1744/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1078 - mae: 0.0827 - val_loss: 0.3851 - val_mae: 0.1208\n",
            "Epoch 1745/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0923 - mae: 0.0771 - val_loss: 0.3882 - val_mae: 0.1196\n",
            "Epoch 1746/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1056 - mae: 0.0864 - val_loss: 0.3856 - val_mae: 0.1192\n",
            "Epoch 1747/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1203 - mae: 0.0843 - val_loss: 0.3897 - val_mae: 0.1191\n",
            "Epoch 1748/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1427 - mae: 0.0922 - val_loss: 0.3855 - val_mae: 0.1197\n",
            "Epoch 1749/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0897 - mae: 0.0748 - val_loss: 0.3882 - val_mae: 0.1191\n",
            "Epoch 1750/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0838 - mae: 0.0790 - val_loss: 0.3904 - val_mae: 0.1184\n",
            "Epoch 1751/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0850 - mae: 0.0740 - val_loss: 0.3879 - val_mae: 0.1188\n",
            "Epoch 1752/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1264 - mae: 0.0872 - val_loss: 0.3867 - val_mae: 0.1203\n",
            "Epoch 1753/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1119 - mae: 0.0866 - val_loss: 0.3892 - val_mae: 0.1193\n",
            "Epoch 1754/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1016 - mae: 0.0819 - val_loss: 0.3869 - val_mae: 0.1202\n",
            "Epoch 1755/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1271 - mae: 0.0922 - val_loss: 0.3871 - val_mae: 0.1191\n",
            "Epoch 1756/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0716 - mae: 0.0704 - val_loss: 0.3874 - val_mae: 0.1188\n",
            "Epoch 1757/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1526 - mae: 0.0929 - val_loss: 0.3869 - val_mae: 0.1193\n",
            "Epoch 1758/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1366 - mae: 0.0922 - val_loss: 0.3872 - val_mae: 0.1194\n",
            "Epoch 1759/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1208 - mae: 0.0882 - val_loss: 0.3882 - val_mae: 0.1199\n",
            "Epoch 1760/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0723 - mae: 0.0756 - val_loss: 0.3896 - val_mae: 0.1188\n",
            "Epoch 1761/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1096 - mae: 0.0867 - val_loss: 0.3880 - val_mae: 0.1201\n",
            "Epoch 1762/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1077 - mae: 0.0834 - val_loss: 0.3872 - val_mae: 0.1195\n",
            "Epoch 1763/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0895 - mae: 0.0818 - val_loss: 0.3883 - val_mae: 0.1192\n",
            "Epoch 1764/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1181 - mae: 0.0857 - val_loss: 0.3897 - val_mae: 0.1208\n",
            "Epoch 1765/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1153 - mae: 0.0836 - val_loss: 0.3877 - val_mae: 0.1196\n",
            "Epoch 1766/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0933 - mae: 0.0814 - val_loss: 0.3893 - val_mae: 0.1194\n",
            "Epoch 1767/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1159 - mae: 0.0827 - val_loss: 0.3880 - val_mae: 0.1202\n",
            "Epoch 1768/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1515 - mae: 0.0970 - val_loss: 0.3877 - val_mae: 0.1199\n",
            "Epoch 1769/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0966 - mae: 0.0778 - val_loss: 0.3899 - val_mae: 0.1191\n",
            "Epoch 1770/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0977 - mae: 0.0845 - val_loss: 0.3883 - val_mae: 0.1181\n",
            "Epoch 1771/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1348 - mae: 0.0847 - val_loss: 0.3868 - val_mae: 0.1201\n",
            "Epoch 1772/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0882 - mae: 0.0782 - val_loss: 0.3890 - val_mae: 0.1191\n",
            "Epoch 1773/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0834 - mae: 0.0765 - val_loss: 0.3864 - val_mae: 0.1199\n",
            "Epoch 1774/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0803 - mae: 0.0780 - val_loss: 0.3879 - val_mae: 0.1197\n",
            "Epoch 1775/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0804 - mae: 0.0742 - val_loss: 0.3861 - val_mae: 0.1208\n",
            "Epoch 1776/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1287 - mae: 0.0855 - val_loss: 0.3887 - val_mae: 0.1198\n",
            "Epoch 1777/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0779 - mae: 0.0715 - val_loss: 0.3892 - val_mae: 0.1194\n",
            "Epoch 1778/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1175 - mae: 0.0879 - val_loss: 0.3896 - val_mae: 0.1193\n",
            "Epoch 1779/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1048 - mae: 0.0794 - val_loss: 0.3890 - val_mae: 0.1190\n",
            "Epoch 1780/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1449 - mae: 0.0925 - val_loss: 0.3866 - val_mae: 0.1197\n",
            "Epoch 1781/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1094 - mae: 0.0820 - val_loss: 0.3899 - val_mae: 0.1192\n",
            "Epoch 1782/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1097 - mae: 0.0838 - val_loss: 0.3899 - val_mae: 0.1190\n",
            "Epoch 1783/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0855 - mae: 0.0813 - val_loss: 0.3890 - val_mae: 0.1186\n",
            "Epoch 1784/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0648 - mae: 0.0673 - val_loss: 0.3894 - val_mae: 0.1187\n",
            "Epoch 1785/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0947 - mae: 0.0782 - val_loss: 0.3863 - val_mae: 0.1204\n",
            "Epoch 1786/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1110 - mae: 0.0848 - val_loss: 0.3898 - val_mae: 0.1203\n",
            "Epoch 1787/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0662 - mae: 0.0718 - val_loss: 0.3901 - val_mae: 0.1192\n",
            "Epoch 1788/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1202 - mae: 0.0841 - val_loss: 0.3862 - val_mae: 0.1221\n",
            "Epoch 1789/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0860 - mae: 0.0805 - val_loss: 0.3882 - val_mae: 0.1200\n",
            "Epoch 1790/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0892 - mae: 0.0852 - val_loss: 0.3923 - val_mae: 0.1183\n",
            "Epoch 1791/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0901 - mae: 0.0800 - val_loss: 0.3876 - val_mae: 0.1201\n",
            "Epoch 1792/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1000 - mae: 0.0762 - val_loss: 0.3855 - val_mae: 0.1212\n",
            "Epoch 1793/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0856 - mae: 0.0836 - val_loss: 0.3902 - val_mae: 0.1193\n",
            "Epoch 1794/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0868 - mae: 0.0805 - val_loss: 0.3885 - val_mae: 0.1201\n",
            "Epoch 1795/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0795 - mae: 0.0761 - val_loss: 0.3875 - val_mae: 0.1199\n",
            "Epoch 1796/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0890 - mae: 0.0771 - val_loss: 0.3870 - val_mae: 0.1195\n",
            "Epoch 1797/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1234 - mae: 0.0915 - val_loss: 0.3875 - val_mae: 0.1199\n",
            "Epoch 1798/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0898 - mae: 0.0795 - val_loss: 0.3881 - val_mae: 0.1188\n",
            "Epoch 1799/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1069 - mae: 0.0836 - val_loss: 0.3857 - val_mae: 0.1187\n",
            "Epoch 1800/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0891 - mae: 0.0754 - val_loss: 0.3878 - val_mae: 0.1187\n",
            "Epoch 1801/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0870 - mae: 0.0768 - val_loss: 0.3868 - val_mae: 0.1194\n",
            "Epoch 1802/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1353 - mae: 0.0899 - val_loss: 0.3861 - val_mae: 0.1201\n",
            "Epoch 1803/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1295 - mae: 0.0813 - val_loss: 0.3885 - val_mae: 0.1199\n",
            "Epoch 1804/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0805 - mae: 0.0800 - val_loss: 0.3902 - val_mae: 0.1195\n",
            "Epoch 1805/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1336 - mae: 0.0922 - val_loss: 0.3887 - val_mae: 0.1219\n",
            "Epoch 1806/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1086 - mae: 0.0885 - val_loss: 0.3882 - val_mae: 0.1193\n",
            "Epoch 1807/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0645 - mae: 0.0728 - val_loss: 0.3902 - val_mae: 0.1187\n",
            "Epoch 1808/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0800 - mae: 0.0787 - val_loss: 0.3857 - val_mae: 0.1203\n",
            "Epoch 1809/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0842 - mae: 0.0747 - val_loss: 0.3871 - val_mae: 0.1202\n",
            "Epoch 1810/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1388 - mae: 0.0902 - val_loss: 0.3891 - val_mae: 0.1197\n",
            "Epoch 1811/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1154 - mae: 0.0904 - val_loss: 0.3898 - val_mae: 0.1200\n",
            "Epoch 1812/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1385 - mae: 0.0942 - val_loss: 0.3884 - val_mae: 0.1187\n",
            "Epoch 1813/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1341 - mae: 0.0938 - val_loss: 0.3876 - val_mae: 0.1189\n",
            "Epoch 1814/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1001 - mae: 0.0824 - val_loss: 0.3878 - val_mae: 0.1196\n",
            "Epoch 1815/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0870 - mae: 0.0762 - val_loss: 0.3895 - val_mae: 0.1195\n",
            "Epoch 1816/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0939 - mae: 0.0815 - val_loss: 0.3899 - val_mae: 0.1180\n",
            "Epoch 1817/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0791 - mae: 0.0741 - val_loss: 0.3890 - val_mae: 0.1188\n",
            "Epoch 1818/2000\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0726 - mae: 0.0713 - val_loss: 0.3896 - val_mae: 0.1196\n",
            "Epoch 1819/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1275 - mae: 0.0900 - val_loss: 0.3879 - val_mae: 0.1212\n",
            "Epoch 1820/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1091 - mae: 0.0831 - val_loss: 0.3872 - val_mae: 0.1205\n",
            "Epoch 1821/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0907 - mae: 0.0758 - val_loss: 0.3875 - val_mae: 0.1191\n",
            "Epoch 1822/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0988 - mae: 0.0852 - val_loss: 0.3892 - val_mae: 0.1187\n",
            "Epoch 1823/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1132 - mae: 0.0874 - val_loss: 0.3893 - val_mae: 0.1202\n",
            "Epoch 1824/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1104 - mae: 0.0878 - val_loss: 0.3881 - val_mae: 0.1244\n",
            "Epoch 1825/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1064 - mae: 0.0884 - val_loss: 0.3891 - val_mae: 0.1199\n",
            "Epoch 1826/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0940 - mae: 0.0843 - val_loss: 0.3875 - val_mae: 0.1220\n",
            "Epoch 1827/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0793 - mae: 0.0785 - val_loss: 0.3889 - val_mae: 0.1211\n",
            "Epoch 1828/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1210 - mae: 0.0839 - val_loss: 0.3900 - val_mae: 0.1208\n",
            "Epoch 1829/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1039 - mae: 0.0808 - val_loss: 0.3896 - val_mae: 0.1206\n",
            "Epoch 1830/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0756 - mae: 0.0753 - val_loss: 0.3873 - val_mae: 0.1213\n",
            "Epoch 1831/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0595 - mae: 0.0704 - val_loss: 0.3873 - val_mae: 0.1195\n",
            "Epoch 1832/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1495 - mae: 0.0958 - val_loss: 0.3887 - val_mae: 0.1200\n",
            "Epoch 1833/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0785 - mae: 0.0747 - val_loss: 0.3888 - val_mae: 0.1193\n",
            "Epoch 1834/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1251 - mae: 0.0837 - val_loss: 0.3868 - val_mae: 0.1199\n",
            "Epoch 1835/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0816 - mae: 0.0776 - val_loss: 0.3871 - val_mae: 0.1198\n",
            "Epoch 1836/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1097 - mae: 0.0832 - val_loss: 0.3878 - val_mae: 0.1200\n",
            "Epoch 1837/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1027 - mae: 0.0838 - val_loss: 0.3886 - val_mae: 0.1201\n",
            "Epoch 1838/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1101 - mae: 0.0821 - val_loss: 0.3900 - val_mae: 0.1195\n",
            "Epoch 1839/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0903 - mae: 0.0819 - val_loss: 0.3930 - val_mae: 0.1190\n",
            "Epoch 1840/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1370 - mae: 0.0884 - val_loss: 0.3863 - val_mae: 0.1201\n",
            "Epoch 1841/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0977 - mae: 0.0842 - val_loss: 0.3878 - val_mae: 0.1182\n",
            "Epoch 1842/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1294 - mae: 0.0889 - val_loss: 0.3860 - val_mae: 0.1201\n",
            "Epoch 1843/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1113 - mae: 0.0809 - val_loss: 0.3864 - val_mae: 0.1194\n",
            "Epoch 1844/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1146 - mae: 0.0867 - val_loss: 0.3874 - val_mae: 0.1189\n",
            "Epoch 1845/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0919 - mae: 0.0806 - val_loss: 0.3889 - val_mae: 0.1192\n",
            "Epoch 1846/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0908 - mae: 0.0802 - val_loss: 0.3876 - val_mae: 0.1193\n",
            "Epoch 1847/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1217 - mae: 0.0887 - val_loss: 0.3873 - val_mae: 0.1199\n",
            "Epoch 1848/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0909 - mae: 0.0802 - val_loss: 0.3859 - val_mae: 0.1195\n",
            "Epoch 1849/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0855 - mae: 0.0805 - val_loss: 0.3878 - val_mae: 0.1186\n",
            "Epoch 1850/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1218 - mae: 0.0908 - val_loss: 0.3873 - val_mae: 0.1207\n",
            "Epoch 1851/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0793 - mae: 0.0759 - val_loss: 0.3893 - val_mae: 0.1215\n",
            "Epoch 1852/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1035 - mae: 0.0887 - val_loss: 0.3867 - val_mae: 0.1198\n",
            "Epoch 1853/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1269 - mae: 0.0904 - val_loss: 0.3896 - val_mae: 0.1195\n",
            "Epoch 1854/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1328 - mae: 0.0925 - val_loss: 0.3861 - val_mae: 0.1207\n",
            "Epoch 1855/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1083 - mae: 0.0888 - val_loss: 0.3895 - val_mae: 0.1189\n",
            "Epoch 1856/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0930 - mae: 0.0834 - val_loss: 0.3915 - val_mae: 0.1258\n",
            "Epoch 1857/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0978 - mae: 0.0936 - val_loss: 0.3880 - val_mae: 0.1220\n",
            "Epoch 1858/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1200 - mae: 0.0907 - val_loss: 0.3879 - val_mae: 0.1222\n",
            "Epoch 1859/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1184 - mae: 0.0834 - val_loss: 0.3892 - val_mae: 0.1191\n",
            "Epoch 1860/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1210 - mae: 0.0874 - val_loss: 0.3891 - val_mae: 0.1190\n",
            "Epoch 1861/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1155 - mae: 0.0878 - val_loss: 0.3875 - val_mae: 0.1217\n",
            "Epoch 1862/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0773 - mae: 0.0768 - val_loss: 0.3901 - val_mae: 0.1201\n",
            "Epoch 1863/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0985 - mae: 0.0789 - val_loss: 0.3887 - val_mae: 0.1199\n",
            "Epoch 1864/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1032 - mae: 0.0850 - val_loss: 0.3888 - val_mae: 0.1191\n",
            "Epoch 1865/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0918 - mae: 0.0806 - val_loss: 0.3880 - val_mae: 0.1199\n",
            "Epoch 1866/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1242 - mae: 0.0909 - val_loss: 0.3902 - val_mae: 0.1193\n",
            "Epoch 1867/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0824 - mae: 0.0765 - val_loss: 0.3882 - val_mae: 0.1191\n",
            "Epoch 1868/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1292 - mae: 0.0893 - val_loss: 0.3874 - val_mae: 0.1207\n",
            "Epoch 1869/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1248 - mae: 0.0893 - val_loss: 0.3899 - val_mae: 0.1197\n",
            "Epoch 1870/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1326 - mae: 0.0909 - val_loss: 0.3916 - val_mae: 0.1201\n",
            "Epoch 1871/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1402 - mae: 0.0948 - val_loss: 0.3916 - val_mae: 0.1197\n",
            "Epoch 1872/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0835 - mae: 0.0738 - val_loss: 0.3912 - val_mae: 0.1191\n",
            "Epoch 1873/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0789 - mae: 0.0734 - val_loss: 0.3878 - val_mae: 0.1194\n",
            "Epoch 1874/2000\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0724 - mae: 0.0743 - val_loss: 0.3886 - val_mae: 0.1196\n",
            "Epoch 1875/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1407 - mae: 0.0895 - val_loss: 0.3860 - val_mae: 0.1214\n",
            "Epoch 1876/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0832 - mae: 0.0783 - val_loss: 0.3876 - val_mae: 0.1194\n",
            "Epoch 1877/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0983 - mae: 0.0858 - val_loss: 0.3881 - val_mae: 0.1220\n",
            "Epoch 1878/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0813 - mae: 0.0790 - val_loss: 0.3891 - val_mae: 0.1192\n",
            "Epoch 1879/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0915 - mae: 0.0799 - val_loss: 0.3896 - val_mae: 0.1192\n",
            "Epoch 1880/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0862 - mae: 0.0809 - val_loss: 0.3873 - val_mae: 0.1197\n",
            "Epoch 1881/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1064 - mae: 0.0837 - val_loss: 0.3887 - val_mae: 0.1184\n",
            "Epoch 1882/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0925 - mae: 0.0798 - val_loss: 0.3864 - val_mae: 0.1190\n",
            "Epoch 1883/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0984 - mae: 0.0780 - val_loss: 0.3889 - val_mae: 0.1193\n",
            "Epoch 1884/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1460 - mae: 0.0962 - val_loss: 0.3872 - val_mae: 0.1193\n",
            "Epoch 1885/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0773 - mae: 0.0777 - val_loss: 0.3914 - val_mae: 0.1193\n",
            "Epoch 1886/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0804 - mae: 0.0794 - val_loss: 0.3883 - val_mae: 0.1223\n",
            "Epoch 1887/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1146 - mae: 0.0911 - val_loss: 0.3857 - val_mae: 0.1224\n",
            "Epoch 1888/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1150 - mae: 0.0836 - val_loss: 0.3898 - val_mae: 0.1202\n",
            "Epoch 1889/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0943 - mae: 0.0776 - val_loss: 0.3888 - val_mae: 0.1192\n",
            "Epoch 1890/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1205 - mae: 0.0880 - val_loss: 0.3900 - val_mae: 0.1190\n",
            "Epoch 1891/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1042 - mae: 0.0852 - val_loss: 0.3883 - val_mae: 0.1192\n",
            "Epoch 1892/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1192 - mae: 0.0843 - val_loss: 0.3907 - val_mae: 0.1202\n",
            "Epoch 1893/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0933 - mae: 0.0834 - val_loss: 0.3898 - val_mae: 0.1194\n",
            "Epoch 1894/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0829 - mae: 0.0738 - val_loss: 0.3900 - val_mae: 0.1198\n",
            "Epoch 1895/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0995 - mae: 0.0833 - val_loss: 0.3896 - val_mae: 0.1195\n",
            "Epoch 1896/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1101 - mae: 0.0829 - val_loss: 0.3866 - val_mae: 0.1205\n",
            "Epoch 1897/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1163 - mae: 0.0881 - val_loss: 0.3888 - val_mae: 0.1199\n",
            "Epoch 1898/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0945 - mae: 0.0825 - val_loss: 0.3868 - val_mae: 0.1194\n",
            "Epoch 1899/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1039 - mae: 0.0847 - val_loss: 0.3895 - val_mae: 0.1191\n",
            "Epoch 1900/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1128 - mae: 0.0867 - val_loss: 0.3903 - val_mae: 0.1191\n",
            "Epoch 1901/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0811 - mae: 0.0723 - val_loss: 0.3894 - val_mae: 0.1190\n",
            "Epoch 1902/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0977 - mae: 0.0769 - val_loss: 0.3895 - val_mae: 0.1200\n",
            "Epoch 1903/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0762 - mae: 0.0745 - val_loss: 0.3902 - val_mae: 0.1194\n",
            "Epoch 1904/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0720 - mae: 0.0763 - val_loss: 0.3894 - val_mae: 0.1195\n",
            "Epoch 1905/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1214 - mae: 0.0901 - val_loss: 0.3876 - val_mae: 0.1201\n",
            "Epoch 1906/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0779 - mae: 0.0690 - val_loss: 0.3879 - val_mae: 0.1206\n",
            "Epoch 1907/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0929 - mae: 0.0827 - val_loss: 0.3891 - val_mae: 0.1198\n",
            "Epoch 1908/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1017 - mae: 0.0823 - val_loss: 0.3875 - val_mae: 0.1196\n",
            "Epoch 1909/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1108 - mae: 0.0854 - val_loss: 0.3879 - val_mae: 0.1194\n",
            "Epoch 1910/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0809 - mae: 0.0762 - val_loss: 0.3913 - val_mae: 0.1181\n",
            "Epoch 1911/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1103 - mae: 0.0847 - val_loss: 0.3873 - val_mae: 0.1210\n",
            "Epoch 1912/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1084 - mae: 0.0876 - val_loss: 0.3889 - val_mae: 0.1197\n",
            "Epoch 1913/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1024 - mae: 0.0832 - val_loss: 0.3902 - val_mae: 0.1195\n",
            "Epoch 1914/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1181 - mae: 0.0866 - val_loss: 0.3891 - val_mae: 0.1191\n",
            "Epoch 1915/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1369 - mae: 0.0884 - val_loss: 0.3883 - val_mae: 0.1201\n",
            "Epoch 1916/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1196 - mae: 0.0866 - val_loss: 0.3882 - val_mae: 0.1187\n",
            "Epoch 1917/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0909 - mae: 0.0812 - val_loss: 0.3873 - val_mae: 0.1194\n",
            "Epoch 1918/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1014 - mae: 0.0814 - val_loss: 0.3867 - val_mae: 0.1190\n",
            "Epoch 1919/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1016 - mae: 0.0794 - val_loss: 0.3877 - val_mae: 0.1231\n",
            "Epoch 1920/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0919 - mae: 0.0812 - val_loss: 0.3860 - val_mae: 0.1202\n",
            "Epoch 1921/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0825 - mae: 0.0788 - val_loss: 0.3883 - val_mae: 0.1219\n",
            "Epoch 1922/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0913 - mae: 0.0826 - val_loss: 0.3864 - val_mae: 0.1190\n",
            "Epoch 1923/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1009 - mae: 0.0787 - val_loss: 0.3882 - val_mae: 0.1202\n",
            "Epoch 1924/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0935 - mae: 0.0837 - val_loss: 0.3862 - val_mae: 0.1192\n",
            "Epoch 1925/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0929 - mae: 0.0802 - val_loss: 0.3849 - val_mae: 0.1198\n",
            "Epoch 1926/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0844 - mae: 0.0795 - val_loss: 0.3864 - val_mae: 0.1182\n",
            "Epoch 1927/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1016 - mae: 0.0816 - val_loss: 0.3861 - val_mae: 0.1196\n",
            "Epoch 1928/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1006 - mae: 0.0845 - val_loss: 0.3861 - val_mae: 0.1204\n",
            "Epoch 1929/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1340 - mae: 0.0876 - val_loss: 0.3884 - val_mae: 0.1211\n",
            "Epoch 1930/2000\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1129 - mae: 0.0877 - val_loss: 0.3881 - val_mae: 0.1201\n",
            "Epoch 1931/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0879 - mae: 0.0791 - val_loss: 0.3868 - val_mae: 0.1197\n",
            "Epoch 1932/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0729 - mae: 0.0728 - val_loss: 0.3888 - val_mae: 0.1187\n",
            "Epoch 1933/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0943 - mae: 0.0810 - val_loss: 0.3882 - val_mae: 0.1192\n",
            "Epoch 1934/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0891 - mae: 0.0767 - val_loss: 0.3859 - val_mae: 0.1194\n",
            "Epoch 1935/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1165 - mae: 0.0886 - val_loss: 0.3855 - val_mae: 0.1188\n",
            "Epoch 1936/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0916 - mae: 0.0817 - val_loss: 0.3862 - val_mae: 0.1187\n",
            "Epoch 1937/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0824 - mae: 0.0785 - val_loss: 0.3873 - val_mae: 0.1196\n",
            "Epoch 1938/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0801 - mae: 0.0738 - val_loss: 0.3870 - val_mae: 0.1201\n",
            "Epoch 1939/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1032 - mae: 0.0832 - val_loss: 0.3894 - val_mae: 0.1194\n",
            "Epoch 1940/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0869 - mae: 0.0808 - val_loss: 0.3862 - val_mae: 0.1196\n",
            "Epoch 1941/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0921 - mae: 0.0825 - val_loss: 0.3875 - val_mae: 0.1186\n",
            "Epoch 1942/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1382 - mae: 0.0897 - val_loss: 0.3850 - val_mae: 0.1205\n",
            "Epoch 1943/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0834 - mae: 0.0805 - val_loss: 0.3898 - val_mae: 0.1192\n",
            "Epoch 1944/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1084 - mae: 0.0811 - val_loss: 0.3873 - val_mae: 0.1190\n",
            "Epoch 1945/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1357 - mae: 0.0886 - val_loss: 0.3872 - val_mae: 0.1190\n",
            "Epoch 1946/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1080 - mae: 0.0857 - val_loss: 0.3887 - val_mae: 0.1188\n",
            "Epoch 1947/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1360 - mae: 0.0966 - val_loss: 0.3862 - val_mae: 0.1195\n",
            "Epoch 1948/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0986 - mae: 0.0792 - val_loss: 0.3876 - val_mae: 0.1190\n",
            "Epoch 1949/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1208 - mae: 0.0826 - val_loss: 0.3885 - val_mae: 0.1183\n",
            "Epoch 1950/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0984 - mae: 0.0815 - val_loss: 0.3863 - val_mae: 0.1219\n",
            "Epoch 1951/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0950 - mae: 0.0817 - val_loss: 0.3907 - val_mae: 0.1196\n",
            "Epoch 1952/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1273 - mae: 0.0898 - val_loss: 0.3883 - val_mae: 0.1206\n",
            "Epoch 1953/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0997 - mae: 0.0814 - val_loss: 0.3865 - val_mae: 0.1229\n",
            "Epoch 1954/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0949 - mae: 0.0862 - val_loss: 0.3874 - val_mae: 0.1231\n",
            "Epoch 1955/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0771 - mae: 0.0741 - val_loss: 0.3880 - val_mae: 0.1207\n",
            "Epoch 1956/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1086 - mae: 0.0891 - val_loss: 0.3894 - val_mae: 0.1249\n",
            "Epoch 1957/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1212 - mae: 0.0906 - val_loss: 0.3860 - val_mae: 0.1224\n",
            "Epoch 1958/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0918 - mae: 0.0840 - val_loss: 0.3886 - val_mae: 0.1220\n",
            "Epoch 1959/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0806 - mae: 0.0793 - val_loss: 0.3877 - val_mae: 0.1213\n",
            "Epoch 1960/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1117 - mae: 0.0854 - val_loss: 0.3875 - val_mae: 0.1220\n",
            "Epoch 1961/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0949 - mae: 0.0844 - val_loss: 0.3873 - val_mae: 0.1201\n",
            "Epoch 1962/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1060 - mae: 0.0860 - val_loss: 0.3898 - val_mae: 0.1198\n",
            "Epoch 1963/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0958 - mae: 0.0813 - val_loss: 0.3889 - val_mae: 0.1210\n",
            "Epoch 1964/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0981 - mae: 0.0785 - val_loss: 0.3894 - val_mae: 0.1194\n",
            "Epoch 1965/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0776 - mae: 0.0752 - val_loss: 0.3857 - val_mae: 0.1208\n",
            "Epoch 1966/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1001 - mae: 0.0824 - val_loss: 0.3875 - val_mae: 0.1190\n",
            "Epoch 1967/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1199 - mae: 0.0882 - val_loss: 0.3876 - val_mae: 0.1189\n",
            "Epoch 1968/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0867 - mae: 0.0801 - val_loss: 0.3862 - val_mae: 0.1204\n",
            "Epoch 1969/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1024 - mae: 0.0857 - val_loss: 0.3876 - val_mae: 0.1189\n",
            "Epoch 1970/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0907 - mae: 0.0802 - val_loss: 0.3893 - val_mae: 0.1193\n",
            "Epoch 1971/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0782 - mae: 0.0806 - val_loss: 0.3890 - val_mae: 0.1191\n",
            "Epoch 1972/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1145 - mae: 0.0915 - val_loss: 0.3887 - val_mae: 0.1193\n",
            "Epoch 1973/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1002 - mae: 0.0858 - val_loss: 0.3856 - val_mae: 0.1198\n",
            "Epoch 1974/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1040 - mae: 0.0793 - val_loss: 0.3885 - val_mae: 0.1203\n",
            "Epoch 1975/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0870 - mae: 0.0820 - val_loss: 0.3901 - val_mae: 0.1196\n",
            "Epoch 1976/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1008 - mae: 0.0865 - val_loss: 0.3883 - val_mae: 0.1195\n",
            "Epoch 1977/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1246 - mae: 0.0938 - val_loss: 0.3865 - val_mae: 0.1209\n",
            "Epoch 1978/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0718 - mae: 0.0722 - val_loss: 0.3908 - val_mae: 0.1189\n",
            "Epoch 1979/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1451 - mae: 0.0939 - val_loss: 0.4127 - val_mae: 0.1237\n",
            "Epoch 1980/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1439 - mae: 0.0966 - val_loss: 0.4010 - val_mae: 0.1231\n",
            "Epoch 1981/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0956 - mae: 0.0833 - val_loss: 0.3874 - val_mae: 0.1296\n",
            "Epoch 1982/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0955 - mae: 0.0895 - val_loss: 0.3882 - val_mae: 0.1314\n",
            "Epoch 1983/2000\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.1008 - mae: 0.0927 - val_loss: 0.3908 - val_mae: 0.1290\n",
            "Epoch 1984/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0824 - mae: 0.0856 - val_loss: 0.3928 - val_mae: 0.1279\n",
            "Epoch 1985/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0987 - mae: 0.0901 - val_loss: 0.3867 - val_mae: 0.1266\n",
            "Epoch 1986/2000\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.0838 - mae: 0.0846 - val_loss: 0.3874 - val_mae: 0.1374\n",
            "Epoch 1987/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0896 - mae: 0.0887 - val_loss: 0.4238 - val_mae: 0.1501\n",
            "Epoch 1988/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1308 - mae: 0.1077 - val_loss: 0.3866 - val_mae: 0.1311\n",
            "Epoch 1989/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1144 - mae: 0.0938 - val_loss: 0.3908 - val_mae: 0.1274\n",
            "Epoch 1990/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0976 - mae: 0.0877 - val_loss: 0.3884 - val_mae: 0.1248\n",
            "Epoch 1991/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1184 - mae: 0.0916 - val_loss: 0.3879 - val_mae: 0.1230\n",
            "Epoch 1992/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0725 - mae: 0.0720 - val_loss: 0.3899 - val_mae: 0.1223\n",
            "Epoch 1993/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0994 - mae: 0.0834 - val_loss: 0.3879 - val_mae: 0.1226\n",
            "Epoch 1994/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1157 - mae: 0.0938 - val_loss: 0.3880 - val_mae: 0.1222\n",
            "Epoch 1995/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1100 - mae: 0.0866 - val_loss: 0.3873 - val_mae: 0.1227\n",
            "Epoch 1996/2000\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.0852 - mae: 0.0797 - val_loss: 0.3900 - val_mae: 0.1212\n",
            "Epoch 1997/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1415 - mae: 0.0917 - val_loss: 0.3892 - val_mae: 0.1216\n",
            "Epoch 1998/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0842 - mae: 0.0817 - val_loss: 0.3882 - val_mae: 0.1213\n",
            "Epoch 1999/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1223 - mae: 0.0909 - val_loss: 0.3877 - val_mae: 0.1217\n",
            "Epoch 2000/2000\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1512 - mae: 0.0966 - val_loss: 0.3868 - val_mae: 0.1218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEyC9uuzjZPB",
        "outputId": "f8fd9fce-badd-4f3c-8fa0-8ed648abbb8c"
      },
      "source": [
        "# モデルの評価\n",
        "score = model_2.evaluate([x_fs_test_n, x_fp_test_n], y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test mae:', score[1])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255/255 [==============================] - 0s 2ms/step - loss: 0.2324 - mae: 0.1043\n",
            "Test loss: 0.23240745067596436\n",
            "Test mae: 0.10426082462072372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "J1ONSYXujZPB",
        "outputId": "88b4e5ba-df5a-41e4-ac18-a0d2706da5ba"
      },
      "source": [
        "# 学習経過の可視化\n",
        "loss     = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "nb_epoch = len(loss)\n",
        "for i in range(900):\n",
        "  if max(loss)>2: \n",
        "    loss = loss[1:]\n",
        "    val_loss = val_loss[1:]\n",
        "  else:\n",
        "    plt.plot(range(i,nb_epoch), loss, marker='.', label='loss')\n",
        "    plt.plot(range(i,nb_epoch), val_loss, marker='.', label='val_loss')\n",
        "    break\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "-0xqmhPAjZPB",
        "outputId": "bd0fc0d8-ab30-4992-f215-cd856d353272"
      },
      "source": [
        "# 学習経過の可視化\n",
        "mae     = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "nb_epoch = len(mae)\n",
        "for i in range(900):\n",
        "  if max(mae)>2: \n",
        "    mae = mae[1:]\n",
        "    val_mae = val_mae[1:]\n",
        "  else:\n",
        "    plt.plot(range(i,nb_epoch), mae,     marker='.', label='mae')\n",
        "    plt.plot(range(i,nb_epoch), val_mae, marker='.', label='val_mae')\n",
        "    break\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('mae')\n",
        "plt.show()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSHLHy2HjZPC"
      },
      "source": [
        "# 学習モデルの保存\n",
        "model_2.save(str(n)+\"_random.seed(\"+str(seed)+\")_train\"+str(train)+\".h5\")"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja60HEp4k6GP"
      },
      "source": [
        "# model_3\n",
        "\n",
        "# データの前処理\n",
        "\n",
        "\n",
        "## 変数設定(各条件を変えてたくさん試すため)\n",
        "train = 0.8                 #train:validのtrainデータの割合\n",
        "seed = 1                       \n",
        "random.seed(seed)           #乱数seed固定\n",
        "\n",
        "\n",
        "## データ加工\n",
        "\n",
        "### データ抽出(各データをランダムにシャッフル→train,valid,testに分割。各大きさのデータが同じ数だけ抽出される。)\n",
        "for i in range (1,6):\n",
        "  exec(\"lst_fs\"+str(i)+\"_shuffle = random.sample(lst_fs\"+str(i)+\", len(lst_fs\"+str(i)+\"))\")  \n",
        "  exec(\"lst_fs\"+str(i)+\"_train = lst_fs\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")       \n",
        "  exec(\"lst_fs\"+str(i)+\"_valid = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\")          \n",
        "  exec(\"lst_fs\"+str(i)+\"_test = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_shuffle = random.sample(lst_fp\"+str(i)+\", len(lst_fp\"+str(i)+\"))\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_train = lst_fp\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_valid = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\") \n",
        "  exec(\"lst_fp\"+str(i)+\"_test = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "\n",
        "### train,valid,testの各々について、大きさ、位置、表面温度分布データに分割\n",
        "for i in range (1,6):\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_train = [r[0] for r in lst_fs\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_train = [r[0] for r in lst_fp\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_train = [r[1:-1] for r in lst_fp\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_valid = [r[0] for r in lst_fs\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_valid = [r[0] for r in lst_fp\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_valid = [r[1:-1] for r in lst_fp\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_test = [r[0] for r in lst_fs\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_test = [r[0] for r in lst_fp\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_test = [r[1:-1] for r in lst_fp\"+str(i)+\"_test]\")\n",
        "\n",
        "### データを結合(入力データ・正解データの大枠完成)\n",
        "lst_x_fs_train = lst_x_fs1_train + lst_x_fs2_train + lst_x_fs3_train + lst_x_fs4_train + lst_x_fs5_train\n",
        "lst_x_fp_train = lst_x_fp1_train + lst_x_fp2_train + lst_x_fp3_train + lst_x_fp4_train + lst_x_fp5_train\n",
        "lst_y_train = lst_y1_train + lst_y2_train + lst_y3_train + lst_y4_train + lst_y5_train\n",
        "\n",
        "lst_x_fs_valid = lst_x_fs1_valid + lst_x_fs2_valid + lst_x_fs3_valid + lst_x_fs4_valid + lst_x_fs5_valid\n",
        "lst_x_fp_valid = lst_x_fp1_valid + lst_x_fp2_valid + lst_x_fp3_valid + lst_x_fp4_valid + lst_x_fp5_valid\n",
        "lst_y_valid = lst_y1_valid + lst_y2_valid + lst_y3_valid + lst_y4_valid + lst_y5_valid\n",
        "\n",
        "lst_x_fs_test = lst_x_fs1_test + lst_x_fs2_test + lst_x_fs3_test + lst_x_fs4_test + lst_x_fs5_test\n",
        "lst_x_fp_test = lst_x_fp1_test + lst_x_fp2_test + lst_x_fp3_test + lst_x_fp4_test + lst_x_fp5_test\n",
        "lst_y_test = lst_y1_test + lst_y2_test + lst_y3_test + lst_y4_test + lst_y5_test\n",
        "\n",
        "### np.arrayで変換\n",
        "lst_f0 = np.array(lst_f0, dtype=float)\n",
        "lst_x_fs_train = np.array(lst_x_fs_train, dtype=int)\n",
        "lst_x_fp_train = np.array(lst_x_fp_train, dtype=int)\n",
        "lst_x_fs_valid = np.array(lst_x_fs_valid, dtype=int)\n",
        "lst_x_fp_valid = np.array(lst_x_fp_valid, dtype=int)\n",
        "lst_x_fs_test = np.array(lst_x_fs_test, dtype=int)\n",
        "lst_x_fp_test = np.array(lst_x_fp_test, dtype=int)\n",
        "lst_y_train = np.array(lst_y_train, dtype=float)\n",
        "lst_y_valid = np.array(lst_y_valid, dtype=float)\n",
        "lst_y_test = np.array(lst_y_test, dtype=float)\n",
        "\n",
        "### 入力データを二次元化\n",
        "x_fs_train = lst_x_fs_train.reshape(-1, 1)\n",
        "x_fs_valid = lst_x_fs_valid.reshape(-1, 1)\n",
        "x_fs_test = lst_x_fs_test.reshape(-1, 1)\n",
        "x_fp_train = lst_x_fp_train.reshape(-1, 1)\n",
        "x_fp_valid = lst_x_fp_valid.reshape(-1, 1)\n",
        "x_fp_test = lst_x_fp_test.reshape(-1, 1)\n",
        "\n",
        "### 温度分布データを、穴なし温度分布データとの差に変換\n",
        "y_train = lst_y_train - lst_f0\n",
        "y_valid = lst_y_valid - lst_f0\n",
        "y_test = lst_y_test - lst_f0\n",
        "\n",
        "### 入力データの正規化\n",
        "scaler_x = MinMaxScaler()\n",
        "x_fs_train_n = scaler_x.fit_transform(x_fs_train)\n",
        "x_fs_valid_n = scaler_x.fit_transform(x_fs_valid)\n",
        "x_fs_test_n = scaler_x.fit_transform(x_fs_test) \n",
        "x_fp_train_n = scaler_x.fit_transform(x_fp_train)\n",
        "x_fp_valid_n = scaler_x.fit_transform(x_fp_valid)\n",
        "x_fp_test_n = scaler_x.fit_transform(x_fp_test) "
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBatPiQOk6GQ"
      },
      "source": [
        "# NN\n",
        "\n",
        "## 入力を定義\n",
        "input1 = Input(shape=(1,))\n",
        "input2 = Input(shape=(1,))\n",
        "\n",
        "## 入力1から結合前まで\n",
        "x = Dense(1, activation=\"linear\")(input1)\n",
        "x = Model(inputs=input1, outputs=x)\n",
        "\n",
        "## 入力2から結合前まで\n",
        "y = Dense(1, activation=\"linear\")(input2)\n",
        "y = Model(inputs=input2, outputs=y)\n",
        "\n",
        "## 結合\n",
        "combined = concatenate([x.output, y.output])\n",
        "\n",
        "## 密結合\n",
        "z = Dense(32, activation=\"relu\")(combined)\n",
        "z = Dense(512, activation=\"relu\")(z)\n",
        "z = Dense(256, activation=\"relu\")(z)\n",
        "z = Dense(128, activation=\"relu\")(z)\n",
        "z = Dense(50)(z)\n",
        "\n",
        "## モデル定義とコンパイル\n",
        "model_3 = Model(inputs=[x.input, y.input], outputs=z)\n",
        "model_3.compile(loss='mse', optimizer='adam', metrics=['mae'])"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdnCoAHAk6GR",
        "outputId": "775f6c99-2f99-4962-cd31-dd179f80b644"
      },
      "source": [
        "# 学習\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "history = model_3.fit([x_fs_train_n, x_fp_train_n], y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=([x_fs_valid_n, x_fp_valid_n], y_valid))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "25/25 [==============================] - 1s 14ms/step - loss: 0.3642 - mae: 0.2387 - val_loss: 0.2319 - val_mae: 0.1765\n",
            "Epoch 2/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2750 - mae: 0.1695 - val_loss: 0.2105 - val_mae: 0.1641\n",
            "Epoch 3/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2871 - mae: 0.1751 - val_loss: 0.2033 - val_mae: 0.1671\n",
            "Epoch 4/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3262 - mae: 0.1798 - val_loss: 0.1791 - val_mae: 0.1613\n",
            "Epoch 5/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2539 - mae: 0.1781 - val_loss: 0.1800 - val_mae: 0.1704\n",
            "Epoch 6/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2130 - mae: 0.1639 - val_loss: 0.1718 - val_mae: 0.1583\n",
            "Epoch 7/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3228 - mae: 0.1827 - val_loss: 0.1717 - val_mae: 0.1650\n",
            "Epoch 8/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2969 - mae: 0.1792 - val_loss: 0.1726 - val_mae: 0.1661\n",
            "Epoch 9/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2422 - mae: 0.1744 - val_loss: 0.1669 - val_mae: 0.1658\n",
            "Epoch 10/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3497 - mae: 0.1868 - val_loss: 0.1635 - val_mae: 0.1634\n",
            "Epoch 11/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2741 - mae: 0.1832 - val_loss: 0.1630 - val_mae: 0.1607\n",
            "Epoch 12/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2293 - mae: 0.1712 - val_loss: 0.1616 - val_mae: 0.1560\n",
            "Epoch 13/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2759 - mae: 0.1741 - val_loss: 0.1589 - val_mae: 0.1566\n",
            "Epoch 14/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2020 - mae: 0.1572 - val_loss: 0.1541 - val_mae: 0.1498\n",
            "Epoch 15/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2800 - mae: 0.1758 - val_loss: 0.1605 - val_mae: 0.1584\n",
            "Epoch 16/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1972 - mae: 0.1589 - val_loss: 0.1492 - val_mae: 0.1513\n",
            "Epoch 17/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2623 - mae: 0.1714 - val_loss: 0.1487 - val_mae: 0.1523\n",
            "Epoch 18/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2285 - mae: 0.1657 - val_loss: 0.1737 - val_mae: 0.1658\n",
            "Epoch 19/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1586 - mae: 0.1498 - val_loss: 0.2198 - val_mae: 0.2168\n",
            "Epoch 20/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2555 - mae: 0.1938 - val_loss: 0.1597 - val_mae: 0.1698\n",
            "Epoch 21/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3020 - mae: 0.1921 - val_loss: 0.1508 - val_mae: 0.1491\n",
            "Epoch 22/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1836 - mae: 0.1438 - val_loss: 0.1516 - val_mae: 0.1635\n",
            "Epoch 23/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3216 - mae: 0.1859 - val_loss: 0.1470 - val_mae: 0.1509\n",
            "Epoch 24/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2699 - mae: 0.1659 - val_loss: 0.1560 - val_mae: 0.1551\n",
            "Epoch 25/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2856 - mae: 0.1694 - val_loss: 0.1542 - val_mae: 0.1517\n",
            "Epoch 26/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2252 - mae: 0.1618 - val_loss: 0.1695 - val_mae: 0.1802\n",
            "Epoch 27/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2840 - mae: 0.1784 - val_loss: 0.1613 - val_mae: 0.1638\n",
            "Epoch 28/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2061 - mae: 0.1550 - val_loss: 0.1492 - val_mae: 0.1561\n",
            "Epoch 29/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2819 - mae: 0.1784 - val_loss: 0.1414 - val_mae: 0.1457\n",
            "Epoch 30/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2457 - mae: 0.1580 - val_loss: 0.1389 - val_mae: 0.1445\n",
            "Epoch 31/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2090 - mae: 0.1528 - val_loss: 0.1404 - val_mae: 0.1472\n",
            "Epoch 32/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1906 - mae: 0.1532 - val_loss: 0.1603 - val_mae: 0.1570\n",
            "Epoch 33/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2158 - mae: 0.1678 - val_loss: 0.1501 - val_mae: 0.1535\n",
            "Epoch 34/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1692 - mae: 0.1505 - val_loss: 0.1519 - val_mae: 0.1630\n",
            "Epoch 35/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3809 - mae: 0.1917 - val_loss: 0.1395 - val_mae: 0.1461\n",
            "Epoch 36/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.3350 - mae: 0.1779 - val_loss: 0.1615 - val_mae: 0.1600\n",
            "Epoch 37/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2366 - mae: 0.1637 - val_loss: 0.1396 - val_mae: 0.1468\n",
            "Epoch 38/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1995 - mae: 0.1532 - val_loss: 0.1420 - val_mae: 0.1431\n",
            "Epoch 39/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1482 - mae: 0.1433 - val_loss: 0.1513 - val_mae: 0.1542\n",
            "Epoch 40/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2168 - mae: 0.1621 - val_loss: 0.1440 - val_mae: 0.1472\n",
            "Epoch 41/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2283 - mae: 0.1532 - val_loss: 0.1582 - val_mae: 0.1605\n",
            "Epoch 42/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1886 - mae: 0.1511 - val_loss: 0.1599 - val_mae: 0.1548\n",
            "Epoch 43/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2287 - mae: 0.1674 - val_loss: 0.1514 - val_mae: 0.1577\n",
            "Epoch 44/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1759 - mae: 0.1516 - val_loss: 0.1665 - val_mae: 0.1695\n",
            "Epoch 45/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2676 - mae: 0.1677 - val_loss: 0.1430 - val_mae: 0.1489\n",
            "Epoch 46/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2128 - mae: 0.1539 - val_loss: 0.1463 - val_mae: 0.1478\n",
            "Epoch 47/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2076 - mae: 0.1549 - val_loss: 0.1420 - val_mae: 0.1482\n",
            "Epoch 48/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1486 - mae: 0.1508 - val_loss: 0.1477 - val_mae: 0.1506\n",
            "Epoch 49/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2339 - mae: 0.1590 - val_loss: 0.1413 - val_mae: 0.1460\n",
            "Epoch 50/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1417 - mae: 0.1385 - val_loss: 0.1584 - val_mae: 0.1557\n",
            "Epoch 51/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1942 - mae: 0.1483 - val_loss: 0.1553 - val_mae: 0.1560\n",
            "Epoch 52/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2330 - mae: 0.1601 - val_loss: 0.1436 - val_mae: 0.1473\n",
            "Epoch 53/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2335 - mae: 0.1612 - val_loss: 0.1408 - val_mae: 0.1423\n",
            "Epoch 54/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1950 - mae: 0.1489 - val_loss: 0.1595 - val_mae: 0.1740\n",
            "Epoch 55/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1861 - mae: 0.1580 - val_loss: 0.1454 - val_mae: 0.1565\n",
            "Epoch 56/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3335 - mae: 0.1617 - val_loss: 0.1361 - val_mae: 0.1383\n",
            "Epoch 57/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2792 - mae: 0.1549 - val_loss: 0.1423 - val_mae: 0.1414\n",
            "Epoch 58/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2998 - mae: 0.1631 - val_loss: 0.1413 - val_mae: 0.1410\n",
            "Epoch 59/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1734 - mae: 0.1381 - val_loss: 0.1453 - val_mae: 0.1531\n",
            "Epoch 60/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1980 - mae: 0.1585 - val_loss: 0.1537 - val_mae: 0.1584\n",
            "Epoch 61/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1727 - mae: 0.1535 - val_loss: 0.1422 - val_mae: 0.1432\n",
            "Epoch 62/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1889 - mae: 0.1455 - val_loss: 0.1459 - val_mae: 0.1424\n",
            "Epoch 63/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1924 - mae: 0.1519 - val_loss: 0.1574 - val_mae: 0.1513\n",
            "Epoch 64/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2000 - mae: 0.1502 - val_loss: 0.1504 - val_mae: 0.1462\n",
            "Epoch 65/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3559 - mae: 0.1710 - val_loss: 0.1376 - val_mae: 0.1382\n",
            "Epoch 66/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2439 - mae: 0.1468 - val_loss: 0.1374 - val_mae: 0.1397\n",
            "Epoch 67/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2917 - mae: 0.1534 - val_loss: 0.1443 - val_mae: 0.1403\n",
            "Epoch 68/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2281 - mae: 0.1457 - val_loss: 0.1484 - val_mae: 0.1448\n",
            "Epoch 69/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2510 - mae: 0.1567 - val_loss: 0.1377 - val_mae: 0.1359\n",
            "Epoch 70/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1894 - mae: 0.1398 - val_loss: 0.1515 - val_mae: 0.1470\n",
            "Epoch 71/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1761 - mae: 0.1413 - val_loss: 0.1488 - val_mae: 0.1434\n",
            "Epoch 72/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3039 - mae: 0.1526 - val_loss: 0.1384 - val_mae: 0.1402\n",
            "Epoch 73/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2183 - mae: 0.1524 - val_loss: 0.1570 - val_mae: 0.1519\n",
            "Epoch 74/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2919 - mae: 0.1602 - val_loss: 0.1501 - val_mae: 0.1453\n",
            "Epoch 75/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1796 - mae: 0.1392 - val_loss: 0.1421 - val_mae: 0.1384\n",
            "Epoch 76/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1941 - mae: 0.1437 - val_loss: 0.1438 - val_mae: 0.1381\n",
            "Epoch 77/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2042 - mae: 0.1363 - val_loss: 0.1422 - val_mae: 0.1404\n",
            "Epoch 78/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1822 - mae: 0.1357 - val_loss: 0.1463 - val_mae: 0.1417\n",
            "Epoch 79/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1849 - mae: 0.1358 - val_loss: 0.1551 - val_mae: 0.1437\n",
            "Epoch 80/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1562 - mae: 0.1434 - val_loss: 0.1508 - val_mae: 0.1432\n",
            "Epoch 81/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2158 - mae: 0.1527 - val_loss: 0.1410 - val_mae: 0.1354\n",
            "Epoch 82/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1870 - mae: 0.1381 - val_loss: 0.1423 - val_mae: 0.1407\n",
            "Epoch 83/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1826 - mae: 0.1442 - val_loss: 0.1612 - val_mae: 0.1534\n",
            "Epoch 84/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2174 - mae: 0.1622 - val_loss: 0.1453 - val_mae: 0.1381\n",
            "Epoch 85/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1934 - mae: 0.1399 - val_loss: 0.1406 - val_mae: 0.1427\n",
            "Epoch 86/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1400 - mae: 0.1360 - val_loss: 0.1392 - val_mae: 0.1375\n",
            "Epoch 87/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3618 - mae: 0.1841 - val_loss: 0.1425 - val_mae: 0.1437\n",
            "Epoch 88/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2381 - mae: 0.1464 - val_loss: 0.1487 - val_mae: 0.1457\n",
            "Epoch 89/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1583 - mae: 0.1334 - val_loss: 0.1487 - val_mae: 0.1412\n",
            "Epoch 90/2000\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 0.1619 - mae: 0.1334 - val_loss: 0.1461 - val_mae: 0.1383\n",
            "Epoch 91/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2238 - mae: 0.1418 - val_loss: 0.1610 - val_mae: 0.1511\n",
            "Epoch 92/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2084 - mae: 0.1468 - val_loss: 0.1499 - val_mae: 0.1498\n",
            "Epoch 93/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2082 - mae: 0.1549 - val_loss: 0.1520 - val_mae: 0.1424\n",
            "Epoch 94/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2572 - mae: 0.1454 - val_loss: 0.1418 - val_mae: 0.1377\n",
            "Epoch 95/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2293 - mae: 0.1459 - val_loss: 0.1411 - val_mae: 0.1371\n",
            "Epoch 96/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1798 - mae: 0.1427 - val_loss: 0.1465 - val_mae: 0.1380\n",
            "Epoch 97/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2071 - mae: 0.1362 - val_loss: 0.1430 - val_mae: 0.1323\n",
            "Epoch 98/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1735 - mae: 0.1368 - val_loss: 0.1519 - val_mae: 0.1423\n",
            "Epoch 99/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1699 - mae: 0.1412 - val_loss: 0.1577 - val_mae: 0.1456\n",
            "Epoch 100/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1916 - mae: 0.1404 - val_loss: 0.1488 - val_mae: 0.1418\n",
            "Epoch 101/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1534 - mae: 0.1291 - val_loss: 0.1538 - val_mae: 0.1428\n",
            "Epoch 102/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2370 - mae: 0.1470 - val_loss: 0.1405 - val_mae: 0.1314\n",
            "Epoch 103/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1996 - mae: 0.1301 - val_loss: 0.1492 - val_mae: 0.1365\n",
            "Epoch 104/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1618 - mae: 0.1311 - val_loss: 0.1489 - val_mae: 0.1364\n",
            "Epoch 105/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2611 - mae: 0.1450 - val_loss: 0.1332 - val_mae: 0.1274\n",
            "Epoch 106/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1954 - mae: 0.1323 - val_loss: 0.1543 - val_mae: 0.1431\n",
            "Epoch 107/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3159 - mae: 0.1639 - val_loss: 0.1457 - val_mae: 0.1333\n",
            "Epoch 108/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1857 - mae: 0.1352 - val_loss: 0.1567 - val_mae: 0.1426\n",
            "Epoch 109/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2573 - mae: 0.1464 - val_loss: 0.1364 - val_mae: 0.1303\n",
            "Epoch 110/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2652 - mae: 0.1457 - val_loss: 0.1434 - val_mae: 0.1351\n",
            "Epoch 111/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1784 - mae: 0.1333 - val_loss: 0.1483 - val_mae: 0.1392\n",
            "Epoch 112/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1670 - mae: 0.1389 - val_loss: 0.1524 - val_mae: 0.1380\n",
            "Epoch 113/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2467 - mae: 0.1469 - val_loss: 0.1381 - val_mae: 0.1286\n",
            "Epoch 114/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2449 - mae: 0.1339 - val_loss: 0.1395 - val_mae: 0.1340\n",
            "Epoch 115/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3160 - mae: 0.1634 - val_loss: 0.1415 - val_mae: 0.1412\n",
            "Epoch 116/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2394 - mae: 0.1456 - val_loss: 0.1417 - val_mae: 0.1329\n",
            "Epoch 117/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1877 - mae: 0.1291 - val_loss: 0.1492 - val_mae: 0.1379\n",
            "Epoch 118/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2169 - mae: 0.1398 - val_loss: 0.1457 - val_mae: 0.1336\n",
            "Epoch 119/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2560 - mae: 0.1342 - val_loss: 0.1437 - val_mae: 0.1312\n",
            "Epoch 120/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1484 - mae: 0.1233 - val_loss: 0.1358 - val_mae: 0.1302\n",
            "Epoch 121/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1755 - mae: 0.1375 - val_loss: 0.1439 - val_mae: 0.1314\n",
            "Epoch 122/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1707 - mae: 0.1288 - val_loss: 0.1482 - val_mae: 0.1397\n",
            "Epoch 123/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1365 - mae: 0.1302 - val_loss: 0.1501 - val_mae: 0.1318\n",
            "Epoch 124/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1835 - mae: 0.1358 - val_loss: 0.1495 - val_mae: 0.1293\n",
            "Epoch 125/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2198 - mae: 0.1367 - val_loss: 0.1419 - val_mae: 0.1251\n",
            "Epoch 126/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1741 - mae: 0.1271 - val_loss: 0.1534 - val_mae: 0.1342\n",
            "Epoch 127/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2105 - mae: 0.1387 - val_loss: 0.1467 - val_mae: 0.1303\n",
            "Epoch 128/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2436 - mae: 0.1378 - val_loss: 0.1525 - val_mae: 0.1323\n",
            "Epoch 129/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1690 - mae: 0.1261 - val_loss: 0.1445 - val_mae: 0.1260\n",
            "Epoch 130/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2674 - mae: 0.1390 - val_loss: 0.1568 - val_mae: 0.1315\n",
            "Epoch 131/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1813 - mae: 0.1336 - val_loss: 0.1523 - val_mae: 0.1318\n",
            "Epoch 132/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2140 - mae: 0.1308 - val_loss: 0.1519 - val_mae: 0.1283\n",
            "Epoch 133/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1973 - mae: 0.1292 - val_loss: 0.1524 - val_mae: 0.1469\n",
            "Epoch 134/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1894 - mae: 0.1360 - val_loss: 0.1480 - val_mae: 0.1374\n",
            "Epoch 135/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1892 - mae: 0.1269 - val_loss: 0.1482 - val_mae: 0.1274\n",
            "Epoch 136/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2255 - mae: 0.1321 - val_loss: 0.1405 - val_mae: 0.1244\n",
            "Epoch 137/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3501 - mae: 0.1499 - val_loss: 0.1505 - val_mae: 0.1291\n",
            "Epoch 138/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1776 - mae: 0.1227 - val_loss: 0.1424 - val_mae: 0.1244\n",
            "Epoch 139/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1778 - mae: 0.1167 - val_loss: 0.1470 - val_mae: 0.1248\n",
            "Epoch 140/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1760 - mae: 0.1251 - val_loss: 0.1534 - val_mae: 0.1312\n",
            "Epoch 141/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1659 - mae: 0.1311 - val_loss: 0.1492 - val_mae: 0.1251\n",
            "Epoch 142/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2093 - mae: 0.1293 - val_loss: 0.1502 - val_mae: 0.1317\n",
            "Epoch 143/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1759 - mae: 0.1262 - val_loss: 0.1533 - val_mae: 0.1267\n",
            "Epoch 144/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.1675 - mae: 0.1245 - val_loss: 0.1439 - val_mae: 0.1244\n",
            "Epoch 145/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1410 - mae: 0.1098 - val_loss: 0.1584 - val_mae: 0.1358\n",
            "Epoch 146/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1760 - mae: 0.1228 - val_loss: 0.1409 - val_mae: 0.1238\n",
            "Epoch 147/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2211 - mae: 0.1277 - val_loss: 0.1420 - val_mae: 0.1196\n",
            "Epoch 148/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2173 - mae: 0.1231 - val_loss: 0.1372 - val_mae: 0.1196\n",
            "Epoch 149/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1588 - mae: 0.1164 - val_loss: 0.1340 - val_mae: 0.1244\n",
            "Epoch 150/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2089 - mae: 0.1247 - val_loss: 0.1457 - val_mae: 0.1185\n",
            "Epoch 151/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2952 - mae: 0.1385 - val_loss: 0.1439 - val_mae: 0.1241\n",
            "Epoch 152/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2118 - mae: 0.1317 - val_loss: 0.1415 - val_mae: 0.1207\n",
            "Epoch 153/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1517 - mae: 0.1153 - val_loss: 0.1461 - val_mae: 0.1238\n",
            "Epoch 154/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2614 - mae: 0.1468 - val_loss: 0.1563 - val_mae: 0.1256\n",
            "Epoch 155/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2192 - mae: 0.1351 - val_loss: 0.1349 - val_mae: 0.1205\n",
            "Epoch 156/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2995 - mae: 0.1384 - val_loss: 0.1364 - val_mae: 0.1214\n",
            "Epoch 157/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1908 - mae: 0.1214 - val_loss: 0.1485 - val_mae: 0.1264\n",
            "Epoch 158/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2331 - mae: 0.1295 - val_loss: 0.1517 - val_mae: 0.1335\n",
            "Epoch 159/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2190 - mae: 0.1351 - val_loss: 0.1625 - val_mae: 0.1403\n",
            "Epoch 160/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1901 - mae: 0.1276 - val_loss: 0.1392 - val_mae: 0.1204\n",
            "Epoch 161/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1621 - mae: 0.1198 - val_loss: 0.1495 - val_mae: 0.1219\n",
            "Epoch 162/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1325 - mae: 0.1095 - val_loss: 0.1438 - val_mae: 0.1236\n",
            "Epoch 163/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2253 - mae: 0.1252 - val_loss: 0.1430 - val_mae: 0.1224\n",
            "Epoch 164/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1246 - mae: 0.1072 - val_loss: 0.1424 - val_mae: 0.1191\n",
            "Epoch 165/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2020 - mae: 0.1157 - val_loss: 0.1373 - val_mae: 0.1179\n",
            "Epoch 166/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2919 - mae: 0.1297 - val_loss: 0.1414 - val_mae: 0.1154\n",
            "Epoch 167/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1444 - mae: 0.1141 - val_loss: 0.1355 - val_mae: 0.1177\n",
            "Epoch 168/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1754 - mae: 0.1176 - val_loss: 0.1416 - val_mae: 0.1177\n",
            "Epoch 169/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2402 - mae: 0.1241 - val_loss: 0.1386 - val_mae: 0.1131\n",
            "Epoch 170/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1747 - mae: 0.1039 - val_loss: 0.1374 - val_mae: 0.1169\n",
            "Epoch 171/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1564 - mae: 0.1087 - val_loss: 0.1450 - val_mae: 0.1202\n",
            "Epoch 172/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1343 - mae: 0.1053 - val_loss: 0.1453 - val_mae: 0.1155\n",
            "Epoch 173/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1903 - mae: 0.1171 - val_loss: 0.1475 - val_mae: 0.1217\n",
            "Epoch 174/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1501 - mae: 0.1118 - val_loss: 0.1481 - val_mae: 0.1177\n",
            "Epoch 175/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2433 - mae: 0.1329 - val_loss: 0.1448 - val_mae: 0.1138\n",
            "Epoch 176/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1766 - mae: 0.1093 - val_loss: 0.1496 - val_mae: 0.1214\n",
            "Epoch 177/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1740 - mae: 0.1212 - val_loss: 0.1389 - val_mae: 0.1112\n",
            "Epoch 178/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2723 - mae: 0.1347 - val_loss: 0.1403 - val_mae: 0.1154\n",
            "Epoch 179/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1728 - mae: 0.1078 - val_loss: 0.1406 - val_mae: 0.1147\n",
            "Epoch 180/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1175 - mae: 0.1010 - val_loss: 0.1461 - val_mae: 0.1215\n",
            "Epoch 181/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1806 - mae: 0.1174 - val_loss: 0.1551 - val_mae: 0.1202\n",
            "Epoch 182/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1742 - mae: 0.1104 - val_loss: 0.1414 - val_mae: 0.1208\n",
            "Epoch 183/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2268 - mae: 0.1244 - val_loss: 0.1438 - val_mae: 0.1184\n",
            "Epoch 184/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1633 - mae: 0.1129 - val_loss: 0.1468 - val_mae: 0.1186\n",
            "Epoch 185/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1940 - mae: 0.1180 - val_loss: 0.1435 - val_mae: 0.1179\n",
            "Epoch 186/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1749 - mae: 0.1093 - val_loss: 0.1412 - val_mae: 0.1245\n",
            "Epoch 187/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1321 - mae: 0.1077 - val_loss: 0.1512 - val_mae: 0.1228\n",
            "Epoch 188/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1352 - mae: 0.1111 - val_loss: 0.1410 - val_mae: 0.1136\n",
            "Epoch 189/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1838 - mae: 0.1192 - val_loss: 0.1524 - val_mae: 0.1214\n",
            "Epoch 190/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1457 - mae: 0.1121 - val_loss: 0.1512 - val_mae: 0.1198\n",
            "Epoch 191/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2870 - mae: 0.1411 - val_loss: 0.1486 - val_mae: 0.1195\n",
            "Epoch 192/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1521 - mae: 0.1105 - val_loss: 0.1517 - val_mae: 0.1209\n",
            "Epoch 193/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1359 - mae: 0.1024 - val_loss: 0.1594 - val_mae: 0.1236\n",
            "Epoch 194/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2010 - mae: 0.1200 - val_loss: 0.1489 - val_mae: 0.1222\n",
            "Epoch 195/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2366 - mae: 0.1290 - val_loss: 0.1441 - val_mae: 0.1236\n",
            "Epoch 196/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2118 - mae: 0.1228 - val_loss: 0.1437 - val_mae: 0.1223\n",
            "Epoch 197/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1475 - mae: 0.1168 - val_loss: 0.1442 - val_mae: 0.1172\n",
            "Epoch 198/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.1515 - mae: 0.1099 - val_loss: 0.1486 - val_mae: 0.1193\n",
            "Epoch 199/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1255 - mae: 0.1055 - val_loss: 0.1486 - val_mae: 0.1160\n",
            "Epoch 200/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1557 - mae: 0.1111 - val_loss: 0.1445 - val_mae: 0.1174\n",
            "Epoch 201/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1996 - mae: 0.1147 - val_loss: 0.1615 - val_mae: 0.1272\n",
            "Epoch 202/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2444 - mae: 0.1219 - val_loss: 0.1429 - val_mae: 0.1162\n",
            "Epoch 203/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2006 - mae: 0.1177 - val_loss: 0.1420 - val_mae: 0.1156\n",
            "Epoch 204/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1980 - mae: 0.1231 - val_loss: 0.1482 - val_mae: 0.1298\n",
            "Epoch 205/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1608 - mae: 0.1235 - val_loss: 0.1544 - val_mae: 0.1453\n",
            "Epoch 206/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2033 - mae: 0.1359 - val_loss: 0.1476 - val_mae: 0.1262\n",
            "Epoch 207/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2091 - mae: 0.1267 - val_loss: 0.1472 - val_mae: 0.1165\n",
            "Epoch 208/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1917 - mae: 0.1182 - val_loss: 0.1446 - val_mae: 0.1146\n",
            "Epoch 209/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.1119 - val_loss: 0.1415 - val_mae: 0.1108\n",
            "Epoch 210/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1410 - mae: 0.1090 - val_loss: 0.1478 - val_mae: 0.1159\n",
            "Epoch 211/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1505 - mae: 0.1078 - val_loss: 0.1577 - val_mae: 0.1216\n",
            "Epoch 212/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1583 - mae: 0.1127 - val_loss: 0.1497 - val_mae: 0.1183\n",
            "Epoch 213/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1750 - mae: 0.1131 - val_loss: 0.1429 - val_mae: 0.1145\n",
            "Epoch 214/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1910 - mae: 0.1200 - val_loss: 0.1464 - val_mae: 0.1132\n",
            "Epoch 215/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1640 - mae: 0.1062 - val_loss: 0.1546 - val_mae: 0.1180\n",
            "Epoch 216/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1827 - mae: 0.1102 - val_loss: 0.1470 - val_mae: 0.1166\n",
            "Epoch 217/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2098 - mae: 0.1064 - val_loss: 0.1494 - val_mae: 0.1150\n",
            "Epoch 218/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1828 - mae: 0.1096 - val_loss: 0.1397 - val_mae: 0.1137\n",
            "Epoch 219/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2270 - mae: 0.1114 - val_loss: 0.1354 - val_mae: 0.1085\n",
            "Epoch 220/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1851 - mae: 0.1088 - val_loss: 0.1486 - val_mae: 0.1196\n",
            "Epoch 221/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1533 - mae: 0.1099 - val_loss: 0.1369 - val_mae: 0.1115\n",
            "Epoch 222/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1450 - mae: 0.1092 - val_loss: 0.1468 - val_mae: 0.1133\n",
            "Epoch 223/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2558 - mae: 0.1218 - val_loss: 0.1476 - val_mae: 0.1139\n",
            "Epoch 224/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2010 - mae: 0.1089 - val_loss: 0.1464 - val_mae: 0.1159\n",
            "Epoch 225/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2587 - mae: 0.1261 - val_loss: 0.1420 - val_mae: 0.1142\n",
            "Epoch 226/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2045 - mae: 0.1228 - val_loss: 0.1510 - val_mae: 0.1189\n",
            "Epoch 227/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2076 - mae: 0.1178 - val_loss: 0.1415 - val_mae: 0.1116\n",
            "Epoch 228/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2252 - mae: 0.1206 - val_loss: 0.1521 - val_mae: 0.1202\n",
            "Epoch 229/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2093 - mae: 0.1131 - val_loss: 0.1406 - val_mae: 0.1112\n",
            "Epoch 230/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2402 - mae: 0.1209 - val_loss: 0.1433 - val_mae: 0.1161\n",
            "Epoch 231/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2712 - mae: 0.1233 - val_loss: 0.1428 - val_mae: 0.1150\n",
            "Epoch 232/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2329 - mae: 0.1205 - val_loss: 0.1376 - val_mae: 0.1132\n",
            "Epoch 233/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2258 - mae: 0.1183 - val_loss: 0.1457 - val_mae: 0.1138\n",
            "Epoch 234/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3030 - mae: 0.1320 - val_loss: 0.1387 - val_mae: 0.1116\n",
            "Epoch 235/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1349 - mae: 0.0986 - val_loss: 0.1508 - val_mae: 0.1176\n",
            "Epoch 236/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2052 - mae: 0.1124 - val_loss: 0.1490 - val_mae: 0.1153\n",
            "Epoch 237/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1721 - mae: 0.1039 - val_loss: 0.1491 - val_mae: 0.1143\n",
            "Epoch 238/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1556 - mae: 0.1078 - val_loss: 0.1635 - val_mae: 0.1274\n",
            "Epoch 239/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3223 - mae: 0.1493 - val_loss: 0.1410 - val_mae: 0.1178\n",
            "Epoch 240/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1539 - mae: 0.1025 - val_loss: 0.1445 - val_mae: 0.1344\n",
            "Epoch 241/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1790 - mae: 0.1321 - val_loss: 0.1544 - val_mae: 0.1320\n",
            "Epoch 242/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1551 - mae: 0.1118 - val_loss: 0.1533 - val_mae: 0.1223\n",
            "Epoch 243/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1949 - mae: 0.1203 - val_loss: 0.1550 - val_mae: 0.1251\n",
            "Epoch 244/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1979 - mae: 0.1222 - val_loss: 0.1519 - val_mae: 0.1162\n",
            "Epoch 245/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2395 - mae: 0.1256 - val_loss: 0.1461 - val_mae: 0.1197\n",
            "Epoch 246/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2133 - mae: 0.1167 - val_loss: 0.1530 - val_mae: 0.1156\n",
            "Epoch 247/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3272 - mae: 0.1419 - val_loss: 0.1408 - val_mae: 0.1140\n",
            "Epoch 248/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1449 - mae: 0.0979 - val_loss: 0.1514 - val_mae: 0.1158\n",
            "Epoch 249/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2516 - mae: 0.1195 - val_loss: 0.1418 - val_mae: 0.1136\n",
            "Epoch 250/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1988 - mae: 0.1106 - val_loss: 0.1522 - val_mae: 0.1154\n",
            "Epoch 251/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1706 - mae: 0.0997 - val_loss: 0.1392 - val_mae: 0.1100\n",
            "Epoch 252/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.2662 - mae: 0.1271 - val_loss: 0.1421 - val_mae: 0.1101\n",
            "Epoch 253/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2037 - mae: 0.1077 - val_loss: 0.1311 - val_mae: 0.1178\n",
            "Epoch 254/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2428 - mae: 0.1360 - val_loss: 0.1502 - val_mae: 0.1377\n",
            "Epoch 255/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1472 - mae: 0.1169 - val_loss: 0.1447 - val_mae: 0.1201\n",
            "Epoch 256/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1960 - mae: 0.1210 - val_loss: 0.1435 - val_mae: 0.1134\n",
            "Epoch 257/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1612 - mae: 0.1110 - val_loss: 0.1426 - val_mae: 0.1115\n",
            "Epoch 258/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2189 - mae: 0.1196 - val_loss: 0.1537 - val_mae: 0.1183\n",
            "Epoch 259/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2420 - mae: 0.1164 - val_loss: 0.1430 - val_mae: 0.1098\n",
            "Epoch 260/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2815 - mae: 0.1275 - val_loss: 0.1413 - val_mae: 0.1131\n",
            "Epoch 261/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1967 - mae: 0.1026 - val_loss: 0.1435 - val_mae: 0.1137\n",
            "Epoch 262/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1818 - mae: 0.1072 - val_loss: 0.1430 - val_mae: 0.1114\n",
            "Epoch 263/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1654 - mae: 0.1051 - val_loss: 0.1530 - val_mae: 0.1179\n",
            "Epoch 264/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1796 - mae: 0.1150 - val_loss: 0.1408 - val_mae: 0.1109\n",
            "Epoch 265/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2104 - mae: 0.1145 - val_loss: 0.1449 - val_mae: 0.1131\n",
            "Epoch 266/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1993 - mae: 0.1101 - val_loss: 0.1545 - val_mae: 0.1170\n",
            "Epoch 267/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1939 - mae: 0.1141 - val_loss: 0.1473 - val_mae: 0.1141\n",
            "Epoch 268/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1905 - mae: 0.1124 - val_loss: 0.1485 - val_mae: 0.1131\n",
            "Epoch 269/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1872 - mae: 0.1131 - val_loss: 0.1522 - val_mae: 0.1149\n",
            "Epoch 270/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1997 - mae: 0.1142 - val_loss: 0.1485 - val_mae: 0.1157\n",
            "Epoch 271/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2064 - mae: 0.1197 - val_loss: 0.1449 - val_mae: 0.1137\n",
            "Epoch 272/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1885 - mae: 0.1073 - val_loss: 0.1467 - val_mae: 0.1130\n",
            "Epoch 273/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1867 - mae: 0.1088 - val_loss: 0.1414 - val_mae: 0.1116\n",
            "Epoch 274/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2389 - mae: 0.1103 - val_loss: 0.1529 - val_mae: 0.1164\n",
            "Epoch 275/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2343 - mae: 0.1171 - val_loss: 0.1436 - val_mae: 0.1124\n",
            "Epoch 276/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2078 - mae: 0.1107 - val_loss: 0.1498 - val_mae: 0.1145\n",
            "Epoch 277/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1952 - mae: 0.1124 - val_loss: 0.1533 - val_mae: 0.1161\n",
            "Epoch 278/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1389 - mae: 0.0990 - val_loss: 0.1448 - val_mae: 0.1113\n",
            "Epoch 279/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1883 - mae: 0.1095 - val_loss: 0.1473 - val_mae: 0.1128\n",
            "Epoch 280/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1324 - mae: 0.0972 - val_loss: 0.1477 - val_mae: 0.1126\n",
            "Epoch 281/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1663 - mae: 0.1091 - val_loss: 0.1438 - val_mae: 0.1096\n",
            "Epoch 282/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3085 - mae: 0.1232 - val_loss: 0.1413 - val_mae: 0.1104\n",
            "Epoch 283/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1968 - mae: 0.1110 - val_loss: 0.1481 - val_mae: 0.1125\n",
            "Epoch 284/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1580 - mae: 0.1081 - val_loss: 0.1435 - val_mae: 0.1141\n",
            "Epoch 285/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2584 - mae: 0.1212 - val_loss: 0.1506 - val_mae: 0.1176\n",
            "Epoch 286/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1615 - mae: 0.1023 - val_loss: 0.1546 - val_mae: 0.1164\n",
            "Epoch 287/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1570 - mae: 0.1095 - val_loss: 0.1459 - val_mae: 0.1175\n",
            "Epoch 288/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2202 - mae: 0.1176 - val_loss: 0.1427 - val_mae: 0.1118\n",
            "Epoch 289/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1902 - mae: 0.1090 - val_loss: 0.1477 - val_mae: 0.1137\n",
            "Epoch 290/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1418 - mae: 0.0984 - val_loss: 0.1446 - val_mae: 0.1144\n",
            "Epoch 291/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1532 - mae: 0.1072 - val_loss: 0.1488 - val_mae: 0.1147\n",
            "Epoch 292/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2067 - mae: 0.1168 - val_loss: 0.1482 - val_mae: 0.1284\n",
            "Epoch 293/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2399 - mae: 0.1282 - val_loss: 0.1432 - val_mae: 0.1206\n",
            "Epoch 294/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2179 - mae: 0.1259 - val_loss: 0.1414 - val_mae: 0.1113\n",
            "Epoch 295/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1582 - mae: 0.1034 - val_loss: 0.1480 - val_mae: 0.1122\n",
            "Epoch 296/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2539 - mae: 0.1192 - val_loss: 0.1509 - val_mae: 0.1151\n",
            "Epoch 297/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2085 - mae: 0.1189 - val_loss: 0.1461 - val_mae: 0.1148\n",
            "Epoch 298/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1220 - mae: 0.0968 - val_loss: 0.1482 - val_mae: 0.1208\n",
            "Epoch 299/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1714 - mae: 0.1193 - val_loss: 0.1488 - val_mae: 0.1162\n",
            "Epoch 300/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2315 - mae: 0.1232 - val_loss: 0.1441 - val_mae: 0.1137\n",
            "Epoch 301/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1565 - mae: 0.1063 - val_loss: 0.1454 - val_mae: 0.1149\n",
            "Epoch 302/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1854 - mae: 0.1112 - val_loss: 0.1508 - val_mae: 0.1139\n",
            "Epoch 303/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2325 - mae: 0.1245 - val_loss: 0.1538 - val_mae: 0.1211\n",
            "Epoch 304/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2037 - mae: 0.1158 - val_loss: 0.1499 - val_mae: 0.1181\n",
            "Epoch 305/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1692 - mae: 0.1179 - val_loss: 0.1448 - val_mae: 0.1210\n",
            "Epoch 306/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.2402 - mae: 0.1313 - val_loss: 0.1490 - val_mae: 0.1168\n",
            "Epoch 307/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2083 - mae: 0.1160 - val_loss: 0.1502 - val_mae: 0.1141\n",
            "Epoch 308/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1545 - mae: 0.1037 - val_loss: 0.1452 - val_mae: 0.1161\n",
            "Epoch 309/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1599 - mae: 0.1094 - val_loss: 0.1442 - val_mae: 0.1119\n",
            "Epoch 310/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2664 - mae: 0.1239 - val_loss: 0.1407 - val_mae: 0.1087\n",
            "Epoch 311/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1371 - mae: 0.0920 - val_loss: 0.1455 - val_mae: 0.1114\n",
            "Epoch 312/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1707 - mae: 0.1071 - val_loss: 0.1485 - val_mae: 0.1133\n",
            "Epoch 313/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1748 - mae: 0.1081 - val_loss: 0.1464 - val_mae: 0.1141\n",
            "Epoch 314/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1700 - mae: 0.1084 - val_loss: 0.1518 - val_mae: 0.1176\n",
            "Epoch 315/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3085 - mae: 0.1414 - val_loss: 0.1504 - val_mae: 0.1144\n",
            "Epoch 316/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2260 - mae: 0.1209 - val_loss: 0.1464 - val_mae: 0.1112\n",
            "Epoch 317/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1885 - mae: 0.1033 - val_loss: 0.1456 - val_mae: 0.1114\n",
            "Epoch 318/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1598 - mae: 0.1068 - val_loss: 0.1527 - val_mae: 0.1156\n",
            "Epoch 319/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1515 - mae: 0.1030 - val_loss: 0.1501 - val_mae: 0.1137\n",
            "Epoch 320/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1857 - mae: 0.1098 - val_loss: 0.1482 - val_mae: 0.1164\n",
            "Epoch 321/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1485 - mae: 0.1064 - val_loss: 0.1476 - val_mae: 0.1129\n",
            "Epoch 322/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2100 - mae: 0.1153 - val_loss: 0.1453 - val_mae: 0.1134\n",
            "Epoch 323/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2458 - mae: 0.1143 - val_loss: 0.1511 - val_mae: 0.1128\n",
            "Epoch 324/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1899 - mae: 0.1084 - val_loss: 0.1478 - val_mae: 0.1113\n",
            "Epoch 325/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2249 - mae: 0.1162 - val_loss: 0.1490 - val_mae: 0.1129\n",
            "Epoch 326/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2236 - mae: 0.1107 - val_loss: 0.1514 - val_mae: 0.1147\n",
            "Epoch 327/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1795 - mae: 0.1077 - val_loss: 0.1410 - val_mae: 0.1090\n",
            "Epoch 328/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1337 - mae: 0.1015 - val_loss: 0.1414 - val_mae: 0.1086\n",
            "Epoch 329/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2181 - mae: 0.1123 - val_loss: 0.1533 - val_mae: 0.1163\n",
            "Epoch 330/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1554 - mae: 0.1047 - val_loss: 0.1456 - val_mae: 0.1136\n",
            "Epoch 331/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2225 - mae: 0.1202 - val_loss: 0.1479 - val_mae: 0.1154\n",
            "Epoch 332/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1831 - mae: 0.1094 - val_loss: 0.1425 - val_mae: 0.1104\n",
            "Epoch 333/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1962 - mae: 0.1072 - val_loss: 0.1513 - val_mae: 0.1163\n",
            "Epoch 334/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1510 - mae: 0.1099 - val_loss: 0.1456 - val_mae: 0.1114\n",
            "Epoch 335/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1556 - mae: 0.1045 - val_loss: 0.1489 - val_mae: 0.1120\n",
            "Epoch 336/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1735 - mae: 0.1069 - val_loss: 0.1539 - val_mae: 0.1145\n",
            "Epoch 337/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1626 - mae: 0.1051 - val_loss: 0.1432 - val_mae: 0.1081\n",
            "Epoch 338/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2573 - mae: 0.1162 - val_loss: 0.1441 - val_mae: 0.1083\n",
            "Epoch 339/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1347 - mae: 0.0937 - val_loss: 0.1465 - val_mae: 0.1113\n",
            "Epoch 340/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1679 - mae: 0.1038 - val_loss: 0.1570 - val_mae: 0.1177\n",
            "Epoch 341/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1837 - mae: 0.1034 - val_loss: 0.1468 - val_mae: 0.1096\n",
            "Epoch 342/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1965 - mae: 0.1068 - val_loss: 0.1510 - val_mae: 0.1127\n",
            "Epoch 343/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1671 - mae: 0.1084 - val_loss: 0.1442 - val_mae: 0.1102\n",
            "Epoch 344/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1860 - mae: 0.1097 - val_loss: 0.1485 - val_mae: 0.1152\n",
            "Epoch 345/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1406 - mae: 0.1016 - val_loss: 0.1471 - val_mae: 0.1110\n",
            "Epoch 346/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1916 - mae: 0.1110 - val_loss: 0.1522 - val_mae: 0.1113\n",
            "Epoch 347/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2220 - mae: 0.1134 - val_loss: 0.1484 - val_mae: 0.1109\n",
            "Epoch 348/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1959 - mae: 0.1091 - val_loss: 0.1503 - val_mae: 0.1118\n",
            "Epoch 349/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1403 - mae: 0.1025 - val_loss: 0.1434 - val_mae: 0.1109\n",
            "Epoch 350/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2075 - mae: 0.1153 - val_loss: 0.1528 - val_mae: 0.1129\n",
            "Epoch 351/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1520 - mae: 0.0951 - val_loss: 0.1436 - val_mae: 0.1107\n",
            "Epoch 352/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1691 - mae: 0.1143 - val_loss: 0.1576 - val_mae: 0.1153\n",
            "Epoch 353/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1353 - mae: 0.0966 - val_loss: 0.1450 - val_mae: 0.1091\n",
            "Epoch 354/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2030 - mae: 0.1085 - val_loss: 0.1471 - val_mae: 0.1104\n",
            "Epoch 355/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2481 - mae: 0.1256 - val_loss: 0.1496 - val_mae: 0.1128\n",
            "Epoch 356/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1502 - mae: 0.1012 - val_loss: 0.1492 - val_mae: 0.1149\n",
            "Epoch 357/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1693 - mae: 0.0983 - val_loss: 0.1494 - val_mae: 0.1166\n",
            "Epoch 358/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2120 - mae: 0.1205 - val_loss: 0.1473 - val_mae: 0.1111\n",
            "Epoch 359/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1266 - mae: 0.1017 - val_loss: 0.1448 - val_mae: 0.1102\n",
            "Epoch 360/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.1098 - mae: 0.0939 - val_loss: 0.1458 - val_mae: 0.1101\n",
            "Epoch 361/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1801 - mae: 0.1074 - val_loss: 0.1534 - val_mae: 0.1123\n",
            "Epoch 362/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1673 - mae: 0.1033 - val_loss: 0.1472 - val_mae: 0.1119\n",
            "Epoch 363/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1730 - mae: 0.1077 - val_loss: 0.1539 - val_mae: 0.1146\n",
            "Epoch 364/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1780 - mae: 0.1080 - val_loss: 0.1469 - val_mae: 0.1114\n",
            "Epoch 365/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1558 - mae: 0.1079 - val_loss: 0.1445 - val_mae: 0.1093\n",
            "Epoch 366/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1419 - mae: 0.1067 - val_loss: 0.1504 - val_mae: 0.1134\n",
            "Epoch 367/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1795 - mae: 0.1110 - val_loss: 0.1500 - val_mae: 0.1182\n",
            "Epoch 368/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2409 - mae: 0.1216 - val_loss: 0.1516 - val_mae: 0.1130\n",
            "Epoch 369/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1656 - mae: 0.1036 - val_loss: 0.1484 - val_mae: 0.1158\n",
            "Epoch 370/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1629 - mae: 0.1042 - val_loss: 0.1463 - val_mae: 0.1151\n",
            "Epoch 371/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1774 - mae: 0.1062 - val_loss: 0.1468 - val_mae: 0.1145\n",
            "Epoch 372/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1995 - mae: 0.1162 - val_loss: 0.1471 - val_mae: 0.1112\n",
            "Epoch 373/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1834 - mae: 0.1079 - val_loss: 0.1479 - val_mae: 0.1102\n",
            "Epoch 374/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1434 - mae: 0.1007 - val_loss: 0.1441 - val_mae: 0.1096\n",
            "Epoch 375/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1666 - mae: 0.1027 - val_loss: 0.1534 - val_mae: 0.1137\n",
            "Epoch 376/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1441 - mae: 0.0983 - val_loss: 0.1432 - val_mae: 0.1114\n",
            "Epoch 377/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1985 - mae: 0.1097 - val_loss: 0.1522 - val_mae: 0.1149\n",
            "Epoch 378/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1904 - mae: 0.1130 - val_loss: 0.1483 - val_mae: 0.1097\n",
            "Epoch 379/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1453 - mae: 0.1020 - val_loss: 0.1467 - val_mae: 0.1137\n",
            "Epoch 380/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2401 - mae: 0.1173 - val_loss: 0.1483 - val_mae: 0.1121\n",
            "Epoch 381/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1910 - mae: 0.1039 - val_loss: 0.1400 - val_mae: 0.1080\n",
            "Epoch 382/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2516 - mae: 0.1144 - val_loss: 0.1522 - val_mae: 0.1140\n",
            "Epoch 383/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1810 - mae: 0.1131 - val_loss: 0.1472 - val_mae: 0.1105\n",
            "Epoch 384/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1659 - mae: 0.1076 - val_loss: 0.1486 - val_mae: 0.1118\n",
            "Epoch 385/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2015 - mae: 0.1191 - val_loss: 0.1416 - val_mae: 0.1078\n",
            "Epoch 386/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1758 - mae: 0.1072 - val_loss: 0.1479 - val_mae: 0.1103\n",
            "Epoch 387/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1672 - mae: 0.1101 - val_loss: 0.1487 - val_mae: 0.1109\n",
            "Epoch 388/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1683 - mae: 0.1068 - val_loss: 0.1468 - val_mae: 0.1110\n",
            "Epoch 389/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1932 - mae: 0.1017 - val_loss: 0.1504 - val_mae: 0.1135\n",
            "Epoch 390/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1204 - mae: 0.0884 - val_loss: 0.1389 - val_mae: 0.1084\n",
            "Epoch 391/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1286 - mae: 0.0989 - val_loss: 0.1502 - val_mae: 0.1135\n",
            "Epoch 392/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1836 - mae: 0.1120 - val_loss: 0.1462 - val_mae: 0.1115\n",
            "Epoch 393/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1937 - mae: 0.1071 - val_loss: 0.1511 - val_mae: 0.1146\n",
            "Epoch 394/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2094 - mae: 0.1071 - val_loss: 0.1464 - val_mae: 0.1111\n",
            "Epoch 395/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1551 - mae: 0.1047 - val_loss: 0.1488 - val_mae: 0.1121\n",
            "Epoch 396/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1713 - mae: 0.1068 - val_loss: 0.1438 - val_mae: 0.1089\n",
            "Epoch 397/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1330 - mae: 0.0970 - val_loss: 0.1508 - val_mae: 0.1131\n",
            "Epoch 398/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1738 - mae: 0.1024 - val_loss: 0.1397 - val_mae: 0.1079\n",
            "Epoch 399/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2023 - mae: 0.1118 - val_loss: 0.1505 - val_mae: 0.1112\n",
            "Epoch 400/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1738 - mae: 0.1066 - val_loss: 0.1489 - val_mae: 0.1107\n",
            "Epoch 401/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2221 - mae: 0.1088 - val_loss: 0.1437 - val_mae: 0.1080\n",
            "Epoch 402/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2417 - mae: 0.1130 - val_loss: 0.1464 - val_mae: 0.1102\n",
            "Epoch 403/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1608 - mae: 0.1041 - val_loss: 0.1481 - val_mae: 0.1110\n",
            "Epoch 404/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1569 - mae: 0.1023 - val_loss: 0.1529 - val_mae: 0.1138\n",
            "Epoch 405/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1398 - mae: 0.0977 - val_loss: 0.1499 - val_mae: 0.1100\n",
            "Epoch 406/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2941 - mae: 0.1233 - val_loss: 0.1451 - val_mae: 0.1076\n",
            "Epoch 407/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1922 - mae: 0.1040 - val_loss: 0.1430 - val_mae: 0.1121\n",
            "Epoch 408/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1958 - mae: 0.1111 - val_loss: 0.1522 - val_mae: 0.1113\n",
            "Epoch 409/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1956 - mae: 0.1119 - val_loss: 0.1468 - val_mae: 0.1117\n",
            "Epoch 410/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2207 - mae: 0.1097 - val_loss: 0.1477 - val_mae: 0.1103\n",
            "Epoch 411/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1652 - mae: 0.1026 - val_loss: 0.1478 - val_mae: 0.1106\n",
            "Epoch 412/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1715 - mae: 0.1048 - val_loss: 0.1480 - val_mae: 0.1128\n",
            "Epoch 413/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1990 - mae: 0.1090 - val_loss: 0.1540 - val_mae: 0.1123\n",
            "Epoch 414/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1808 - mae: 0.1058 - val_loss: 0.1435 - val_mae: 0.1091\n",
            "Epoch 415/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2783 - mae: 0.1238 - val_loss: 0.1453 - val_mae: 0.1079\n",
            "Epoch 416/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2361 - mae: 0.1126 - val_loss: 0.1458 - val_mae: 0.1110\n",
            "Epoch 417/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1435 - mae: 0.0987 - val_loss: 0.1492 - val_mae: 0.1150\n",
            "Epoch 418/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2002 - mae: 0.1103 - val_loss: 0.1460 - val_mae: 0.1238\n",
            "Epoch 419/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2372 - mae: 0.1237 - val_loss: 0.1429 - val_mae: 0.1207\n",
            "Epoch 420/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2030 - mae: 0.1214 - val_loss: 0.1446 - val_mae: 0.1099\n",
            "Epoch 421/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2814 - mae: 0.1265 - val_loss: 0.1467 - val_mae: 0.1118\n",
            "Epoch 422/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1337 - mae: 0.0944 - val_loss: 0.1433 - val_mae: 0.1105\n",
            "Epoch 423/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1430 - mae: 0.1024 - val_loss: 0.1478 - val_mae: 0.1129\n",
            "Epoch 424/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3042 - mae: 0.1263 - val_loss: 0.1465 - val_mae: 0.1078\n",
            "Epoch 425/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1470 - mae: 0.1020 - val_loss: 0.1429 - val_mae: 0.1128\n",
            "Epoch 426/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.1766 - mae: 0.1052 - val_loss: 0.1526 - val_mae: 0.1152\n",
            "Epoch 427/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1472 - mae: 0.1027 - val_loss: 0.1431 - val_mae: 0.1144\n",
            "Epoch 428/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1663 - mae: 0.1102 - val_loss: 0.1456 - val_mae: 0.1091\n",
            "Epoch 429/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1678 - mae: 0.1058 - val_loss: 0.1500 - val_mae: 0.1106\n",
            "Epoch 430/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1669 - mae: 0.1040 - val_loss: 0.1445 - val_mae: 0.1097\n",
            "Epoch 431/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1974 - mae: 0.1102 - val_loss: 0.1545 - val_mae: 0.1128\n",
            "Epoch 432/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1051 - mae: 0.0907 - val_loss: 0.1403 - val_mae: 0.1062\n",
            "Epoch 433/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1507 - mae: 0.1038 - val_loss: 0.1612 - val_mae: 0.1184\n",
            "Epoch 434/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1707 - mae: 0.1049 - val_loss: 0.1490 - val_mae: 0.1216\n",
            "Epoch 435/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2146 - mae: 0.1261 - val_loss: 0.1411 - val_mae: 0.1095\n",
            "Epoch 436/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1505 - mae: 0.1010 - val_loss: 0.1491 - val_mae: 0.1238\n",
            "Epoch 437/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1856 - mae: 0.1187 - val_loss: 0.1523 - val_mae: 0.1154\n",
            "Epoch 438/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1647 - mae: 0.1000 - val_loss: 0.1440 - val_mae: 0.1084\n",
            "Epoch 439/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2102 - mae: 0.1105 - val_loss: 0.1505 - val_mae: 0.1117\n",
            "Epoch 440/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1736 - mae: 0.1025 - val_loss: 0.1446 - val_mae: 0.1156\n",
            "Epoch 441/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1766 - mae: 0.1056 - val_loss: 0.1488 - val_mae: 0.1111\n",
            "Epoch 442/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1633 - mae: 0.0990 - val_loss: 0.1455 - val_mae: 0.1129\n",
            "Epoch 443/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2264 - mae: 0.1188 - val_loss: 0.1471 - val_mae: 0.1085\n",
            "Epoch 444/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1496 - mae: 0.1029 - val_loss: 0.1468 - val_mae: 0.1089\n",
            "Epoch 445/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1686 - mae: 0.1048 - val_loss: 0.1478 - val_mae: 0.1091\n",
            "Epoch 446/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1431 - mae: 0.0947 - val_loss: 0.1504 - val_mae: 0.1088\n",
            "Epoch 447/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1409 - mae: 0.0960 - val_loss: 0.1453 - val_mae: 0.1072\n",
            "Epoch 448/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1969 - mae: 0.1160 - val_loss: 0.1462 - val_mae: 0.1082\n",
            "Epoch 449/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1328 - mae: 0.0966 - val_loss: 0.1484 - val_mae: 0.1113\n",
            "Epoch 450/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.1037 - val_loss: 0.1481 - val_mae: 0.1094\n",
            "Epoch 451/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1768 - mae: 0.0996 - val_loss: 0.1481 - val_mae: 0.1117\n",
            "Epoch 452/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2299 - mae: 0.1198 - val_loss: 0.1476 - val_mae: 0.1095\n",
            "Epoch 453/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2093 - mae: 0.1126 - val_loss: 0.1484 - val_mae: 0.1094\n",
            "Epoch 454/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2827 - mae: 0.1265 - val_loss: 0.1506 - val_mae: 0.1088\n",
            "Epoch 455/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2168 - mae: 0.1092 - val_loss: 0.1423 - val_mae: 0.1083\n",
            "Epoch 456/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1515 - mae: 0.1063 - val_loss: 0.1491 - val_mae: 0.1092\n",
            "Epoch 457/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1442 - mae: 0.1023 - val_loss: 0.1500 - val_mae: 0.1096\n",
            "Epoch 458/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2802 - mae: 0.1168 - val_loss: 0.1461 - val_mae: 0.1084\n",
            "Epoch 459/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2294 - mae: 0.1068 - val_loss: 0.1471 - val_mae: 0.1080\n",
            "Epoch 460/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1966 - mae: 0.1025 - val_loss: 0.1458 - val_mae: 0.1089\n",
            "Epoch 461/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1627 - mae: 0.1001 - val_loss: 0.1474 - val_mae: 0.1102\n",
            "Epoch 462/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1838 - mae: 0.0998 - val_loss: 0.1484 - val_mae: 0.1092\n",
            "Epoch 463/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1260 - mae: 0.0936 - val_loss: 0.1477 - val_mae: 0.1099\n",
            "Epoch 464/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1676 - mae: 0.1058 - val_loss: 0.1502 - val_mae: 0.1109\n",
            "Epoch 465/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1896 - mae: 0.1039 - val_loss: 0.1446 - val_mae: 0.1081\n",
            "Epoch 466/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1860 - mae: 0.1063 - val_loss: 0.1473 - val_mae: 0.1091\n",
            "Epoch 467/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1270 - mae: 0.0937 - val_loss: 0.1523 - val_mae: 0.1112\n",
            "Epoch 468/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1473 - mae: 0.0936 - val_loss: 0.1469 - val_mae: 0.1089\n",
            "Epoch 469/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1515 - mae: 0.0982 - val_loss: 0.1503 - val_mae: 0.1113\n",
            "Epoch 470/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2129 - mae: 0.1082 - val_loss: 0.1551 - val_mae: 0.1122\n",
            "Epoch 471/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2155 - mae: 0.1153 - val_loss: 0.1424 - val_mae: 0.1087\n",
            "Epoch 472/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2074 - mae: 0.1053 - val_loss: 0.1484 - val_mae: 0.1097\n",
            "Epoch 473/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1932 - mae: 0.1060 - val_loss: 0.1452 - val_mae: 0.1090\n",
            "Epoch 474/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1719 - mae: 0.1032 - val_loss: 0.1489 - val_mae: 0.1130\n",
            "Epoch 475/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2428 - mae: 0.1222 - val_loss: 0.1456 - val_mae: 0.1104\n",
            "Epoch 476/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2491 - mae: 0.1190 - val_loss: 0.1480 - val_mae: 0.1096\n",
            "Epoch 477/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1650 - mae: 0.1035 - val_loss: 0.1544 - val_mae: 0.1136\n",
            "Epoch 478/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2178 - mae: 0.1051 - val_loss: 0.1504 - val_mae: 0.1089\n",
            "Epoch 479/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1277 - mae: 0.0949 - val_loss: 0.1408 - val_mae: 0.1057\n",
            "Epoch 480/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2583 - mae: 0.1173 - val_loss: 0.1525 - val_mae: 0.1121\n",
            "Epoch 481/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1969 - mae: 0.1099 - val_loss: 0.1437 - val_mae: 0.1100\n",
            "Epoch 482/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1640 - mae: 0.1062 - val_loss: 0.1452 - val_mae: 0.1079\n",
            "Epoch 483/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1721 - mae: 0.1120 - val_loss: 0.1404 - val_mae: 0.1057\n",
            "Epoch 484/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2121 - mae: 0.1055 - val_loss: 0.1486 - val_mae: 0.1103\n",
            "Epoch 485/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1667 - mae: 0.1030 - val_loss: 0.1519 - val_mae: 0.1109\n",
            "Epoch 486/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3140 - mae: 0.1286 - val_loss: 0.1517 - val_mae: 0.1094\n",
            "Epoch 487/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2308 - mae: 0.1185 - val_loss: 0.1482 - val_mae: 0.1083\n",
            "Epoch 488/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1999 - mae: 0.1037 - val_loss: 0.1459 - val_mae: 0.1072\n",
            "Epoch 489/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.1321 - val_loss: 0.1495 - val_mae: 0.1104\n",
            "Epoch 490/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2243 - mae: 0.1082 - val_loss: 0.1486 - val_mae: 0.1082\n",
            "Epoch 491/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1727 - mae: 0.1033 - val_loss: 0.1453 - val_mae: 0.1070\n",
            "Epoch 492/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1828 - mae: 0.1065 - val_loss: 0.1480 - val_mae: 0.1095\n",
            "Epoch 493/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.1870 - mae: 0.1066 - val_loss: 0.1469 - val_mae: 0.1089\n",
            "Epoch 494/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1704 - mae: 0.1093 - val_loss: 0.1433 - val_mae: 0.1072\n",
            "Epoch 495/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1771 - mae: 0.1080 - val_loss: 0.1490 - val_mae: 0.1083\n",
            "Epoch 496/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1770 - mae: 0.1130 - val_loss: 0.1489 - val_mae: 0.1088\n",
            "Epoch 497/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1714 - mae: 0.1071 - val_loss: 0.1497 - val_mae: 0.1096\n",
            "Epoch 498/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1853 - mae: 0.1103 - val_loss: 0.1483 - val_mae: 0.1088\n",
            "Epoch 499/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1773 - mae: 0.1027 - val_loss: 0.1506 - val_mae: 0.1115\n",
            "Epoch 500/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1926 - mae: 0.1059 - val_loss: 0.1454 - val_mae: 0.1080\n",
            "Epoch 501/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1578 - mae: 0.1038 - val_loss: 0.1490 - val_mae: 0.1103\n",
            "Epoch 502/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1851 - mae: 0.1129 - val_loss: 0.1498 - val_mae: 0.1100\n",
            "Epoch 503/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2305 - mae: 0.1139 - val_loss: 0.1530 - val_mae: 0.1100\n",
            "Epoch 504/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1698 - mae: 0.1041 - val_loss: 0.1429 - val_mae: 0.1073\n",
            "Epoch 505/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2406 - mae: 0.1071 - val_loss: 0.1494 - val_mae: 0.1113\n",
            "Epoch 506/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1816 - mae: 0.1044 - val_loss: 0.1453 - val_mae: 0.1073\n",
            "Epoch 507/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1775 - mae: 0.1025 - val_loss: 0.1510 - val_mae: 0.1108\n",
            "Epoch 508/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1627 - mae: 0.0983 - val_loss: 0.1461 - val_mae: 0.1074\n",
            "Epoch 509/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2682 - mae: 0.1167 - val_loss: 0.1468 - val_mae: 0.1076\n",
            "Epoch 510/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1688 - mae: 0.1025 - val_loss: 0.1439 - val_mae: 0.1068\n",
            "Epoch 511/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1456 - mae: 0.1001 - val_loss: 0.1483 - val_mae: 0.1098\n",
            "Epoch 512/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1931 - mae: 0.1036 - val_loss: 0.1468 - val_mae: 0.1106\n",
            "Epoch 513/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2038 - mae: 0.1099 - val_loss: 0.1457 - val_mae: 0.1083\n",
            "Epoch 514/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2096 - mae: 0.1123 - val_loss: 0.1480 - val_mae: 0.1089\n",
            "Epoch 515/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2236 - mae: 0.1106 - val_loss: 0.1490 - val_mae: 0.1090\n",
            "Epoch 516/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1216 - mae: 0.0909 - val_loss: 0.1479 - val_mae: 0.1100\n",
            "Epoch 517/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1910 - mae: 0.1009 - val_loss: 0.1517 - val_mae: 0.1095\n",
            "Epoch 518/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1266 - mae: 0.0879 - val_loss: 0.1502 - val_mae: 0.1128\n",
            "Epoch 519/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2226 - mae: 0.1086 - val_loss: 0.1484 - val_mae: 0.1094\n",
            "Epoch 520/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1315 - mae: 0.0963 - val_loss: 0.1407 - val_mae: 0.1065\n",
            "Epoch 521/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1953 - mae: 0.1078 - val_loss: 0.1501 - val_mae: 0.1114\n",
            "Epoch 522/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1541 - mae: 0.1064 - val_loss: 0.1420 - val_mae: 0.1145\n",
            "Epoch 523/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1783 - mae: 0.1106 - val_loss: 0.1512 - val_mae: 0.1104\n",
            "Epoch 524/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2543 - mae: 0.1164 - val_loss: 0.1321 - val_mae: 0.1059\n",
            "Epoch 525/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1876 - mae: 0.1068 - val_loss: 0.1500 - val_mae: 0.1266\n",
            "Epoch 526/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1940 - mae: 0.1258 - val_loss: 0.1474 - val_mae: 0.1170\n",
            "Epoch 527/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2309 - mae: 0.1200 - val_loss: 0.1450 - val_mae: 0.1199\n",
            "Epoch 528/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1820 - mae: 0.1164 - val_loss: 0.1471 - val_mae: 0.1159\n",
            "Epoch 529/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1320 - mae: 0.0987 - val_loss: 0.1487 - val_mae: 0.1112\n",
            "Epoch 530/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2203 - mae: 0.1125 - val_loss: 0.1495 - val_mae: 0.1117\n",
            "Epoch 531/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2048 - mae: 0.1124 - val_loss: 0.1449 - val_mae: 0.1099\n",
            "Epoch 532/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1136 - mae: 0.0846 - val_loss: 0.1503 - val_mae: 0.1086\n",
            "Epoch 533/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1672 - mae: 0.0964 - val_loss: 0.1446 - val_mae: 0.1078\n",
            "Epoch 534/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1695 - mae: 0.1003 - val_loss: 0.1468 - val_mae: 0.1077\n",
            "Epoch 535/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1512 - mae: 0.0995 - val_loss: 0.1444 - val_mae: 0.1076\n",
            "Epoch 536/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1734 - mae: 0.0985 - val_loss: 0.1484 - val_mae: 0.1109\n",
            "Epoch 537/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1546 - mae: 0.0964 - val_loss: 0.1473 - val_mae: 0.1075\n",
            "Epoch 538/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1606 - mae: 0.0969 - val_loss: 0.1452 - val_mae: 0.1073\n",
            "Epoch 539/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2753 - mae: 0.1160 - val_loss: 0.1491 - val_mae: 0.1084\n",
            "Epoch 540/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2413 - mae: 0.1147 - val_loss: 0.1439 - val_mae: 0.1063\n",
            "Epoch 541/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2593 - mae: 0.1131 - val_loss: 0.1472 - val_mae: 0.1079\n",
            "Epoch 542/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1709 - mae: 0.1025 - val_loss: 0.1503 - val_mae: 0.1102\n",
            "Epoch 543/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2079 - mae: 0.1107 - val_loss: 0.1453 - val_mae: 0.1105\n",
            "Epoch 544/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1961 - mae: 0.1083 - val_loss: 0.1405 - val_mae: 0.1092\n",
            "Epoch 545/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2177 - mae: 0.1095 - val_loss: 0.1509 - val_mae: 0.1157\n",
            "Epoch 546/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1895 - mae: 0.1126 - val_loss: 0.1402 - val_mae: 0.1092\n",
            "Epoch 547/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1656 - mae: 0.1006 - val_loss: 0.1485 - val_mae: 0.1106\n",
            "Epoch 548/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2051 - mae: 0.1155 - val_loss: 0.1466 - val_mae: 0.1104\n",
            "Epoch 549/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.1443 - mae: 0.1002 - val_loss: 0.1486 - val_mae: 0.1082\n",
            "Epoch 550/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1827 - mae: 0.1086 - val_loss: 0.1473 - val_mae: 0.1091\n",
            "Epoch 551/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2272 - mae: 0.1128 - val_loss: 0.1463 - val_mae: 0.1071\n",
            "Epoch 552/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1754 - mae: 0.1000 - val_loss: 0.1438 - val_mae: 0.1067\n",
            "Epoch 553/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1580 - mae: 0.0989 - val_loss: 0.1492 - val_mae: 0.1100\n",
            "Epoch 554/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1799 - mae: 0.1010 - val_loss: 0.1493 - val_mae: 0.1089\n",
            "Epoch 555/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1455 - mae: 0.0983 - val_loss: 0.1444 - val_mae: 0.1053\n",
            "Epoch 556/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1950 - mae: 0.1076 - val_loss: 0.1501 - val_mae: 0.1096\n",
            "Epoch 557/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1936 - mae: 0.1050 - val_loss: 0.1489 - val_mae: 0.1086\n",
            "Epoch 558/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1987 - mae: 0.1045 - val_loss: 0.1482 - val_mae: 0.1121\n",
            "Epoch 559/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2057 - mae: 0.1079 - val_loss: 0.1712 - val_mae: 0.1447\n",
            "Epoch 560/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1537 - mae: 0.1175 - val_loss: 0.1465 - val_mae: 0.1184\n",
            "Epoch 561/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1368 - mae: 0.1013 - val_loss: 0.1437 - val_mae: 0.1129\n",
            "Epoch 562/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2135 - mae: 0.1156 - val_loss: 0.1441 - val_mae: 0.1277\n",
            "Epoch 563/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1887 - mae: 0.1215 - val_loss: 0.1571 - val_mae: 0.1261\n",
            "Epoch 564/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2441 - mae: 0.1313 - val_loss: 0.1487 - val_mae: 0.1144\n",
            "Epoch 565/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1940 - mae: 0.1146 - val_loss: 0.1470 - val_mae: 0.1188\n",
            "Epoch 566/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1307 - mae: 0.1001 - val_loss: 0.1523 - val_mae: 0.1167\n",
            "Epoch 567/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1764 - mae: 0.1051 - val_loss: 0.1531 - val_mae: 0.1151\n",
            "Epoch 568/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1591 - mae: 0.1019 - val_loss: 0.1469 - val_mae: 0.1093\n",
            "Epoch 569/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1975 - mae: 0.1047 - val_loss: 0.1509 - val_mae: 0.1087\n",
            "Epoch 570/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1561 - mae: 0.0988 - val_loss: 0.1437 - val_mae: 0.1064\n",
            "Epoch 571/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1532 - mae: 0.0979 - val_loss: 0.1502 - val_mae: 0.1103\n",
            "Epoch 572/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1647 - mae: 0.1000 - val_loss: 0.1485 - val_mae: 0.1103\n",
            "Epoch 573/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1563 - mae: 0.0958 - val_loss: 0.1464 - val_mae: 0.1091\n",
            "Epoch 574/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1275 - mae: 0.0959 - val_loss: 0.1467 - val_mae: 0.1080\n",
            "Epoch 575/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1658 - mae: 0.1027 - val_loss: 0.1571 - val_mae: 0.1113\n",
            "Epoch 576/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2479 - mae: 0.1079 - val_loss: 0.1505 - val_mae: 0.1086\n",
            "Epoch 577/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2118 - mae: 0.1141 - val_loss: 0.1488 - val_mae: 0.1077\n",
            "Epoch 578/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1600 - mae: 0.0965 - val_loss: 0.1501 - val_mae: 0.1083\n",
            "Epoch 579/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1683 - mae: 0.1022 - val_loss: 0.1440 - val_mae: 0.1056\n",
            "Epoch 580/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1441 - mae: 0.0968 - val_loss: 0.1499 - val_mae: 0.1079\n",
            "Epoch 581/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2183 - mae: 0.1102 - val_loss: 0.1502 - val_mae: 0.1094\n",
            "Epoch 582/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2288 - mae: 0.1189 - val_loss: 0.1475 - val_mae: 0.1086\n",
            "Epoch 583/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1394 - mae: 0.1013 - val_loss: 0.1439 - val_mae: 0.1054\n",
            "Epoch 584/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1747 - mae: 0.1046 - val_loss: 0.1522 - val_mae: 0.1089\n",
            "Epoch 585/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1759 - mae: 0.1031 - val_loss: 0.1552 - val_mae: 0.1107\n",
            "Epoch 586/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1518 - mae: 0.0971 - val_loss: 0.1491 - val_mae: 0.1091\n",
            "Epoch 587/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1412 - mae: 0.0987 - val_loss: 0.1444 - val_mae: 0.1055\n",
            "Epoch 588/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2419 - mae: 0.1055 - val_loss: 0.1533 - val_mae: 0.1101\n",
            "Epoch 589/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1792 - mae: 0.1073 - val_loss: 0.1419 - val_mae: 0.1043\n",
            "Epoch 590/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1594 - mae: 0.0944 - val_loss: 0.1522 - val_mae: 0.1086\n",
            "Epoch 591/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1557 - mae: 0.1028 - val_loss: 0.1455 - val_mae: 0.1055\n",
            "Epoch 592/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1520 - mae: 0.0993 - val_loss: 0.1472 - val_mae: 0.1073\n",
            "Epoch 593/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1626 - mae: 0.1012 - val_loss: 0.1530 - val_mae: 0.1093\n",
            "Epoch 594/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1497 - mae: 0.1036 - val_loss: 0.1478 - val_mae: 0.1070\n",
            "Epoch 595/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1764 - mae: 0.0974 - val_loss: 0.1533 - val_mae: 0.1092\n",
            "Epoch 596/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1728 - mae: 0.0997 - val_loss: 0.1485 - val_mae: 0.1076\n",
            "Epoch 597/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2483 - mae: 0.1104 - val_loss: 0.1519 - val_mae: 0.1092\n",
            "Epoch 598/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1480 - mae: 0.0986 - val_loss: 0.1447 - val_mae: 0.1052\n",
            "Epoch 599/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1984 - mae: 0.1071 - val_loss: 0.1529 - val_mae: 0.1102\n",
            "Epoch 600/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2701 - mae: 0.1161 - val_loss: 0.1517 - val_mae: 0.1091\n",
            "Epoch 601/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1591 - mae: 0.1036 - val_loss: 0.1432 - val_mae: 0.1062\n",
            "Epoch 602/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1773 - mae: 0.1029 - val_loss: 0.1413 - val_mae: 0.1126\n",
            "Epoch 603/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3373 - mae: 0.1364 - val_loss: 0.1380 - val_mae: 0.1146\n",
            "Epoch 604/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2026 - mae: 0.1072 - val_loss: 0.1423 - val_mae: 0.1097\n",
            "Epoch 605/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2977 - mae: 0.1210 - val_loss: 0.1458 - val_mae: 0.1063\n",
            "Epoch 606/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1357 - mae: 0.0991 - val_loss: 0.1407 - val_mae: 0.1050\n",
            "Epoch 607/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1911 - mae: 0.1057 - val_loss: 0.1510 - val_mae: 0.1107\n",
            "Epoch 608/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1257 - mae: 0.0923 - val_loss: 0.1460 - val_mae: 0.1090\n",
            "Epoch 609/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1585 - mae: 0.0974 - val_loss: 0.1482 - val_mae: 0.1075\n",
            "Epoch 610/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1479 - mae: 0.0991 - val_loss: 0.1517 - val_mae: 0.1120\n",
            "Epoch 611/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2385 - mae: 0.1190 - val_loss: 0.1470 - val_mae: 0.1085\n",
            "Epoch 612/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1216 - mae: 0.0876 - val_loss: 0.1496 - val_mae: 0.1091\n",
            "Epoch 613/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.1547 - mae: 0.1034 - val_loss: 0.1475 - val_mae: 0.1084\n",
            "Epoch 614/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2496 - mae: 0.1144 - val_loss: 0.1496 - val_mae: 0.1084\n",
            "Epoch 615/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1766 - mae: 0.0929 - val_loss: 0.1518 - val_mae: 0.1096\n",
            "Epoch 616/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2083 - mae: 0.1041 - val_loss: 0.1497 - val_mae: 0.1083\n",
            "Epoch 617/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1200 - mae: 0.0914 - val_loss: 0.1419 - val_mae: 0.1048\n",
            "Epoch 618/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1584 - mae: 0.1010 - val_loss: 0.1576 - val_mae: 0.1133\n",
            "Epoch 619/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1526 - mae: 0.0980 - val_loss: 0.1487 - val_mae: 0.1086\n",
            "Epoch 620/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1903 - mae: 0.1016 - val_loss: 0.1532 - val_mae: 0.1094\n",
            "Epoch 621/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2024 - mae: 0.1036 - val_loss: 0.1446 - val_mae: 0.1069\n",
            "Epoch 622/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2040 - mae: 0.1048 - val_loss: 0.1433 - val_mae: 0.1062\n",
            "Epoch 623/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1850 - mae: 0.1047 - val_loss: 0.1491 - val_mae: 0.1086\n",
            "Epoch 624/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1804 - mae: 0.1027 - val_loss: 0.1449 - val_mae: 0.1064\n",
            "Epoch 625/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1614 - mae: 0.1013 - val_loss: 0.1512 - val_mae: 0.1087\n",
            "Epoch 626/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2924 - mae: 0.1215 - val_loss: 0.1481 - val_mae: 0.1082\n",
            "Epoch 627/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1950 - mae: 0.1065 - val_loss: 0.1503 - val_mae: 0.1098\n",
            "Epoch 628/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2467 - mae: 0.1126 - val_loss: 0.1487 - val_mae: 0.1078\n",
            "Epoch 629/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1427 - mae: 0.1001 - val_loss: 0.1458 - val_mae: 0.1069\n",
            "Epoch 630/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1436 - mae: 0.0938 - val_loss: 0.1472 - val_mae: 0.1089\n",
            "Epoch 631/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2906 - mae: 0.1184 - val_loss: 0.1490 - val_mae: 0.1087\n",
            "Epoch 632/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2195 - mae: 0.1118 - val_loss: 0.1522 - val_mae: 0.1099\n",
            "Epoch 633/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1492 - mae: 0.1003 - val_loss: 0.1474 - val_mae: 0.1067\n",
            "Epoch 634/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2148 - mae: 0.1107 - val_loss: 0.1527 - val_mae: 0.1136\n",
            "Epoch 635/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1608 - mae: 0.1037 - val_loss: 0.1447 - val_mae: 0.1070\n",
            "Epoch 636/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1688 - mae: 0.1040 - val_loss: 0.1424 - val_mae: 0.1071\n",
            "Epoch 637/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1479 - mae: 0.0939 - val_loss: 0.1548 - val_mae: 0.1101\n",
            "Epoch 638/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1521 - mae: 0.1005 - val_loss: 0.1459 - val_mae: 0.1078\n",
            "Epoch 639/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1760 - mae: 0.1055 - val_loss: 0.1542 - val_mae: 0.1104\n",
            "Epoch 640/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1935 - mae: 0.1084 - val_loss: 0.1531 - val_mae: 0.1097\n",
            "Epoch 641/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1969 - mae: 0.1146 - val_loss: 0.1465 - val_mae: 0.1071\n",
            "Epoch 642/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3036 - mae: 0.1244 - val_loss: 0.1443 - val_mae: 0.1062\n",
            "Epoch 643/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1735 - mae: 0.0960 - val_loss: 0.1486 - val_mae: 0.1070\n",
            "Epoch 644/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1968 - mae: 0.1039 - val_loss: 0.1499 - val_mae: 0.1078\n",
            "Epoch 645/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1500 - mae: 0.0967 - val_loss: 0.1462 - val_mae: 0.1061\n",
            "Epoch 646/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1222 - mae: 0.0956 - val_loss: 0.1443 - val_mae: 0.1058\n",
            "Epoch 647/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1676 - mae: 0.1047 - val_loss: 0.1548 - val_mae: 0.1090\n",
            "Epoch 648/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1714 - mae: 0.1053 - val_loss: 0.1502 - val_mae: 0.1087\n",
            "Epoch 649/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1697 - mae: 0.1092 - val_loss: 0.1495 - val_mae: 0.1080\n",
            "Epoch 650/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1718 - mae: 0.0984 - val_loss: 0.1499 - val_mae: 0.1097\n",
            "Epoch 651/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2004 - mae: 0.1026 - val_loss: 0.1527 - val_mae: 0.1114\n",
            "Epoch 652/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2075 - mae: 0.0991 - val_loss: 0.1474 - val_mae: 0.1083\n",
            "Epoch 653/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2291 - mae: 0.1110 - val_loss: 0.1408 - val_mae: 0.1183\n",
            "Epoch 654/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1845 - mae: 0.1108 - val_loss: 0.1527 - val_mae: 0.1229\n",
            "Epoch 655/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2008 - mae: 0.1257 - val_loss: 0.1471 - val_mae: 0.1189\n",
            "Epoch 656/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2107 - mae: 0.1205 - val_loss: 0.1541 - val_mae: 0.1216\n",
            "Epoch 657/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2208 - mae: 0.1234 - val_loss: 0.1573 - val_mae: 0.1378\n",
            "Epoch 658/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1902 - mae: 0.1251 - val_loss: 0.1447 - val_mae: 0.1132\n",
            "Epoch 659/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1637 - mae: 0.1072 - val_loss: 0.1449 - val_mae: 0.1107\n",
            "Epoch 660/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1247 - mae: 0.0953 - val_loss: 0.1509 - val_mae: 0.1110\n",
            "Epoch 661/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1250 - mae: 0.0938 - val_loss: 0.1501 - val_mae: 0.1167\n",
            "Epoch 662/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2100 - mae: 0.1177 - val_loss: 0.1484 - val_mae: 0.1096\n",
            "Epoch 663/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1844 - mae: 0.0996 - val_loss: 0.1460 - val_mae: 0.1069\n",
            "Epoch 664/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1638 - mae: 0.0958 - val_loss: 0.1472 - val_mae: 0.1076\n",
            "Epoch 665/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2186 - mae: 0.1088 - val_loss: 0.1536 - val_mae: 0.1113\n",
            "Epoch 666/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2126 - mae: 0.1085 - val_loss: 0.1479 - val_mae: 0.1066\n",
            "Epoch 667/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1574 - mae: 0.0948 - val_loss: 0.1474 - val_mae: 0.1062\n",
            "Epoch 668/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1671 - mae: 0.1019 - val_loss: 0.1470 - val_mae: 0.1084\n",
            "Epoch 669/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1849 - mae: 0.1034 - val_loss: 0.1503 - val_mae: 0.1097\n",
            "Epoch 670/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2002 - mae: 0.1077 - val_loss: 0.1508 - val_mae: 0.1088\n",
            "Epoch 671/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1497 - mae: 0.0996 - val_loss: 0.1467 - val_mae: 0.1077\n",
            "Epoch 672/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1608 - mae: 0.0938 - val_loss: 0.1500 - val_mae: 0.1088\n",
            "Epoch 673/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1736 - mae: 0.1065 - val_loss: 0.1471 - val_mae: 0.1075\n",
            "Epoch 674/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2335 - mae: 0.1175 - val_loss: 0.1547 - val_mae: 0.1129\n",
            "Epoch 675/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1733 - mae: 0.0973 - val_loss: 0.1507 - val_mae: 0.1091\n",
            "Epoch 676/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2340 - mae: 0.1109 - val_loss: 0.1454 - val_mae: 0.1052\n",
            "Epoch 677/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1441 - mae: 0.0972 - val_loss: 0.1478 - val_mae: 0.1082\n",
            "Epoch 678/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2275 - mae: 0.1062 - val_loss: 0.1499 - val_mae: 0.1088\n",
            "Epoch 679/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1445 - mae: 0.1001 - val_loss: 0.1423 - val_mae: 0.1046\n",
            "Epoch 680/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.1402 - mae: 0.0952 - val_loss: 0.1491 - val_mae: 0.1089\n",
            "Epoch 681/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1651 - mae: 0.1042 - val_loss: 0.1548 - val_mae: 0.1120\n",
            "Epoch 682/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1627 - mae: 0.1030 - val_loss: 0.1480 - val_mae: 0.1079\n",
            "Epoch 683/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1588 - mae: 0.0959 - val_loss: 0.1507 - val_mae: 0.1078\n",
            "Epoch 684/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2368 - mae: 0.1124 - val_loss: 0.1448 - val_mae: 0.1051\n",
            "Epoch 685/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1414 - mae: 0.0960 - val_loss: 0.1495 - val_mae: 0.1113\n",
            "Epoch 686/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1983 - mae: 0.1076 - val_loss: 0.1507 - val_mae: 0.1085\n",
            "Epoch 687/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1961 - mae: 0.1112 - val_loss: 0.1460 - val_mae: 0.1070\n",
            "Epoch 688/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2204 - mae: 0.1078 - val_loss: 0.1460 - val_mae: 0.1064\n",
            "Epoch 689/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1524 - mae: 0.0889 - val_loss: 0.1439 - val_mae: 0.1058\n",
            "Epoch 690/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1644 - mae: 0.1018 - val_loss: 0.1466 - val_mae: 0.1066\n",
            "Epoch 691/2000\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 0.2506 - mae: 0.1162 - val_loss: 0.1505 - val_mae: 0.1072\n",
            "Epoch 692/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2033 - mae: 0.1058 - val_loss: 0.1512 - val_mae: 0.1088\n",
            "Epoch 693/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1792 - mae: 0.1012 - val_loss: 0.1503 - val_mae: 0.1093\n",
            "Epoch 694/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1716 - mae: 0.1020 - val_loss: 0.1496 - val_mae: 0.1084\n",
            "Epoch 695/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2746 - mae: 0.1154 - val_loss: 0.1468 - val_mae: 0.1074\n",
            "Epoch 696/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1823 - mae: 0.1015 - val_loss: 0.1466 - val_mae: 0.1063\n",
            "Epoch 697/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1978 - mae: 0.1086 - val_loss: 0.1516 - val_mae: 0.1093\n",
            "Epoch 698/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1906 - mae: 0.0992 - val_loss: 0.1513 - val_mae: 0.1109\n",
            "Epoch 699/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2093 - mae: 0.1129 - val_loss: 0.1490 - val_mae: 0.1073\n",
            "Epoch 700/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1264 - mae: 0.0875 - val_loss: 0.1479 - val_mae: 0.1078\n",
            "Epoch 701/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2359 - mae: 0.1099 - val_loss: 0.1471 - val_mae: 0.1058\n",
            "Epoch 702/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1910 - mae: 0.1011 - val_loss: 0.1479 - val_mae: 0.1062\n",
            "Epoch 703/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1623 - mae: 0.0970 - val_loss: 0.1492 - val_mae: 0.1077\n",
            "Epoch 704/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1730 - mae: 0.1007 - val_loss: 0.1470 - val_mae: 0.1065\n",
            "Epoch 705/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1918 - mae: 0.1035 - val_loss: 0.1513 - val_mae: 0.1077\n",
            "Epoch 706/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1571 - mae: 0.0981 - val_loss: 0.1481 - val_mae: 0.1095\n",
            "Epoch 707/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1400 - mae: 0.0958 - val_loss: 0.1491 - val_mae: 0.1077\n",
            "Epoch 708/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1606 - mae: 0.0962 - val_loss: 0.1533 - val_mae: 0.1106\n",
            "Epoch 709/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1502 - mae: 0.0999 - val_loss: 0.1462 - val_mae: 0.1065\n",
            "Epoch 710/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2746 - mae: 0.1125 - val_loss: 0.1530 - val_mae: 0.1085\n",
            "Epoch 711/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2261 - mae: 0.1154 - val_loss: 0.1449 - val_mae: 0.1060\n",
            "Epoch 712/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1576 - mae: 0.0991 - val_loss: 0.1441 - val_mae: 0.1065\n",
            "Epoch 713/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2412 - mae: 0.1089 - val_loss: 0.1515 - val_mae: 0.1079\n",
            "Epoch 714/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1566 - mae: 0.1020 - val_loss: 0.1481 - val_mae: 0.1121\n",
            "Epoch 715/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2215 - mae: 0.1214 - val_loss: 0.1568 - val_mae: 0.1402\n",
            "Epoch 716/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1291 - mae: 0.1239 - val_loss: 0.1349 - val_mae: 0.1143\n",
            "Epoch 717/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1470 - mae: 0.1068 - val_loss: 0.1484 - val_mae: 0.1129\n",
            "Epoch 718/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1839 - mae: 0.1071 - val_loss: 0.1491 - val_mae: 0.1101\n",
            "Epoch 719/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1897 - mae: 0.1099 - val_loss: 0.1446 - val_mae: 0.1073\n",
            "Epoch 720/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1832 - mae: 0.1028 - val_loss: 0.1515 - val_mae: 0.1108\n",
            "Epoch 721/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1680 - mae: 0.1023 - val_loss: 0.1469 - val_mae: 0.1068\n",
            "Epoch 722/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1808 - mae: 0.1026 - val_loss: 0.1450 - val_mae: 0.1056\n",
            "Epoch 723/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2030 - mae: 0.0999 - val_loss: 0.1480 - val_mae: 0.1081\n",
            "Epoch 724/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1958 - mae: 0.1067 - val_loss: 0.1472 - val_mae: 0.1071\n",
            "Epoch 725/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1500 - mae: 0.0968 - val_loss: 0.1472 - val_mae: 0.1072\n",
            "Epoch 726/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2130 - mae: 0.1084 - val_loss: 0.1494 - val_mae: 0.1076\n",
            "Epoch 727/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2423 - mae: 0.1063 - val_loss: 0.1511 - val_mae: 0.1097\n",
            "Epoch 728/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2236 - mae: 0.1101 - val_loss: 0.1487 - val_mae: 0.1067\n",
            "Epoch 729/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1746 - mae: 0.1062 - val_loss: 0.1415 - val_mae: 0.1045\n",
            "Epoch 730/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2323 - mae: 0.1083 - val_loss: 0.1525 - val_mae: 0.1093\n",
            "Epoch 731/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1454 - mae: 0.0968 - val_loss: 0.1483 - val_mae: 0.1074\n",
            "Epoch 732/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1512 - mae: 0.0930 - val_loss: 0.1445 - val_mae: 0.1053\n",
            "Epoch 733/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1962 - mae: 0.1008 - val_loss: 0.1499 - val_mae: 0.1071\n",
            "Epoch 734/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1720 - mae: 0.1002 - val_loss: 0.1511 - val_mae: 0.1076\n",
            "Epoch 735/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1716 - mae: 0.1022 - val_loss: 0.1478 - val_mae: 0.1063\n",
            "Epoch 736/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2639 - mae: 0.1208 - val_loss: 0.1507 - val_mae: 0.1087\n",
            "Epoch 737/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2039 - mae: 0.1059 - val_loss: 0.1484 - val_mae: 0.1093\n",
            "Epoch 738/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1817 - mae: 0.1026 - val_loss: 0.1505 - val_mae: 0.1072\n",
            "Epoch 739/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1941 - mae: 0.1019 - val_loss: 0.1480 - val_mae: 0.1072\n",
            "Epoch 740/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1797 - mae: 0.1004 - val_loss: 0.1486 - val_mae: 0.1065\n",
            "Epoch 741/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2664 - mae: 0.1188 - val_loss: 0.1455 - val_mae: 0.1057\n",
            "Epoch 742/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1795 - mae: 0.0993 - val_loss: 0.1521 - val_mae: 0.1100\n",
            "Epoch 743/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1831 - mae: 0.1004 - val_loss: 0.1503 - val_mae: 0.1085\n",
            "Epoch 744/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1845 - mae: 0.1069 - val_loss: 0.1468 - val_mae: 0.1074\n",
            "Epoch 745/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1531 - mae: 0.0938 - val_loss: 0.1483 - val_mae: 0.1070\n",
            "Epoch 746/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2217 - mae: 0.1074 - val_loss: 0.1466 - val_mae: 0.1069\n",
            "Epoch 747/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.1678 - mae: 0.0986 - val_loss: 0.1514 - val_mae: 0.1090\n",
            "Epoch 748/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1539 - mae: 0.0972 - val_loss: 0.1490 - val_mae: 0.1067\n",
            "Epoch 749/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1642 - mae: 0.0928 - val_loss: 0.1497 - val_mae: 0.1070\n",
            "Epoch 750/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1195 - mae: 0.0940 - val_loss: 0.1458 - val_mae: 0.1061\n",
            "Epoch 751/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2230 - mae: 0.1107 - val_loss: 0.1487 - val_mae: 0.1064\n",
            "Epoch 752/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1918 - mae: 0.1111 - val_loss: 0.1495 - val_mae: 0.1091\n",
            "Epoch 753/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2750 - mae: 0.1115 - val_loss: 0.1478 - val_mae: 0.1071\n",
            "Epoch 754/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1439 - mae: 0.0938 - val_loss: 0.1463 - val_mae: 0.1053\n",
            "Epoch 755/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1517 - mae: 0.0974 - val_loss: 0.1479 - val_mae: 0.1066\n",
            "Epoch 756/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1873 - mae: 0.1076 - val_loss: 0.1493 - val_mae: 0.1074\n",
            "Epoch 757/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1385 - mae: 0.0951 - val_loss: 0.1505 - val_mae: 0.1081\n",
            "Epoch 758/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1805 - mae: 0.1062 - val_loss: 0.1494 - val_mae: 0.1072\n",
            "Epoch 759/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1307 - mae: 0.0915 - val_loss: 0.1471 - val_mae: 0.1064\n",
            "Epoch 760/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1297 - mae: 0.0957 - val_loss: 0.1477 - val_mae: 0.1081\n",
            "Epoch 761/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1286 - mae: 0.0898 - val_loss: 0.1514 - val_mae: 0.1086\n",
            "Epoch 762/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1549 - mae: 0.0996 - val_loss: 0.1474 - val_mae: 0.1063\n",
            "Epoch 763/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1525 - mae: 0.0978 - val_loss: 0.1499 - val_mae: 0.1069\n",
            "Epoch 764/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1573 - mae: 0.0977 - val_loss: 0.1489 - val_mae: 0.1092\n",
            "Epoch 765/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2664 - mae: 0.1204 - val_loss: 0.1506 - val_mae: 0.1130\n",
            "Epoch 766/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1653 - mae: 0.1010 - val_loss: 0.1446 - val_mae: 0.1163\n",
            "Epoch 767/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1511 - mae: 0.1124 - val_loss: 0.1538 - val_mae: 0.1232\n",
            "Epoch 768/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1717 - mae: 0.1102 - val_loss: 0.1466 - val_mae: 0.1110\n",
            "Epoch 769/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2267 - mae: 0.1106 - val_loss: 0.1479 - val_mae: 0.1091\n",
            "Epoch 770/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1489 - mae: 0.1029 - val_loss: 0.1448 - val_mae: 0.1067\n",
            "Epoch 771/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1469 - mae: 0.0926 - val_loss: 0.1518 - val_mae: 0.1087\n",
            "Epoch 772/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1592 - mae: 0.0988 - val_loss: 0.1493 - val_mae: 0.1074\n",
            "Epoch 773/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3009 - mae: 0.1204 - val_loss: 0.1468 - val_mae: 0.1054\n",
            "Epoch 774/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2126 - mae: 0.1037 - val_loss: 0.1460 - val_mae: 0.1059\n",
            "Epoch 775/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2134 - mae: 0.1098 - val_loss: 0.1459 - val_mae: 0.1063\n",
            "Epoch 776/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2208 - mae: 0.1051 - val_loss: 0.1520 - val_mae: 0.1071\n",
            "Epoch 777/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1529 - mae: 0.0970 - val_loss: 0.1468 - val_mae: 0.1063\n",
            "Epoch 778/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1309 - mae: 0.0910 - val_loss: 0.1464 - val_mae: 0.1070\n",
            "Epoch 779/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1428 - mae: 0.0978 - val_loss: 0.1460 - val_mae: 0.1067\n",
            "Epoch 780/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1406 - mae: 0.0923 - val_loss: 0.1491 - val_mae: 0.1071\n",
            "Epoch 781/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1774 - mae: 0.1009 - val_loss: 0.1545 - val_mae: 0.1107\n",
            "Epoch 782/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2428 - mae: 0.1099 - val_loss: 0.1501 - val_mae: 0.1071\n",
            "Epoch 783/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1659 - mae: 0.0989 - val_loss: 0.1456 - val_mae: 0.1066\n",
            "Epoch 784/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2250 - mae: 0.1084 - val_loss: 0.1533 - val_mae: 0.1093\n",
            "Epoch 785/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2030 - mae: 0.1102 - val_loss: 0.1483 - val_mae: 0.1096\n",
            "Epoch 786/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3102 - mae: 0.1259 - val_loss: 0.1458 - val_mae: 0.1066\n",
            "Epoch 787/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1316 - mae: 0.0998 - val_loss: 0.1449 - val_mae: 0.1070\n",
            "Epoch 788/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2216 - mae: 0.1130 - val_loss: 0.1554 - val_mae: 0.1101\n",
            "Epoch 789/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2148 - mae: 0.1063 - val_loss: 0.1510 - val_mae: 0.1069\n",
            "Epoch 790/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2537 - mae: 0.1125 - val_loss: 0.1489 - val_mae: 0.1056\n",
            "Epoch 791/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1217 - mae: 0.0881 - val_loss: 0.1441 - val_mae: 0.1058\n",
            "Epoch 792/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1504 - mae: 0.1014 - val_loss: 0.1458 - val_mae: 0.1080\n",
            "Epoch 793/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1864 - mae: 0.1054 - val_loss: 0.1482 - val_mae: 0.1071\n",
            "Epoch 794/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1636 - mae: 0.1027 - val_loss: 0.1482 - val_mae: 0.1066\n",
            "Epoch 795/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2228 - mae: 0.1042 - val_loss: 0.1505 - val_mae: 0.1074\n",
            "Epoch 796/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1616 - mae: 0.0976 - val_loss: 0.1460 - val_mae: 0.1048\n",
            "Epoch 797/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1816 - mae: 0.1029 - val_loss: 0.1538 - val_mae: 0.1090\n",
            "Epoch 798/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1992 - mae: 0.1042 - val_loss: 0.1484 - val_mae: 0.1064\n",
            "Epoch 799/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2072 - mae: 0.1021 - val_loss: 0.1555 - val_mae: 0.1084\n",
            "Epoch 800/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1860 - mae: 0.1101 - val_loss: 0.1401 - val_mae: 0.1031\n",
            "Epoch 801/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1264 - mae: 0.0887 - val_loss: 0.1458 - val_mae: 0.1059\n",
            "Epoch 802/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1167 - mae: 0.0901 - val_loss: 0.1482 - val_mae: 0.1121\n",
            "Epoch 803/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1128 - mae: 0.0872 - val_loss: 0.1477 - val_mae: 0.1073\n",
            "Epoch 804/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1796 - mae: 0.1011 - val_loss: 0.1514 - val_mae: 0.1080\n",
            "Epoch 805/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2681 - mae: 0.1133 - val_loss: 0.1487 - val_mae: 0.1094\n",
            "Epoch 806/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1559 - mae: 0.1008 - val_loss: 0.1517 - val_mae: 0.1090\n",
            "Epoch 807/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1285 - mae: 0.0964 - val_loss: 0.1462 - val_mae: 0.1058\n",
            "Epoch 808/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2747 - mae: 0.1141 - val_loss: 0.1484 - val_mae: 0.1063\n",
            "Epoch 809/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1979 - mae: 0.1064 - val_loss: 0.1516 - val_mae: 0.1091\n",
            "Epoch 810/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1999 - mae: 0.1057 - val_loss: 0.1511 - val_mae: 0.1093\n",
            "Epoch 811/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2022 - mae: 0.1006 - val_loss: 0.1483 - val_mae: 0.1058\n",
            "Epoch 812/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1822 - mae: 0.1002 - val_loss: 0.1482 - val_mae: 0.1065\n",
            "Epoch 813/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1591 - mae: 0.0993 - val_loss: 0.1441 - val_mae: 0.1041\n",
            "Epoch 814/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.1155 - mae: 0.0880 - val_loss: 0.1445 - val_mae: 0.1047\n",
            "Epoch 815/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1375 - mae: 0.0918 - val_loss: 0.1480 - val_mae: 0.1099\n",
            "Epoch 816/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1684 - mae: 0.1054 - val_loss: 0.1508 - val_mae: 0.1082\n",
            "Epoch 817/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2050 - mae: 0.1073 - val_loss: 0.1536 - val_mae: 0.1104\n",
            "Epoch 818/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1508 - mae: 0.0962 - val_loss: 0.1483 - val_mae: 0.1061\n",
            "Epoch 819/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1416 - mae: 0.0952 - val_loss: 0.1483 - val_mae: 0.1107\n",
            "Epoch 820/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1971 - mae: 0.1117 - val_loss: 0.1457 - val_mae: 0.1101\n",
            "Epoch 821/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1996 - mae: 0.1096 - val_loss: 0.1392 - val_mae: 0.1056\n",
            "Epoch 822/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1484 - mae: 0.0953 - val_loss: 0.1477 - val_mae: 0.1118\n",
            "Epoch 823/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1349 - mae: 0.0948 - val_loss: 0.1482 - val_mae: 0.1113\n",
            "Epoch 824/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2413 - mae: 0.1211 - val_loss: 0.1507 - val_mae: 0.1081\n",
            "Epoch 825/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1651 - mae: 0.1015 - val_loss: 0.1432 - val_mae: 0.1082\n",
            "Epoch 826/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2114 - mae: 0.1067 - val_loss: 0.1514 - val_mae: 0.1087\n",
            "Epoch 827/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2823 - mae: 0.1207 - val_loss: 0.1474 - val_mae: 0.1054\n",
            "Epoch 828/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1759 - mae: 0.1046 - val_loss: 0.1471 - val_mae: 0.1056\n",
            "Epoch 829/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1268 - mae: 0.0902 - val_loss: 0.1481 - val_mae: 0.1062\n",
            "Epoch 830/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3080 - mae: 0.1247 - val_loss: 0.1555 - val_mae: 0.1108\n",
            "Epoch 831/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1670 - mae: 0.1043 - val_loss: 0.1413 - val_mae: 0.1047\n",
            "Epoch 832/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2097 - mae: 0.1090 - val_loss: 0.1489 - val_mae: 0.1074\n",
            "Epoch 833/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2065 - mae: 0.0988 - val_loss: 0.1483 - val_mae: 0.1065\n",
            "Epoch 834/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1686 - mae: 0.1009 - val_loss: 0.1519 - val_mae: 0.1084\n",
            "Epoch 835/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2499 - mae: 0.1110 - val_loss: 0.1507 - val_mae: 0.1078\n",
            "Epoch 836/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1013 - mae: 0.0884 - val_loss: 0.1390 - val_mae: 0.1029\n",
            "Epoch 837/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1621 - mae: 0.0947 - val_loss: 0.1552 - val_mae: 0.1114\n",
            "Epoch 838/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2036 - mae: 0.1086 - val_loss: 0.1533 - val_mae: 0.1090\n",
            "Epoch 839/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1740 - mae: 0.0928 - val_loss: 0.1476 - val_mae: 0.1057\n",
            "Epoch 840/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1713 - mae: 0.1042 - val_loss: 0.1463 - val_mae: 0.1073\n",
            "Epoch 841/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1147 - mae: 0.0898 - val_loss: 0.1459 - val_mae: 0.1062\n",
            "Epoch 842/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1710 - mae: 0.0977 - val_loss: 0.1553 - val_mae: 0.1096\n",
            "Epoch 843/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1715 - mae: 0.1039 - val_loss: 0.1472 - val_mae: 0.1106\n",
            "Epoch 844/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2236 - mae: 0.1087 - val_loss: 0.1496 - val_mae: 0.1080\n",
            "Epoch 845/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2006 - mae: 0.1125 - val_loss: 0.1485 - val_mae: 0.1080\n",
            "Epoch 846/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1833 - mae: 0.1024 - val_loss: 0.1447 - val_mae: 0.1068\n",
            "Epoch 847/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2303 - mae: 0.1119 - val_loss: 0.1473 - val_mae: 0.1060\n",
            "Epoch 848/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1711 - mae: 0.0975 - val_loss: 0.1462 - val_mae: 0.1062\n",
            "Epoch 849/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1464 - mae: 0.0950 - val_loss: 0.1498 - val_mae: 0.1070\n",
            "Epoch 850/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2639 - mae: 0.1232 - val_loss: 0.1515 - val_mae: 0.1089\n",
            "Epoch 851/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1272 - mae: 0.0873 - val_loss: 0.1486 - val_mae: 0.1068\n",
            "Epoch 852/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2576 - mae: 0.1135 - val_loss: 0.1523 - val_mae: 0.1090\n",
            "Epoch 853/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1446 - mae: 0.0962 - val_loss: 0.1424 - val_mae: 0.1044\n",
            "Epoch 854/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1676 - mae: 0.0963 - val_loss: 0.1504 - val_mae: 0.1087\n",
            "Epoch 855/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1688 - mae: 0.1069 - val_loss: 0.1492 - val_mae: 0.1072\n",
            "Epoch 856/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2076 - mae: 0.1058 - val_loss: 0.1501 - val_mae: 0.1065\n",
            "Epoch 857/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1723 - mae: 0.1001 - val_loss: 0.1494 - val_mae: 0.1073\n",
            "Epoch 858/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2051 - mae: 0.1033 - val_loss: 0.1500 - val_mae: 0.1063\n",
            "Epoch 859/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2112 - mae: 0.1035 - val_loss: 0.1473 - val_mae: 0.1059\n",
            "Epoch 860/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1890 - mae: 0.1068 - val_loss: 0.1484 - val_mae: 0.1069\n",
            "Epoch 861/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1249 - mae: 0.0870 - val_loss: 0.1464 - val_mae: 0.1060\n",
            "Epoch 862/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1807 - mae: 0.1010 - val_loss: 0.1497 - val_mae: 0.1086\n",
            "Epoch 863/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1361 - mae: 0.0893 - val_loss: 0.1523 - val_mae: 0.1082\n",
            "Epoch 864/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2247 - mae: 0.1102 - val_loss: 0.1502 - val_mae: 0.1068\n",
            "Epoch 865/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1644 - mae: 0.0984 - val_loss: 0.1469 - val_mae: 0.1052\n",
            "Epoch 866/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1842 - mae: 0.1067 - val_loss: 0.1460 - val_mae: 0.1059\n",
            "Epoch 867/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2129 - mae: 0.0998 - val_loss: 0.1494 - val_mae: 0.1068\n",
            "Epoch 868/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1999 - mae: 0.1057 - val_loss: 0.1517 - val_mae: 0.1085\n",
            "Epoch 869/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1277 - mae: 0.0939 - val_loss: 0.1459 - val_mae: 0.1060\n",
            "Epoch 870/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1389 - mae: 0.0946 - val_loss: 0.1503 - val_mae: 0.1087\n",
            "Epoch 871/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2059 - mae: 0.1029 - val_loss: 0.1516 - val_mae: 0.1098\n",
            "Epoch 872/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1961 - mae: 0.1068 - val_loss: 0.1494 - val_mae: 0.1083\n",
            "Epoch 873/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2234 - mae: 0.1148 - val_loss: 0.1458 - val_mae: 0.1067\n",
            "Epoch 874/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1181 - mae: 0.0907 - val_loss: 0.1455 - val_mae: 0.1064\n",
            "Epoch 875/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1717 - mae: 0.1081 - val_loss: 0.1509 - val_mae: 0.1073\n",
            "Epoch 876/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1455 - mae: 0.0929 - val_loss: 0.1492 - val_mae: 0.1069\n",
            "Epoch 877/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2609 - mae: 0.1172 - val_loss: 0.1534 - val_mae: 0.1101\n",
            "Epoch 878/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1713 - mae: 0.1044 - val_loss: 0.1446 - val_mae: 0.1072\n",
            "Epoch 879/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2133 - mae: 0.1011 - val_loss: 0.1510 - val_mae: 0.1087\n",
            "Epoch 880/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1771 - mae: 0.1080 - val_loss: 0.1441 - val_mae: 0.1085\n",
            "Epoch 881/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1265 - mae: 0.0921 - val_loss: 0.1522 - val_mae: 0.1084\n",
            "Epoch 882/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2871 - mae: 0.1246 - val_loss: 0.1486 - val_mae: 0.1064\n",
            "Epoch 883/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1721 - mae: 0.0967 - val_loss: 0.1474 - val_mae: 0.1076\n",
            "Epoch 884/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2885 - mae: 0.1183 - val_loss: 0.1510 - val_mae: 0.1074\n",
            "Epoch 885/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1932 - mae: 0.1101 - val_loss: 0.1433 - val_mae: 0.1077\n",
            "Epoch 886/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1666 - mae: 0.0988 - val_loss: 0.1480 - val_mae: 0.1113\n",
            "Epoch 887/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1394 - mae: 0.0971 - val_loss: 0.1486 - val_mae: 0.1155\n",
            "Epoch 888/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1655 - mae: 0.1057 - val_loss: 0.1498 - val_mae: 0.1160\n",
            "Epoch 889/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1986 - mae: 0.1143 - val_loss: 0.1503 - val_mae: 0.1142\n",
            "Epoch 890/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1645 - mae: 0.1081 - val_loss: 0.1528 - val_mae: 0.1111\n",
            "Epoch 891/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1693 - mae: 0.1055 - val_loss: 0.1509 - val_mae: 0.1095\n",
            "Epoch 892/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1515 - mae: 0.0959 - val_loss: 0.1469 - val_mae: 0.1058\n",
            "Epoch 893/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1866 - mae: 0.1008 - val_loss: 0.1480 - val_mae: 0.1074\n",
            "Epoch 894/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2273 - mae: 0.1130 - val_loss: 0.1477 - val_mae: 0.1058\n",
            "Epoch 895/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1330 - mae: 0.0905 - val_loss: 0.1521 - val_mae: 0.1086\n",
            "Epoch 896/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2343 - mae: 0.1149 - val_loss: 0.1510 - val_mae: 0.1099\n",
            "Epoch 897/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1519 - mae: 0.0972 - val_loss: 0.1453 - val_mae: 0.1056\n",
            "Epoch 898/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1322 - mae: 0.0929 - val_loss: 0.1444 - val_mae: 0.1053\n",
            "Epoch 899/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2099 - mae: 0.1077 - val_loss: 0.1537 - val_mae: 0.1087\n",
            "Epoch 900/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1865 - mae: 0.1031 - val_loss: 0.1446 - val_mae: 0.1061\n",
            "Epoch 901/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1427 - mae: 0.1002 - val_loss: 0.1492 - val_mae: 0.1089\n",
            "Epoch 902/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2095 - mae: 0.1078 - val_loss: 0.1539 - val_mae: 0.1100\n",
            "Epoch 903/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1693 - mae: 0.1038 - val_loss: 0.1498 - val_mae: 0.1078\n",
            "Epoch 904/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1901 - mae: 0.1053 - val_loss: 0.1445 - val_mae: 0.1053\n",
            "Epoch 905/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1631 - mae: 0.0954 - val_loss: 0.1471 - val_mae: 0.1052\n",
            "Epoch 906/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1618 - mae: 0.0939 - val_loss: 0.1505 - val_mae: 0.1080\n",
            "Epoch 907/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1657 - mae: 0.0977 - val_loss: 0.1492 - val_mae: 0.1085\n",
            "Epoch 908/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1413 - mae: 0.0957 - val_loss: 0.1477 - val_mae: 0.1088\n",
            "Epoch 909/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1251 - mae: 0.0933 - val_loss: 0.1456 - val_mae: 0.1054\n",
            "Epoch 910/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1957 - mae: 0.0981 - val_loss: 0.1552 - val_mae: 0.1085\n",
            "Epoch 911/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2226 - mae: 0.1046 - val_loss: 0.1467 - val_mae: 0.1055\n",
            "Epoch 912/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1935 - mae: 0.0979 - val_loss: 0.1494 - val_mae: 0.1055\n",
            "Epoch 913/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1975 - mae: 0.1071 - val_loss: 0.1455 - val_mae: 0.1055\n",
            "Epoch 914/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2912 - mae: 0.1167 - val_loss: 0.1497 - val_mae: 0.1076\n",
            "Epoch 915/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1919 - mae: 0.1063 - val_loss: 0.1488 - val_mae: 0.1086\n",
            "Epoch 916/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1596 - mae: 0.0970 - val_loss: 0.1499 - val_mae: 0.1100\n",
            "Epoch 917/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1151 - mae: 0.0927 - val_loss: 0.1459 - val_mae: 0.1093\n",
            "Epoch 918/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1831 - mae: 0.1173 - val_loss: 0.1492 - val_mae: 0.1083\n",
            "Epoch 919/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1719 - mae: 0.0954 - val_loss: 0.1509 - val_mae: 0.1070\n",
            "Epoch 920/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1583 - mae: 0.0961 - val_loss: 0.1504 - val_mae: 0.1078\n",
            "Epoch 921/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2184 - mae: 0.1082 - val_loss: 0.1517 - val_mae: 0.1074\n",
            "Epoch 922/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2440 - mae: 0.1100 - val_loss: 0.1475 - val_mae: 0.1051\n",
            "Epoch 923/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1867 - mae: 0.1034 - val_loss: 0.1471 - val_mae: 0.1059\n",
            "Epoch 924/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1763 - mae: 0.1069 - val_loss: 0.1509 - val_mae: 0.1080\n",
            "Epoch 925/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1482 - mae: 0.0995 - val_loss: 0.1433 - val_mae: 0.1064\n",
            "Epoch 926/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1271 - mae: 0.0890 - val_loss: 0.1479 - val_mae: 0.1080\n",
            "Epoch 927/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1751 - mae: 0.1006 - val_loss: 0.1528 - val_mae: 0.1098\n",
            "Epoch 928/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1512 - mae: 0.0942 - val_loss: 0.1448 - val_mae: 0.1051\n",
            "Epoch 929/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1166 - mae: 0.0867 - val_loss: 0.1465 - val_mae: 0.1064\n",
            "Epoch 930/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1110 - mae: 0.0863 - val_loss: 0.1498 - val_mae: 0.1068\n",
            "Epoch 931/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1867 - mae: 0.1014 - val_loss: 0.1508 - val_mae: 0.1079\n",
            "Epoch 932/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1931 - mae: 0.1000 - val_loss: 0.1519 - val_mae: 0.1087\n",
            "Epoch 933/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2042 - mae: 0.1096 - val_loss: 0.1491 - val_mae: 0.1072\n",
            "Epoch 934/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1475 - mae: 0.0929 - val_loss: 0.1470 - val_mae: 0.1072\n",
            "Epoch 935/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.2812 - mae: 0.1227 - val_loss: 0.1495 - val_mae: 0.1075\n",
            "Epoch 936/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1331 - mae: 0.0959 - val_loss: 0.1454 - val_mae: 0.1062\n",
            "Epoch 937/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1851 - mae: 0.1055 - val_loss: 0.1495 - val_mae: 0.1072\n",
            "Epoch 938/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2355 - mae: 0.1167 - val_loss: 0.1482 - val_mae: 0.1066\n",
            "Epoch 939/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1791 - mae: 0.1029 - val_loss: 0.1463 - val_mae: 0.1050\n",
            "Epoch 940/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2110 - mae: 0.0996 - val_loss: 0.1509 - val_mae: 0.1077\n",
            "Epoch 941/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2084 - mae: 0.1085 - val_loss: 0.1516 - val_mae: 0.1091\n",
            "Epoch 942/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1355 - mae: 0.0988 - val_loss: 0.1442 - val_mae: 0.1069\n",
            "Epoch 943/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2433 - mae: 0.1120 - val_loss: 0.1523 - val_mae: 0.1068\n",
            "Epoch 944/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1826 - mae: 0.1014 - val_loss: 0.1460 - val_mae: 0.1057\n",
            "Epoch 945/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1950 - mae: 0.1075 - val_loss: 0.1492 - val_mae: 0.1074\n",
            "Epoch 946/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1844 - mae: 0.1013 - val_loss: 0.1506 - val_mae: 0.1070\n",
            "Epoch 947/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1953 - mae: 0.1050 - val_loss: 0.1485 - val_mae: 0.1067\n",
            "Epoch 948/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2158 - mae: 0.1024 - val_loss: 0.1513 - val_mae: 0.1066\n",
            "Epoch 949/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1877 - mae: 0.1051 - val_loss: 0.1460 - val_mae: 0.1050\n",
            "Epoch 950/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2063 - mae: 0.0971 - val_loss: 0.1491 - val_mae: 0.1067\n",
            "Epoch 951/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2189 - mae: 0.1074 - val_loss: 0.1479 - val_mae: 0.1061\n",
            "Epoch 952/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1550 - mae: 0.0965 - val_loss: 0.1491 - val_mae: 0.1067\n",
            "Epoch 953/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1436 - mae: 0.0981 - val_loss: 0.1449 - val_mae: 0.1043\n",
            "Epoch 954/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1981 - mae: 0.0955 - val_loss: 0.1496 - val_mae: 0.1069\n",
            "Epoch 955/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1752 - mae: 0.1010 - val_loss: 0.1485 - val_mae: 0.1071\n",
            "Epoch 956/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2893 - mae: 0.1158 - val_loss: 0.1506 - val_mae: 0.1069\n",
            "Epoch 957/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1688 - mae: 0.0991 - val_loss: 0.1502 - val_mae: 0.1069\n",
            "Epoch 958/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2856 - mae: 0.1171 - val_loss: 0.1338 - val_mae: 0.1280\n",
            "Epoch 959/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2696 - mae: 0.1377 - val_loss: 0.1442 - val_mae: 0.1226\n",
            "Epoch 960/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3133 - mae: 0.1337 - val_loss: 0.1445 - val_mae: 0.1096\n",
            "Epoch 961/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2430 - mae: 0.1219 - val_loss: 0.1403 - val_mae: 0.1034\n",
            "Epoch 962/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1373 - mae: 0.0907 - val_loss: 0.1429 - val_mae: 0.1051\n",
            "Epoch 963/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1593 - mae: 0.0995 - val_loss: 0.1492 - val_mae: 0.1113\n",
            "Epoch 964/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1769 - mae: 0.1055 - val_loss: 0.1491 - val_mae: 0.1089\n",
            "Epoch 965/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1123 - mae: 0.0866 - val_loss: 0.1459 - val_mae: 0.1051\n",
            "Epoch 966/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1233 - mae: 0.0911 - val_loss: 0.1505 - val_mae: 0.1082\n",
            "Epoch 967/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1585 - mae: 0.1011 - val_loss: 0.1483 - val_mae: 0.1066\n",
            "Epoch 968/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2588 - mae: 0.1106 - val_loss: 0.1511 - val_mae: 0.1078\n",
            "Epoch 969/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2067 - mae: 0.1058 - val_loss: 0.1478 - val_mae: 0.1060\n",
            "Epoch 970/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2001 - mae: 0.1020 - val_loss: 0.1468 - val_mae: 0.1068\n",
            "Epoch 971/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1345 - mae: 0.0985 - val_loss: 0.1430 - val_mae: 0.1053\n",
            "Epoch 972/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1641 - mae: 0.0925 - val_loss: 0.1513 - val_mae: 0.1077\n",
            "Epoch 973/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1941 - mae: 0.1061 - val_loss: 0.1479 - val_mae: 0.1063\n",
            "Epoch 974/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1416 - mae: 0.0837 - val_loss: 0.1478 - val_mae: 0.1075\n",
            "Epoch 975/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2125 - mae: 0.1150 - val_loss: 0.1441 - val_mae: 0.1064\n",
            "Epoch 976/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2154 - mae: 0.1111 - val_loss: 0.1504 - val_mae: 0.1067\n",
            "Epoch 977/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2180 - mae: 0.0964 - val_loss: 0.1507 - val_mae: 0.1063\n",
            "Epoch 978/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2138 - mae: 0.1053 - val_loss: 0.1467 - val_mae: 0.1044\n",
            "Epoch 979/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2172 - mae: 0.1045 - val_loss: 0.1520 - val_mae: 0.1065\n",
            "Epoch 980/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2455 - mae: 0.1094 - val_loss: 0.1481 - val_mae: 0.1059\n",
            "Epoch 981/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1726 - mae: 0.0968 - val_loss: 0.1468 - val_mae: 0.1060\n",
            "Epoch 982/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3016 - mae: 0.1170 - val_loss: 0.1477 - val_mae: 0.1048\n",
            "Epoch 983/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1921 - mae: 0.1031 - val_loss: 0.1422 - val_mae: 0.1033\n",
            "Epoch 984/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1891 - mae: 0.1005 - val_loss: 0.1470 - val_mae: 0.1052\n",
            "Epoch 985/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1525 - mae: 0.0960 - val_loss: 0.1448 - val_mae: 0.1053\n",
            "Epoch 986/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1810 - mae: 0.1023 - val_loss: 0.1494 - val_mae: 0.1073\n",
            "Epoch 987/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1538 - mae: 0.0959 - val_loss: 0.1519 - val_mae: 0.1075\n",
            "Epoch 988/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2247 - mae: 0.1079 - val_loss: 0.1494 - val_mae: 0.1088\n",
            "Epoch 989/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1544 - mae: 0.0978 - val_loss: 0.1474 - val_mae: 0.1052\n",
            "Epoch 990/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1184 - mae: 0.0850 - val_loss: 0.1473 - val_mae: 0.1059\n",
            "Epoch 991/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1911 - mae: 0.1041 - val_loss: 0.1525 - val_mae: 0.1079\n",
            "Epoch 992/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1437 - mae: 0.0873 - val_loss: 0.1491 - val_mae: 0.1069\n",
            "Epoch 993/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1585 - mae: 0.0920 - val_loss: 0.1444 - val_mae: 0.1065\n",
            "Epoch 994/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1908 - mae: 0.1036 - val_loss: 0.1601 - val_mae: 0.1441\n",
            "Epoch 995/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2043 - mae: 0.1575 - val_loss: 0.1468 - val_mae: 0.1479\n",
            "Epoch 996/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2717 - mae: 0.1391 - val_loss: 0.1528 - val_mae: 0.1241\n",
            "Epoch 997/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1608 - mae: 0.1092 - val_loss: 0.1460 - val_mae: 0.1079\n",
            "Epoch 998/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2643 - mae: 0.1100 - val_loss: 0.1498 - val_mae: 0.1089\n",
            "Epoch 999/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1579 - mae: 0.0985 - val_loss: 0.1465 - val_mae: 0.1064\n",
            "Epoch 1000/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2755 - mae: 0.1134 - val_loss: 0.1477 - val_mae: 0.1050\n",
            "Epoch 1001/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1675 - mae: 0.0962 - val_loss: 0.1490 - val_mae: 0.1066\n",
            "Epoch 1002/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2509 - mae: 0.1105 - val_loss: 0.1502 - val_mae: 0.1073\n",
            "Epoch 1003/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1790 - mae: 0.0995 - val_loss: 0.1490 - val_mae: 0.1062\n",
            "Epoch 1004/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2211 - mae: 0.1058 - val_loss: 0.1495 - val_mae: 0.1070\n",
            "Epoch 1005/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1556 - mae: 0.0987 - val_loss: 0.1472 - val_mae: 0.1050\n",
            "Epoch 1006/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1795 - mae: 0.1011 - val_loss: 0.1458 - val_mae: 0.1049\n",
            "Epoch 1007/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2925 - mae: 0.1156 - val_loss: 0.1504 - val_mae: 0.1084\n",
            "Epoch 1008/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1400 - mae: 0.0950 - val_loss: 0.1431 - val_mae: 0.1047\n",
            "Epoch 1009/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2010 - mae: 0.1084 - val_loss: 0.1501 - val_mae: 0.1065\n",
            "Epoch 1010/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1266 - mae: 0.0897 - val_loss: 0.1505 - val_mae: 0.1068\n",
            "Epoch 1011/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2400 - mae: 0.1043 - val_loss: 0.1509 - val_mae: 0.1068\n",
            "Epoch 1012/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2332 - mae: 0.1129 - val_loss: 0.1500 - val_mae: 0.1064\n",
            "Epoch 1013/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1097 - mae: 0.0852 - val_loss: 0.1465 - val_mae: 0.1053\n",
            "Epoch 1014/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2021 - mae: 0.1003 - val_loss: 0.1510 - val_mae: 0.1086\n",
            "Epoch 1015/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1482 - mae: 0.0963 - val_loss: 0.1459 - val_mae: 0.1050\n",
            "Epoch 1016/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1789 - mae: 0.1005 - val_loss: 0.1498 - val_mae: 0.1062\n",
            "Epoch 1017/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2213 - mae: 0.1028 - val_loss: 0.1548 - val_mae: 0.1080\n",
            "Epoch 1018/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1309 - mae: 0.0879 - val_loss: 0.1442 - val_mae: 0.1051\n",
            "Epoch 1019/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1806 - mae: 0.1001 - val_loss: 0.1477 - val_mae: 0.1058\n",
            "Epoch 1020/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1401 - mae: 0.0987 - val_loss: 0.1505 - val_mae: 0.1090\n",
            "Epoch 1021/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1489 - mae: 0.0919 - val_loss: 0.1473 - val_mae: 0.1067\n",
            "Epoch 1022/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1327 - mae: 0.0966 - val_loss: 0.1477 - val_mae: 0.1058\n",
            "Epoch 1023/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2441 - mae: 0.1075 - val_loss: 0.1527 - val_mae: 0.1100\n",
            "Epoch 1024/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1639 - mae: 0.1025 - val_loss: 0.1522 - val_mae: 0.1084\n",
            "Epoch 1025/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1313 - mae: 0.0922 - val_loss: 0.1482 - val_mae: 0.1056\n",
            "Epoch 1026/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1650 - mae: 0.1027 - val_loss: 0.1465 - val_mae: 0.1053\n",
            "Epoch 1027/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1915 - mae: 0.1026 - val_loss: 0.1512 - val_mae: 0.1065\n",
            "Epoch 1028/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1703 - mae: 0.0955 - val_loss: 0.1524 - val_mae: 0.1084\n",
            "Epoch 1029/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1865 - mae: 0.1015 - val_loss: 0.1455 - val_mae: 0.1039\n",
            "Epoch 1030/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1766 - mae: 0.0957 - val_loss: 0.1477 - val_mae: 0.1056\n",
            "Epoch 1031/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2334 - mae: 0.1124 - val_loss: 0.1530 - val_mae: 0.1075\n",
            "Epoch 1032/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1600 - mae: 0.0993 - val_loss: 0.1470 - val_mae: 0.1065\n",
            "Epoch 1033/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2038 - mae: 0.1093 - val_loss: 0.1523 - val_mae: 0.1079\n",
            "Epoch 1034/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1872 - mae: 0.0989 - val_loss: 0.1502 - val_mae: 0.1086\n",
            "Epoch 1035/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1159 - mae: 0.0877 - val_loss: 0.1439 - val_mae: 0.1045\n",
            "Epoch 1036/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1803 - mae: 0.1013 - val_loss: 0.1535 - val_mae: 0.1082\n",
            "Epoch 1037/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2763 - mae: 0.1217 - val_loss: 0.1558 - val_mae: 0.1110\n",
            "Epoch 1038/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1805 - mae: 0.0994 - val_loss: 0.1464 - val_mae: 0.1053\n",
            "Epoch 1039/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1735 - mae: 0.0962 - val_loss: 0.1454 - val_mae: 0.1047\n",
            "Epoch 1040/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1936 - mae: 0.1026 - val_loss: 0.1487 - val_mae: 0.1076\n",
            "Epoch 1041/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1605 - mae: 0.0940 - val_loss: 0.1494 - val_mae: 0.1054\n",
            "Epoch 1042/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2192 - mae: 0.1089 - val_loss: 0.1503 - val_mae: 0.1088\n",
            "Epoch 1043/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1188 - mae: 0.0958 - val_loss: 0.1425 - val_mae: 0.1034\n",
            "Epoch 1044/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1490 - mae: 0.0929 - val_loss: 0.1487 - val_mae: 0.1053\n",
            "Epoch 1045/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2909 - mae: 0.1172 - val_loss: 0.1519 - val_mae: 0.1068\n",
            "Epoch 1046/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1125 - mae: 0.0853 - val_loss: 0.1479 - val_mae: 0.1061\n",
            "Epoch 1047/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2148 - mae: 0.1170 - val_loss: 0.1529 - val_mae: 0.1080\n",
            "Epoch 1048/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2246 - mae: 0.1103 - val_loss: 0.1507 - val_mae: 0.1065\n",
            "Epoch 1049/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2222 - mae: 0.1104 - val_loss: 0.1482 - val_mae: 0.1053\n",
            "Epoch 1050/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2097 - mae: 0.1025 - val_loss: 0.1488 - val_mae: 0.1057\n",
            "Epoch 1051/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1562 - mae: 0.1002 - val_loss: 0.1479 - val_mae: 0.1057\n",
            "Epoch 1052/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1552 - mae: 0.0923 - val_loss: 0.1503 - val_mae: 0.1060\n",
            "Epoch 1053/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1684 - mae: 0.0952 - val_loss: 0.1467 - val_mae: 0.1053\n",
            "Epoch 1054/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.1863 - mae: 0.1063 - val_loss: 0.1474 - val_mae: 0.1063\n",
            "Epoch 1055/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1259 - mae: 0.0884 - val_loss: 0.1472 - val_mae: 0.1055\n",
            "Epoch 1056/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1644 - mae: 0.0961 - val_loss: 0.1492 - val_mae: 0.1067\n",
            "Epoch 1057/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1569 - mae: 0.0975 - val_loss: 0.1483 - val_mae: 0.1056\n",
            "Epoch 1058/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1639 - mae: 0.0967 - val_loss: 0.1510 - val_mae: 0.1075\n",
            "Epoch 1059/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2007 - mae: 0.1104 - val_loss: 0.1509 - val_mae: 0.1065\n",
            "Epoch 1060/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2128 - mae: 0.1049 - val_loss: 0.1484 - val_mae: 0.1066\n",
            "Epoch 1061/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2155 - mae: 0.1120 - val_loss: 0.1739 - val_mae: 0.1482\n",
            "Epoch 1062/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2046 - mae: 0.1375 - val_loss: 0.1495 - val_mae: 0.1277\n",
            "Epoch 1063/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1496 - mae: 0.1178 - val_loss: 0.1509 - val_mae: 0.1202\n",
            "Epoch 1064/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3220 - mae: 0.1311 - val_loss: 0.1446 - val_mae: 0.1099\n",
            "Epoch 1065/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2400 - mae: 0.1183 - val_loss: 0.1420 - val_mae: 0.1064\n",
            "Epoch 1066/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1527 - mae: 0.0960 - val_loss: 0.1502 - val_mae: 0.1077\n",
            "Epoch 1067/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2063 - mae: 0.1050 - val_loss: 0.1508 - val_mae: 0.1085\n",
            "Epoch 1068/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1826 - mae: 0.1043 - val_loss: 0.1434 - val_mae: 0.1057\n",
            "Epoch 1069/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1674 - mae: 0.0974 - val_loss: 0.1493 - val_mae: 0.1063\n",
            "Epoch 1070/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2759 - mae: 0.1152 - val_loss: 0.1459 - val_mae: 0.1059\n",
            "Epoch 1071/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1564 - mae: 0.0959 - val_loss: 0.1502 - val_mae: 0.1067\n",
            "Epoch 1072/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1196 - mae: 0.0940 - val_loss: 0.1479 - val_mae: 0.1055\n",
            "Epoch 1073/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1470 - mae: 0.0962 - val_loss: 0.1539 - val_mae: 0.1088\n",
            "Epoch 1074/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1985 - mae: 0.0986 - val_loss: 0.1469 - val_mae: 0.1047\n",
            "Epoch 1075/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2122 - mae: 0.1026 - val_loss: 0.1524 - val_mae: 0.1082\n",
            "Epoch 1076/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1638 - mae: 0.1010 - val_loss: 0.1473 - val_mae: 0.1058\n",
            "Epoch 1077/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2576 - mae: 0.1177 - val_loss: 0.1496 - val_mae: 0.1068\n",
            "Epoch 1078/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2280 - mae: 0.1071 - val_loss: 0.1480 - val_mae: 0.1070\n",
            "Epoch 1079/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2099 - mae: 0.1064 - val_loss: 0.1433 - val_mae: 0.1048\n",
            "Epoch 1080/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1440 - mae: 0.0955 - val_loss: 0.1502 - val_mae: 0.1066\n",
            "Epoch 1081/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2064 - mae: 0.1072 - val_loss: 0.1510 - val_mae: 0.1060\n",
            "Epoch 1082/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2901 - mae: 0.1178 - val_loss: 0.1524 - val_mae: 0.1072\n",
            "Epoch 1083/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1816 - mae: 0.1002 - val_loss: 0.1469 - val_mae: 0.1067\n",
            "Epoch 1084/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1348 - mae: 0.0887 - val_loss: 0.1487 - val_mae: 0.1057\n",
            "Epoch 1085/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1305 - mae: 0.0957 - val_loss: 0.1439 - val_mae: 0.1036\n",
            "Epoch 1086/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1593 - mae: 0.0970 - val_loss: 0.1519 - val_mae: 0.1096\n",
            "Epoch 1087/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1528 - mae: 0.0977 - val_loss: 0.1476 - val_mae: 0.1060\n",
            "Epoch 1088/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1504 - mae: 0.0949 - val_loss: 0.1503 - val_mae: 0.1077\n",
            "Epoch 1089/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1719 - mae: 0.1047 - val_loss: 0.1466 - val_mae: 0.1052\n",
            "Epoch 1090/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1313 - mae: 0.0932 - val_loss: 0.1475 - val_mae: 0.1061\n",
            "Epoch 1091/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2114 - mae: 0.1088 - val_loss: 0.1524 - val_mae: 0.1078\n",
            "Epoch 1092/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1744 - mae: 0.0995 - val_loss: 0.1509 - val_mae: 0.1073\n",
            "Epoch 1093/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1419 - mae: 0.0900 - val_loss: 0.1453 - val_mae: 0.1055\n",
            "Epoch 1094/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2036 - mae: 0.1011 - val_loss: 0.1544 - val_mae: 0.1093\n",
            "Epoch 1095/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1612 - mae: 0.0970 - val_loss: 0.1482 - val_mae: 0.1050\n",
            "Epoch 1096/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1504 - mae: 0.0899 - val_loss: 0.1480 - val_mae: 0.1060\n",
            "Epoch 1097/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1882 - mae: 0.1034 - val_loss: 0.1499 - val_mae: 0.1071\n",
            "Epoch 1098/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1799 - mae: 0.1023 - val_loss: 0.1476 - val_mae: 0.1053\n",
            "Epoch 1099/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1608 - mae: 0.1017 - val_loss: 0.1463 - val_mae: 0.1050\n",
            "Epoch 1100/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2793 - mae: 0.1123 - val_loss: 0.1520 - val_mae: 0.1088\n",
            "Epoch 1101/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1772 - mae: 0.1028 - val_loss: 0.1480 - val_mae: 0.1046\n",
            "Epoch 1102/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1455 - mae: 0.0903 - val_loss: 0.1487 - val_mae: 0.1057\n",
            "Epoch 1103/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1552 - mae: 0.0934 - val_loss: 0.1478 - val_mae: 0.1061\n",
            "Epoch 1104/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1853 - mae: 0.1082 - val_loss: 0.1491 - val_mae: 0.1063\n",
            "Epoch 1105/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2151 - mae: 0.1004 - val_loss: 0.1506 - val_mae: 0.1059\n",
            "Epoch 1106/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2066 - mae: 0.1045 - val_loss: 0.1473 - val_mae: 0.1084\n",
            "Epoch 1107/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1627 - mae: 0.1026 - val_loss: 0.1478 - val_mae: 0.1058\n",
            "Epoch 1108/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2375 - mae: 0.1060 - val_loss: 0.1528 - val_mae: 0.1081\n",
            "Epoch 1109/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2047 - mae: 0.1012 - val_loss: 0.1480 - val_mae: 0.1061\n",
            "Epoch 1110/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1396 - mae: 0.0945 - val_loss: 0.1471 - val_mae: 0.1058\n",
            "Epoch 1111/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2083 - mae: 0.1013 - val_loss: 0.1494 - val_mae: 0.1061\n",
            "Epoch 1112/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2210 - mae: 0.1102 - val_loss: 0.1507 - val_mae: 0.1063\n",
            "Epoch 1113/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1801 - mae: 0.0931 - val_loss: 0.1477 - val_mae: 0.1054\n",
            "Epoch 1114/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1594 - mae: 0.0998 - val_loss: 0.1482 - val_mae: 0.1059\n",
            "Epoch 1115/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1630 - mae: 0.1022 - val_loss: 0.1491 - val_mae: 0.1063\n",
            "Epoch 1116/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1671 - mae: 0.1012 - val_loss: 0.1486 - val_mae: 0.1064\n",
            "Epoch 1117/2000\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.2060 - mae: 0.1136 - val_loss: 0.1511 - val_mae: 0.1073\n",
            "Epoch 1118/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1252 - mae: 0.0939 - val_loss: 0.1431 - val_mae: 0.1050\n",
            "Epoch 1119/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1409 - mae: 0.0968 - val_loss: 0.1498 - val_mae: 0.1073\n",
            "Epoch 1120/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2539 - mae: 0.1143 - val_loss: 0.1514 - val_mae: 0.1066\n",
            "Epoch 1121/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1935 - mae: 0.1017 - val_loss: 0.1471 - val_mae: 0.1046\n",
            "Epoch 1122/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1967 - mae: 0.1030 - val_loss: 0.1491 - val_mae: 0.1053\n",
            "Epoch 1123/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1687 - mae: 0.0942 - val_loss: 0.1451 - val_mae: 0.1040\n",
            "Epoch 1124/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1290 - mae: 0.0956 - val_loss: 0.1457 - val_mae: 0.1042\n",
            "Epoch 1125/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1212 - mae: 0.0839 - val_loss: 0.1485 - val_mae: 0.1062\n",
            "Epoch 1126/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1502 - mae: 0.0986 - val_loss: 0.1509 - val_mae: 0.1061\n",
            "Epoch 1127/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1503 - mae: 0.0921 - val_loss: 0.1507 - val_mae: 0.1071\n",
            "Epoch 1128/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2016 - mae: 0.1079 - val_loss: 0.1509 - val_mae: 0.1076\n",
            "Epoch 1129/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2282 - mae: 0.1022 - val_loss: 0.1494 - val_mae: 0.1057\n",
            "Epoch 1130/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1840 - mae: 0.1020 - val_loss: 0.1505 - val_mae: 0.1058\n",
            "Epoch 1131/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1552 - mae: 0.0971 - val_loss: 0.1491 - val_mae: 0.1070\n",
            "Epoch 1132/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1791 - mae: 0.1030 - val_loss: 0.1479 - val_mae: 0.1057\n",
            "Epoch 1133/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1939 - mae: 0.1095 - val_loss: 0.1507 - val_mae: 0.1068\n",
            "Epoch 1134/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1158 - mae: 0.0881 - val_loss: 0.1470 - val_mae: 0.1064\n",
            "Epoch 1135/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2016 - mae: 0.1030 - val_loss: 0.1517 - val_mae: 0.1075\n",
            "Epoch 1136/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2507 - mae: 0.1100 - val_loss: 0.1481 - val_mae: 0.1044\n",
            "Epoch 1137/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1372 - mae: 0.0880 - val_loss: 0.1485 - val_mae: 0.1066\n",
            "Epoch 1138/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1656 - mae: 0.0984 - val_loss: 0.1481 - val_mae: 0.1072\n",
            "Epoch 1139/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1655 - mae: 0.1044 - val_loss: 0.1485 - val_mae: 0.1069\n",
            "Epoch 1140/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1638 - mae: 0.0991 - val_loss: 0.1482 - val_mae: 0.1067\n",
            "Epoch 1141/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1409 - mae: 0.0986 - val_loss: 0.1468 - val_mae: 0.1051\n",
            "Epoch 1142/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1634 - mae: 0.0975 - val_loss: 0.1487 - val_mae: 0.1060\n",
            "Epoch 1143/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2008 - mae: 0.1097 - val_loss: 0.1519 - val_mae: 0.1074\n",
            "Epoch 1144/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2050 - mae: 0.1071 - val_loss: 0.1490 - val_mae: 0.1067\n",
            "Epoch 1145/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1755 - mae: 0.1000 - val_loss: 0.1435 - val_mae: 0.1062\n",
            "Epoch 1146/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2097 - mae: 0.1082 - val_loss: 0.1810 - val_mae: 0.1229\n",
            "Epoch 1147/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1789 - mae: 0.1152 - val_loss: 0.1626 - val_mae: 0.1329\n",
            "Epoch 1148/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1902 - mae: 0.1222 - val_loss: 0.1558 - val_mae: 0.1282\n",
            "Epoch 1149/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3601 - mae: 0.1589 - val_loss: 0.1489 - val_mae: 0.1280\n",
            "Epoch 1150/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1729 - mae: 0.1140 - val_loss: 0.1455 - val_mae: 0.1093\n",
            "Epoch 1151/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1883 - mae: 0.1056 - val_loss: 0.1469 - val_mae: 0.1078\n",
            "Epoch 1152/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1261 - mae: 0.0920 - val_loss: 0.1442 - val_mae: 0.1053\n",
            "Epoch 1153/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2389 - mae: 0.1117 - val_loss: 0.1506 - val_mae: 0.1058\n",
            "Epoch 1154/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1836 - mae: 0.1006 - val_loss: 0.1481 - val_mae: 0.1062\n",
            "Epoch 1155/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1835 - mae: 0.0985 - val_loss: 0.1511 - val_mae: 0.1075\n",
            "Epoch 1156/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1502 - mae: 0.0999 - val_loss: 0.1457 - val_mae: 0.1061\n",
            "Epoch 1157/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2320 - mae: 0.1153 - val_loss: 0.1499 - val_mae: 0.1098\n",
            "Epoch 1158/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1108 - mae: 0.0854 - val_loss: 0.1447 - val_mae: 0.1063\n",
            "Epoch 1159/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2360 - mae: 0.1044 - val_loss: 0.1491 - val_mae: 0.1061\n",
            "Epoch 1160/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2044 - mae: 0.1076 - val_loss: 0.1519 - val_mae: 0.1076\n",
            "Epoch 1161/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1794 - mae: 0.1013 - val_loss: 0.1437 - val_mae: 0.1053\n",
            "Epoch 1162/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1149 - mae: 0.0865 - val_loss: 0.1468 - val_mae: 0.1083\n",
            "Epoch 1163/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1440 - mae: 0.0979 - val_loss: 0.1479 - val_mae: 0.1070\n",
            "Epoch 1164/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2399 - mae: 0.1043 - val_loss: 0.1551 - val_mae: 0.1086\n",
            "Epoch 1165/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2652 - mae: 0.1147 - val_loss: 0.1481 - val_mae: 0.1063\n",
            "Epoch 1166/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2075 - mae: 0.1082 - val_loss: 0.1475 - val_mae: 0.1050\n",
            "Epoch 1167/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1968 - mae: 0.1163 - val_loss: 0.1470 - val_mae: 0.1062\n",
            "Epoch 1168/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1338 - mae: 0.0898 - val_loss: 0.1461 - val_mae: 0.1061\n",
            "Epoch 1169/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2221 - mae: 0.1132 - val_loss: 0.1506 - val_mae: 0.1073\n",
            "Epoch 1170/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2745 - mae: 0.1108 - val_loss: 0.1514 - val_mae: 0.1075\n",
            "Epoch 1171/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2351 - mae: 0.1078 - val_loss: 0.1454 - val_mae: 0.1051\n",
            "Epoch 1172/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1708 - mae: 0.0954 - val_loss: 0.1483 - val_mae: 0.1053\n",
            "Epoch 1173/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1731 - mae: 0.1070 - val_loss: 0.1470 - val_mae: 0.1048\n",
            "Epoch 1174/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2954 - mae: 0.1179 - val_loss: 0.1511 - val_mae: 0.1070\n",
            "Epoch 1175/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1709 - mae: 0.1059 - val_loss: 0.1465 - val_mae: 0.1063\n",
            "Epoch 1176/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1555 - mae: 0.1013 - val_loss: 0.1504 - val_mae: 0.1062\n",
            "Epoch 1177/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2541 - mae: 0.1166 - val_loss: 0.1499 - val_mae: 0.1066\n",
            "Epoch 1178/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1941 - mae: 0.1052 - val_loss: 0.1504 - val_mae: 0.1069\n",
            "Epoch 1179/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1568 - mae: 0.0988 - val_loss: 0.1494 - val_mae: 0.1052\n",
            "Epoch 1180/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2248 - mae: 0.1041 - val_loss: 0.1482 - val_mae: 0.1051\n",
            "Epoch 1181/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1957 - mae: 0.1007 - val_loss: 0.1471 - val_mae: 0.1048\n",
            "Epoch 1182/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1469 - mae: 0.0942 - val_loss: 0.1455 - val_mae: 0.1049\n",
            "Epoch 1183/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1607 - mae: 0.1001 - val_loss: 0.1497 - val_mae: 0.1059\n",
            "Epoch 1184/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2192 - mae: 0.1036 - val_loss: 0.1495 - val_mae: 0.1066\n",
            "Epoch 1185/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1765 - mae: 0.1020 - val_loss: 0.1503 - val_mae: 0.1063\n",
            "Epoch 1186/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2795 - mae: 0.1132 - val_loss: 0.1506 - val_mae: 0.1073\n",
            "Epoch 1187/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2862 - mae: 0.1147 - val_loss: 0.1456 - val_mae: 0.1041\n",
            "Epoch 1188/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2190 - mae: 0.1038 - val_loss: 0.1475 - val_mae: 0.1067\n",
            "Epoch 1189/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1308 - mae: 0.0907 - val_loss: 0.1446 - val_mae: 0.1060\n",
            "Epoch 1190/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1866 - mae: 0.1084 - val_loss: 0.1505 - val_mae: 0.1070\n",
            "Epoch 1191/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1419 - mae: 0.0897 - val_loss: 0.1516 - val_mae: 0.1071\n",
            "Epoch 1192/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1398 - mae: 0.0926 - val_loss: 0.1508 - val_mae: 0.1067\n",
            "Epoch 1193/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.0942 - mae: 0.0819 - val_loss: 0.1454 - val_mae: 0.1040\n",
            "Epoch 1194/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1593 - mae: 0.0928 - val_loss: 0.1534 - val_mae: 0.1073\n",
            "Epoch 1195/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2449 - mae: 0.1076 - val_loss: 0.1503 - val_mae: 0.1063\n",
            "Epoch 1196/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1609 - mae: 0.0988 - val_loss: 0.1497 - val_mae: 0.1061\n",
            "Epoch 1197/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2558 - mae: 0.1075 - val_loss: 0.1515 - val_mae: 0.1067\n",
            "Epoch 1198/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2567 - mae: 0.1078 - val_loss: 0.1479 - val_mae: 0.1046\n",
            "Epoch 1199/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2028 - mae: 0.1052 - val_loss: 0.1446 - val_mae: 0.1051\n",
            "Epoch 1200/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1204 - mae: 0.0888 - val_loss: 0.1458 - val_mae: 0.1049\n",
            "Epoch 1201/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1500 - mae: 0.0990 - val_loss: 0.1511 - val_mae: 0.1066\n",
            "Epoch 1202/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1654 - mae: 0.1011 - val_loss: 0.1509 - val_mae: 0.1070\n",
            "Epoch 1203/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1393 - mae: 0.0888 - val_loss: 0.1504 - val_mae: 0.1068\n",
            "Epoch 1204/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1536 - mae: 0.0926 - val_loss: 0.1523 - val_mae: 0.1068\n",
            "Epoch 1205/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1761 - mae: 0.0985 - val_loss: 0.1476 - val_mae: 0.1052\n",
            "Epoch 1206/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2043 - mae: 0.1009 - val_loss: 0.1542 - val_mae: 0.1082\n",
            "Epoch 1207/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1839 - mae: 0.1047 - val_loss: 0.1466 - val_mae: 0.1062\n",
            "Epoch 1208/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1472 - mae: 0.1017 - val_loss: 0.1446 - val_mae: 0.1056\n",
            "Epoch 1209/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1663 - mae: 0.0960 - val_loss: 0.1488 - val_mae: 0.1074\n",
            "Epoch 1210/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1542 - mae: 0.1013 - val_loss: 0.1520 - val_mae: 0.1072\n",
            "Epoch 1211/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2053 - mae: 0.1106 - val_loss: 0.1520 - val_mae: 0.1073\n",
            "Epoch 1212/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2608 - mae: 0.1162 - val_loss: 0.1517 - val_mae: 0.1077\n",
            "Epoch 1213/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2175 - mae: 0.1000 - val_loss: 0.1483 - val_mae: 0.1059\n",
            "Epoch 1214/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2085 - mae: 0.1046 - val_loss: 0.1476 - val_mae: 0.1046\n",
            "Epoch 1215/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1977 - mae: 0.1043 - val_loss: 0.1499 - val_mae: 0.1064\n",
            "Epoch 1216/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2313 - mae: 0.1078 - val_loss: 0.1499 - val_mae: 0.1073\n",
            "Epoch 1217/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1913 - mae: 0.1092 - val_loss: 0.1520 - val_mae: 0.1073\n",
            "Epoch 1218/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2033 - mae: 0.1022 - val_loss: 0.1452 - val_mae: 0.1045\n",
            "Epoch 1219/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2275 - mae: 0.1067 - val_loss: 0.1498 - val_mae: 0.1062\n",
            "Epoch 1220/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1856 - mae: 0.1025 - val_loss: 0.1507 - val_mae: 0.1070\n",
            "Epoch 1221/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2526 - mae: 0.1176 - val_loss: 0.1501 - val_mae: 0.1057\n",
            "Epoch 1222/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1797 - mae: 0.0956 - val_loss: 0.1453 - val_mae: 0.1045\n",
            "Epoch 1223/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1365 - mae: 0.0877 - val_loss: 0.1468 - val_mae: 0.1046\n",
            "Epoch 1224/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1386 - mae: 0.0895 - val_loss: 0.1474 - val_mae: 0.1084\n",
            "Epoch 1225/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1615 - mae: 0.0937 - val_loss: 0.1478 - val_mae: 0.1063\n",
            "Epoch 1226/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1721 - mae: 0.0991 - val_loss: 0.1527 - val_mae: 0.1065\n",
            "Epoch 1227/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1309 - mae: 0.0857 - val_loss: 0.1498 - val_mae: 0.1062\n",
            "Epoch 1228/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1887 - mae: 0.1023 - val_loss: 0.1497 - val_mae: 0.1056\n",
            "Epoch 1229/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1771 - mae: 0.0977 - val_loss: 0.1531 - val_mae: 0.1079\n",
            "Epoch 1230/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1963 - mae: 0.1018 - val_loss: 0.1465 - val_mae: 0.1051\n",
            "Epoch 1231/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1980 - mae: 0.1110 - val_loss: 0.1481 - val_mae: 0.1052\n",
            "Epoch 1232/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1665 - mae: 0.1003 - val_loss: 0.1517 - val_mae: 0.1075\n",
            "Epoch 1233/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2429 - mae: 0.1114 - val_loss: 0.1508 - val_mae: 0.1070\n",
            "Epoch 1234/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2082 - mae: 0.1068 - val_loss: 0.1474 - val_mae: 0.1054\n",
            "Epoch 1235/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1578 - mae: 0.0958 - val_loss: 0.1502 - val_mae: 0.1058\n",
            "Epoch 1236/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1854 - mae: 0.1062 - val_loss: 0.1467 - val_mae: 0.1058\n",
            "Epoch 1237/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2366 - mae: 0.1000 - val_loss: 0.1478 - val_mae: 0.1052\n",
            "Epoch 1238/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2002 - mae: 0.1100 - val_loss: 0.1500 - val_mae: 0.1062\n",
            "Epoch 1239/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2281 - mae: 0.1043 - val_loss: 0.1509 - val_mae: 0.1076\n",
            "Epoch 1240/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1440 - mae: 0.0970 - val_loss: 0.1463 - val_mae: 0.1050\n",
            "Epoch 1241/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1583 - mae: 0.0938 - val_loss: 0.1533 - val_mae: 0.1073\n",
            "Epoch 1242/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2189 - mae: 0.1043 - val_loss: 0.1462 - val_mae: 0.1044\n",
            "Epoch 1243/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1836 - mae: 0.0995 - val_loss: 0.1494 - val_mae: 0.1061\n",
            "Epoch 1244/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1606 - mae: 0.0985 - val_loss: 0.1497 - val_mae: 0.1067\n",
            "Epoch 1245/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2529 - mae: 0.1154 - val_loss: 0.1499 - val_mae: 0.1060\n",
            "Epoch 1246/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2057 - mae: 0.1019 - val_loss: 0.1513 - val_mae: 0.1061\n",
            "Epoch 1247/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1753 - mae: 0.0956 - val_loss: 0.1508 - val_mae: 0.1082\n",
            "Epoch 1248/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1525 - mae: 0.0957 - val_loss: 0.1476 - val_mae: 0.1056\n",
            "Epoch 1249/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1635 - mae: 0.1005 - val_loss: 0.1490 - val_mae: 0.1096\n",
            "Epoch 1250/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2069 - mae: 0.1053 - val_loss: 0.1527 - val_mae: 0.1084\n",
            "Epoch 1251/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2269 - mae: 0.1123 - val_loss: 0.1509 - val_mae: 0.1077\n",
            "Epoch 1252/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2682 - mae: 0.1147 - val_loss: 0.1496 - val_mae: 0.1063\n",
            "Epoch 1253/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1655 - mae: 0.0944 - val_loss: 0.1492 - val_mae: 0.1065\n",
            "Epoch 1254/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1260 - mae: 0.0898 - val_loss: 0.1468 - val_mae: 0.1055\n",
            "Epoch 1255/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1557 - mae: 0.0918 - val_loss: 0.1483 - val_mae: 0.1057\n",
            "Epoch 1256/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2485 - mae: 0.1118 - val_loss: 0.1535 - val_mae: 0.1081\n",
            "Epoch 1257/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1601 - mae: 0.1025 - val_loss: 0.1472 - val_mae: 0.1072\n",
            "Epoch 1258/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1753 - mae: 0.1036 - val_loss: 0.1510 - val_mae: 0.1125\n",
            "Epoch 1259/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2414 - mae: 0.1210 - val_loss: 0.1518 - val_mae: 0.1070\n",
            "Epoch 1260/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1539 - mae: 0.0975 - val_loss: 0.1404 - val_mae: 0.1075\n",
            "Epoch 1261/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1285 - mae: 0.0985 - val_loss: 0.1396 - val_mae: 0.1072\n",
            "Epoch 1262/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2872 - mae: 0.1185 - val_loss: 0.1326 - val_mae: 0.1044\n",
            "Epoch 1263/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1657 - mae: 0.1078 - val_loss: 0.1340 - val_mae: 0.1237\n",
            "Epoch 1264/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1968 - mae: 0.1324 - val_loss: 0.1538 - val_mae: 0.1261\n",
            "Epoch 1265/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1835 - mae: 0.1190 - val_loss: 0.1470 - val_mae: 0.1109\n",
            "Epoch 1266/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1838 - mae: 0.1092 - val_loss: 0.1470 - val_mae: 0.1101\n",
            "Epoch 1267/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1791 - mae: 0.1025 - val_loss: 0.1505 - val_mae: 0.1074\n",
            "Epoch 1268/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1640 - mae: 0.0900 - val_loss: 0.1473 - val_mae: 0.1051\n",
            "Epoch 1269/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2169 - mae: 0.1082 - val_loss: 0.1474 - val_mae: 0.1048\n",
            "Epoch 1270/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2309 - mae: 0.1066 - val_loss: 0.1508 - val_mae: 0.1063\n",
            "Epoch 1271/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2704 - mae: 0.1098 - val_loss: 0.1484 - val_mae: 0.1053\n",
            "Epoch 1272/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1537 - mae: 0.0865 - val_loss: 0.1457 - val_mae: 0.1056\n",
            "Epoch 1273/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2022 - mae: 0.1068 - val_loss: 0.1493 - val_mae: 0.1059\n",
            "Epoch 1274/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1958 - mae: 0.1020 - val_loss: 0.1483 - val_mae: 0.1057\n",
            "Epoch 1275/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2622 - mae: 0.1102 - val_loss: 0.1468 - val_mae: 0.1041\n",
            "Epoch 1276/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1267 - mae: 0.0872 - val_loss: 0.1448 - val_mae: 0.1050\n",
            "Epoch 1277/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2111 - mae: 0.1112 - val_loss: 0.1515 - val_mae: 0.1081\n",
            "Epoch 1278/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1560 - mae: 0.1025 - val_loss: 0.1457 - val_mae: 0.1050\n",
            "Epoch 1279/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1487 - mae: 0.0923 - val_loss: 0.1503 - val_mae: 0.1079\n",
            "Epoch 1280/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1809 - mae: 0.1037 - val_loss: 0.1533 - val_mae: 0.1070\n",
            "Epoch 1281/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2864 - mae: 0.1178 - val_loss: 0.1458 - val_mae: 0.1045\n",
            "Epoch 1282/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1675 - mae: 0.0941 - val_loss: 0.1470 - val_mae: 0.1040\n",
            "Epoch 1283/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1050 - mae: 0.0838 - val_loss: 0.1411 - val_mae: 0.1025\n",
            "Epoch 1284/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1571 - mae: 0.1005 - val_loss: 0.1505 - val_mae: 0.1082\n",
            "Epoch 1285/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.2355 - mae: 0.1060 - val_loss: 0.1522 - val_mae: 0.1072\n",
            "Epoch 1286/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2791 - mae: 0.1187 - val_loss: 0.1465 - val_mae: 0.1046\n",
            "Epoch 1287/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1520 - mae: 0.0887 - val_loss: 0.1444 - val_mae: 0.1033\n",
            "Epoch 1288/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2186 - mae: 0.1067 - val_loss: 0.1529 - val_mae: 0.1076\n",
            "Epoch 1289/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1788 - mae: 0.0957 - val_loss: 0.1486 - val_mae: 0.1051\n",
            "Epoch 1290/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1849 - mae: 0.1029 - val_loss: 0.1473 - val_mae: 0.1046\n",
            "Epoch 1291/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1748 - mae: 0.1031 - val_loss: 0.1468 - val_mae: 0.1036\n",
            "Epoch 1292/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1613 - mae: 0.0855 - val_loss: 0.1483 - val_mae: 0.1054\n",
            "Epoch 1293/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1681 - mae: 0.0928 - val_loss: 0.1479 - val_mae: 0.1052\n",
            "Epoch 1294/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2229 - mae: 0.1100 - val_loss: 0.1476 - val_mae: 0.1047\n",
            "Epoch 1295/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1698 - mae: 0.0962 - val_loss: 0.1491 - val_mae: 0.1062\n",
            "Epoch 1296/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1373 - mae: 0.0935 - val_loss: 0.1465 - val_mae: 0.1044\n",
            "Epoch 1297/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1987 - mae: 0.1022 - val_loss: 0.1501 - val_mae: 0.1053\n",
            "Epoch 1298/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1135 - mae: 0.0857 - val_loss: 0.1473 - val_mae: 0.1044\n",
            "Epoch 1299/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1287 - mae: 0.0931 - val_loss: 0.1473 - val_mae: 0.1056\n",
            "Epoch 1300/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1549 - mae: 0.0948 - val_loss: 0.1517 - val_mae: 0.1069\n",
            "Epoch 1301/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2487 - mae: 0.1119 - val_loss: 0.1510 - val_mae: 0.1061\n",
            "Epoch 1302/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1981 - mae: 0.1049 - val_loss: 0.1485 - val_mae: 0.1050\n",
            "Epoch 1303/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1830 - mae: 0.1010 - val_loss: 0.1501 - val_mae: 0.1052\n",
            "Epoch 1304/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1522 - mae: 0.0925 - val_loss: 0.1521 - val_mae: 0.1088\n",
            "Epoch 1305/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1652 - mae: 0.0958 - val_loss: 0.1487 - val_mae: 0.1052\n",
            "Epoch 1306/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1780 - mae: 0.1015 - val_loss: 0.1523 - val_mae: 0.1080\n",
            "Epoch 1307/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1376 - mae: 0.0900 - val_loss: 0.1479 - val_mae: 0.1053\n",
            "Epoch 1308/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1665 - mae: 0.0953 - val_loss: 0.1506 - val_mae: 0.1052\n",
            "Epoch 1309/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1705 - mae: 0.0999 - val_loss: 0.1469 - val_mae: 0.1049\n",
            "Epoch 1310/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2313 - mae: 0.1086 - val_loss: 0.1522 - val_mae: 0.1066\n",
            "Epoch 1311/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1575 - mae: 0.0973 - val_loss: 0.1498 - val_mae: 0.1056\n",
            "Epoch 1312/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2182 - mae: 0.1009 - val_loss: 0.1513 - val_mae: 0.1061\n",
            "Epoch 1313/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1668 - mae: 0.0996 - val_loss: 0.1480 - val_mae: 0.1065\n",
            "Epoch 1314/2000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.1550 - mae: 0.0941 - val_loss: 0.1429 - val_mae: 0.1037\n",
            "Epoch 1315/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1914 - mae: 0.1059 - val_loss: 0.1508 - val_mae: 0.1071\n",
            "Epoch 1316/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1818 - mae: 0.0993 - val_loss: 0.1501 - val_mae: 0.1064\n",
            "Epoch 1317/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.1635 - mae: 0.0926 - val_loss: 0.1533 - val_mae: 0.1079\n",
            "Epoch 1318/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1350 - mae: 0.0966 - val_loss: 0.1460 - val_mae: 0.1047\n",
            "Epoch 1319/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1318 - mae: 0.0912 - val_loss: 0.1498 - val_mae: 0.1073\n",
            "Epoch 1320/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2202 - mae: 0.1062 - val_loss: 0.1494 - val_mae: 0.1064\n",
            "Epoch 1321/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2862 - mae: 0.1179 - val_loss: 0.1507 - val_mae: 0.1062\n",
            "Epoch 1322/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2090 - mae: 0.1044 - val_loss: 0.1520 - val_mae: 0.1066\n",
            "Epoch 1323/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1807 - mae: 0.0942 - val_loss: 0.1458 - val_mae: 0.1042\n",
            "Epoch 1324/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1370 - mae: 0.0909 - val_loss: 0.1477 - val_mae: 0.1063\n",
            "Epoch 1325/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2488 - mae: 0.1093 - val_loss: 0.1485 - val_mae: 0.1064\n",
            "Epoch 1326/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1686 - mae: 0.0946 - val_loss: 0.1488 - val_mae: 0.1076\n",
            "Epoch 1327/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1488 - mae: 0.0959 - val_loss: 0.1493 - val_mae: 0.1058\n",
            "Epoch 1328/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1867 - mae: 0.0951 - val_loss: 0.1490 - val_mae: 0.1063\n",
            "Epoch 1329/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1996 - mae: 0.1053 - val_loss: 0.1508 - val_mae: 0.1063\n",
            "Epoch 1330/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1983 - mae: 0.1049 - val_loss: 0.1487 - val_mae: 0.1054\n",
            "Epoch 1331/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1493 - mae: 0.0982 - val_loss: 0.1498 - val_mae: 0.1065\n",
            "Epoch 1332/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1602 - mae: 0.0941 - val_loss: 0.1496 - val_mae: 0.1056\n",
            "Epoch 1333/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2617 - mae: 0.1140 - val_loss: 0.1513 - val_mae: 0.1059\n",
            "Epoch 1334/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2267 - mae: 0.1077 - val_loss: 0.1474 - val_mae: 0.1059\n",
            "Epoch 1335/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1540 - mae: 0.0953 - val_loss: 0.1486 - val_mae: 0.1052\n",
            "Epoch 1336/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1480 - mae: 0.0935 - val_loss: 0.1532 - val_mae: 0.1074\n",
            "Epoch 1337/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1703 - mae: 0.0957 - val_loss: 0.1493 - val_mae: 0.1057\n",
            "Epoch 1338/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1636 - mae: 0.0977 - val_loss: 0.1470 - val_mae: 0.1041\n",
            "Epoch 1339/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1141 - mae: 0.0887 - val_loss: 0.1436 - val_mae: 0.1049\n",
            "Epoch 1340/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1563 - mae: 0.0941 - val_loss: 0.1573 - val_mae: 0.1090\n",
            "Epoch 1341/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1574 - mae: 0.0965 - val_loss: 0.1505 - val_mae: 0.1067\n",
            "Epoch 1342/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1246 - mae: 0.0910 - val_loss: 0.1460 - val_mae: 0.1052\n",
            "Epoch 1343/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1462 - mae: 0.0946 - val_loss: 0.1523 - val_mae: 0.1069\n",
            "Epoch 1344/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1868 - mae: 0.1011 - val_loss: 0.1514 - val_mae: 0.1089\n",
            "Epoch 1345/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1169 - mae: 0.0907 - val_loss: 0.1464 - val_mae: 0.1046\n",
            "Epoch 1346/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3061 - mae: 0.1290 - val_loss: 0.1544 - val_mae: 0.1095\n",
            "Epoch 1347/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2510 - mae: 0.1108 - val_loss: 0.1511 - val_mae: 0.1068\n",
            "Epoch 1348/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1608 - mae: 0.1005 - val_loss: 0.1481 - val_mae: 0.1057\n",
            "Epoch 1349/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2455 - mae: 0.1142 - val_loss: 0.1485 - val_mae: 0.1051\n",
            "Epoch 1350/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1287 - mae: 0.0875 - val_loss: 0.1477 - val_mae: 0.1054\n",
            "Epoch 1351/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1266 - mae: 0.0880 - val_loss: 0.1481 - val_mae: 0.1056\n",
            "Epoch 1352/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1946 - mae: 0.1033 - val_loss: 0.1521 - val_mae: 0.1067\n",
            "Epoch 1353/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1940 - mae: 0.1012 - val_loss: 0.1510 - val_mae: 0.1055\n",
            "Epoch 1354/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1163 - mae: 0.0819 - val_loss: 0.1489 - val_mae: 0.1057\n",
            "Epoch 1355/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1585 - mae: 0.0948 - val_loss: 0.1495 - val_mae: 0.1070\n",
            "Epoch 1356/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1529 - mae: 0.0983 - val_loss: 0.1490 - val_mae: 0.1061\n",
            "Epoch 1357/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2418 - mae: 0.1120 - val_loss: 0.1525 - val_mae: 0.1068\n",
            "Epoch 1358/2000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.1651 - mae: 0.1043 - val_loss: 0.1485 - val_mae: 0.1051\n",
            "Epoch 1359/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1654 - mae: 0.0962 - val_loss: 0.1466 - val_mae: 0.1052\n",
            "Epoch 1360/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2010 - mae: 0.0985 - val_loss: 0.1505 - val_mae: 0.1057\n",
            "Epoch 1361/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1653 - mae: 0.0990 - val_loss: 0.1504 - val_mae: 0.1059\n",
            "Epoch 1362/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2032 - mae: 0.1052 - val_loss: 0.1468 - val_mae: 0.1053\n",
            "Epoch 1363/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2118 - mae: 0.1017 - val_loss: 0.1515 - val_mae: 0.1058\n",
            "Epoch 1364/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1848 - mae: 0.1012 - val_loss: 0.1483 - val_mae: 0.1056\n",
            "Epoch 1365/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2304 - mae: 0.1082 - val_loss: 0.1509 - val_mae: 0.1086\n",
            "Epoch 1366/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2936 - mae: 0.1244 - val_loss: 0.1442 - val_mae: 0.1046\n",
            "Epoch 1367/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1935 - mae: 0.1031 - val_loss: 0.1524 - val_mae: 0.1330\n",
            "Epoch 1368/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2361 - mae: 0.1363 - val_loss: 0.1344 - val_mae: 0.1102\n",
            "Epoch 1369/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1552 - mae: 0.1059 - val_loss: 0.1535 - val_mae: 0.1231\n",
            "Epoch 1370/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1464 - mae: 0.1129 - val_loss: 0.1519 - val_mae: 0.1159\n",
            "Epoch 1371/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2633 - mae: 0.1183 - val_loss: 0.1503 - val_mae: 0.1128\n",
            "Epoch 1372/2000\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.1248 - mae: 0.0930 - val_loss: 0.1554 - val_mae: 0.1160\n",
            "Epoch 1373/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1499 - mae: 0.1090 - val_loss: 0.1378 - val_mae: 0.1198\n",
            "Epoch 1374/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2487 - mae: 0.1261 - val_loss: 0.1688 - val_mae: 0.1252\n",
            "Epoch 1375/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1548 - mae: 0.1155 - val_loss: 0.1357 - val_mae: 0.1095\n",
            "Epoch 1376/2000\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.2388 - mae: 0.1135 - val_loss: 0.1503 - val_mae: 0.1089\n",
            "Epoch 1377/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2423 - mae: 0.1126 - val_loss: 0.1465 - val_mae: 0.1058\n",
            "Epoch 1378/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1611 - mae: 0.0970 - val_loss: 0.1501 - val_mae: 0.1063\n",
            "Epoch 1379/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2310 - mae: 0.1147 - val_loss: 0.1493 - val_mae: 0.1056\n",
            "Epoch 1380/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1589 - mae: 0.0958 - val_loss: 0.1466 - val_mae: 0.1046\n",
            "Epoch 1381/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1293 - mae: 0.0910 - val_loss: 0.1488 - val_mae: 0.1054\n",
            "Epoch 1382/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1554 - mae: 0.0965 - val_loss: 0.1495 - val_mae: 0.1061\n",
            "Epoch 1383/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1906 - mae: 0.1037 - val_loss: 0.1497 - val_mae: 0.1061\n",
            "Epoch 1384/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1936 - mae: 0.1062 - val_loss: 0.1498 - val_mae: 0.1064\n",
            "Epoch 1385/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2344 - mae: 0.1086 - val_loss: 0.1506 - val_mae: 0.1064\n",
            "Epoch 1386/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1791 - mae: 0.1011 - val_loss: 0.1511 - val_mae: 0.1060\n",
            "Epoch 1387/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1692 - mae: 0.0998 - val_loss: 0.1458 - val_mae: 0.1046\n",
            "Epoch 1388/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1538 - mae: 0.1022 - val_loss: 0.1472 - val_mae: 0.1050\n",
            "Epoch 1389/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1293 - mae: 0.0883 - val_loss: 0.1535 - val_mae: 0.1081\n",
            "Epoch 1390/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1450 - mae: 0.0905 - val_loss: 0.1509 - val_mae: 0.1080\n",
            "Epoch 1391/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1515 - mae: 0.0987 - val_loss: 0.1459 - val_mae: 0.1048\n",
            "Epoch 1392/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1963 - mae: 0.1031 - val_loss: 0.1525 - val_mae: 0.1071\n",
            "Epoch 1393/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1500 - mae: 0.0976 - val_loss: 0.1490 - val_mae: 0.1054\n",
            "Epoch 1394/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1869 - mae: 0.1028 - val_loss: 0.1498 - val_mae: 0.1055\n",
            "Epoch 1395/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2334 - mae: 0.1056 - val_loss: 0.1505 - val_mae: 0.1062\n",
            "Epoch 1396/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1887 - mae: 0.0974 - val_loss: 0.1489 - val_mae: 0.1058\n",
            "Epoch 1397/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2400 - mae: 0.0980 - val_loss: 0.1499 - val_mae: 0.1058\n",
            "Epoch 1398/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1850 - mae: 0.1005 - val_loss: 0.1480 - val_mae: 0.1059\n",
            "Epoch 1399/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1642 - mae: 0.0992 - val_loss: 0.1479 - val_mae: 0.1054\n",
            "Epoch 1400/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2200 - mae: 0.1068 - val_loss: 0.1487 - val_mae: 0.1052\n",
            "Epoch 1401/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1291 - mae: 0.0844 - val_loss: 0.1516 - val_mae: 0.1065\n",
            "Epoch 1402/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2392 - mae: 0.1086 - val_loss: 0.1508 - val_mae: 0.1067\n",
            "Epoch 1403/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1669 - mae: 0.1035 - val_loss: 0.1486 - val_mae: 0.1047\n",
            "Epoch 1404/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2545 - mae: 0.1130 - val_loss: 0.1522 - val_mae: 0.1071\n",
            "Epoch 1405/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1983 - mae: 0.1052 - val_loss: 0.1509 - val_mae: 0.1068\n",
            "Epoch 1406/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1720 - mae: 0.1015 - val_loss: 0.1488 - val_mae: 0.1067\n",
            "Epoch 1407/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1692 - mae: 0.0942 - val_loss: 0.1479 - val_mae: 0.1053\n",
            "Epoch 1408/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1361 - mae: 0.0953 - val_loss: 0.1480 - val_mae: 0.1050\n",
            "Epoch 1409/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1579 - mae: 0.0990 - val_loss: 0.1501 - val_mae: 0.1065\n",
            "Epoch 1410/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1479 - mae: 0.0967 - val_loss: 0.1510 - val_mae: 0.1064\n",
            "Epoch 1411/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1851 - mae: 0.1015 - val_loss: 0.1514 - val_mae: 0.1066\n",
            "Epoch 1412/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1909 - mae: 0.0948 - val_loss: 0.1530 - val_mae: 0.1061\n",
            "Epoch 1413/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1311 - mae: 0.0911 - val_loss: 0.1463 - val_mae: 0.1041\n",
            "Epoch 1414/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1565 - mae: 0.0921 - val_loss: 0.1488 - val_mae: 0.1052\n",
            "Epoch 1415/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1238 - mae: 0.0907 - val_loss: 0.1456 - val_mae: 0.1050\n",
            "Epoch 1416/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2176 - mae: 0.1052 - val_loss: 0.1543 - val_mae: 0.1076\n",
            "Epoch 1417/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1470 - mae: 0.0921 - val_loss: 0.1481 - val_mae: 0.1047\n",
            "Epoch 1418/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1916 - mae: 0.0953 - val_loss: 0.1521 - val_mae: 0.1070\n",
            "Epoch 1419/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1325 - mae: 0.0952 - val_loss: 0.1462 - val_mae: 0.1034\n",
            "Epoch 1420/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2461 - mae: 0.1060 - val_loss: 0.1495 - val_mae: 0.1065\n",
            "Epoch 1421/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2794 - mae: 0.1178 - val_loss: 0.1496 - val_mae: 0.1055\n",
            "Epoch 1422/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1690 - mae: 0.0964 - val_loss: 0.1521 - val_mae: 0.1064\n",
            "Epoch 1423/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1401 - mae: 0.0890 - val_loss: 0.1505 - val_mae: 0.1062\n",
            "Epoch 1424/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1505 - mae: 0.0928 - val_loss: 0.1451 - val_mae: 0.1057\n",
            "Epoch 1425/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2349 - mae: 0.1079 - val_loss: 0.1457 - val_mae: 0.1036\n",
            "Epoch 1426/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1996 - mae: 0.1014 - val_loss: 0.1530 - val_mae: 0.1086\n",
            "Epoch 1427/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2192 - mae: 0.1064 - val_loss: 0.1506 - val_mae: 0.1056\n",
            "Epoch 1428/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.1581 - mae: 0.0950 - val_loss: 0.1480 - val_mae: 0.1054\n",
            "Epoch 1429/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2309 - mae: 0.1152 - val_loss: 0.1505 - val_mae: 0.1071\n",
            "Epoch 1430/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1974 - mae: 0.1041 - val_loss: 0.1522 - val_mae: 0.1065\n",
            "Epoch 1431/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1881 - mae: 0.1021 - val_loss: 0.1501 - val_mae: 0.1062\n",
            "Epoch 1432/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1796 - mae: 0.0953 - val_loss: 0.1476 - val_mae: 0.1049\n",
            "Epoch 1433/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1977 - mae: 0.0976 - val_loss: 0.1521 - val_mae: 0.1061\n",
            "Epoch 1434/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1909 - mae: 0.1005 - val_loss: 0.1485 - val_mae: 0.1052\n",
            "Epoch 1435/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1316 - mae: 0.0918 - val_loss: 0.1465 - val_mae: 0.1042\n",
            "Epoch 1436/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1647 - mae: 0.1012 - val_loss: 0.1496 - val_mae: 0.1057\n",
            "Epoch 1437/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1371 - mae: 0.0931 - val_loss: 0.1501 - val_mae: 0.1065\n",
            "Epoch 1438/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1396 - mae: 0.0893 - val_loss: 0.1496 - val_mae: 0.1057\n",
            "Epoch 1439/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1891 - mae: 0.0984 - val_loss: 0.1505 - val_mae: 0.1073\n",
            "Epoch 1440/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1739 - mae: 0.1021 - val_loss: 0.1493 - val_mae: 0.1052\n",
            "Epoch 1441/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1399 - mae: 0.0898 - val_loss: 0.1495 - val_mae: 0.1061\n",
            "Epoch 1442/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1329 - mae: 0.0914 - val_loss: 0.1469 - val_mae: 0.1046\n",
            "Epoch 1443/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1885 - mae: 0.1065 - val_loss: 0.1506 - val_mae: 0.1060\n",
            "Epoch 1444/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1540 - mae: 0.0988 - val_loss: 0.1474 - val_mae: 0.1053\n",
            "Epoch 1445/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1248 - mae: 0.0884 - val_loss: 0.1480 - val_mae: 0.1055\n",
            "Epoch 1446/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1611 - mae: 0.0964 - val_loss: 0.1516 - val_mae: 0.1072\n",
            "Epoch 1447/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1773 - mae: 0.0959 - val_loss: 0.1518 - val_mae: 0.1056\n",
            "Epoch 1448/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1899 - mae: 0.0942 - val_loss: 0.1507 - val_mae: 0.1061\n",
            "Epoch 1449/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1871 - mae: 0.1019 - val_loss: 0.1488 - val_mae: 0.1061\n",
            "Epoch 1450/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1419 - mae: 0.0916 - val_loss: 0.1517 - val_mae: 0.1072\n",
            "Epoch 1451/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1827 - mae: 0.0996 - val_loss: 0.1502 - val_mae: 0.1082\n",
            "Epoch 1452/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1661 - mae: 0.0990 - val_loss: 0.1499 - val_mae: 0.1074\n",
            "Epoch 1453/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1874 - mae: 0.1002 - val_loss: 0.1469 - val_mae: 0.1047\n",
            "Epoch 1454/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1619 - mae: 0.0974 - val_loss: 0.1449 - val_mae: 0.1030\n",
            "Epoch 1455/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1626 - mae: 0.0952 - val_loss: 0.1512 - val_mae: 0.1065\n",
            "Epoch 1456/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2083 - mae: 0.1089 - val_loss: 0.1509 - val_mae: 0.1069\n",
            "Epoch 1457/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1533 - mae: 0.0949 - val_loss: 0.1487 - val_mae: 0.1053\n",
            "Epoch 1458/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2522 - mae: 0.1100 - val_loss: 0.1509 - val_mae: 0.1064\n",
            "Epoch 1459/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2041 - mae: 0.1094 - val_loss: 0.1468 - val_mae: 0.1056\n",
            "Epoch 1460/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1539 - mae: 0.0946 - val_loss: 0.1494 - val_mae: 0.1070\n",
            "Epoch 1461/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1665 - mae: 0.1058 - val_loss: 0.1496 - val_mae: 0.1062\n",
            "Epoch 1462/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1589 - mae: 0.0984 - val_loss: 0.1495 - val_mae: 0.1056\n",
            "Epoch 1463/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1379 - mae: 0.0959 - val_loss: 0.1454 - val_mae: 0.1044\n",
            "Epoch 1464/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1630 - mae: 0.0937 - val_loss: 0.1488 - val_mae: 0.1056\n",
            "Epoch 1465/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1728 - mae: 0.1032 - val_loss: 0.1509 - val_mae: 0.1066\n",
            "Epoch 1466/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1793 - mae: 0.0987 - val_loss: 0.1524 - val_mae: 0.1067\n",
            "Epoch 1467/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1610 - mae: 0.0958 - val_loss: 0.1501 - val_mae: 0.1063\n",
            "Epoch 1468/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1431 - mae: 0.0959 - val_loss: 0.1508 - val_mae: 0.1066\n",
            "Epoch 1469/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1525 - mae: 0.0969 - val_loss: 0.1501 - val_mae: 0.1056\n",
            "Epoch 1470/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1911 - mae: 0.0969 - val_loss: 0.1510 - val_mae: 0.1063\n",
            "Epoch 1471/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2637 - mae: 0.1132 - val_loss: 0.1496 - val_mae: 0.1059\n",
            "Epoch 1472/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2326 - mae: 0.1029 - val_loss: 0.1503 - val_mae: 0.1074\n",
            "Epoch 1473/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1953 - mae: 0.1038 - val_loss: 0.1500 - val_mae: 0.1066\n",
            "Epoch 1474/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1577 - mae: 0.0922 - val_loss: 0.1496 - val_mae: 0.1052\n",
            "Epoch 1475/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2038 - mae: 0.1046 - val_loss: 0.1507 - val_mae: 0.1062\n",
            "Epoch 1476/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1597 - mae: 0.0981 - val_loss: 0.1454 - val_mae: 0.1038\n",
            "Epoch 1477/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2585 - mae: 0.1115 - val_loss: 0.1510 - val_mae: 0.1067\n",
            "Epoch 1478/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1902 - mae: 0.1021 - val_loss: 0.1477 - val_mae: 0.1071\n",
            "Epoch 1479/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2687 - mae: 0.1144 - val_loss: 0.1487 - val_mae: 0.1056\n",
            "Epoch 1480/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1674 - mae: 0.0961 - val_loss: 0.1478 - val_mae: 0.1052\n",
            "Epoch 1481/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1241 - mae: 0.0845 - val_loss: 0.1442 - val_mae: 0.1060\n",
            "Epoch 1482/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1506 - mae: 0.1088 - val_loss: 0.1614 - val_mae: 0.1320\n",
            "Epoch 1483/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2186 - mae: 0.1255 - val_loss: 0.1510 - val_mae: 0.1245\n",
            "Epoch 1484/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2088 - mae: 0.1160 - val_loss: 0.1526 - val_mae: 0.1114\n",
            "Epoch 1485/2000\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.1925 - mae: 0.1091 - val_loss: 0.1493 - val_mae: 0.1087\n",
            "Epoch 1486/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2252 - mae: 0.1073 - val_loss: 0.1514 - val_mae: 0.1087\n",
            "Epoch 1487/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1978 - mae: 0.1075 - val_loss: 0.1484 - val_mae: 0.1043\n",
            "Epoch 1488/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1437 - mae: 0.0959 - val_loss: 0.1459 - val_mae: 0.1044\n",
            "Epoch 1489/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1391 - mae: 0.0936 - val_loss: 0.1507 - val_mae: 0.1071\n",
            "Epoch 1490/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1632 - mae: 0.0941 - val_loss: 0.1517 - val_mae: 0.1058\n",
            "Epoch 1491/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1504 - mae: 0.0983 - val_loss: 0.1516 - val_mae: 0.1074\n",
            "Epoch 1492/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1665 - mae: 0.0959 - val_loss: 0.1494 - val_mae: 0.1053\n",
            "Epoch 1493/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1797 - mae: 0.0985 - val_loss: 0.1524 - val_mae: 0.1067\n",
            "Epoch 1494/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1724 - mae: 0.1014 - val_loss: 0.1502 - val_mae: 0.1049\n",
            "Epoch 1495/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1990 - mae: 0.1079 - val_loss: 0.1479 - val_mae: 0.1047\n",
            "Epoch 1496/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1952 - mae: 0.1075 - val_loss: 0.1503 - val_mae: 0.1078\n",
            "Epoch 1497/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1728 - mae: 0.0954 - val_loss: 0.1515 - val_mae: 0.1059\n",
            "Epoch 1498/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1933 - mae: 0.1038 - val_loss: 0.1496 - val_mae: 0.1056\n",
            "Epoch 1499/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1988 - mae: 0.0967 - val_loss: 0.1464 - val_mae: 0.1052\n",
            "Epoch 1500/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1743 - mae: 0.1011 - val_loss: 0.1478 - val_mae: 0.1051\n",
            "Epoch 1501/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1849 - mae: 0.0993 - val_loss: 0.1468 - val_mae: 0.1057\n",
            "Epoch 1502/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1490 - mae: 0.0890 - val_loss: 0.1474 - val_mae: 0.1050\n",
            "Epoch 1503/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1228 - mae: 0.0876 - val_loss: 0.1499 - val_mae: 0.1062\n",
            "Epoch 1504/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1776 - mae: 0.1047 - val_loss: 0.1503 - val_mae: 0.1067\n",
            "Epoch 1505/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1943 - mae: 0.1045 - val_loss: 0.1545 - val_mae: 0.1084\n",
            "Epoch 1506/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1969 - mae: 0.1119 - val_loss: 0.1495 - val_mae: 0.1066\n",
            "Epoch 1507/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1812 - mae: 0.0936 - val_loss: 0.1471 - val_mae: 0.1040\n",
            "Epoch 1508/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1657 - mae: 0.0982 - val_loss: 0.1507 - val_mae: 0.1060\n",
            "Epoch 1509/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2301 - mae: 0.1087 - val_loss: 0.1464 - val_mae: 0.1053\n",
            "Epoch 1510/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1876 - mae: 0.1076 - val_loss: 0.1489 - val_mae: 0.1058\n",
            "Epoch 1511/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1845 - mae: 0.1028 - val_loss: 0.1517 - val_mae: 0.1075\n",
            "Epoch 1512/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1759 - mae: 0.1028 - val_loss: 0.1473 - val_mae: 0.1057\n",
            "Epoch 1513/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1294 - mae: 0.0954 - val_loss: 0.1475 - val_mae: 0.1058\n",
            "Epoch 1514/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1644 - mae: 0.1003 - val_loss: 0.1504 - val_mae: 0.1067\n",
            "Epoch 1515/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1596 - mae: 0.1005 - val_loss: 0.1477 - val_mae: 0.1057\n",
            "Epoch 1516/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1728 - mae: 0.0972 - val_loss: 0.1532 - val_mae: 0.1071\n",
            "Epoch 1517/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1323 - mae: 0.0893 - val_loss: 0.1524 - val_mae: 0.1070\n",
            "Epoch 1518/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1533 - mae: 0.0931 - val_loss: 0.1503 - val_mae: 0.1058\n",
            "Epoch 1519/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1525 - mae: 0.0930 - val_loss: 0.1499 - val_mae: 0.1059\n",
            "Epoch 1520/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1653 - mae: 0.1014 - val_loss: 0.1504 - val_mae: 0.1056\n",
            "Epoch 1521/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1571 - mae: 0.1049 - val_loss: 0.1480 - val_mae: 0.1055\n",
            "Epoch 1522/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2023 - mae: 0.1096 - val_loss: 0.1483 - val_mae: 0.1051\n",
            "Epoch 1523/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1621 - mae: 0.0960 - val_loss: 0.1500 - val_mae: 0.1066\n",
            "Epoch 1524/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1910 - mae: 0.1033 - val_loss: 0.1510 - val_mae: 0.1063\n",
            "Epoch 1525/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1706 - mae: 0.1036 - val_loss: 0.1505 - val_mae: 0.1070\n",
            "Epoch 1526/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1508 - mae: 0.0955 - val_loss: 0.1456 - val_mae: 0.1037\n",
            "Epoch 1527/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1551 - mae: 0.0969 - val_loss: 0.1498 - val_mae: 0.1073\n",
            "Epoch 1528/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1283 - mae: 0.0898 - val_loss: 0.1495 - val_mae: 0.1057\n",
            "Epoch 1529/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1702 - mae: 0.0980 - val_loss: 0.1544 - val_mae: 0.1073\n",
            "Epoch 1530/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2216 - mae: 0.1136 - val_loss: 0.1505 - val_mae: 0.1059\n",
            "Epoch 1531/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2162 - mae: 0.1085 - val_loss: 0.1496 - val_mae: 0.1056\n",
            "Epoch 1532/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1611 - mae: 0.0978 - val_loss: 0.1478 - val_mae: 0.1053\n",
            "Epoch 1533/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1975 - mae: 0.1050 - val_loss: 0.1516 - val_mae: 0.1068\n",
            "Epoch 1534/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1528 - mae: 0.0935 - val_loss: 0.1500 - val_mae: 0.1071\n",
            "Epoch 1535/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1740 - mae: 0.0972 - val_loss: 0.1474 - val_mae: 0.1034\n",
            "Epoch 1536/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2100 - mae: 0.0995 - val_loss: 0.1502 - val_mae: 0.1056\n",
            "Epoch 1537/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2582 - mae: 0.1084 - val_loss: 0.1508 - val_mae: 0.1058\n",
            "Epoch 1538/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2640 - mae: 0.1135 - val_loss: 0.1483 - val_mae: 0.1051\n",
            "Epoch 1539/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1990 - mae: 0.1016 - val_loss: 0.1521 - val_mae: 0.1063\n",
            "Epoch 1540/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1213 - mae: 0.0820 - val_loss: 0.1472 - val_mae: 0.1056\n",
            "Epoch 1541/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2456 - mae: 0.1053 - val_loss: 0.1471 - val_mae: 0.1051\n",
            "Epoch 1542/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1584 - mae: 0.0986 - val_loss: 0.1493 - val_mae: 0.1062\n",
            "Epoch 1543/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1447 - mae: 0.0968 - val_loss: 0.1483 - val_mae: 0.1049\n",
            "Epoch 1544/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1951 - mae: 0.0948 - val_loss: 0.1487 - val_mae: 0.1053\n",
            "Epoch 1545/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1443 - mae: 0.0937 - val_loss: 0.1487 - val_mae: 0.1047\n",
            "Epoch 1546/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1143 - mae: 0.0844 - val_loss: 0.1495 - val_mae: 0.1052\n",
            "Epoch 1547/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2554 - mae: 0.1097 - val_loss: 0.1521 - val_mae: 0.1078\n",
            "Epoch 1548/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1467 - mae: 0.0911 - val_loss: 0.1460 - val_mae: 0.1044\n",
            "Epoch 1549/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1545 - mae: 0.0907 - val_loss: 0.1502 - val_mae: 0.1064\n",
            "Epoch 1550/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1447 - mae: 0.0936 - val_loss: 0.1502 - val_mae: 0.1054\n",
            "Epoch 1551/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2187 - mae: 0.1095 - val_loss: 0.1533 - val_mae: 0.1070\n",
            "Epoch 1552/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1922 - mae: 0.1084 - val_loss: 0.1482 - val_mae: 0.1052\n",
            "Epoch 1553/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2456 - mae: 0.1070 - val_loss: 0.1519 - val_mae: 0.1078\n",
            "Epoch 1554/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.1693 - mae: 0.0970 - val_loss: 0.1501 - val_mae: 0.1047\n",
            "Epoch 1555/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1915 - mae: 0.1046 - val_loss: 0.1474 - val_mae: 0.1057\n",
            "Epoch 1556/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1943 - mae: 0.1050 - val_loss: 0.1489 - val_mae: 0.1050\n",
            "Epoch 1557/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1545 - mae: 0.0964 - val_loss: 0.1458 - val_mae: 0.1043\n",
            "Epoch 1558/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1846 - mae: 0.1010 - val_loss: 0.1512 - val_mae: 0.1066\n",
            "Epoch 1559/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1952 - mae: 0.1038 - val_loss: 0.1533 - val_mae: 0.1084\n",
            "Epoch 1560/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1357 - mae: 0.0936 - val_loss: 0.1457 - val_mae: 0.1047\n",
            "Epoch 1561/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1768 - mae: 0.0988 - val_loss: 0.1496 - val_mae: 0.1055\n",
            "Epoch 1562/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1963 - mae: 0.1053 - val_loss: 0.1499 - val_mae: 0.1055\n",
            "Epoch 1563/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1659 - mae: 0.0966 - val_loss: 0.1478 - val_mae: 0.1058\n",
            "Epoch 1564/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1135 - mae: 0.0848 - val_loss: 0.1450 - val_mae: 0.1034\n",
            "Epoch 1565/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1541 - mae: 0.0955 - val_loss: 0.1447 - val_mae: 0.1058\n",
            "Epoch 1566/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2103 - mae: 0.1071 - val_loss: 0.1496 - val_mae: 0.1142\n",
            "Epoch 1567/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1677 - mae: 0.1065 - val_loss: 0.1516 - val_mae: 0.1133\n",
            "Epoch 1568/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1076 - mae: 0.0938 - val_loss: 0.1485 - val_mae: 0.1074\n",
            "Epoch 1569/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2059 - mae: 0.1137 - val_loss: 0.1517 - val_mae: 0.1075\n",
            "Epoch 1570/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2082 - mae: 0.1031 - val_loss: 0.1518 - val_mae: 0.1074\n",
            "Epoch 1571/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2333 - mae: 0.1077 - val_loss: 0.1503 - val_mae: 0.1063\n",
            "Epoch 1572/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1627 - mae: 0.1013 - val_loss: 0.1499 - val_mae: 0.1064\n",
            "Epoch 1573/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1570 - mae: 0.0957 - val_loss: 0.1498 - val_mae: 0.1060\n",
            "Epoch 1574/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1789 - mae: 0.0919 - val_loss: 0.1552 - val_mae: 0.1091\n",
            "Epoch 1575/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2954 - mae: 0.1142 - val_loss: 0.1463 - val_mae: 0.1043\n",
            "Epoch 1576/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1435 - mae: 0.0960 - val_loss: 0.1460 - val_mae: 0.1053\n",
            "Epoch 1577/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1732 - mae: 0.1000 - val_loss: 0.1469 - val_mae: 0.1044\n",
            "Epoch 1578/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2682 - mae: 0.1120 - val_loss: 0.1490 - val_mae: 0.1046\n",
            "Epoch 1579/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1974 - mae: 0.0996 - val_loss: 0.1521 - val_mae: 0.1067\n",
            "Epoch 1580/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1946 - mae: 0.1055 - val_loss: 0.1492 - val_mae: 0.1054\n",
            "Epoch 1581/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2048 - mae: 0.1019 - val_loss: 0.1512 - val_mae: 0.1054\n",
            "Epoch 1582/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1827 - mae: 0.1045 - val_loss: 0.1457 - val_mae: 0.1049\n",
            "Epoch 1583/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1829 - mae: 0.0979 - val_loss: 0.1501 - val_mae: 0.1055\n",
            "Epoch 1584/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1651 - mae: 0.0984 - val_loss: 0.1507 - val_mae: 0.1059\n",
            "Epoch 1585/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2040 - mae: 0.1075 - val_loss: 0.1495 - val_mae: 0.1054\n",
            "Epoch 1586/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2066 - mae: 0.1012 - val_loss: 0.1478 - val_mae: 0.1054\n",
            "Epoch 1587/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2004 - mae: 0.1095 - val_loss: 0.1491 - val_mae: 0.1050\n",
            "Epoch 1588/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2470 - mae: 0.1156 - val_loss: 0.1479 - val_mae: 0.1044\n",
            "Epoch 1589/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1461 - mae: 0.0886 - val_loss: 0.1476 - val_mae: 0.1056\n",
            "Epoch 1590/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1440 - mae: 0.0978 - val_loss: 0.1479 - val_mae: 0.1056\n",
            "Epoch 1591/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1931 - mae: 0.1044 - val_loss: 0.1507 - val_mae: 0.1073\n",
            "Epoch 1592/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2777 - mae: 0.1175 - val_loss: 0.1490 - val_mae: 0.1048\n",
            "Epoch 1593/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1723 - mae: 0.1004 - val_loss: 0.1494 - val_mae: 0.1049\n",
            "Epoch 1594/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1733 - mae: 0.0889 - val_loss: 0.1479 - val_mae: 0.1048\n",
            "Epoch 1595/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2098 - mae: 0.1000 - val_loss: 0.1504 - val_mae: 0.1055\n",
            "Epoch 1596/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1848 - mae: 0.1047 - val_loss: 0.1459 - val_mae: 0.1057\n",
            "Epoch 1597/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1296 - mae: 0.0915 - val_loss: 0.1481 - val_mae: 0.1057\n",
            "Epoch 1598/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1816 - mae: 0.0984 - val_loss: 0.1515 - val_mae: 0.1056\n",
            "Epoch 1599/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1498 - mae: 0.0991 - val_loss: 0.1442 - val_mae: 0.1036\n",
            "Epoch 1600/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1925 - mae: 0.1011 - val_loss: 0.1494 - val_mae: 0.1046\n",
            "Epoch 1601/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1732 - mae: 0.0985 - val_loss: 0.1525 - val_mae: 0.1076\n",
            "Epoch 1602/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1593 - mae: 0.0969 - val_loss: 0.1475 - val_mae: 0.1051\n",
            "Epoch 1603/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1498 - mae: 0.0918 - val_loss: 0.1511 - val_mae: 0.1060\n",
            "Epoch 1604/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1559 - mae: 0.0969 - val_loss: 0.1484 - val_mae: 0.1059\n",
            "Epoch 1605/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1737 - mae: 0.0984 - val_loss: 0.1501 - val_mae: 0.1064\n",
            "Epoch 1606/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2204 - mae: 0.1060 - val_loss: 0.1515 - val_mae: 0.1065\n",
            "Epoch 1607/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1926 - mae: 0.1068 - val_loss: 0.1468 - val_mae: 0.1055\n",
            "Epoch 1608/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1817 - mae: 0.1062 - val_loss: 0.1509 - val_mae: 0.1057\n",
            "Epoch 1609/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1772 - mae: 0.0971 - val_loss: 0.1475 - val_mae: 0.1072\n",
            "Epoch 1610/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2212 - mae: 0.1112 - val_loss: 0.1539 - val_mae: 0.1073\n",
            "Epoch 1611/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2031 - mae: 0.1074 - val_loss: 0.1492 - val_mae: 0.1046\n",
            "Epoch 1612/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1845 - mae: 0.1039 - val_loss: 0.1496 - val_mae: 0.1052\n",
            "Epoch 1613/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.2591 - mae: 0.1037 - val_loss: 0.1493 - val_mae: 0.1047\n",
            "Epoch 1614/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2667 - mae: 0.1080 - val_loss: 0.1504 - val_mae: 0.1052\n",
            "Epoch 1615/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1930 - mae: 0.1024 - val_loss: 0.1513 - val_mae: 0.1088\n",
            "Epoch 1616/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1535 - mae: 0.0950 - val_loss: 0.1457 - val_mae: 0.1036\n",
            "Epoch 1617/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1204 - mae: 0.0870 - val_loss: 0.1466 - val_mae: 0.1040\n",
            "Epoch 1618/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1976 - mae: 0.1088 - val_loss: 0.1558 - val_mae: 0.1091\n",
            "Epoch 1619/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2590 - mae: 0.1192 - val_loss: 0.1486 - val_mae: 0.1053\n",
            "Epoch 1620/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1873 - mae: 0.0992 - val_loss: 0.1511 - val_mae: 0.1066\n",
            "Epoch 1621/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1649 - mae: 0.0918 - val_loss: 0.1495 - val_mae: 0.1058\n",
            "Epoch 1622/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1503 - mae: 0.0911 - val_loss: 0.1488 - val_mae: 0.1062\n",
            "Epoch 1623/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1815 - mae: 0.0986 - val_loss: 0.1469 - val_mae: 0.1062\n",
            "Epoch 1624/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1969 - mae: 0.0999 - val_loss: 0.1488 - val_mae: 0.1059\n",
            "Epoch 1625/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1885 - mae: 0.0974 - val_loss: 0.1513 - val_mae: 0.1065\n",
            "Epoch 1626/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1203 - mae: 0.0851 - val_loss: 0.1462 - val_mae: 0.1034\n",
            "Epoch 1627/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1760 - mae: 0.1050 - val_loss: 0.1488 - val_mae: 0.1054\n",
            "Epoch 1628/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2111 - mae: 0.1054 - val_loss: 0.1514 - val_mae: 0.1069\n",
            "Epoch 1629/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1420 - mae: 0.0916 - val_loss: 0.1501 - val_mae: 0.1061\n",
            "Epoch 1630/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1628 - mae: 0.0982 - val_loss: 0.1493 - val_mae: 0.1054\n",
            "Epoch 1631/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1666 - mae: 0.0970 - val_loss: 0.1493 - val_mae: 0.1056\n",
            "Epoch 1632/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1508 - mae: 0.0957 - val_loss: 0.1509 - val_mae: 0.1064\n",
            "Epoch 1633/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2503 - mae: 0.1061 - val_loss: 0.1486 - val_mae: 0.1049\n",
            "Epoch 1634/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1794 - mae: 0.0982 - val_loss: 0.1496 - val_mae: 0.1053\n",
            "Epoch 1635/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1668 - mae: 0.0873 - val_loss: 0.1522 - val_mae: 0.1065\n",
            "Epoch 1636/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1843 - mae: 0.1031 - val_loss: 0.1450 - val_mae: 0.1041\n",
            "Epoch 1637/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1286 - mae: 0.0926 - val_loss: 0.1453 - val_mae: 0.1053\n",
            "Epoch 1638/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1764 - mae: 0.1102 - val_loss: 0.1492 - val_mae: 0.1160\n",
            "Epoch 1639/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2149 - mae: 0.1211 - val_loss: 0.1558 - val_mae: 0.1146\n",
            "Epoch 1640/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1258 - mae: 0.0925 - val_loss: 0.1464 - val_mae: 0.1054\n",
            "Epoch 1641/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2015 - mae: 0.1098 - val_loss: 0.1495 - val_mae: 0.1084\n",
            "Epoch 1642/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1936 - mae: 0.1000 - val_loss: 0.1370 - val_mae: 0.1058\n",
            "Epoch 1643/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1763 - mae: 0.1097 - val_loss: 0.1383 - val_mae: 0.1069\n",
            "Epoch 1644/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1752 - mae: 0.1001 - val_loss: 0.1476 - val_mae: 0.1087\n",
            "Epoch 1645/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1722 - mae: 0.0976 - val_loss: 0.1520 - val_mae: 0.1091\n",
            "Epoch 1646/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1857 - mae: 0.1035 - val_loss: 0.1494 - val_mae: 0.1074\n",
            "Epoch 1647/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1724 - mae: 0.0996 - val_loss: 0.1488 - val_mae: 0.1051\n",
            "Epoch 1648/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1906 - mae: 0.1092 - val_loss: 0.1484 - val_mae: 0.1050\n",
            "Epoch 1649/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1911 - mae: 0.1028 - val_loss: 0.1506 - val_mae: 0.1070\n",
            "Epoch 1650/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2096 - mae: 0.1071 - val_loss: 0.1483 - val_mae: 0.1047\n",
            "Epoch 1651/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2193 - mae: 0.1073 - val_loss: 0.1505 - val_mae: 0.1053\n",
            "Epoch 1652/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1358 - mae: 0.0902 - val_loss: 0.1493 - val_mae: 0.1059\n",
            "Epoch 1653/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2009 - mae: 0.1052 - val_loss: 0.1499 - val_mae: 0.1057\n",
            "Epoch 1654/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1320 - mae: 0.0893 - val_loss: 0.1482 - val_mae: 0.1045\n",
            "Epoch 1655/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1977 - mae: 0.1086 - val_loss: 0.1509 - val_mae: 0.1060\n",
            "Epoch 1656/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2522 - mae: 0.1030 - val_loss: 0.1572 - val_mae: 0.1102\n",
            "Epoch 1657/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1610 - mae: 0.0979 - val_loss: 0.1467 - val_mae: 0.1046\n",
            "Epoch 1658/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1760 - mae: 0.1018 - val_loss: 0.1492 - val_mae: 0.1055\n",
            "Epoch 1659/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2395 - mae: 0.1124 - val_loss: 0.1482 - val_mae: 0.1047\n",
            "Epoch 1660/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2138 - mae: 0.1078 - val_loss: 0.1499 - val_mae: 0.1064\n",
            "Epoch 1661/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1212 - mae: 0.0885 - val_loss: 0.1481 - val_mae: 0.1048\n",
            "Epoch 1662/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2137 - mae: 0.1075 - val_loss: 0.1500 - val_mae: 0.1057\n",
            "Epoch 1663/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1231 - mae: 0.0876 - val_loss: 0.1465 - val_mae: 0.1036\n",
            "Epoch 1664/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1687 - mae: 0.1029 - val_loss: 0.1517 - val_mae: 0.1071\n",
            "Epoch 1665/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1979 - mae: 0.0994 - val_loss: 0.1508 - val_mae: 0.1065\n",
            "Epoch 1666/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2037 - mae: 0.1021 - val_loss: 0.1513 - val_mae: 0.1072\n",
            "Epoch 1667/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1875 - mae: 0.1022 - val_loss: 0.1485 - val_mae: 0.1060\n",
            "Epoch 1668/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1851 - mae: 0.1002 - val_loss: 0.1502 - val_mae: 0.1059\n",
            "Epoch 1669/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1675 - mae: 0.1029 - val_loss: 0.1504 - val_mae: 0.1067\n",
            "Epoch 1670/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1752 - mae: 0.1001 - val_loss: 0.1485 - val_mae: 0.1046\n",
            "Epoch 1671/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1878 - mae: 0.1041 - val_loss: 0.1494 - val_mae: 0.1052\n",
            "Epoch 1672/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2374 - mae: 0.1107 - val_loss: 0.1527 - val_mae: 0.1057\n",
            "Epoch 1673/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1749 - mae: 0.0951 - val_loss: 0.1504 - val_mae: 0.1081\n",
            "Epoch 1674/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1383 - mae: 0.0956 - val_loss: 0.1461 - val_mae: 0.1033\n",
            "Epoch 1675/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2681 - mae: 0.1121 - val_loss: 0.1482 - val_mae: 0.1059\n",
            "Epoch 1676/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1789 - mae: 0.1024 - val_loss: 0.1506 - val_mae: 0.1056\n",
            "Epoch 1677/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1327 - mae: 0.0968 - val_loss: 0.1465 - val_mae: 0.1056\n",
            "Epoch 1678/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1730 - mae: 0.1054 - val_loss: 0.1513 - val_mae: 0.1065\n",
            "Epoch 1679/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2066 - mae: 0.1085 - val_loss: 0.1529 - val_mae: 0.1071\n",
            "Epoch 1680/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.1534 - mae: 0.0933 - val_loss: 0.1492 - val_mae: 0.1057\n",
            "Epoch 1681/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1685 - mae: 0.1014 - val_loss: 0.1491 - val_mae: 0.1058\n",
            "Epoch 1682/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1453 - mae: 0.0936 - val_loss: 0.1493 - val_mae: 0.1050\n",
            "Epoch 1683/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1461 - mae: 0.0923 - val_loss: 0.1500 - val_mae: 0.1048\n",
            "Epoch 1684/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1715 - mae: 0.0976 - val_loss: 0.1509 - val_mae: 0.1058\n",
            "Epoch 1685/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3056 - mae: 0.1197 - val_loss: 0.1488 - val_mae: 0.1050\n",
            "Epoch 1686/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1728 - mae: 0.0972 - val_loss: 0.1502 - val_mae: 0.1055\n",
            "Epoch 1687/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1850 - mae: 0.0993 - val_loss: 0.1498 - val_mae: 0.1057\n",
            "Epoch 1688/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1823 - mae: 0.1081 - val_loss: 0.1497 - val_mae: 0.1055\n",
            "Epoch 1689/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2052 - mae: 0.1020 - val_loss: 0.1498 - val_mae: 0.1046\n",
            "Epoch 1690/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2317 - mae: 0.1092 - val_loss: 0.1489 - val_mae: 0.1061\n",
            "Epoch 1691/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1949 - mae: 0.1016 - val_loss: 0.1459 - val_mae: 0.1043\n",
            "Epoch 1692/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1824 - mae: 0.1020 - val_loss: 0.1493 - val_mae: 0.1057\n",
            "Epoch 1693/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1460 - mae: 0.0983 - val_loss: 0.1505 - val_mae: 0.1064\n",
            "Epoch 1694/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1609 - mae: 0.0912 - val_loss: 0.1493 - val_mae: 0.1054\n",
            "Epoch 1695/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1363 - mae: 0.0867 - val_loss: 0.1512 - val_mae: 0.1060\n",
            "Epoch 1696/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1318 - mae: 0.0948 - val_loss: 0.1448 - val_mae: 0.1038\n",
            "Epoch 1697/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1850 - mae: 0.0963 - val_loss: 0.1524 - val_mae: 0.1071\n",
            "Epoch 1698/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1790 - mae: 0.1031 - val_loss: 0.1482 - val_mae: 0.1047\n",
            "Epoch 1699/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1407 - mae: 0.0947 - val_loss: 0.1475 - val_mae: 0.1039\n",
            "Epoch 1700/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1944 - mae: 0.1066 - val_loss: 0.1513 - val_mae: 0.1073\n",
            "Epoch 1701/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1290 - mae: 0.0908 - val_loss: 0.1464 - val_mae: 0.1041\n",
            "Epoch 1702/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1784 - mae: 0.1005 - val_loss: 0.1498 - val_mae: 0.1069\n",
            "Epoch 1703/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1196 - mae: 0.0892 - val_loss: 0.1501 - val_mae: 0.1055\n",
            "Epoch 1704/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2214 - mae: 0.1070 - val_loss: 0.1495 - val_mae: 0.1053\n",
            "Epoch 1705/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1616 - mae: 0.1030 - val_loss: 0.1465 - val_mae: 0.1047\n",
            "Epoch 1706/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1592 - mae: 0.0957 - val_loss: 0.1531 - val_mae: 0.1066\n",
            "Epoch 1707/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2016 - mae: 0.1067 - val_loss: 0.1525 - val_mae: 0.1069\n",
            "Epoch 1708/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2094 - mae: 0.1013 - val_loss: 0.1518 - val_mae: 0.1073\n",
            "Epoch 1709/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1740 - mae: 0.1030 - val_loss: 0.1481 - val_mae: 0.1049\n",
            "Epoch 1710/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1590 - mae: 0.0920 - val_loss: 0.1506 - val_mae: 0.1061\n",
            "Epoch 1711/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2314 - mae: 0.1125 - val_loss: 0.1507 - val_mae: 0.1052\n",
            "Epoch 1712/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1846 - mae: 0.0989 - val_loss: 0.1494 - val_mae: 0.1064\n",
            "Epoch 1713/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1805 - mae: 0.0961 - val_loss: 0.1495 - val_mae: 0.1050\n",
            "Epoch 1714/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2040 - mae: 0.1006 - val_loss: 0.1515 - val_mae: 0.1099\n",
            "Epoch 1715/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1742 - mae: 0.1004 - val_loss: 0.1510 - val_mae: 0.1082\n",
            "Epoch 1716/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1479 - mae: 0.1049 - val_loss: 0.1474 - val_mae: 0.1069\n",
            "Epoch 1717/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2623 - mae: 0.1033 - val_loss: 0.1472 - val_mae: 0.1047\n",
            "Epoch 1718/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1758 - mae: 0.0953 - val_loss: 0.1473 - val_mae: 0.1049\n",
            "Epoch 1719/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1692 - mae: 0.0943 - val_loss: 0.1475 - val_mae: 0.1047\n",
            "Epoch 1720/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2631 - mae: 0.1176 - val_loss: 0.1486 - val_mae: 0.1051\n",
            "Epoch 1721/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2097 - mae: 0.1053 - val_loss: 0.1497 - val_mae: 0.1067\n",
            "Epoch 1722/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1589 - mae: 0.0939 - val_loss: 0.1480 - val_mae: 0.1039\n",
            "Epoch 1723/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3267 - mae: 0.1264 - val_loss: 0.1530 - val_mae: 0.1067\n",
            "Epoch 1724/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1743 - mae: 0.1035 - val_loss: 0.1475 - val_mae: 0.1052\n",
            "Epoch 1725/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1997 - mae: 0.1098 - val_loss: 0.1506 - val_mae: 0.1062\n",
            "Epoch 1726/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2251 - mae: 0.0996 - val_loss: 0.1474 - val_mae: 0.1046\n",
            "Epoch 1727/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1590 - mae: 0.0954 - val_loss: 0.1490 - val_mae: 0.1066\n",
            "Epoch 1728/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1859 - mae: 0.1006 - val_loss: 0.1484 - val_mae: 0.1055\n",
            "Epoch 1729/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2191 - mae: 0.1129 - val_loss: 0.1488 - val_mae: 0.1046\n",
            "Epoch 1730/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2226 - mae: 0.1042 - val_loss: 0.1481 - val_mae: 0.1048\n",
            "Epoch 1731/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1742 - mae: 0.0974 - val_loss: 0.1488 - val_mae: 0.1053\n",
            "Epoch 1732/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1563 - mae: 0.0994 - val_loss: 0.1495 - val_mae: 0.1053\n",
            "Epoch 1733/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1746 - mae: 0.0952 - val_loss: 0.1527 - val_mae: 0.1067\n",
            "Epoch 1734/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1798 - mae: 0.1025 - val_loss: 0.1452 - val_mae: 0.1040\n",
            "Epoch 1735/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2068 - mae: 0.1011 - val_loss: 0.1465 - val_mae: 0.1041\n",
            "Epoch 1736/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1605 - mae: 0.0983 - val_loss: 0.1509 - val_mae: 0.1070\n",
            "Epoch 1737/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1577 - mae: 0.0991 - val_loss: 0.1464 - val_mae: 0.1049\n",
            "Epoch 1738/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2245 - mae: 0.1073 - val_loss: 0.1510 - val_mae: 0.1084\n",
            "Epoch 1739/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1310 - mae: 0.0963 - val_loss: 0.1545 - val_mae: 0.1278\n",
            "Epoch 1740/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2321 - mae: 0.1295 - val_loss: 0.1504 - val_mae: 0.1174\n",
            "Epoch 1741/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1682 - mae: 0.1117 - val_loss: 0.1485 - val_mae: 0.1100\n",
            "Epoch 1742/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1758 - mae: 0.0982 - val_loss: 0.1498 - val_mae: 0.1080\n",
            "Epoch 1743/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1195 - mae: 0.0873 - val_loss: 0.1482 - val_mae: 0.1052\n",
            "Epoch 1744/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1932 - mae: 0.1044 - val_loss: 0.1507 - val_mae: 0.1059\n",
            "Epoch 1745/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2067 - mae: 0.1099 - val_loss: 0.1497 - val_mae: 0.1064\n",
            "Epoch 1746/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.1886 - mae: 0.1017 - val_loss: 0.1484 - val_mae: 0.1067\n",
            "Epoch 1747/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1690 - mae: 0.0969 - val_loss: 0.1521 - val_mae: 0.1068\n",
            "Epoch 1748/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3295 - mae: 0.1234 - val_loss: 0.1513 - val_mae: 0.1067\n",
            "Epoch 1749/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1658 - mae: 0.0976 - val_loss: 0.1476 - val_mae: 0.1043\n",
            "Epoch 1750/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1451 - mae: 0.0910 - val_loss: 0.1480 - val_mae: 0.1049\n",
            "Epoch 1751/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1266 - mae: 0.0952 - val_loss: 0.1476 - val_mae: 0.1042\n",
            "Epoch 1752/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2109 - mae: 0.1009 - val_loss: 0.1490 - val_mae: 0.1045\n",
            "Epoch 1753/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1807 - mae: 0.0970 - val_loss: 0.1501 - val_mae: 0.1054\n",
            "Epoch 1754/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2187 - mae: 0.1099 - val_loss: 0.1505 - val_mae: 0.1051\n",
            "Epoch 1755/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2179 - mae: 0.1058 - val_loss: 0.1517 - val_mae: 0.1066\n",
            "Epoch 1756/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1714 - mae: 0.0924 - val_loss: 0.1508 - val_mae: 0.1056\n",
            "Epoch 1757/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1468 - mae: 0.0969 - val_loss: 0.1449 - val_mae: 0.1036\n",
            "Epoch 1758/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1105 - mae: 0.0888 - val_loss: 0.1474 - val_mae: 0.1055\n",
            "Epoch 1759/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1696 - mae: 0.0998 - val_loss: 0.1516 - val_mae: 0.1064\n",
            "Epoch 1760/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1619 - mae: 0.0950 - val_loss: 0.1500 - val_mae: 0.1052\n",
            "Epoch 1761/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2044 - mae: 0.1060 - val_loss: 0.1494 - val_mae: 0.1051\n",
            "Epoch 1762/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1881 - mae: 0.1014 - val_loss: 0.1488 - val_mae: 0.1052\n",
            "Epoch 1763/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1728 - mae: 0.0962 - val_loss: 0.1511 - val_mae: 0.1076\n",
            "Epoch 1764/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2501 - mae: 0.1060 - val_loss: 0.1506 - val_mae: 0.1058\n",
            "Epoch 1765/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1304 - mae: 0.0934 - val_loss: 0.1483 - val_mae: 0.1054\n",
            "Epoch 1766/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2054 - mae: 0.0987 - val_loss: 0.1510 - val_mae: 0.1053\n",
            "Epoch 1767/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1972 - mae: 0.1004 - val_loss: 0.1511 - val_mae: 0.1066\n",
            "Epoch 1768/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1808 - mae: 0.0941 - val_loss: 0.1500 - val_mae: 0.1051\n",
            "Epoch 1769/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2078 - mae: 0.1067 - val_loss: 0.1480 - val_mae: 0.1053\n",
            "Epoch 1770/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1933 - mae: 0.1030 - val_loss: 0.1512 - val_mae: 0.1057\n",
            "Epoch 1771/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1899 - mae: 0.1006 - val_loss: 0.1494 - val_mae: 0.1045\n",
            "Epoch 1772/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2464 - mae: 0.1131 - val_loss: 0.1495 - val_mae: 0.1048\n",
            "Epoch 1773/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1816 - mae: 0.1077 - val_loss: 0.1490 - val_mae: 0.1058\n",
            "Epoch 1774/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2713 - mae: 0.1164 - val_loss: 0.1523 - val_mae: 0.1072\n",
            "Epoch 1775/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2099 - mae: 0.1024 - val_loss: 0.1500 - val_mae: 0.1055\n",
            "Epoch 1776/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2316 - mae: 0.1085 - val_loss: 0.1456 - val_mae: 0.1038\n",
            "Epoch 1777/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2892 - mae: 0.1175 - val_loss: 0.1487 - val_mae: 0.1050\n",
            "Epoch 1778/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2563 - mae: 0.1093 - val_loss: 0.1506 - val_mae: 0.1059\n",
            "Epoch 1779/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1701 - mae: 0.0985 - val_loss: 0.1453 - val_mae: 0.1049\n",
            "Epoch 1780/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1863 - mae: 0.1030 - val_loss: 0.1483 - val_mae: 0.1058\n",
            "Epoch 1781/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1599 - mae: 0.0951 - val_loss: 0.1518 - val_mae: 0.1062\n",
            "Epoch 1782/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2182 - mae: 0.1090 - val_loss: 0.1522 - val_mae: 0.1058\n",
            "Epoch 1783/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1383 - mae: 0.0932 - val_loss: 0.1466 - val_mae: 0.1037\n",
            "Epoch 1784/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1420 - mae: 0.0951 - val_loss: 0.1482 - val_mae: 0.1050\n",
            "Epoch 1785/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2884 - mae: 0.1241 - val_loss: 0.1531 - val_mae: 0.1070\n",
            "Epoch 1786/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2161 - mae: 0.1036 - val_loss: 0.1514 - val_mae: 0.1064\n",
            "Epoch 1787/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1992 - mae: 0.1052 - val_loss: 0.1491 - val_mae: 0.1050\n",
            "Epoch 1788/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1678 - mae: 0.0941 - val_loss: 0.1503 - val_mae: 0.1052\n",
            "Epoch 1789/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2365 - mae: 0.0988 - val_loss: 0.1490 - val_mae: 0.1057\n",
            "Epoch 1790/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2820 - mae: 0.1186 - val_loss: 0.1503 - val_mae: 0.1068\n",
            "Epoch 1791/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1967 - mae: 0.1003 - val_loss: 0.1458 - val_mae: 0.1032\n",
            "Epoch 1792/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2631 - mae: 0.1134 - val_loss: 0.1491 - val_mae: 0.1056\n",
            "Epoch 1793/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1117 - mae: 0.0855 - val_loss: 0.1477 - val_mae: 0.1060\n",
            "Epoch 1794/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2065 - mae: 0.1036 - val_loss: 0.1517 - val_mae: 0.1060\n",
            "Epoch 1795/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2283 - mae: 0.1076 - val_loss: 0.1495 - val_mae: 0.1062\n",
            "Epoch 1796/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1906 - mae: 0.1025 - val_loss: 0.1460 - val_mae: 0.1032\n",
            "Epoch 1797/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1593 - mae: 0.1035 - val_loss: 0.1465 - val_mae: 0.1040\n",
            "Epoch 1798/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1869 - mae: 0.1077 - val_loss: 0.1507 - val_mae: 0.1058\n",
            "Epoch 1799/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1881 - mae: 0.0983 - val_loss: 0.1513 - val_mae: 0.1061\n",
            "Epoch 1800/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1491 - mae: 0.0949 - val_loss: 0.1509 - val_mae: 0.1055\n",
            "Epoch 1801/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1781 - mae: 0.0959 - val_loss: 0.1518 - val_mae: 0.1061\n",
            "Epoch 1802/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1796 - mae: 0.0951 - val_loss: 0.1500 - val_mae: 0.1051\n",
            "Epoch 1803/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1944 - mae: 0.1024 - val_loss: 0.1497 - val_mae: 0.1054\n",
            "Epoch 1804/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2101 - mae: 0.0999 - val_loss: 0.1525 - val_mae: 0.1078\n",
            "Epoch 1805/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1422 - mae: 0.0900 - val_loss: 0.1460 - val_mae: 0.1033\n",
            "Epoch 1806/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1582 - mae: 0.1032 - val_loss: 0.1457 - val_mae: 0.1035\n",
            "Epoch 1807/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1788 - mae: 0.1000 - val_loss: 0.1505 - val_mae: 0.1058\n",
            "Epoch 1808/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1354 - mae: 0.0926 - val_loss: 0.1488 - val_mae: 0.1055\n",
            "Epoch 1809/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2171 - mae: 0.1113 - val_loss: 0.1500 - val_mae: 0.1048\n",
            "Epoch 1810/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2504 - mae: 0.1065 - val_loss: 0.1503 - val_mae: 0.1054\n",
            "Epoch 1811/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1562 - mae: 0.0950 - val_loss: 0.1523 - val_mae: 0.1058\n",
            "Epoch 1812/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1793 - mae: 0.1009 - val_loss: 0.1518 - val_mae: 0.1066\n",
            "Epoch 1813/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1726 - mae: 0.1003 - val_loss: 0.1481 - val_mae: 0.1043\n",
            "Epoch 1814/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1793 - mae: 0.0981 - val_loss: 0.1510 - val_mae: 0.1060\n",
            "Epoch 1815/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1991 - mae: 0.1037 - val_loss: 0.1499 - val_mae: 0.1056\n",
            "Epoch 1816/2000\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1759 - mae: 0.0999 - val_loss: 0.1488 - val_mae: 0.1049\n",
            "Epoch 1817/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2386 - mae: 0.1115 - val_loss: 0.1521 - val_mae: 0.1062\n",
            "Epoch 1818/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1204 - mae: 0.0919 - val_loss: 0.1452 - val_mae: 0.1044\n",
            "Epoch 1819/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1432 - mae: 0.0916 - val_loss: 0.1494 - val_mae: 0.1060\n",
            "Epoch 1820/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1414 - mae: 0.0938 - val_loss: 0.1493 - val_mae: 0.1054\n",
            "Epoch 1821/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2203 - mae: 0.1077 - val_loss: 0.1503 - val_mae: 0.1061\n",
            "Epoch 1822/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1472 - mae: 0.0925 - val_loss: 0.1503 - val_mae: 0.1058\n",
            "Epoch 1823/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1538 - mae: 0.1045 - val_loss: 0.1447 - val_mae: 0.1055\n",
            "Epoch 1824/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1731 - mae: 0.0967 - val_loss: 0.1471 - val_mae: 0.1057\n",
            "Epoch 1825/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2321 - mae: 0.1100 - val_loss: 0.1514 - val_mae: 0.1075\n",
            "Epoch 1826/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1525 - mae: 0.1031 - val_loss: 0.1461 - val_mae: 0.1046\n",
            "Epoch 1827/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1934 - mae: 0.1020 - val_loss: 0.1540 - val_mae: 0.1073\n",
            "Epoch 1828/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2169 - mae: 0.1110 - val_loss: 0.1481 - val_mae: 0.1041\n",
            "Epoch 1829/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2063 - mae: 0.1047 - val_loss: 0.1507 - val_mae: 0.1060\n",
            "Epoch 1830/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1329 - mae: 0.0939 - val_loss: 0.1469 - val_mae: 0.1055\n",
            "Epoch 1831/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2277 - mae: 0.1145 - val_loss: 0.1512 - val_mae: 0.1071\n",
            "Epoch 1832/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1964 - mae: 0.1030 - val_loss: 0.1497 - val_mae: 0.1057\n",
            "Epoch 1833/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2535 - mae: 0.1176 - val_loss: 0.1495 - val_mae: 0.1053\n",
            "Epoch 1834/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1808 - mae: 0.1009 - val_loss: 0.1479 - val_mae: 0.1048\n",
            "Epoch 1835/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2432 - mae: 0.1125 - val_loss: 0.1512 - val_mae: 0.1071\n",
            "Epoch 1836/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1976 - mae: 0.0990 - val_loss: 0.1511 - val_mae: 0.1060\n",
            "Epoch 1837/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1892 - mae: 0.1019 - val_loss: 0.1512 - val_mae: 0.1069\n",
            "Epoch 1838/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1805 - mae: 0.1033 - val_loss: 0.1503 - val_mae: 0.1057\n",
            "Epoch 1839/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2134 - mae: 0.1006 - val_loss: 0.1474 - val_mae: 0.1056\n",
            "Epoch 1840/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2578 - mae: 0.1150 - val_loss: 0.1481 - val_mae: 0.1052\n",
            "Epoch 1841/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1686 - mae: 0.1007 - val_loss: 0.1477 - val_mae: 0.1047\n",
            "Epoch 1842/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2537 - mae: 0.1178 - val_loss: 0.1526 - val_mae: 0.1062\n",
            "Epoch 1843/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1679 - mae: 0.0919 - val_loss: 0.1469 - val_mae: 0.1040\n",
            "Epoch 1844/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1661 - mae: 0.0990 - val_loss: 0.1507 - val_mae: 0.1050\n",
            "Epoch 1845/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1732 - mae: 0.0951 - val_loss: 0.1480 - val_mae: 0.1042\n",
            "Epoch 1846/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2675 - mae: 0.1163 - val_loss: 0.1490 - val_mae: 0.1053\n",
            "Epoch 1847/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1540 - mae: 0.0904 - val_loss: 0.1487 - val_mae: 0.1057\n",
            "Epoch 1848/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1554 - mae: 0.0955 - val_loss: 0.1490 - val_mae: 0.1062\n",
            "Epoch 1849/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1484 - mae: 0.0908 - val_loss: 0.1501 - val_mae: 0.1047\n",
            "Epoch 1850/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2972 - mae: 0.1145 - val_loss: 0.1507 - val_mae: 0.1059\n",
            "Epoch 1851/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1419 - mae: 0.0973 - val_loss: 0.1472 - val_mae: 0.1049\n",
            "Epoch 1852/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1732 - mae: 0.1015 - val_loss: 0.1503 - val_mae: 0.1059\n",
            "Epoch 1853/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1727 - mae: 0.0981 - val_loss: 0.1509 - val_mae: 0.1071\n",
            "Epoch 1854/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1595 - mae: 0.0939 - val_loss: 0.1485 - val_mae: 0.1046\n",
            "Epoch 1855/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2636 - mae: 0.1091 - val_loss: 0.1514 - val_mae: 0.1068\n",
            "Epoch 1856/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1616 - mae: 0.0911 - val_loss: 0.1476 - val_mae: 0.1053\n",
            "Epoch 1857/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1328 - mae: 0.0913 - val_loss: 0.1485 - val_mae: 0.1058\n",
            "Epoch 1858/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1239 - mae: 0.0870 - val_loss: 0.1495 - val_mae: 0.1053\n",
            "Epoch 1859/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2626 - mae: 0.1205 - val_loss: 0.1527 - val_mae: 0.1069\n",
            "Epoch 1860/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2223 - mae: 0.1028 - val_loss: 0.1513 - val_mae: 0.1059\n",
            "Epoch 1861/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1821 - mae: 0.0991 - val_loss: 0.1498 - val_mae: 0.1055\n",
            "Epoch 1862/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1533 - mae: 0.0896 - val_loss: 0.1472 - val_mae: 0.1050\n",
            "Epoch 1863/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1530 - mae: 0.0956 - val_loss: 0.1516 - val_mae: 0.1069\n",
            "Epoch 1864/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1630 - mae: 0.0939 - val_loss: 0.1480 - val_mae: 0.1051\n",
            "Epoch 1865/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2442 - mae: 0.1069 - val_loss: 0.1492 - val_mae: 0.1093\n",
            "Epoch 1866/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2148 - mae: 0.1088 - val_loss: 0.1516 - val_mae: 0.1078\n",
            "Epoch 1867/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1854 - mae: 0.1027 - val_loss: 0.1486 - val_mae: 0.1061\n",
            "Epoch 1868/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2218 - mae: 0.1104 - val_loss: 0.1491 - val_mae: 0.1055\n",
            "Epoch 1869/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2340 - mae: 0.1110 - val_loss: 0.1486 - val_mae: 0.1050\n",
            "Epoch 1870/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2318 - mae: 0.1066 - val_loss: 0.1523 - val_mae: 0.1067\n",
            "Epoch 1871/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1745 - mae: 0.0981 - val_loss: 0.1506 - val_mae: 0.1056\n",
            "Epoch 1872/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1814 - mae: 0.0986 - val_loss: 0.1492 - val_mae: 0.1069\n",
            "Epoch 1873/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2422 - mae: 0.1134 - val_loss: 0.1489 - val_mae: 0.1049\n",
            "Epoch 1874/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1695 - mae: 0.1019 - val_loss: 0.1483 - val_mae: 0.1050\n",
            "Epoch 1875/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1651 - mae: 0.1013 - val_loss: 0.1504 - val_mae: 0.1065\n",
            "Epoch 1876/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2006 - mae: 0.1049 - val_loss: 0.1499 - val_mae: 0.1065\n",
            "Epoch 1877/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1993 - mae: 0.1098 - val_loss: 0.1478 - val_mae: 0.1050\n",
            "Epoch 1878/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2051 - mae: 0.1090 - val_loss: 0.1523 - val_mae: 0.1070\n",
            "Epoch 1879/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1638 - mae: 0.0929 - val_loss: 0.1488 - val_mae: 0.1042\n",
            "Epoch 1880/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1799 - mae: 0.0952 - val_loss: 0.1505 - val_mae: 0.1066\n",
            "Epoch 1881/2000\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1469 - mae: 0.0919 - val_loss: 0.1494 - val_mae: 0.1055\n",
            "Epoch 1882/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1660 - mae: 0.0988 - val_loss: 0.1492 - val_mae: 0.1059\n",
            "Epoch 1883/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1498 - mae: 0.0924 - val_loss: 0.1486 - val_mae: 0.1060\n",
            "Epoch 1884/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2282 - mae: 0.1040 - val_loss: 0.1493 - val_mae: 0.1055\n",
            "Epoch 1885/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1801 - mae: 0.0997 - val_loss: 0.1498 - val_mae: 0.1051\n",
            "Epoch 1886/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2004 - mae: 0.1063 - val_loss: 0.1485 - val_mae: 0.1056\n",
            "Epoch 1887/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1960 - mae: 0.1006 - val_loss: 0.1519 - val_mae: 0.1059\n",
            "Epoch 1888/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1595 - mae: 0.0966 - val_loss: 0.1473 - val_mae: 0.1048\n",
            "Epoch 1889/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2530 - mae: 0.1089 - val_loss: 0.1514 - val_mae: 0.1071\n",
            "Epoch 1890/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1471 - mae: 0.0916 - val_loss: 0.1492 - val_mae: 0.1063\n",
            "Epoch 1891/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1493 - mae: 0.0921 - val_loss: 0.1465 - val_mae: 0.1051\n",
            "Epoch 1892/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2173 - mae: 0.1049 - val_loss: 0.1530 - val_mae: 0.1063\n",
            "Epoch 1893/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1822 - mae: 0.1035 - val_loss: 0.1491 - val_mae: 0.1056\n",
            "Epoch 1894/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2068 - mae: 0.1010 - val_loss: 0.1514 - val_mae: 0.1072\n",
            "Epoch 1895/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1498 - mae: 0.0964 - val_loss: 0.1452 - val_mae: 0.1037\n",
            "Epoch 1896/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1786 - mae: 0.0996 - val_loss: 0.1494 - val_mae: 0.1055\n",
            "Epoch 1897/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2434 - mae: 0.1132 - val_loss: 0.1486 - val_mae: 0.1047\n",
            "Epoch 1898/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2018 - mae: 0.1006 - val_loss: 0.1491 - val_mae: 0.1055\n",
            "Epoch 1899/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1487 - mae: 0.0928 - val_loss: 0.1483 - val_mae: 0.1047\n",
            "Epoch 1900/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1998 - mae: 0.1004 - val_loss: 0.1504 - val_mae: 0.1065\n",
            "Epoch 1901/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1635 - mae: 0.1059 - val_loss: 0.1475 - val_mae: 0.1042\n",
            "Epoch 1902/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1428 - mae: 0.0959 - val_loss: 0.1493 - val_mae: 0.1057\n",
            "Epoch 1903/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2399 - mae: 0.1059 - val_loss: 0.1505 - val_mae: 0.1065\n",
            "Epoch 1904/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1605 - mae: 0.0998 - val_loss: 0.1522 - val_mae: 0.1076\n",
            "Epoch 1905/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2114 - mae: 0.1091 - val_loss: 0.1507 - val_mae: 0.1065\n",
            "Epoch 1906/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1499 - mae: 0.0936 - val_loss: 0.1482 - val_mae: 0.1047\n",
            "Epoch 1907/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1512 - mae: 0.0928 - val_loss: 0.1511 - val_mae: 0.1063\n",
            "Epoch 1908/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1719 - mae: 0.1009 - val_loss: 0.1494 - val_mae: 0.1065\n",
            "Epoch 1909/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1783 - mae: 0.0981 - val_loss: 0.1479 - val_mae: 0.1044\n",
            "Epoch 1910/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1531 - mae: 0.0953 - val_loss: 0.1473 - val_mae: 0.1043\n",
            "Epoch 1911/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1800 - mae: 0.0978 - val_loss: 0.1485 - val_mae: 0.1060\n",
            "Epoch 1912/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1751 - mae: 0.1024 - val_loss: 0.1495 - val_mae: 0.1062\n",
            "Epoch 1913/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2428 - mae: 0.1085 - val_loss: 0.1508 - val_mae: 0.1076\n",
            "Epoch 1914/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2294 - mae: 0.1119 - val_loss: 0.1477 - val_mae: 0.1063\n",
            "Epoch 1915/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1865 - mae: 0.0979 - val_loss: 0.1525 - val_mae: 0.1077\n",
            "Epoch 1916/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2488 - mae: 0.1095 - val_loss: 0.1476 - val_mae: 0.1050\n",
            "Epoch 1917/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1932 - mae: 0.1013 - val_loss: 0.1515 - val_mae: 0.1063\n",
            "Epoch 1918/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2153 - mae: 0.1080 - val_loss: 0.1481 - val_mae: 0.1051\n",
            "Epoch 1919/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2774 - mae: 0.1170 - val_loss: 0.1508 - val_mae: 0.1078\n",
            "Epoch 1920/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1554 - mae: 0.0934 - val_loss: 0.1475 - val_mae: 0.1045\n",
            "Epoch 1921/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1730 - mae: 0.1040 - val_loss: 0.1480 - val_mae: 0.1060\n",
            "Epoch 1922/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1972 - mae: 0.1023 - val_loss: 0.1491 - val_mae: 0.1057\n",
            "Epoch 1923/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1461 - mae: 0.0921 - val_loss: 0.1508 - val_mae: 0.1061\n",
            "Epoch 1924/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1941 - mae: 0.1050 - val_loss: 0.1483 - val_mae: 0.1047\n",
            "Epoch 1925/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2211 - mae: 0.1051 - val_loss: 0.1495 - val_mae: 0.1054\n",
            "Epoch 1926/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1684 - mae: 0.0982 - val_loss: 0.1490 - val_mae: 0.1048\n",
            "Epoch 1927/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1149 - mae: 0.0874 - val_loss: 0.1465 - val_mae: 0.1045\n",
            "Epoch 1928/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1549 - mae: 0.0932 - val_loss: 0.1498 - val_mae: 0.1056\n",
            "Epoch 1929/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2129 - mae: 0.1087 - val_loss: 0.1504 - val_mae: 0.1058\n",
            "Epoch 1930/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2028 - mae: 0.1078 - val_loss: 0.1507 - val_mae: 0.1056\n",
            "Epoch 1931/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3199 - mae: 0.1191 - val_loss: 0.1514 - val_mae: 0.1068\n",
            "Epoch 1932/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1852 - mae: 0.1013 - val_loss: 0.1500 - val_mae: 0.1055\n",
            "Epoch 1933/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1578 - mae: 0.0968 - val_loss: 0.1493 - val_mae: 0.1052\n",
            "Epoch 1934/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1909 - mae: 0.1039 - val_loss: 0.1457 - val_mae: 0.1041\n",
            "Epoch 1935/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2043 - mae: 0.1060 - val_loss: 0.1495 - val_mae: 0.1057\n",
            "Epoch 1936/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2010 - mae: 0.1054 - val_loss: 0.1515 - val_mae: 0.1072\n",
            "Epoch 1937/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1682 - mae: 0.0957 - val_loss: 0.1498 - val_mae: 0.1078\n",
            "Epoch 1938/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1381 - mae: 0.0915 - val_loss: 0.1512 - val_mae: 0.1070\n",
            "Epoch 1939/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2212 - mae: 0.1101 - val_loss: 0.1539 - val_mae: 0.1075\n",
            "Epoch 1940/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1715 - mae: 0.0968 - val_loss: 0.1481 - val_mae: 0.1052\n",
            "Epoch 1941/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1896 - mae: 0.1032 - val_loss: 0.1483 - val_mae: 0.1049\n",
            "Epoch 1942/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2754 - mae: 0.1093 - val_loss: 0.1489 - val_mae: 0.1062\n",
            "Epoch 1943/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1658 - mae: 0.1007 - val_loss: 0.1526 - val_mae: 0.1307\n",
            "Epoch 1944/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1935 - mae: 0.1238 - val_loss: 0.1397 - val_mae: 0.1076\n",
            "Epoch 1945/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1653 - mae: 0.1058 - val_loss: 0.1450 - val_mae: 0.1096\n",
            "Epoch 1946/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1897 - mae: 0.1080 - val_loss: 0.1426 - val_mae: 0.1215\n",
            "Epoch 1947/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2081 - mae: 0.1270 - val_loss: 0.1448 - val_mae: 0.1152\n",
            "Epoch 1948/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1457 - mae: 0.1002 - val_loss: 0.1394 - val_mae: 0.1038\n",
            "Epoch 1949/2000\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.1606 - mae: 0.1089 - val_loss: 0.1483 - val_mae: 0.1083\n",
            "Epoch 1950/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1793 - mae: 0.1007 - val_loss: 0.1405 - val_mae: 0.1105\n",
            "Epoch 1951/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2087 - mae: 0.1151 - val_loss: 0.1568 - val_mae: 0.1181\n",
            "Epoch 1952/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1783 - mae: 0.1051 - val_loss: 0.1451 - val_mae: 0.1090\n",
            "Epoch 1953/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1927 - mae: 0.1087 - val_loss: 0.1518 - val_mae: 0.1108\n",
            "Epoch 1954/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1975 - mae: 0.1075 - val_loss: 0.1464 - val_mae: 0.1051\n",
            "Epoch 1955/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1391 - mae: 0.0854 - val_loss: 0.1477 - val_mae: 0.1048\n",
            "Epoch 1956/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1671 - mae: 0.0921 - val_loss: 0.1502 - val_mae: 0.1051\n",
            "Epoch 1957/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1847 - mae: 0.1063 - val_loss: 0.1467 - val_mae: 0.1037\n",
            "Epoch 1958/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2665 - mae: 0.1130 - val_loss: 0.1520 - val_mae: 0.1062\n",
            "Epoch 1959/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1696 - mae: 0.1007 - val_loss: 0.1456 - val_mae: 0.1028\n",
            "Epoch 1960/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2075 - mae: 0.1093 - val_loss: 0.1492 - val_mae: 0.1049\n",
            "Epoch 1961/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2768 - mae: 0.1209 - val_loss: 0.1505 - val_mae: 0.1059\n",
            "Epoch 1962/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1354 - mae: 0.0891 - val_loss: 0.1457 - val_mae: 0.1040\n",
            "Epoch 1963/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1408 - mae: 0.0949 - val_loss: 0.1475 - val_mae: 0.1042\n",
            "Epoch 1964/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1414 - mae: 0.0913 - val_loss: 0.1469 - val_mae: 0.1041\n",
            "Epoch 1965/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1260 - mae: 0.0910 - val_loss: 0.1497 - val_mae: 0.1052\n",
            "Epoch 1966/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1979 - mae: 0.0973 - val_loss: 0.1512 - val_mae: 0.1059\n",
            "Epoch 1967/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2138 - mae: 0.1093 - val_loss: 0.1479 - val_mae: 0.1052\n",
            "Epoch 1968/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1359 - mae: 0.0905 - val_loss: 0.1513 - val_mae: 0.1054\n",
            "Epoch 1969/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1507 - mae: 0.0973 - val_loss: 0.1499 - val_mae: 0.1046\n",
            "Epoch 1970/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1318 - mae: 0.0892 - val_loss: 0.1517 - val_mae: 0.1061\n",
            "Epoch 1971/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1702 - mae: 0.0936 - val_loss: 0.1495 - val_mae: 0.1047\n",
            "Epoch 1972/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2028 - mae: 0.1033 - val_loss: 0.1494 - val_mae: 0.1051\n",
            "Epoch 1973/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2000 - mae: 0.0963 - val_loss: 0.1479 - val_mae: 0.1042\n",
            "Epoch 1974/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1366 - mae: 0.0919 - val_loss: 0.1472 - val_mae: 0.1037\n",
            "Epoch 1975/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1507 - mae: 0.0949 - val_loss: 0.1453 - val_mae: 0.1030\n",
            "Epoch 1976/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2527 - mae: 0.1064 - val_loss: 0.1554 - val_mae: 0.1085\n",
            "Epoch 1977/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1437 - mae: 0.0955 - val_loss: 0.1468 - val_mae: 0.1041\n",
            "Epoch 1978/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1921 - mae: 0.0976 - val_loss: 0.1524 - val_mae: 0.1063\n",
            "Epoch 1979/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1402 - mae: 0.0843 - val_loss: 0.1493 - val_mae: 0.1045\n",
            "Epoch 1980/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1812 - mae: 0.0966 - val_loss: 0.1482 - val_mae: 0.1048\n",
            "Epoch 1981/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1565 - mae: 0.0901 - val_loss: 0.1513 - val_mae: 0.1055\n",
            "Epoch 1982/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1585 - mae: 0.0964 - val_loss: 0.1499 - val_mae: 0.1046\n",
            "Epoch 1983/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2233 - mae: 0.1085 - val_loss: 0.1508 - val_mae: 0.1054\n",
            "Epoch 1984/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1875 - mae: 0.0981 - val_loss: 0.1497 - val_mae: 0.1046\n",
            "Epoch 1985/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2170 - mae: 0.1095 - val_loss: 0.1491 - val_mae: 0.1051\n",
            "Epoch 1986/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1599 - mae: 0.0946 - val_loss: 0.1498 - val_mae: 0.1049\n",
            "Epoch 1987/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1780 - mae: 0.1032 - val_loss: 0.1475 - val_mae: 0.1039\n",
            "Epoch 1988/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.2003 - mae: 0.1041 - val_loss: 0.1524 - val_mae: 0.1060\n",
            "Epoch 1989/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1573 - mae: 0.0963 - val_loss: 0.1504 - val_mae: 0.1052\n",
            "Epoch 1990/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1999 - mae: 0.1017 - val_loss: 0.1516 - val_mae: 0.1064\n",
            "Epoch 1991/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2083 - mae: 0.1067 - val_loss: 0.1484 - val_mae: 0.1046\n",
            "Epoch 1992/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1574 - mae: 0.0945 - val_loss: 0.1490 - val_mae: 0.1051\n",
            "Epoch 1993/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1964 - mae: 0.1047 - val_loss: 0.1510 - val_mae: 0.1054\n",
            "Epoch 1994/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.1700 - mae: 0.1008 - val_loss: 0.1510 - val_mae: 0.1057\n",
            "Epoch 1995/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1356 - mae: 0.0916 - val_loss: 0.1502 - val_mae: 0.1050\n",
            "Epoch 1996/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.2219 - mae: 0.1102 - val_loss: 0.1485 - val_mae: 0.1048\n",
            "Epoch 1997/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1908 - mae: 0.0999 - val_loss: 0.1510 - val_mae: 0.1058\n",
            "Epoch 1998/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1411 - mae: 0.0909 - val_loss: 0.1501 - val_mae: 0.1059\n",
            "Epoch 1999/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1988 - mae: 0.1003 - val_loss: 0.1495 - val_mae: 0.1050\n",
            "Epoch 2000/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.1460 - mae: 0.0949 - val_loss: 0.1490 - val_mae: 0.1051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyqDqCork6GR",
        "outputId": "adcc76b9-88b1-4035-f83f-d4b6f72345a5"
      },
      "source": [
        "# モデルの評価\n",
        "score = model_3.evaluate([x_fs_test_n, x_fp_test_n], y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test mae:', score[1])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255/255 [==============================] - 0s 1ms/step - loss: 0.2403 - mae: 0.1059\n",
            "Test loss: 0.24034056067466736\n",
            "Test mae: 0.10589764267206192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "zVrKnrPXk6GS",
        "outputId": "ae6bbe3d-e483-4b2a-be63-2e2b2f663fb2"
      },
      "source": [
        "# 学習経過の可視化\n",
        "loss     = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "nb_epoch = len(loss)\n",
        "for i in range(900):\n",
        "  if max(loss)>2: \n",
        "    loss = loss[1:]\n",
        "    val_loss = val_loss[1:]\n",
        "  else:\n",
        "    plt.plot(range(i,nb_epoch), loss, marker='.', label='loss')\n",
        "    plt.plot(range(i,nb_epoch), val_loss, marker='.', label='val_loss')\n",
        "    break\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "MLmN0rurk6GS",
        "outputId": "e478b36e-bab2-45aa-c70f-0ab1528d4d47"
      },
      "source": [
        "# 学習経過の可視化\n",
        "mae     = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "nb_epoch = len(mae)\n",
        "for i in range(900):\n",
        "  if max(mae)>2: \n",
        "    mae = mae[1:]\n",
        "    val_mae = val_mae[1:]\n",
        "  else:\n",
        "    plt.plot(range(i,nb_epoch), mae,     marker='.', label='mae')\n",
        "    plt.plot(range(i,nb_epoch), val_mae, marker='.', label='val_mae')\n",
        "    break\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('mae')\n",
        "plt.show()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJmafoj8k6GS"
      },
      "source": [
        "# 学習モデルの保存\n",
        "model_3.save(str(n)+\"_random.seed(\"+str(seed)+\")_train\"+str(train)+\".h5\")"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2tPlZTflFCf"
      },
      "source": [
        "# model_4\n",
        "\n",
        "# データの前処理\n",
        "\n",
        "\n",
        "## 変数設定(各条件を変えてたくさん試すため)\n",
        "train = 0.5                 #train:validのtrainデータの割合\n",
        "seed = 1                       \n",
        "random.seed(seed)           #乱数seed固定\n",
        "\n",
        "\n",
        "## データ加工\n",
        "\n",
        "### データ抽出(各データをランダムにシャッフル→train,valid,testに分割。各大きさのデータが同じ数だけ抽出される。)\n",
        "for i in range (1,6):\n",
        "  exec(\"lst_fs\"+str(i)+\"_shuffle = random.sample(lst_fs\"+str(i)+\", len(lst_fs\"+str(i)+\"))\")  \n",
        "  exec(\"lst_fs\"+str(i)+\"_train = lst_fs\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")       \n",
        "  exec(\"lst_fs\"+str(i)+\"_valid = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\")          \n",
        "  exec(\"lst_fs\"+str(i)+\"_test = lst_fs\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_shuffle = random.sample(lst_fp\"+str(i)+\", len(lst_fp\"+str(i)+\"))\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_train = lst_fp\"+str(i)+\"_shuffle[0:\"+str(int(n/5*train))+\"]\")\n",
        "  exec(\"lst_fp\"+str(i)+\"_valid = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5*train))+\":\"+str(int(n/5))+\"]\") \n",
        "  exec(\"lst_fp\"+str(i)+\"_test = lst_fp\"+str(i)+\"_shuffle[\"+str(int(n/5))+\":-1]\")\n",
        "\n",
        "### train,valid,testの各々について、大きさ、位置、表面温度分布データに分割\n",
        "for i in range (1,6):\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_train = [r[0] for r in lst_fs\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_train = [r[0] for r in lst_fp\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_train = [r[1:-1] for r in lst_fp\"+str(i)+\"_train]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_valid = [r[0] for r in lst_fs\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_valid = [r[0] for r in lst_fp\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_valid = [r[1:-1] for r in lst_fp\"+str(i)+\"_valid]\")\n",
        "  exec(\"lst_x_fs\"+str(i)+\"_test = [r[0] for r in lst_fs\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_x_fp\"+str(i)+\"_test = [r[0] for r in lst_fp\"+str(i)+\"_test]\")\n",
        "  exec(\"lst_y\"+str(i)+\"_test = [r[1:-1] for r in lst_fp\"+str(i)+\"_test]\")\n",
        "\n",
        "### データを結合(入力データ・正解データの大枠完成)\n",
        "lst_x_fs_train = lst_x_fs1_train + lst_x_fs2_train + lst_x_fs3_train + lst_x_fs4_train + lst_x_fs5_train\n",
        "lst_x_fp_train = lst_x_fp1_train + lst_x_fp2_train + lst_x_fp3_train + lst_x_fp4_train + lst_x_fp5_train\n",
        "lst_y_train = lst_y1_train + lst_y2_train + lst_y3_train + lst_y4_train + lst_y5_train\n",
        "\n",
        "lst_x_fs_valid = lst_x_fs1_valid + lst_x_fs2_valid + lst_x_fs3_valid + lst_x_fs4_valid + lst_x_fs5_valid\n",
        "lst_x_fp_valid = lst_x_fp1_valid + lst_x_fp2_valid + lst_x_fp3_valid + lst_x_fp4_valid + lst_x_fp5_valid\n",
        "lst_y_valid = lst_y1_valid + lst_y2_valid + lst_y3_valid + lst_y4_valid + lst_y5_valid\n",
        "\n",
        "lst_x_fs_test = lst_x_fs1_test + lst_x_fs2_test + lst_x_fs3_test + lst_x_fs4_test + lst_x_fs5_test\n",
        "lst_x_fp_test = lst_x_fp1_test + lst_x_fp2_test + lst_x_fp3_test + lst_x_fp4_test + lst_x_fp5_test\n",
        "lst_y_test = lst_y1_test + lst_y2_test + lst_y3_test + lst_y4_test + lst_y5_test\n",
        "\n",
        "### np.arrayで変換\n",
        "lst_f0 = np.array(lst_f0, dtype=float)\n",
        "lst_x_fs_train = np.array(lst_x_fs_train, dtype=int)\n",
        "lst_x_fp_train = np.array(lst_x_fp_train, dtype=int)\n",
        "lst_x_fs_valid = np.array(lst_x_fs_valid, dtype=int)\n",
        "lst_x_fp_valid = np.array(lst_x_fp_valid, dtype=int)\n",
        "lst_x_fs_test = np.array(lst_x_fs_test, dtype=int)\n",
        "lst_x_fp_test = np.array(lst_x_fp_test, dtype=int)\n",
        "lst_y_train = np.array(lst_y_train, dtype=float)\n",
        "lst_y_valid = np.array(lst_y_valid, dtype=float)\n",
        "lst_y_test = np.array(lst_y_test, dtype=float)\n",
        "\n",
        "### 入力データを二次元化\n",
        "x_fs_train = lst_x_fs_train.reshape(-1, 1)\n",
        "x_fs_valid = lst_x_fs_valid.reshape(-1, 1)\n",
        "x_fs_test = lst_x_fs_test.reshape(-1, 1)\n",
        "x_fp_train = lst_x_fp_train.reshape(-1, 1)\n",
        "x_fp_valid = lst_x_fp_valid.reshape(-1, 1)\n",
        "x_fp_test = lst_x_fp_test.reshape(-1, 1)\n",
        "\n",
        "### 温度分布データを、穴なし温度分布データとの差に変換\n",
        "y_train = lst_y_train - lst_f0\n",
        "y_valid = lst_y_valid - lst_f0\n",
        "y_test = lst_y_test - lst_f0\n",
        "\n",
        "### 入力データの正規化\n",
        "scaler_x = MinMaxScaler()\n",
        "x_fs_train_n = scaler_x.fit_transform(x_fs_train)\n",
        "x_fs_valid_n = scaler_x.fit_transform(x_fs_valid)\n",
        "x_fs_test_n = scaler_x.fit_transform(x_fs_test) \n",
        "x_fp_train_n = scaler_x.fit_transform(x_fp_train)\n",
        "x_fp_valid_n = scaler_x.fit_transform(x_fp_valid)\n",
        "x_fp_test_n = scaler_x.fit_transform(x_fp_test) "
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66_oRLv-lFCg"
      },
      "source": [
        "# NN\n",
        "\n",
        "## 入力を定義\n",
        "input1 = Input(shape=(1,))\n",
        "input2 = Input(shape=(1,))\n",
        "\n",
        "## 入力1から結合前まで\n",
        "x = Dense(1, activation=\"linear\")(input1)\n",
        "x = Model(inputs=input1, outputs=x)\n",
        "\n",
        "## 入力2から結合前まで\n",
        "y = Dense(1, activation=\"linear\")(input2)\n",
        "y = Model(inputs=input2, outputs=y)\n",
        "\n",
        "## 結合\n",
        "combined = concatenate([x.output, y.output])\n",
        "\n",
        "## 密結合\n",
        "z = Dense(32, activation=\"relu\")(combined)\n",
        "z = Dense(512, activation=\"relu\")(z)\n",
        "z = Dense(256, activation=\"relu\")(z)\n",
        "z = Dense(128, activation=\"relu\")(z)\n",
        "z = Dense(50)(z)\n",
        "\n",
        "## モデル定義とコンパイル\n",
        "model_4 = Model(inputs=[x.input, y.input], outputs=z)\n",
        "model_4.compile(loss='mse', optimizer='adam', metrics=['mae'])"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25D_RsjVlFCh",
        "outputId": "1455f950-15ed-4767-aef0-acf79061aa5b"
      },
      "source": [
        "# 学習\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "history = model_4.fit([x_fs_train_n, x_fp_train_n], y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=([x_fs_valid_n, x_fp_valid_n], y_valid))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "16/16 [==============================] - 1s 20ms/step - loss: 0.5647 - mae: 0.2818 - val_loss: 0.2470 - val_mae: 0.1906\n",
            "Epoch 2/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2804 - mae: 0.1816 - val_loss: 0.2242 - val_mae: 0.1793\n",
            "Epoch 3/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2454 - mae: 0.1747 - val_loss: 0.2111 - val_mae: 0.1736\n",
            "Epoch 4/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3311 - mae: 0.1911 - val_loss: 0.2048 - val_mae: 0.1744\n",
            "Epoch 5/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3158 - mae: 0.1888 - val_loss: 0.1964 - val_mae: 0.1623\n",
            "Epoch 6/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1892 - mae: 0.1659 - val_loss: 0.2007 - val_mae: 0.1679\n",
            "Epoch 7/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3841 - mae: 0.1922 - val_loss: 0.1932 - val_mae: 0.1633\n",
            "Epoch 8/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2374 - mae: 0.1715 - val_loss: 0.1926 - val_mae: 0.1670\n",
            "Epoch 9/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2419 - mae: 0.1749 - val_loss: 0.2001 - val_mae: 0.1695\n",
            "Epoch 10/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3281 - mae: 0.2033 - val_loss: 0.1869 - val_mae: 0.1565\n",
            "Epoch 11/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1676 - mae: 0.1535 - val_loss: 0.1865 - val_mae: 0.1642\n",
            "Epoch 12/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5282 - mae: 0.2346 - val_loss: 0.2175 - val_mae: 0.1613\n",
            "Epoch 13/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2256 - mae: 0.1615 - val_loss: 0.1918 - val_mae: 0.1740\n",
            "Epoch 14/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2895 - mae: 0.1884 - val_loss: 0.1829 - val_mae: 0.1509\n",
            "Epoch 15/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2135 - mae: 0.1693 - val_loss: 0.1860 - val_mae: 0.1676\n",
            "Epoch 16/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4005 - mae: 0.2172 - val_loss: 0.1792 - val_mae: 0.1564\n",
            "Epoch 17/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3626 - mae: 0.1909 - val_loss: 0.1767 - val_mae: 0.1559\n",
            "Epoch 18/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4407 - mae: 0.1980 - val_loss: 0.1736 - val_mae: 0.1513\n",
            "Epoch 19/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2168 - mae: 0.1539 - val_loss: 0.1844 - val_mae: 0.1720\n",
            "Epoch 20/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2472 - mae: 0.1846 - val_loss: 0.1881 - val_mae: 0.1609\n",
            "Epoch 21/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4188 - mae: 0.1867 - val_loss: 0.1719 - val_mae: 0.1546\n",
            "Epoch 22/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3176 - mae: 0.1758 - val_loss: 0.1670 - val_mae: 0.1511\n",
            "Epoch 23/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2797 - mae: 0.1763 - val_loss: 0.1654 - val_mae: 0.1501\n",
            "Epoch 24/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2857 - mae: 0.1867 - val_loss: 0.1712 - val_mae: 0.1510\n",
            "Epoch 25/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2386 - mae: 0.1630 - val_loss: 0.1701 - val_mae: 0.1565\n",
            "Epoch 26/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3090 - mae: 0.1914 - val_loss: 0.1717 - val_mae: 0.1588\n",
            "Epoch 27/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3267 - mae: 0.1806 - val_loss: 0.1678 - val_mae: 0.1564\n",
            "Epoch 28/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2304 - mae: 0.1695 - val_loss: 0.1688 - val_mae: 0.1565\n",
            "Epoch 29/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1974 - mae: 0.1626 - val_loss: 0.1638 - val_mae: 0.1522\n",
            "Epoch 30/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2686 - mae: 0.1747 - val_loss: 0.1640 - val_mae: 0.1523\n",
            "Epoch 31/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2988 - mae: 0.1769 - val_loss: 0.1812 - val_mae: 0.1594\n",
            "Epoch 32/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2379 - mae: 0.1724 - val_loss: 0.1635 - val_mae: 0.1557\n",
            "Epoch 33/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2289 - mae: 0.1836 - val_loss: 0.1645 - val_mae: 0.1524\n",
            "Epoch 34/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2631 - mae: 0.1682 - val_loss: 0.1617 - val_mae: 0.1502\n",
            "Epoch 35/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2806 - mae: 0.1740 - val_loss: 0.1592 - val_mae: 0.1458\n",
            "Epoch 36/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1978 - mae: 0.1509 - val_loss: 0.1652 - val_mae: 0.1529\n",
            "Epoch 37/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3491 - mae: 0.1928 - val_loss: 0.1624 - val_mae: 0.1522\n",
            "Epoch 38/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2465 - mae: 0.1633 - val_loss: 0.1925 - val_mae: 0.1752\n",
            "Epoch 39/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2161 - mae: 0.1656 - val_loss: 0.1636 - val_mae: 0.1529\n",
            "Epoch 40/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2323 - mae: 0.1621 - val_loss: 0.1603 - val_mae: 0.1514\n",
            "Epoch 41/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2540 - mae: 0.1609 - val_loss: 0.1594 - val_mae: 0.1480\n",
            "Epoch 42/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2221 - mae: 0.1545 - val_loss: 0.1584 - val_mae: 0.1481\n",
            "Epoch 43/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1692 - mae: 0.1434 - val_loss: 0.1655 - val_mae: 0.1559\n",
            "Epoch 44/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2960 - mae: 0.1676 - val_loss: 0.1559 - val_mae: 0.1429\n",
            "Epoch 45/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1981 - mae: 0.1485 - val_loss: 0.1729 - val_mae: 0.1595\n",
            "Epoch 46/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2498 - mae: 0.1744 - val_loss: 0.1671 - val_mae: 0.1633\n",
            "Epoch 47/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3876 - mae: 0.2004 - val_loss: 0.1567 - val_mae: 0.1463\n",
            "Epoch 48/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2440 - mae: 0.1535 - val_loss: 0.1586 - val_mae: 0.1496\n",
            "Epoch 49/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1809 - mae: 0.1517 - val_loss: 0.1699 - val_mae: 0.1612\n",
            "Epoch 50/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2686 - mae: 0.1783 - val_loss: 0.1604 - val_mae: 0.1462\n",
            "Epoch 51/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1960 - mae: 0.1588 - val_loss: 0.1584 - val_mae: 0.1504\n",
            "Epoch 52/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2373 - mae: 0.1727 - val_loss: 0.1565 - val_mae: 0.1456\n",
            "Epoch 53/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1545 - mae: 0.1409 - val_loss: 0.1620 - val_mae: 0.1499\n",
            "Epoch 54/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.2068 - mae: 0.1488 - val_loss: 0.1595 - val_mae: 0.1490\n",
            "Epoch 55/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2139 - mae: 0.1577 - val_loss: 0.1599 - val_mae: 0.1496\n",
            "Epoch 56/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2008 - mae: 0.1449 - val_loss: 0.1588 - val_mae: 0.1491\n",
            "Epoch 57/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2658 - mae: 0.1696 - val_loss: 0.1563 - val_mae: 0.1453\n",
            "Epoch 58/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1559 - mae: 0.1461 - val_loss: 0.1548 - val_mae: 0.1452\n",
            "Epoch 59/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2705 - mae: 0.1672 - val_loss: 0.1743 - val_mae: 0.1563\n",
            "Epoch 60/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2065 - mae: 0.1525 - val_loss: 0.1587 - val_mae: 0.1492\n",
            "Epoch 61/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2124 - mae: 0.1600 - val_loss: 0.1568 - val_mae: 0.1459\n",
            "Epoch 62/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1843 - mae: 0.1422 - val_loss: 0.1546 - val_mae: 0.1455\n",
            "Epoch 63/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1903 - mae: 0.1549 - val_loss: 0.1590 - val_mae: 0.1467\n",
            "Epoch 64/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2655 - mae: 0.1675 - val_loss: 0.1575 - val_mae: 0.1450\n",
            "Epoch 65/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2183 - mae: 0.1536 - val_loss: 0.1575 - val_mae: 0.1460\n",
            "Epoch 66/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3162 - mae: 0.1708 - val_loss: 0.1534 - val_mae: 0.1403\n",
            "Epoch 67/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2420 - mae: 0.1518 - val_loss: 0.1560 - val_mae: 0.1437\n",
            "Epoch 68/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2127 - mae: 0.1502 - val_loss: 0.1535 - val_mae: 0.1417\n",
            "Epoch 69/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3320 - mae: 0.1771 - val_loss: 0.1613 - val_mae: 0.1459\n",
            "Epoch 70/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1590 - mae: 0.1381 - val_loss: 0.1514 - val_mae: 0.1439\n",
            "Epoch 71/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1906 - mae: 0.1587 - val_loss: 0.1583 - val_mae: 0.1496\n",
            "Epoch 72/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1739 - mae: 0.1525 - val_loss: 0.1594 - val_mae: 0.1472\n",
            "Epoch 73/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2439 - mae: 0.1661 - val_loss: 0.1547 - val_mae: 0.1429\n",
            "Epoch 74/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2286 - mae: 0.1571 - val_loss: 0.1573 - val_mae: 0.1440\n",
            "Epoch 75/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2236 - mae: 0.1476 - val_loss: 0.1539 - val_mae: 0.1418\n",
            "Epoch 76/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1962 - mae: 0.1542 - val_loss: 0.1523 - val_mae: 0.1390\n",
            "Epoch 77/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1833 - mae: 0.1442 - val_loss: 0.1546 - val_mae: 0.1409\n",
            "Epoch 78/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3163 - mae: 0.1636 - val_loss: 0.1543 - val_mae: 0.1388\n",
            "Epoch 79/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2949 - mae: 0.1592 - val_loss: 0.1530 - val_mae: 0.1387\n",
            "Epoch 80/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2177 - mae: 0.1487 - val_loss: 0.1529 - val_mae: 0.1400\n",
            "Epoch 81/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2656 - mae: 0.1553 - val_loss: 0.1539 - val_mae: 0.1391\n",
            "Epoch 82/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2917 - mae: 0.1627 - val_loss: 0.1527 - val_mae: 0.1403\n",
            "Epoch 83/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2678 - mae: 0.1559 - val_loss: 0.1525 - val_mae: 0.1383\n",
            "Epoch 84/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2269 - mae: 0.1473 - val_loss: 0.1588 - val_mae: 0.1459\n",
            "Epoch 85/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1993 - mae: 0.1462 - val_loss: 0.1512 - val_mae: 0.1376\n",
            "Epoch 86/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2507 - mae: 0.1535 - val_loss: 0.1538 - val_mae: 0.1389\n",
            "Epoch 87/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2438 - mae: 0.1645 - val_loss: 0.1556 - val_mae: 0.1411\n",
            "Epoch 88/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3021 - mae: 0.1677 - val_loss: 0.1534 - val_mae: 0.1392\n",
            "Epoch 89/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2487 - mae: 0.1620 - val_loss: 0.1564 - val_mae: 0.1394\n",
            "Epoch 90/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2833 - mae: 0.1520 - val_loss: 0.1550 - val_mae: 0.1384\n",
            "Epoch 91/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2190 - mae: 0.1510 - val_loss: 0.1561 - val_mae: 0.1414\n",
            "Epoch 92/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1999 - mae: 0.1486 - val_loss: 0.1566 - val_mae: 0.1411\n",
            "Epoch 93/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2565 - mae: 0.1651 - val_loss: 0.1547 - val_mae: 0.1388\n",
            "Epoch 94/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2216 - mae: 0.1533 - val_loss: 0.1519 - val_mae: 0.1388\n",
            "Epoch 95/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1831 - mae: 0.1489 - val_loss: 0.1546 - val_mae: 0.1410\n",
            "Epoch 96/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2742 - mae: 0.1624 - val_loss: 0.1547 - val_mae: 0.1378\n",
            "Epoch 97/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3024 - mae: 0.1629 - val_loss: 0.1517 - val_mae: 0.1356\n",
            "Epoch 98/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3123 - mae: 0.1596 - val_loss: 0.1524 - val_mae: 0.1348\n",
            "Epoch 99/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2166 - mae: 0.1422 - val_loss: 0.1539 - val_mae: 0.1423\n",
            "Epoch 100/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3081 - mae: 0.1564 - val_loss: 0.1555 - val_mae: 0.1397\n",
            "Epoch 101/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3138 - mae: 0.1670 - val_loss: 0.1649 - val_mae: 0.1542\n",
            "Epoch 102/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3343 - mae: 0.1689 - val_loss: 0.1588 - val_mae: 0.1405\n",
            "Epoch 103/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1819 - mae: 0.1448 - val_loss: 0.1514 - val_mae: 0.1383\n",
            "Epoch 104/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2094 - mae: 0.1492 - val_loss: 0.1523 - val_mae: 0.1386\n",
            "Epoch 105/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2660 - mae: 0.1561 - val_loss: 0.1528 - val_mae: 0.1358\n",
            "Epoch 106/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3659 - mae: 0.1642 - val_loss: 0.1520 - val_mae: 0.1347\n",
            "Epoch 107/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2091 - mae: 0.1447 - val_loss: 0.1501 - val_mae: 0.1370\n",
            "Epoch 108/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1817 - mae: 0.1423 - val_loss: 0.1523 - val_mae: 0.1356\n",
            "Epoch 109/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2547 - mae: 0.1442 - val_loss: 0.1545 - val_mae: 0.1354\n",
            "Epoch 110/2000\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.1456 - mae: 0.1288 - val_loss: 0.1503 - val_mae: 0.1359\n",
            "Epoch 111/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1854 - mae: 0.1486 - val_loss: 0.1558 - val_mae: 0.1386\n",
            "Epoch 112/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2902 - mae: 0.1576 - val_loss: 0.1571 - val_mae: 0.1347\n",
            "Epoch 113/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2082 - mae: 0.1345 - val_loss: 0.1507 - val_mae: 0.1344\n",
            "Epoch 114/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1815 - mae: 0.1418 - val_loss: 0.1518 - val_mae: 0.1348\n",
            "Epoch 115/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2091 - mae: 0.1520 - val_loss: 0.1541 - val_mae: 0.1368\n",
            "Epoch 116/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1625 - mae: 0.1300 - val_loss: 0.1504 - val_mae: 0.1356\n",
            "Epoch 117/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2632 - mae: 0.1632 - val_loss: 0.1544 - val_mae: 0.1376\n",
            "Epoch 118/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2040 - mae: 0.1340 - val_loss: 0.1520 - val_mae: 0.1341\n",
            "Epoch 119/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2748 - mae: 0.1504 - val_loss: 0.1576 - val_mae: 0.1481\n",
            "Epoch 120/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2642 - mae: 0.1594 - val_loss: 0.1539 - val_mae: 0.1343\n",
            "Epoch 121/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2249 - mae: 0.1581 - val_loss: 0.1571 - val_mae: 0.1440\n",
            "Epoch 122/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1512 - mae: 0.1407 - val_loss: 0.1537 - val_mae: 0.1390\n",
            "Epoch 123/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2472 - mae: 0.1490 - val_loss: 0.1549 - val_mae: 0.1351\n",
            "Epoch 124/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2040 - mae: 0.1399 - val_loss: 0.1485 - val_mae: 0.1303\n",
            "Epoch 125/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1983 - mae: 0.1450 - val_loss: 0.1539 - val_mae: 0.1353\n",
            "Epoch 126/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1864 - mae: 0.1407 - val_loss: 0.1502 - val_mae: 0.1332\n",
            "Epoch 127/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1759 - mae: 0.1323 - val_loss: 0.1547 - val_mae: 0.1365\n",
            "Epoch 128/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2234 - mae: 0.1476 - val_loss: 0.1509 - val_mae: 0.1324\n",
            "Epoch 129/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2445 - mae: 0.1448 - val_loss: 0.1484 - val_mae: 0.1302\n",
            "Epoch 130/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2120 - mae: 0.1392 - val_loss: 0.1529 - val_mae: 0.1327\n",
            "Epoch 131/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2557 - mae: 0.1468 - val_loss: 0.1506 - val_mae: 0.1305\n",
            "Epoch 132/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1679 - mae: 0.1323 - val_loss: 0.1497 - val_mae: 0.1314\n",
            "Epoch 133/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2573 - mae: 0.1427 - val_loss: 0.1516 - val_mae: 0.1301\n",
            "Epoch 134/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1533 - mae: 0.1315 - val_loss: 0.1472 - val_mae: 0.1290\n",
            "Epoch 135/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1846 - mae: 0.1440 - val_loss: 0.1551 - val_mae: 0.1378\n",
            "Epoch 136/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1411 - mae: 0.1265 - val_loss: 0.1548 - val_mae: 0.1354\n",
            "Epoch 137/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1874 - mae: 0.1388 - val_loss: 0.1519 - val_mae: 0.1332\n",
            "Epoch 138/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2727 - mae: 0.1501 - val_loss: 0.1530 - val_mae: 0.1366\n",
            "Epoch 139/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2454 - mae: 0.1492 - val_loss: 0.1519 - val_mae: 0.1308\n",
            "Epoch 140/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2997 - mae: 0.1545 - val_loss: 0.1470 - val_mae: 0.1285\n",
            "Epoch 141/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1986 - mae: 0.1381 - val_loss: 0.1504 - val_mae: 0.1293\n",
            "Epoch 142/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1628 - mae: 0.1320 - val_loss: 0.1526 - val_mae: 0.1314\n",
            "Epoch 143/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2106 - mae: 0.1438 - val_loss: 0.1477 - val_mae: 0.1276\n",
            "Epoch 144/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1979 - mae: 0.1352 - val_loss: 0.1482 - val_mae: 0.1300\n",
            "Epoch 145/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2391 - mae: 0.1470 - val_loss: 0.1554 - val_mae: 0.1335\n",
            "Epoch 146/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2227 - mae: 0.1404 - val_loss: 0.1492 - val_mae: 0.1364\n",
            "Epoch 147/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2316 - mae: 0.1470 - val_loss: 0.1582 - val_mae: 0.1354\n",
            "Epoch 148/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1710 - mae: 0.1342 - val_loss: 0.1575 - val_mae: 0.1445\n",
            "Epoch 149/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2675 - mae: 0.1628 - val_loss: 0.1564 - val_mae: 0.1350\n",
            "Epoch 150/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2151 - mae: 0.1406 - val_loss: 0.1465 - val_mae: 0.1282\n",
            "Epoch 151/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3397 - mae: 0.1589 - val_loss: 0.1555 - val_mae: 0.1353\n",
            "Epoch 152/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2853 - mae: 0.1463 - val_loss: 0.1504 - val_mae: 0.1338\n",
            "Epoch 153/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1706 - mae: 0.1386 - val_loss: 0.1488 - val_mae: 0.1311\n",
            "Epoch 154/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2596 - mae: 0.1425 - val_loss: 0.1490 - val_mae: 0.1286\n",
            "Epoch 155/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1977 - mae: 0.1400 - val_loss: 0.1488 - val_mae: 0.1299\n",
            "Epoch 156/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2878 - mae: 0.1560 - val_loss: 0.1486 - val_mae: 0.1283\n",
            "Epoch 157/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3441 - mae: 0.1691 - val_loss: 0.1586 - val_mae: 0.1365\n",
            "Epoch 158/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2048 - mae: 0.1397 - val_loss: 0.1628 - val_mae: 0.1458\n",
            "Epoch 159/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2929 - mae: 0.1592 - val_loss: 0.1518 - val_mae: 0.1344\n",
            "Epoch 160/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2896 - mae: 0.1596 - val_loss: 0.1519 - val_mae: 0.1303\n",
            "Epoch 161/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3111 - mae: 0.1592 - val_loss: 0.1463 - val_mae: 0.1259\n",
            "Epoch 162/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3391 - mae: 0.1472 - val_loss: 0.1519 - val_mae: 0.1297\n",
            "Epoch 163/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2410 - mae: 0.1393 - val_loss: 0.1497 - val_mae: 0.1305\n",
            "Epoch 164/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1435 - mae: 0.1227 - val_loss: 0.1482 - val_mae: 0.1362\n",
            "Epoch 165/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3985 - mae: 0.1726 - val_loss: 0.1680 - val_mae: 0.1434\n",
            "Epoch 166/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.2275 - mae: 0.1579 - val_loss: 0.1513 - val_mae: 0.1379\n",
            "Epoch 167/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2235 - mae: 0.1470 - val_loss: 0.1508 - val_mae: 0.1328\n",
            "Epoch 168/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1832 - mae: 0.1335 - val_loss: 0.1558 - val_mae: 0.1360\n",
            "Epoch 169/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1752 - mae: 0.1310 - val_loss: 0.1506 - val_mae: 0.1297\n",
            "Epoch 170/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2155 - mae: 0.1348 - val_loss: 0.1498 - val_mae: 0.1297\n",
            "Epoch 171/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3154 - mae: 0.1432 - val_loss: 0.1496 - val_mae: 0.1268\n",
            "Epoch 172/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2831 - mae: 0.1506 - val_loss: 0.1508 - val_mae: 0.1295\n",
            "Epoch 173/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1897 - mae: 0.1364 - val_loss: 0.1461 - val_mae: 0.1258\n",
            "Epoch 174/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2303 - mae: 0.1381 - val_loss: 0.1518 - val_mae: 0.1296\n",
            "Epoch 175/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1672 - mae: 0.1332 - val_loss: 0.1463 - val_mae: 0.1274\n",
            "Epoch 176/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2264 - mae: 0.1509 - val_loss: 0.1498 - val_mae: 0.1294\n",
            "Epoch 177/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2713 - mae: 0.1457 - val_loss: 0.1511 - val_mae: 0.1269\n",
            "Epoch 178/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1674 - mae: 0.1318 - val_loss: 0.1470 - val_mae: 0.1260\n",
            "Epoch 179/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1939 - mae: 0.1311 - val_loss: 0.1494 - val_mae: 0.1265\n",
            "Epoch 180/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1937 - mae: 0.1319 - val_loss: 0.1480 - val_mae: 0.1257\n",
            "Epoch 181/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2635 - mae: 0.1426 - val_loss: 0.1494 - val_mae: 0.1256\n",
            "Epoch 182/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1938 - mae: 0.1294 - val_loss: 0.1492 - val_mae: 0.1262\n",
            "Epoch 183/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1763 - mae: 0.1276 - val_loss: 0.1465 - val_mae: 0.1239\n",
            "Epoch 184/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2003 - mae: 0.1299 - val_loss: 0.1504 - val_mae: 0.1266\n",
            "Epoch 185/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1682 - mae: 0.1340 - val_loss: 0.1472 - val_mae: 0.1261\n",
            "Epoch 186/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1836 - mae: 0.1275 - val_loss: 0.1522 - val_mae: 0.1305\n",
            "Epoch 187/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1803 - mae: 0.1287 - val_loss: 0.1532 - val_mae: 0.1296\n",
            "Epoch 188/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3332 - mae: 0.1526 - val_loss: 0.1522 - val_mae: 0.1308\n",
            "Epoch 189/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2123 - mae: 0.1334 - val_loss: 0.1469 - val_mae: 0.1291\n",
            "Epoch 190/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1522 - mae: 0.1281 - val_loss: 0.1452 - val_mae: 0.1224\n",
            "Epoch 191/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3041 - mae: 0.1457 - val_loss: 0.1520 - val_mae: 0.1274\n",
            "Epoch 192/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3041 - mae: 0.1476 - val_loss: 0.1466 - val_mae: 0.1234\n",
            "Epoch 193/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2407 - mae: 0.1356 - val_loss: 0.1458 - val_mae: 0.1275\n",
            "Epoch 194/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1504 - mae: 0.1228 - val_loss: 0.1478 - val_mae: 0.1241\n",
            "Epoch 195/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1851 - mae: 0.1287 - val_loss: 0.1513 - val_mae: 0.1258\n",
            "Epoch 196/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1671 - mae: 0.1223 - val_loss: 0.1468 - val_mae: 0.1237\n",
            "Epoch 197/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1890 - mae: 0.1281 - val_loss: 0.1506 - val_mae: 0.1267\n",
            "Epoch 198/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1878 - mae: 0.1346 - val_loss: 0.1475 - val_mae: 0.1231\n",
            "Epoch 199/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2056 - mae: 0.1323 - val_loss: 0.1495 - val_mae: 0.1243\n",
            "Epoch 200/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2320 - mae: 0.1366 - val_loss: 0.1458 - val_mae: 0.1224\n",
            "Epoch 201/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2499 - mae: 0.1340 - val_loss: 0.1490 - val_mae: 0.1231\n",
            "Epoch 202/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2014 - mae: 0.1293 - val_loss: 0.1512 - val_mae: 0.1270\n",
            "Epoch 203/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2536 - mae: 0.1419 - val_loss: 0.1473 - val_mae: 0.1221\n",
            "Epoch 204/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2656 - mae: 0.1441 - val_loss: 0.1478 - val_mae: 0.1223\n",
            "Epoch 205/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2879 - mae: 0.1468 - val_loss: 0.1468 - val_mae: 0.1217\n",
            "Epoch 206/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2847 - mae: 0.1500 - val_loss: 0.1473 - val_mae: 0.1232\n",
            "Epoch 207/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2039 - mae: 0.1209 - val_loss: 0.1461 - val_mae: 0.1202\n",
            "Epoch 208/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1951 - mae: 0.1230 - val_loss: 0.1467 - val_mae: 0.1253\n",
            "Epoch 209/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2189 - mae: 0.1284 - val_loss: 0.1478 - val_mae: 0.1242\n",
            "Epoch 210/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1555 - mae: 0.1188 - val_loss: 0.1447 - val_mae: 0.1186\n",
            "Epoch 211/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1939 - mae: 0.1304 - val_loss: 0.1473 - val_mae: 0.1219\n",
            "Epoch 212/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2646 - mae: 0.1366 - val_loss: 0.1462 - val_mae: 0.1202\n",
            "Epoch 213/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1658 - mae: 0.1207 - val_loss: 0.1457 - val_mae: 0.1205\n",
            "Epoch 214/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3021 - mae: 0.1520 - val_loss: 0.1528 - val_mae: 0.1258\n",
            "Epoch 215/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3038 - mae: 0.1478 - val_loss: 0.1494 - val_mae: 0.1220\n",
            "Epoch 216/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2487 - mae: 0.1321 - val_loss: 0.1480 - val_mae: 0.1236\n",
            "Epoch 217/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2537 - mae: 0.1506 - val_loss: 0.1483 - val_mae: 0.1237\n",
            "Epoch 218/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2962 - mae: 0.1390 - val_loss: 0.1478 - val_mae: 0.1221\n",
            "Epoch 219/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2137 - mae: 0.1305 - val_loss: 0.1446 - val_mae: 0.1214\n",
            "Epoch 220/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2053 - mae: 0.1353 - val_loss: 0.1486 - val_mae: 0.1299\n",
            "Epoch 221/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2556 - mae: 0.1444 - val_loss: 0.1523 - val_mae: 0.1312\n",
            "Epoch 222/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.2403 - mae: 0.1449 - val_loss: 0.1474 - val_mae: 0.1291\n",
            "Epoch 223/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1503 - mae: 0.1144 - val_loss: 0.1474 - val_mae: 0.1190\n",
            "Epoch 224/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1710 - mae: 0.1213 - val_loss: 0.1470 - val_mae: 0.1247\n",
            "Epoch 225/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2536 - mae: 0.1363 - val_loss: 0.1474 - val_mae: 0.1217\n",
            "Epoch 226/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3100 - mae: 0.1409 - val_loss: 0.1478 - val_mae: 0.1232\n",
            "Epoch 227/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1576 - mae: 0.1185 - val_loss: 0.1437 - val_mae: 0.1157\n",
            "Epoch 228/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2799 - mae: 0.1444 - val_loss: 0.1456 - val_mae: 0.1172\n",
            "Epoch 229/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2356 - mae: 0.1204 - val_loss: 0.1459 - val_mae: 0.1172\n",
            "Epoch 230/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1904 - mae: 0.1171 - val_loss: 0.1424 - val_mae: 0.1146\n",
            "Epoch 231/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1873 - mae: 0.1254 - val_loss: 0.1498 - val_mae: 0.1207\n",
            "Epoch 232/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3222 - mae: 0.1497 - val_loss: 0.1487 - val_mae: 0.1197\n",
            "Epoch 233/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2973 - mae: 0.1338 - val_loss: 0.1450 - val_mae: 0.1160\n",
            "Epoch 234/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2930 - mae: 0.1401 - val_loss: 0.1425 - val_mae: 0.1189\n",
            "Epoch 235/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2120 - mae: 0.1293 - val_loss: 0.1453 - val_mae: 0.1192\n",
            "Epoch 236/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2856 - mae: 0.1491 - val_loss: 0.1463 - val_mae: 0.1242\n",
            "Epoch 237/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2466 - mae: 0.1389 - val_loss: 0.1454 - val_mae: 0.1169\n",
            "Epoch 238/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2578 - mae: 0.1347 - val_loss: 0.1494 - val_mae: 0.1212\n",
            "Epoch 239/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2332 - mae: 0.1285 - val_loss: 0.1428 - val_mae: 0.1125\n",
            "Epoch 240/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3600 - mae: 0.1464 - val_loss: 0.1431 - val_mae: 0.1139\n",
            "Epoch 241/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1735 - mae: 0.1159 - val_loss: 0.1412 - val_mae: 0.1116\n",
            "Epoch 242/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2418 - mae: 0.1261 - val_loss: 0.1434 - val_mae: 0.1138\n",
            "Epoch 243/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2186 - mae: 0.1282 - val_loss: 0.1437 - val_mae: 0.1147\n",
            "Epoch 244/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3067 - mae: 0.1344 - val_loss: 0.1461 - val_mae: 0.1191\n",
            "Epoch 245/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3273 - mae: 0.1446 - val_loss: 0.1450 - val_mae: 0.1124\n",
            "Epoch 246/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2057 - mae: 0.1262 - val_loss: 0.1442 - val_mae: 0.1124\n",
            "Epoch 247/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2695 - mae: 0.1319 - val_loss: 0.1479 - val_mae: 0.1151\n",
            "Epoch 248/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1550 - mae: 0.1178 - val_loss: 0.1424 - val_mae: 0.1185\n",
            "Epoch 249/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3960 - mae: 0.1554 - val_loss: 0.1457 - val_mae: 0.1202\n",
            "Epoch 250/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1658 - mae: 0.1159 - val_loss: 0.1482 - val_mae: 0.1213\n",
            "Epoch 251/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1822 - mae: 0.1200 - val_loss: 0.1417 - val_mae: 0.1165\n",
            "Epoch 252/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1891 - mae: 0.1228 - val_loss: 0.1461 - val_mae: 0.1165\n",
            "Epoch 253/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2137 - mae: 0.1287 - val_loss: 0.1479 - val_mae: 0.1221\n",
            "Epoch 254/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2908 - mae: 0.1367 - val_loss: 0.1431 - val_mae: 0.1120\n",
            "Epoch 255/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2812 - mae: 0.1258 - val_loss: 0.1460 - val_mae: 0.1133\n",
            "Epoch 256/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2366 - mae: 0.1215 - val_loss: 0.1429 - val_mae: 0.1105\n",
            "Epoch 257/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2016 - mae: 0.1151 - val_loss: 0.1442 - val_mae: 0.1126\n",
            "Epoch 258/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2373 - mae: 0.1292 - val_loss: 0.1425 - val_mae: 0.1140\n",
            "Epoch 259/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1829 - mae: 0.1216 - val_loss: 0.1401 - val_mae: 0.1120\n",
            "Epoch 260/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1682 - mae: 0.1128 - val_loss: 0.1418 - val_mae: 0.1106\n",
            "Epoch 261/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2777 - mae: 0.1530 - val_loss: 0.1435 - val_mae: 0.1149\n",
            "Epoch 262/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1577 - mae: 0.1119 - val_loss: 0.1454 - val_mae: 0.1138\n",
            "Epoch 263/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1646 - mae: 0.1172 - val_loss: 0.1442 - val_mae: 0.1123\n",
            "Epoch 264/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1798 - mae: 0.1181 - val_loss: 0.1451 - val_mae: 0.1133\n",
            "Epoch 265/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1829 - mae: 0.1260 - val_loss: 0.1432 - val_mae: 0.1109\n",
            "Epoch 266/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1417 - mae: 0.1077 - val_loss: 0.1452 - val_mae: 0.1141\n",
            "Epoch 267/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3468 - mae: 0.1561 - val_loss: 0.1498 - val_mae: 0.1330\n",
            "Epoch 268/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2442 - mae: 0.1393 - val_loss: 0.1473 - val_mae: 0.1207\n",
            "Epoch 269/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1923 - mae: 0.1174 - val_loss: 0.1450 - val_mae: 0.1176\n",
            "Epoch 270/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2088 - mae: 0.1250 - val_loss: 0.1493 - val_mae: 0.1248\n",
            "Epoch 271/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1808 - mae: 0.1296 - val_loss: 0.1414 - val_mae: 0.1084\n",
            "Epoch 272/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2613 - mae: 0.1258 - val_loss: 0.1466 - val_mae: 0.1125\n",
            "Epoch 273/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2417 - mae: 0.1327 - val_loss: 0.1405 - val_mae: 0.1090\n",
            "Epoch 274/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3039 - mae: 0.1351 - val_loss: 0.1468 - val_mae: 0.1136\n",
            "Epoch 275/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1432 - mae: 0.1100 - val_loss: 0.1447 - val_mae: 0.1141\n",
            "Epoch 276/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1936 - mae: 0.1207 - val_loss: 0.1479 - val_mae: 0.1130\n",
            "Epoch 277/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2531 - mae: 0.1360 - val_loss: 0.1426 - val_mae: 0.1085\n",
            "Epoch 278/2000\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.2872 - mae: 0.1335 - val_loss: 0.1434 - val_mae: 0.1099\n",
            "Epoch 279/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4042 - mae: 0.1559 - val_loss: 0.1422 - val_mae: 0.1115\n",
            "Epoch 280/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1677 - mae: 0.1123 - val_loss: 0.1423 - val_mae: 0.1107\n",
            "Epoch 281/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2727 - mae: 0.1364 - val_loss: 0.1451 - val_mae: 0.1108\n",
            "Epoch 282/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2725 - mae: 0.1251 - val_loss: 0.1416 - val_mae: 0.1071\n",
            "Epoch 283/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1997 - mae: 0.1228 - val_loss: 0.1395 - val_mae: 0.1084\n",
            "Epoch 284/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2197 - mae: 0.1229 - val_loss: 0.1428 - val_mae: 0.1090\n",
            "Epoch 285/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2193 - mae: 0.1116 - val_loss: 0.1441 - val_mae: 0.1109\n",
            "Epoch 286/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1647 - mae: 0.1092 - val_loss: 0.1415 - val_mae: 0.1074\n",
            "Epoch 287/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3078 - mae: 0.1420 - val_loss: 0.1447 - val_mae: 0.1097\n",
            "Epoch 288/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3825 - mae: 0.1517 - val_loss: 0.1430 - val_mae: 0.1090\n",
            "Epoch 289/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3172 - mae: 0.1311 - val_loss: 0.1420 - val_mae: 0.1076\n",
            "Epoch 290/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2484 - mae: 0.1287 - val_loss: 0.1434 - val_mae: 0.1101\n",
            "Epoch 291/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2416 - mae: 0.1324 - val_loss: 0.1419 - val_mae: 0.1069\n",
            "Epoch 292/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2325 - mae: 0.1151 - val_loss: 0.1426 - val_mae: 0.1065\n",
            "Epoch 293/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2887 - mae: 0.1265 - val_loss: 0.1423 - val_mae: 0.1066\n",
            "Epoch 294/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2226 - mae: 0.1165 - val_loss: 0.1438 - val_mae: 0.1068\n",
            "Epoch 295/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1843 - mae: 0.1195 - val_loss: 0.1407 - val_mae: 0.1059\n",
            "Epoch 296/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2072 - mae: 0.1190 - val_loss: 0.1428 - val_mae: 0.1074\n",
            "Epoch 297/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1354 - mae: 0.1052 - val_loss: 0.1420 - val_mae: 0.1086\n",
            "Epoch 298/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1926 - mae: 0.1166 - val_loss: 0.1420 - val_mae: 0.1087\n",
            "Epoch 299/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2092 - mae: 0.1226 - val_loss: 0.1450 - val_mae: 0.1102\n",
            "Epoch 300/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1413 - mae: 0.1093 - val_loss: 0.1468 - val_mae: 0.1155\n",
            "Epoch 301/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1701 - mae: 0.1217 - val_loss: 0.1414 - val_mae: 0.1104\n",
            "Epoch 302/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1950 - mae: 0.1201 - val_loss: 0.1480 - val_mae: 0.1176\n",
            "Epoch 303/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2431 - mae: 0.1418 - val_loss: 0.1510 - val_mae: 0.1184\n",
            "Epoch 304/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2253 - mae: 0.1233 - val_loss: 0.1415 - val_mae: 0.1114\n",
            "Epoch 305/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1907 - mae: 0.1211 - val_loss: 0.1440 - val_mae: 0.1103\n",
            "Epoch 306/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1399 - mae: 0.1110 - val_loss: 0.1437 - val_mae: 0.1074\n",
            "Epoch 307/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2620 - mae: 0.1240 - val_loss: 0.1459 - val_mae: 0.1079\n",
            "Epoch 308/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2247 - mae: 0.1138 - val_loss: 0.1409 - val_mae: 0.1051\n",
            "Epoch 309/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1616 - mae: 0.1009 - val_loss: 0.1402 - val_mae: 0.1062\n",
            "Epoch 310/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2037 - mae: 0.1219 - val_loss: 0.1454 - val_mae: 0.1099\n",
            "Epoch 311/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2611 - mae: 0.1358 - val_loss: 0.1390 - val_mae: 0.1040\n",
            "Epoch 312/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2332 - mae: 0.1142 - val_loss: 0.1456 - val_mae: 0.1105\n",
            "Epoch 313/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3079 - mae: 0.1384 - val_loss: 0.1457 - val_mae: 0.1138\n",
            "Epoch 314/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1746 - mae: 0.1049 - val_loss: 0.1411 - val_mae: 0.1067\n",
            "Epoch 315/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1992 - mae: 0.1160 - val_loss: 0.1433 - val_mae: 0.1084\n",
            "Epoch 316/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2378 - mae: 0.1319 - val_loss: 0.1449 - val_mae: 0.1098\n",
            "Epoch 317/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1834 - mae: 0.1109 - val_loss: 0.1420 - val_mae: 0.1066\n",
            "Epoch 318/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2365 - mae: 0.1190 - val_loss: 0.1454 - val_mae: 0.1103\n",
            "Epoch 319/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1907 - mae: 0.1174 - val_loss: 0.1407 - val_mae: 0.1045\n",
            "Epoch 320/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3333 - mae: 0.1249 - val_loss: 0.1437 - val_mae: 0.1080\n",
            "Epoch 321/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1571 - mae: 0.1090 - val_loss: 0.1402 - val_mae: 0.1083\n",
            "Epoch 322/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2339 - mae: 0.1143 - val_loss: 0.1445 - val_mae: 0.1087\n",
            "Epoch 323/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2910 - mae: 0.1241 - val_loss: 0.1438 - val_mae: 0.1063\n",
            "Epoch 324/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2050 - mae: 0.1061 - val_loss: 0.1417 - val_mae: 0.1096\n",
            "Epoch 325/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1588 - mae: 0.1136 - val_loss: 0.1426 - val_mae: 0.1108\n",
            "Epoch 326/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2613 - mae: 0.1318 - val_loss: 0.1461 - val_mae: 0.1116\n",
            "Epoch 327/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2030 - mae: 0.1158 - val_loss: 0.1403 - val_mae: 0.1062\n",
            "Epoch 328/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1750 - mae: 0.1115 - val_loss: 0.1424 - val_mae: 0.1078\n",
            "Epoch 329/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1877 - mae: 0.1166 - val_loss: 0.1434 - val_mae: 0.1082\n",
            "Epoch 330/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1726 - mae: 0.1129 - val_loss: 0.1426 - val_mae: 0.1092\n",
            "Epoch 331/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1839 - mae: 0.1191 - val_loss: 0.1429 - val_mae: 0.1122\n",
            "Epoch 332/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1386 - mae: 0.1096 - val_loss: 0.1467 - val_mae: 0.1136\n",
            "Epoch 333/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1625 - mae: 0.1166 - val_loss: 0.1471 - val_mae: 0.1097\n",
            "Epoch 334/2000\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.2565 - mae: 0.1199 - val_loss: 0.1434 - val_mae: 0.1084\n",
            "Epoch 335/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2016 - mae: 0.1258 - val_loss: 0.1395 - val_mae: 0.1050\n",
            "Epoch 336/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1934 - mae: 0.1232 - val_loss: 0.1461 - val_mae: 0.1076\n",
            "Epoch 337/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1748 - mae: 0.1220 - val_loss: 0.1422 - val_mae: 0.1057\n",
            "Epoch 338/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2652 - mae: 0.1255 - val_loss: 0.1433 - val_mae: 0.1093\n",
            "Epoch 339/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2004 - mae: 0.1178 - val_loss: 0.1448 - val_mae: 0.1063\n",
            "Epoch 340/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2724 - mae: 0.1269 - val_loss: 0.1401 - val_mae: 0.1038\n",
            "Epoch 341/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1696 - mae: 0.1029 - val_loss: 0.1440 - val_mae: 0.1068\n",
            "Epoch 342/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2002 - mae: 0.1231 - val_loss: 0.1438 - val_mae: 0.1064\n",
            "Epoch 343/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1542 - mae: 0.1125 - val_loss: 0.1397 - val_mae: 0.1066\n",
            "Epoch 344/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1480 - mae: 0.1059 - val_loss: 0.1491 - val_mae: 0.1225\n",
            "Epoch 345/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3018 - mae: 0.1443 - val_loss: 0.1448 - val_mae: 0.1152\n",
            "Epoch 346/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3153 - mae: 0.1373 - val_loss: 0.1460 - val_mae: 0.1088\n",
            "Epoch 347/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2227 - mae: 0.1226 - val_loss: 0.1405 - val_mae: 0.1038\n",
            "Epoch 348/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1634 - mae: 0.1135 - val_loss: 0.1395 - val_mae: 0.1033\n",
            "Epoch 349/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1823 - mae: 0.1163 - val_loss: 0.1407 - val_mae: 0.1046\n",
            "Epoch 350/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3785 - mae: 0.1357 - val_loss: 0.1470 - val_mae: 0.1101\n",
            "Epoch 351/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1477 - mae: 0.1054 - val_loss: 0.1402 - val_mae: 0.1043\n",
            "Epoch 352/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2101 - mae: 0.1167 - val_loss: 0.1434 - val_mae: 0.1065\n",
            "Epoch 353/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1957 - mae: 0.1103 - val_loss: 0.1434 - val_mae: 0.1054\n",
            "Epoch 354/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1948 - mae: 0.1112 - val_loss: 0.1421 - val_mae: 0.1058\n",
            "Epoch 355/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1754 - mae: 0.1060 - val_loss: 0.1414 - val_mae: 0.1051\n",
            "Epoch 356/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2249 - mae: 0.1209 - val_loss: 0.1437 - val_mae: 0.1066\n",
            "Epoch 357/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3280 - mae: 0.1394 - val_loss: 0.1426 - val_mae: 0.1073\n",
            "Epoch 358/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1402 - mae: 0.1057 - val_loss: 0.1416 - val_mae: 0.1059\n",
            "Epoch 359/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1478 - mae: 0.1001 - val_loss: 0.1449 - val_mae: 0.1093\n",
            "Epoch 360/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2698 - mae: 0.1301 - val_loss: 0.1461 - val_mae: 0.1087\n",
            "Epoch 361/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3133 - mae: 0.1414 - val_loss: 0.1409 - val_mae: 0.1046\n",
            "Epoch 362/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2657 - mae: 0.1262 - val_loss: 0.1413 - val_mae: 0.1052\n",
            "Epoch 363/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2407 - mae: 0.1275 - val_loss: 0.1479 - val_mae: 0.1149\n",
            "Epoch 364/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1539 - mae: 0.1115 - val_loss: 0.1410 - val_mae: 0.1040\n",
            "Epoch 365/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2907 - mae: 0.1346 - val_loss: 0.1432 - val_mae: 0.1063\n",
            "Epoch 366/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2974 - mae: 0.1327 - val_loss: 0.1439 - val_mae: 0.1046\n",
            "Epoch 367/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1879 - mae: 0.1104 - val_loss: 0.1403 - val_mae: 0.1044\n",
            "Epoch 368/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1292 - mae: 0.1029 - val_loss: 0.1435 - val_mae: 0.1134\n",
            "Epoch 369/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1798 - mae: 0.1251 - val_loss: 0.1486 - val_mae: 0.1120\n",
            "Epoch 370/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1601 - mae: 0.1127 - val_loss: 0.1431 - val_mae: 0.1082\n",
            "Epoch 371/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2432 - mae: 0.1235 - val_loss: 0.1440 - val_mae: 0.1098\n",
            "Epoch 372/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1688 - mae: 0.1093 - val_loss: 0.1435 - val_mae: 0.1088\n",
            "Epoch 373/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1156 - mae: 0.0979 - val_loss: 0.1418 - val_mae: 0.1069\n",
            "Epoch 374/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3359 - mae: 0.1445 - val_loss: 0.1439 - val_mae: 0.1048\n",
            "Epoch 375/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1520 - mae: 0.1023 - val_loss: 0.1413 - val_mae: 0.1041\n",
            "Epoch 376/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2260 - mae: 0.1163 - val_loss: 0.1418 - val_mae: 0.1039\n",
            "Epoch 377/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1610 - mae: 0.1059 - val_loss: 0.1450 - val_mae: 0.1058\n",
            "Epoch 378/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2308 - mae: 0.1215 - val_loss: 0.1408 - val_mae: 0.1031\n",
            "Epoch 379/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1495 - mae: 0.1099 - val_loss: 0.1385 - val_mae: 0.1038\n",
            "Epoch 380/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1325 - mae: 0.1029 - val_loss: 0.1422 - val_mae: 0.1066\n",
            "Epoch 381/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2043 - mae: 0.1171 - val_loss: 0.1419 - val_mae: 0.1050\n",
            "Epoch 382/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2658 - mae: 0.1349 - val_loss: 0.1441 - val_mae: 0.1074\n",
            "Epoch 383/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3257 - mae: 0.1379 - val_loss: 0.1441 - val_mae: 0.1041\n",
            "Epoch 384/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1957 - mae: 0.1172 - val_loss: 0.1406 - val_mae: 0.1041\n",
            "Epoch 385/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1894 - mae: 0.1069 - val_loss: 0.1423 - val_mae: 0.1075\n",
            "Epoch 386/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2455 - mae: 0.1298 - val_loss: 0.1415 - val_mae: 0.1073\n",
            "Epoch 387/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2578 - mae: 0.1314 - val_loss: 0.1420 - val_mae: 0.1051\n",
            "Epoch 388/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2583 - mae: 0.1378 - val_loss: 0.1728 - val_mae: 0.1291\n",
            "Epoch 389/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2186 - mae: 0.1331 - val_loss: 0.1737 - val_mae: 0.1455\n",
            "Epoch 390/2000\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.3446 - mae: 0.1630 - val_loss: 0.1489 - val_mae: 0.1238\n",
            "Epoch 391/2000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2439 - mae: 0.1298 - val_loss: 0.1538 - val_mae: 0.1337\n",
            "Epoch 392/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2729 - mae: 0.1567 - val_loss: 0.1626 - val_mae: 0.1325\n",
            "Epoch 393/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2400 - mae: 0.1387 - val_loss: 0.1440 - val_mae: 0.1199\n",
            "Epoch 394/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1537 - mae: 0.1168 - val_loss: 0.1408 - val_mae: 0.1122\n",
            "Epoch 395/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1925 - mae: 0.1208 - val_loss: 0.1476 - val_mae: 0.1094\n",
            "Epoch 396/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1622 - mae: 0.1096 - val_loss: 0.1387 - val_mae: 0.1040\n",
            "Epoch 397/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2344 - mae: 0.1218 - val_loss: 0.1457 - val_mae: 0.1110\n",
            "Epoch 398/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2049 - mae: 0.1180 - val_loss: 0.1433 - val_mae: 0.1057\n",
            "Epoch 399/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2186 - mae: 0.1235 - val_loss: 0.1434 - val_mae: 0.1050\n",
            "Epoch 400/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2168 - mae: 0.1190 - val_loss: 0.1404 - val_mae: 0.1040\n",
            "Epoch 401/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1433 - mae: 0.1068 - val_loss: 0.1396 - val_mae: 0.1039\n",
            "Epoch 402/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3402 - mae: 0.1401 - val_loss: 0.1417 - val_mae: 0.1041\n",
            "Epoch 403/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2296 - mae: 0.1222 - val_loss: 0.1439 - val_mae: 0.1062\n",
            "Epoch 404/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3435 - mae: 0.1413 - val_loss: 0.1459 - val_mae: 0.1080\n",
            "Epoch 405/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2101 - mae: 0.1174 - val_loss: 0.1401 - val_mae: 0.1016\n",
            "Epoch 406/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1940 - mae: 0.1141 - val_loss: 0.1415 - val_mae: 0.1040\n",
            "Epoch 407/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2110 - mae: 0.1110 - val_loss: 0.1465 - val_mae: 0.1064\n",
            "Epoch 408/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1734 - mae: 0.1119 - val_loss: 0.1400 - val_mae: 0.1051\n",
            "Epoch 409/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2647 - mae: 0.1202 - val_loss: 0.1435 - val_mae: 0.1086\n",
            "Epoch 410/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2019 - mae: 0.1192 - val_loss: 0.1391 - val_mae: 0.1013\n",
            "Epoch 411/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2948 - mae: 0.1256 - val_loss: 0.1457 - val_mae: 0.1080\n",
            "Epoch 412/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1382 - mae: 0.1061 - val_loss: 0.1388 - val_mae: 0.1017\n",
            "Epoch 413/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1638 - mae: 0.1070 - val_loss: 0.1403 - val_mae: 0.1027\n",
            "Epoch 414/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2033 - mae: 0.1154 - val_loss: 0.1408 - val_mae: 0.1040\n",
            "Epoch 415/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1864 - mae: 0.1095 - val_loss: 0.1433 - val_mae: 0.1060\n",
            "Epoch 416/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1783 - mae: 0.1074 - val_loss: 0.1436 - val_mae: 0.1053\n",
            "Epoch 417/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1798 - mae: 0.1136 - val_loss: 0.1406 - val_mae: 0.1037\n",
            "Epoch 418/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2912 - mae: 0.1335 - val_loss: 0.1424 - val_mae: 0.1052\n",
            "Epoch 419/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2004 - mae: 0.1130 - val_loss: 0.1411 - val_mae: 0.1046\n",
            "Epoch 420/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1473 - mae: 0.0992 - val_loss: 0.1432 - val_mae: 0.1042\n",
            "Epoch 421/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1859 - mae: 0.1109 - val_loss: 0.1446 - val_mae: 0.1049\n",
            "Epoch 422/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1179 - mae: 0.0942 - val_loss: 0.1396 - val_mae: 0.1039\n",
            "Epoch 423/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2800 - mae: 0.1211 - val_loss: 0.1447 - val_mae: 0.1082\n",
            "Epoch 424/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3250 - mae: 0.1268 - val_loss: 0.1412 - val_mae: 0.1065\n",
            "Epoch 425/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1916 - mae: 0.1183 - val_loss: 0.1415 - val_mae: 0.1035\n",
            "Epoch 426/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3068 - mae: 0.1303 - val_loss: 0.1443 - val_mae: 0.1078\n",
            "Epoch 427/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2105 - mae: 0.1198 - val_loss: 0.1423 - val_mae: 0.1041\n",
            "Epoch 428/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1979 - mae: 0.1111 - val_loss: 0.1413 - val_mae: 0.1042\n",
            "Epoch 429/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2431 - mae: 0.1291 - val_loss: 0.1407 - val_mae: 0.1027\n",
            "Epoch 430/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2181 - mae: 0.1091 - val_loss: 0.1420 - val_mae: 0.1026\n",
            "Epoch 431/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1676 - mae: 0.1124 - val_loss: 0.1406 - val_mae: 0.1023\n",
            "Epoch 432/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2155 - mae: 0.1210 - val_loss: 0.1444 - val_mae: 0.1050\n",
            "Epoch 433/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1789 - mae: 0.1068 - val_loss: 0.1451 - val_mae: 0.1042\n",
            "Epoch 434/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3210 - mae: 0.1222 - val_loss: 0.1410 - val_mae: 0.1023\n",
            "Epoch 435/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2399 - mae: 0.1092 - val_loss: 0.1434 - val_mae: 0.1041\n",
            "Epoch 436/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2521 - mae: 0.1185 - val_loss: 0.1406 - val_mae: 0.1022\n",
            "Epoch 437/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3619 - mae: 0.1352 - val_loss: 0.1418 - val_mae: 0.1022\n",
            "Epoch 438/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1555 - mae: 0.1019 - val_loss: 0.1408 - val_mae: 0.1053\n",
            "Epoch 439/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2214 - mae: 0.1193 - val_loss: 0.1456 - val_mae: 0.1067\n",
            "Epoch 440/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1667 - mae: 0.1148 - val_loss: 0.1392 - val_mae: 0.1027\n",
            "Epoch 441/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2111 - mae: 0.1154 - val_loss: 0.1431 - val_mae: 0.1032\n",
            "Epoch 442/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2228 - mae: 0.1171 - val_loss: 0.1404 - val_mae: 0.1025\n",
            "Epoch 443/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2253 - mae: 0.1134 - val_loss: 0.1434 - val_mae: 0.1041\n",
            "Epoch 444/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1425 - mae: 0.1047 - val_loss: 0.1403 - val_mae: 0.1023\n",
            "Epoch 445/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1950 - mae: 0.1108 - val_loss: 0.1438 - val_mae: 0.1049\n",
            "Epoch 446/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1576 - mae: 0.1094 - val_loss: 0.1414 - val_mae: 0.1043\n",
            "Epoch 447/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1848 - mae: 0.1094 - val_loss: 0.1464 - val_mae: 0.1066\n",
            "Epoch 448/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2238 - mae: 0.1161 - val_loss: 0.1460 - val_mae: 0.1059\n",
            "Epoch 449/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2191 - mae: 0.1212 - val_loss: 0.1435 - val_mae: 0.1044\n",
            "Epoch 450/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1273 - mae: 0.0907 - val_loss: 0.1408 - val_mae: 0.1037\n",
            "Epoch 451/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1674 - mae: 0.1087 - val_loss: 0.1437 - val_mae: 0.1061\n",
            "Epoch 452/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1966 - mae: 0.1139 - val_loss: 0.1432 - val_mae: 0.1038\n",
            "Epoch 453/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1690 - mae: 0.1070 - val_loss: 0.1412 - val_mae: 0.1035\n",
            "Epoch 454/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1567 - mae: 0.1064 - val_loss: 0.1410 - val_mae: 0.1057\n",
            "Epoch 455/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2202 - mae: 0.1161 - val_loss: 0.1471 - val_mae: 0.1061\n",
            "Epoch 456/2000\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1978 - mae: 0.1147 - val_loss: 0.1442 - val_mae: 0.1035\n",
            "Epoch 457/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1904 - mae: 0.1074 - val_loss: 0.1399 - val_mae: 0.1045\n",
            "Epoch 458/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2347 - mae: 0.1145 - val_loss: 0.1453 - val_mae: 0.1065\n",
            "Epoch 459/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1459 - mae: 0.1015 - val_loss: 0.1402 - val_mae: 0.1041\n",
            "Epoch 460/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2652 - mae: 0.1337 - val_loss: 0.1470 - val_mae: 0.1120\n",
            "Epoch 461/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1397 - mae: 0.1080 - val_loss: 0.1402 - val_mae: 0.1071\n",
            "Epoch 462/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1357 - mae: 0.1031 - val_loss: 0.1433 - val_mae: 0.1093\n",
            "Epoch 463/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1735 - mae: 0.1054 - val_loss: 0.1463 - val_mae: 0.1079\n",
            "Epoch 464/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2192 - mae: 0.1136 - val_loss: 0.1427 - val_mae: 0.1032\n",
            "Epoch 465/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1974 - mae: 0.1081 - val_loss: 0.1400 - val_mae: 0.1009\n",
            "Epoch 466/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1415 - mae: 0.0934 - val_loss: 0.1407 - val_mae: 0.1032\n",
            "Epoch 467/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2248 - mae: 0.1121 - val_loss: 0.1422 - val_mae: 0.1041\n",
            "Epoch 468/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2750 - mae: 0.1268 - val_loss: 0.1430 - val_mae: 0.1034\n",
            "Epoch 469/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2140 - mae: 0.1166 - val_loss: 0.1401 - val_mae: 0.1016\n",
            "Epoch 470/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1583 - mae: 0.1004 - val_loss: 0.1431 - val_mae: 0.1064\n",
            "Epoch 471/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1496 - mae: 0.1039 - val_loss: 0.1439 - val_mae: 0.1068\n",
            "Epoch 472/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3400 - mae: 0.1402 - val_loss: 0.1432 - val_mae: 0.1063\n",
            "Epoch 473/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2799 - mae: 0.1249 - val_loss: 0.1462 - val_mae: 0.1063\n",
            "Epoch 474/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1328 - mae: 0.1038 - val_loss: 0.1382 - val_mae: 0.0998\n",
            "Epoch 475/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1589 - mae: 0.0961 - val_loss: 0.1431 - val_mae: 0.1054\n",
            "Epoch 476/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1568 - mae: 0.1104 - val_loss: 0.1442 - val_mae: 0.1042\n",
            "Epoch 477/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1673 - mae: 0.1142 - val_loss: 0.1431 - val_mae: 0.1049\n",
            "Epoch 478/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2654 - mae: 0.1237 - val_loss: 0.1442 - val_mae: 0.1050\n",
            "Epoch 479/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1882 - mae: 0.1132 - val_loss: 0.1399 - val_mae: 0.1030\n",
            "Epoch 480/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2287 - mae: 0.1203 - val_loss: 0.1429 - val_mae: 0.1052\n",
            "Epoch 481/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1685 - mae: 0.1062 - val_loss: 0.1410 - val_mae: 0.1033\n",
            "Epoch 482/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1998 - mae: 0.1191 - val_loss: 0.1435 - val_mae: 0.1036\n",
            "Epoch 483/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3135 - mae: 0.1367 - val_loss: 0.1446 - val_mae: 0.1054\n",
            "Epoch 484/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1742 - mae: 0.1146 - val_loss: 0.1415 - val_mae: 0.1030\n",
            "Epoch 485/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1529 - mae: 0.1079 - val_loss: 0.1405 - val_mae: 0.1033\n",
            "Epoch 486/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3441 - mae: 0.1333 - val_loss: 0.1462 - val_mae: 0.1062\n",
            "Epoch 487/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2087 - mae: 0.1150 - val_loss: 0.1424 - val_mae: 0.1074\n",
            "Epoch 488/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1829 - mae: 0.1124 - val_loss: 0.1426 - val_mae: 0.1051\n",
            "Epoch 489/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1745 - mae: 0.1078 - val_loss: 0.1434 - val_mae: 0.1065\n",
            "Epoch 490/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2122 - mae: 0.1167 - val_loss: 0.1455 - val_mae: 0.1099\n",
            "Epoch 491/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1780 - mae: 0.1165 - val_loss: 0.1417 - val_mae: 0.1042\n",
            "Epoch 492/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1389 - mae: 0.1001 - val_loss: 0.1412 - val_mae: 0.1047\n",
            "Epoch 493/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2659 - mae: 0.1251 - val_loss: 0.1428 - val_mae: 0.1028\n",
            "Epoch 494/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1860 - mae: 0.1097 - val_loss: 0.1450 - val_mae: 0.1055\n",
            "Epoch 495/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2572 - mae: 0.1212 - val_loss: 0.1483 - val_mae: 0.1124\n",
            "Epoch 496/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1968 - mae: 0.1160 - val_loss: 0.1400 - val_mae: 0.1031\n",
            "Epoch 497/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1451 - mae: 0.1051 - val_loss: 0.1410 - val_mae: 0.1064\n",
            "Epoch 498/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1702 - mae: 0.1093 - val_loss: 0.1431 - val_mae: 0.1076\n",
            "Epoch 499/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2950 - mae: 0.1251 - val_loss: 0.1444 - val_mae: 0.1048\n",
            "Epoch 500/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2014 - mae: 0.1066 - val_loss: 0.1404 - val_mae: 0.1017\n",
            "Epoch 501/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1975 - mae: 0.1070 - val_loss: 0.1450 - val_mae: 0.1047\n",
            "Epoch 502/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2327 - mae: 0.1238 - val_loss: 0.1433 - val_mae: 0.1051\n",
            "Epoch 503/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2117 - mae: 0.1179 - val_loss: 0.1407 - val_mae: 0.1009\n",
            "Epoch 504/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2545 - mae: 0.1189 - val_loss: 0.1395 - val_mae: 0.1015\n",
            "Epoch 505/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1258 - mae: 0.0983 - val_loss: 0.1443 - val_mae: 0.1046\n",
            "Epoch 506/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1933 - mae: 0.1082 - val_loss: 0.1455 - val_mae: 0.1042\n",
            "Epoch 507/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1488 - mae: 0.1093 - val_loss: 0.1394 - val_mae: 0.1034\n",
            "Epoch 508/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2755 - mae: 0.1185 - val_loss: 0.1603 - val_mae: 0.1406\n",
            "Epoch 509/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1938 - mae: 0.1460 - val_loss: 0.1481 - val_mae: 0.1204\n",
            "Epoch 510/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2094 - mae: 0.1322 - val_loss: 0.1448 - val_mae: 0.1151\n",
            "Epoch 511/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.1488 - mae: 0.1103 - val_loss: 0.1402 - val_mae: 0.1050\n",
            "Epoch 512/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1336 - mae: 0.1018 - val_loss: 0.1420 - val_mae: 0.1041\n",
            "Epoch 513/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2278 - mae: 0.1233 - val_loss: 0.1445 - val_mae: 0.1059\n",
            "Epoch 514/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1703 - mae: 0.1053 - val_loss: 0.1421 - val_mae: 0.1047\n",
            "Epoch 515/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1751 - mae: 0.1091 - val_loss: 0.1447 - val_mae: 0.1039\n",
            "Epoch 516/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1955 - mae: 0.1139 - val_loss: 0.1440 - val_mae: 0.1033\n",
            "Epoch 517/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2605 - mae: 0.1183 - val_loss: 0.1436 - val_mae: 0.1040\n",
            "Epoch 518/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1721 - mae: 0.1053 - val_loss: 0.1403 - val_mae: 0.1014\n",
            "Epoch 519/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2806 - mae: 0.1243 - val_loss: 0.1436 - val_mae: 0.1042\n",
            "Epoch 520/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1598 - mae: 0.1027 - val_loss: 0.1391 - val_mae: 0.1027\n",
            "Epoch 521/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2265 - mae: 0.1251 - val_loss: 0.1433 - val_mae: 0.1046\n",
            "Epoch 522/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2045 - mae: 0.1143 - val_loss: 0.1447 - val_mae: 0.1042\n",
            "Epoch 523/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1794 - mae: 0.1090 - val_loss: 0.1412 - val_mae: 0.1028\n",
            "Epoch 524/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1216 - mae: 0.0961 - val_loss: 0.1398 - val_mae: 0.1027\n",
            "Epoch 525/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2645 - mae: 0.1261 - val_loss: 0.1452 - val_mae: 0.1049\n",
            "Epoch 526/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1190 - mae: 0.0937 - val_loss: 0.1396 - val_mae: 0.1007\n",
            "Epoch 527/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2706 - mae: 0.1153 - val_loss: 0.1402 - val_mae: 0.1053\n",
            "Epoch 528/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2649 - mae: 0.1221 - val_loss: 0.1446 - val_mae: 0.1047\n",
            "Epoch 529/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3015 - mae: 0.1430 - val_loss: 0.1422 - val_mae: 0.1039\n",
            "Epoch 530/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1567 - mae: 0.1024 - val_loss: 0.1409 - val_mae: 0.1035\n",
            "Epoch 531/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1965 - mae: 0.1184 - val_loss: 0.1425 - val_mae: 0.1034\n",
            "Epoch 532/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1837 - mae: 0.1087 - val_loss: 0.1458 - val_mae: 0.1062\n",
            "Epoch 533/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2144 - mae: 0.1127 - val_loss: 0.1406 - val_mae: 0.1032\n",
            "Epoch 534/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3374 - mae: 0.1211 - val_loss: 0.1417 - val_mae: 0.1022\n",
            "Epoch 535/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1815 - mae: 0.1170 - val_loss: 0.1375 - val_mae: 0.0991\n",
            "Epoch 536/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2211 - mae: 0.1131 - val_loss: 0.1407 - val_mae: 0.1026\n",
            "Epoch 537/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2441 - mae: 0.1190 - val_loss: 0.1439 - val_mae: 0.1037\n",
            "Epoch 538/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1874 - mae: 0.1061 - val_loss: 0.1426 - val_mae: 0.1036\n",
            "Epoch 539/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1852 - mae: 0.1130 - val_loss: 0.1398 - val_mae: 0.1047\n",
            "Epoch 540/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1542 - mae: 0.0978 - val_loss: 0.1450 - val_mae: 0.1063\n",
            "Epoch 541/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2415 - mae: 0.1094 - val_loss: 0.1426 - val_mae: 0.1046\n",
            "Epoch 542/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1925 - mae: 0.1142 - val_loss: 0.1388 - val_mae: 0.1019\n",
            "Epoch 543/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2006 - mae: 0.1181 - val_loss: 0.1428 - val_mae: 0.1057\n",
            "Epoch 544/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2251 - mae: 0.1176 - val_loss: 0.1428 - val_mae: 0.1062\n",
            "Epoch 545/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1912 - mae: 0.1097 - val_loss: 0.1414 - val_mae: 0.1046\n",
            "Epoch 546/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1770 - mae: 0.1112 - val_loss: 0.1424 - val_mae: 0.1056\n",
            "Epoch 547/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2021 - mae: 0.1200 - val_loss: 0.1449 - val_mae: 0.1070\n",
            "Epoch 548/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2432 - mae: 0.1212 - val_loss: 0.1437 - val_mae: 0.1049\n",
            "Epoch 549/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2388 - mae: 0.1247 - val_loss: 0.1415 - val_mae: 0.1020\n",
            "Epoch 550/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1835 - mae: 0.1101 - val_loss: 0.1412 - val_mae: 0.1017\n",
            "Epoch 551/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2941 - mae: 0.1163 - val_loss: 0.1441 - val_mae: 0.1031\n",
            "Epoch 552/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2118 - mae: 0.1148 - val_loss: 0.1415 - val_mae: 0.1011\n",
            "Epoch 553/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2469 - mae: 0.1099 - val_loss: 0.1403 - val_mae: 0.1008\n",
            "Epoch 554/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2498 - mae: 0.1146 - val_loss: 0.1430 - val_mae: 0.1024\n",
            "Epoch 555/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2265 - mae: 0.1115 - val_loss: 0.1432 - val_mae: 0.1035\n",
            "Epoch 556/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2317 - mae: 0.1179 - val_loss: 0.1440 - val_mae: 0.1050\n",
            "Epoch 557/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2021 - mae: 0.1150 - val_loss: 0.1419 - val_mae: 0.1056\n",
            "Epoch 558/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2580 - mae: 0.1179 - val_loss: 0.1437 - val_mae: 0.1037\n",
            "Epoch 559/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1690 - mae: 0.1137 - val_loss: 0.1393 - val_mae: 0.1011\n",
            "Epoch 560/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2792 - mae: 0.1169 - val_loss: 0.1436 - val_mae: 0.1029\n",
            "Epoch 561/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2101 - mae: 0.1136 - val_loss: 0.1389 - val_mae: 0.1007\n",
            "Epoch 562/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1950 - mae: 0.1155 - val_loss: 0.1452 - val_mae: 0.1037\n",
            "Epoch 563/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2746 - mae: 0.1243 - val_loss: 0.1453 - val_mae: 0.1035\n",
            "Epoch 564/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2339 - mae: 0.1230 - val_loss: 0.1424 - val_mae: 0.1045\n",
            "Epoch 565/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2108 - mae: 0.1110 - val_loss: 0.1417 - val_mae: 0.1010\n",
            "Epoch 566/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1495 - mae: 0.0950 - val_loss: 0.1391 - val_mae: 0.1006\n",
            "Epoch 567/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1864 - mae: 0.1035 - val_loss: 0.1429 - val_mae: 0.1045\n",
            "Epoch 568/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2648 - mae: 0.1236 - val_loss: 0.1473 - val_mae: 0.1051\n",
            "Epoch 569/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2405 - mae: 0.1145 - val_loss: 0.1427 - val_mae: 0.1018\n",
            "Epoch 570/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3876 - mae: 0.1318 - val_loss: 0.1429 - val_mae: 0.1027\n",
            "Epoch 571/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1791 - mae: 0.1085 - val_loss: 0.1403 - val_mae: 0.1007\n",
            "Epoch 572/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1847 - mae: 0.1109 - val_loss: 0.1422 - val_mae: 0.1020\n",
            "Epoch 573/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1602 - mae: 0.1101 - val_loss: 0.1402 - val_mae: 0.1010\n",
            "Epoch 574/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1802 - mae: 0.1096 - val_loss: 0.1442 - val_mae: 0.1050\n",
            "Epoch 575/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1975 - mae: 0.1065 - val_loss: 0.1424 - val_mae: 0.1025\n",
            "Epoch 576/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1433 - mae: 0.1039 - val_loss: 0.1411 - val_mae: 0.1014\n",
            "Epoch 577/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2825 - mae: 0.1299 - val_loss: 0.1447 - val_mae: 0.1044\n",
            "Epoch 578/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1916 - mae: 0.1046 - val_loss: 0.1439 - val_mae: 0.1027\n",
            "Epoch 579/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1831 - mae: 0.1085 - val_loss: 0.1430 - val_mae: 0.1040\n",
            "Epoch 580/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2186 - mae: 0.1197 - val_loss: 0.1401 - val_mae: 0.1009\n",
            "Epoch 581/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1362 - mae: 0.1070 - val_loss: 0.1390 - val_mae: 0.1016\n",
            "Epoch 582/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1804 - mae: 0.1114 - val_loss: 0.1434 - val_mae: 0.1036\n",
            "Epoch 583/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2875 - mae: 0.1371 - val_loss: 0.1447 - val_mae: 0.1046\n",
            "Epoch 584/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2074 - mae: 0.1138 - val_loss: 0.1422 - val_mae: 0.1015\n",
            "Epoch 585/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2085 - mae: 0.1144 - val_loss: 0.1422 - val_mae: 0.1018\n",
            "Epoch 586/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1982 - mae: 0.1121 - val_loss: 0.1443 - val_mae: 0.1035\n",
            "Epoch 587/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3039 - mae: 0.1259 - val_loss: 0.1440 - val_mae: 0.1068\n",
            "Epoch 588/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2385 - mae: 0.1162 - val_loss: 0.1403 - val_mae: 0.1017\n",
            "Epoch 589/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1383 - mae: 0.0899 - val_loss: 0.1395 - val_mae: 0.1012\n",
            "Epoch 590/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2756 - mae: 0.1330 - val_loss: 0.1430 - val_mae: 0.1041\n",
            "Epoch 591/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1841 - mae: 0.1064 - val_loss: 0.1407 - val_mae: 0.1007\n",
            "Epoch 592/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2357 - mae: 0.1109 - val_loss: 0.1447 - val_mae: 0.1051\n",
            "Epoch 593/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1547 - mae: 0.1067 - val_loss: 0.1397 - val_mae: 0.1011\n",
            "Epoch 594/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1876 - mae: 0.1095 - val_loss: 0.1445 - val_mae: 0.1045\n",
            "Epoch 595/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1898 - mae: 0.1066 - val_loss: 0.1433 - val_mae: 0.1038\n",
            "Epoch 596/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2556 - mae: 0.1263 - val_loss: 0.1423 - val_mae: 0.1020\n",
            "Epoch 597/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2200 - mae: 0.1071 - val_loss: 0.1413 - val_mae: 0.1018\n",
            "Epoch 598/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3188 - mae: 0.1264 - val_loss: 0.1449 - val_mae: 0.1048\n",
            "Epoch 599/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1366 - mae: 0.1003 - val_loss: 0.1392 - val_mae: 0.0999\n",
            "Epoch 600/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2293 - mae: 0.1192 - val_loss: 0.1412 - val_mae: 0.1027\n",
            "Epoch 601/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1662 - mae: 0.1005 - val_loss: 0.1414 - val_mae: 0.1023\n",
            "Epoch 602/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2607 - mae: 0.1144 - val_loss: 0.1429 - val_mae: 0.1013\n",
            "Epoch 603/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1588 - mae: 0.1012 - val_loss: 0.1411 - val_mae: 0.1022\n",
            "Epoch 604/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4091 - mae: 0.1439 - val_loss: 0.1428 - val_mae: 0.1050\n",
            "Epoch 605/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1629 - mae: 0.1043 - val_loss: 0.1396 - val_mae: 0.1035\n",
            "Epoch 606/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2630 - mae: 0.1242 - val_loss: 0.1431 - val_mae: 0.1056\n",
            "Epoch 607/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1758 - mae: 0.1050 - val_loss: 0.1409 - val_mae: 0.1025\n",
            "Epoch 608/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2362 - mae: 0.1149 - val_loss: 0.1419 - val_mae: 0.1029\n",
            "Epoch 609/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1566 - mae: 0.1005 - val_loss: 0.1437 - val_mae: 0.1045\n",
            "Epoch 610/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2481 - mae: 0.1135 - val_loss: 0.1430 - val_mae: 0.1033\n",
            "Epoch 611/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1621 - mae: 0.1003 - val_loss: 0.1403 - val_mae: 0.1014\n",
            "Epoch 612/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2934 - mae: 0.1184 - val_loss: 0.1444 - val_mae: 0.1030\n",
            "Epoch 613/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1797 - mae: 0.1063 - val_loss: 0.1421 - val_mae: 0.1032\n",
            "Epoch 614/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1771 - mae: 0.1191 - val_loss: 0.1397 - val_mae: 0.1022\n",
            "Epoch 615/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2031 - mae: 0.1119 - val_loss: 0.1444 - val_mae: 0.1039\n",
            "Epoch 616/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1407 - mae: 0.0979 - val_loss: 0.1391 - val_mae: 0.1006\n",
            "Epoch 617/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2521 - mae: 0.1225 - val_loss: 0.1440 - val_mae: 0.1039\n",
            "Epoch 618/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1781 - mae: 0.1106 - val_loss: 0.1424 - val_mae: 0.1024\n",
            "Epoch 619/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2262 - mae: 0.1186 - val_loss: 0.1428 - val_mae: 0.1043\n",
            "Epoch 620/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2061 - mae: 0.1091 - val_loss: 0.1446 - val_mae: 0.1029\n",
            "Epoch 621/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2282 - mae: 0.1206 - val_loss: 0.1410 - val_mae: 0.1045\n",
            "Epoch 622/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2080 - mae: 0.1143 - val_loss: 0.1409 - val_mae: 0.1049\n",
            "Epoch 623/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2959 - mae: 0.1238 - val_loss: 0.1440 - val_mae: 0.1044\n",
            "Epoch 624/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2112 - mae: 0.1189 - val_loss: 0.1420 - val_mae: 0.1051\n",
            "Epoch 625/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.3154 - mae: 0.1294 - val_loss: 0.1412 - val_mae: 0.1019\n",
            "Epoch 626/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1794 - mae: 0.1096 - val_loss: 0.1395 - val_mae: 0.1031\n",
            "Epoch 627/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1754 - mae: 0.1154 - val_loss: 0.1405 - val_mae: 0.1076\n",
            "Epoch 628/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1493 - mae: 0.1142 - val_loss: 0.1455 - val_mae: 0.1086\n",
            "Epoch 629/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3884 - mae: 0.1398 - val_loss: 0.1444 - val_mae: 0.1092\n",
            "Epoch 630/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2229 - mae: 0.1230 - val_loss: 0.1395 - val_mae: 0.1105\n",
            "Epoch 631/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2634 - mae: 0.1288 - val_loss: 0.1402 - val_mae: 0.1107\n",
            "Epoch 632/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1818 - mae: 0.1268 - val_loss: 0.1418 - val_mae: 0.1086\n",
            "Epoch 633/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2399 - mae: 0.1273 - val_loss: 0.1474 - val_mae: 0.1062\n",
            "Epoch 634/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4307 - mae: 0.1511 - val_loss: 0.1437 - val_mae: 0.1086\n",
            "Epoch 635/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3105 - mae: 0.1360 - val_loss: 0.1399 - val_mae: 0.1024\n",
            "Epoch 636/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2817 - mae: 0.1178 - val_loss: 0.1398 - val_mae: 0.1014\n",
            "Epoch 637/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2296 - mae: 0.1101 - val_loss: 0.1405 - val_mae: 0.1009\n",
            "Epoch 638/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2833 - mae: 0.1272 - val_loss: 0.1443 - val_mae: 0.1037\n",
            "Epoch 639/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2212 - mae: 0.1167 - val_loss: 0.1402 - val_mae: 0.1005\n",
            "Epoch 640/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2496 - mae: 0.1157 - val_loss: 0.1418 - val_mae: 0.1022\n",
            "Epoch 641/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2335 - mae: 0.1262 - val_loss: 0.1410 - val_mae: 0.1045\n",
            "Epoch 642/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3093 - mae: 0.1393 - val_loss: 0.1426 - val_mae: 0.1028\n",
            "Epoch 643/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1627 - mae: 0.1044 - val_loss: 0.1436 - val_mae: 0.1029\n",
            "Epoch 644/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2607 - mae: 0.1225 - val_loss: 0.1445 - val_mae: 0.1043\n",
            "Epoch 645/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1627 - mae: 0.1118 - val_loss: 0.1392 - val_mae: 0.1009\n",
            "Epoch 646/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1093 - mae: 0.0924 - val_loss: 0.1399 - val_mae: 0.1017\n",
            "Epoch 647/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2886 - mae: 0.1191 - val_loss: 0.1463 - val_mae: 0.1057\n",
            "Epoch 648/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2715 - mae: 0.1313 - val_loss: 0.1397 - val_mae: 0.1025\n",
            "Epoch 649/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2154 - mae: 0.1184 - val_loss: 0.1415 - val_mae: 0.1026\n",
            "Epoch 650/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1673 - mae: 0.1093 - val_loss: 0.1411 - val_mae: 0.1025\n",
            "Epoch 651/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1691 - mae: 0.1042 - val_loss: 0.1455 - val_mae: 0.1044\n",
            "Epoch 652/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2177 - mae: 0.1163 - val_loss: 0.1407 - val_mae: 0.1025\n",
            "Epoch 653/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3121 - mae: 0.1238 - val_loss: 0.1416 - val_mae: 0.1033\n",
            "Epoch 654/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1813 - mae: 0.1110 - val_loss: 0.1414 - val_mae: 0.1018\n",
            "Epoch 655/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1541 - mae: 0.1038 - val_loss: 0.1458 - val_mae: 0.1047\n",
            "Epoch 656/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3875 - mae: 0.1376 - val_loss: 0.1453 - val_mae: 0.1050\n",
            "Epoch 657/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1523 - mae: 0.0986 - val_loss: 0.1398 - val_mae: 0.1008\n",
            "Epoch 658/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3179 - mae: 0.1306 - val_loss: 0.1408 - val_mae: 0.1037\n",
            "Epoch 659/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2158 - mae: 0.1102 - val_loss: 0.1412 - val_mae: 0.1009\n",
            "Epoch 660/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2683 - mae: 0.1198 - val_loss: 0.1421 - val_mae: 0.1019\n",
            "Epoch 661/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1798 - mae: 0.1105 - val_loss: 0.1424 - val_mae: 0.1017\n",
            "Epoch 662/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3020 - mae: 0.1308 - val_loss: 0.1452 - val_mae: 0.1029\n",
            "Epoch 663/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2644 - mae: 0.1295 - val_loss: 0.1422 - val_mae: 0.1014\n",
            "Epoch 664/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2657 - mae: 0.1207 - val_loss: 0.1401 - val_mae: 0.1007\n",
            "Epoch 665/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2272 - mae: 0.1162 - val_loss: 0.1403 - val_mae: 0.1030\n",
            "Epoch 666/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2719 - mae: 0.1237 - val_loss: 0.1455 - val_mae: 0.1060\n",
            "Epoch 667/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1950 - mae: 0.1152 - val_loss: 0.1430 - val_mae: 0.1041\n",
            "Epoch 668/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2283 - mae: 0.1069 - val_loss: 0.1433 - val_mae: 0.1025\n",
            "Epoch 669/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2269 - mae: 0.1235 - val_loss: 0.1422 - val_mae: 0.1028\n",
            "Epoch 670/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1960 - mae: 0.1104 - val_loss: 0.1420 - val_mae: 0.1019\n",
            "Epoch 671/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1540 - mae: 0.1042 - val_loss: 0.1423 - val_mae: 0.1020\n",
            "Epoch 672/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2777 - mae: 0.1293 - val_loss: 0.1451 - val_mae: 0.1034\n",
            "Epoch 673/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2257 - mae: 0.1139 - val_loss: 0.1440 - val_mae: 0.1015\n",
            "Epoch 674/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1776 - mae: 0.0990 - val_loss: 0.1422 - val_mae: 0.1019\n",
            "Epoch 675/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2700 - mae: 0.1123 - val_loss: 0.1432 - val_mae: 0.1014\n",
            "Epoch 676/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2727 - mae: 0.1208 - val_loss: 0.1402 - val_mae: 0.1025\n",
            "Epoch 677/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2107 - mae: 0.1158 - val_loss: 0.1432 - val_mae: 0.1031\n",
            "Epoch 678/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2742 - mae: 0.1203 - val_loss: 0.1433 - val_mae: 0.1042\n",
            "Epoch 679/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2046 - mae: 0.1148 - val_loss: 0.1416 - val_mae: 0.1008\n",
            "Epoch 680/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1941 - mae: 0.1122 - val_loss: 0.1424 - val_mae: 0.1018\n",
            "Epoch 681/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.2488 - mae: 0.1150 - val_loss: 0.1412 - val_mae: 0.1003\n",
            "Epoch 682/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2129 - mae: 0.1095 - val_loss: 0.1398 - val_mae: 0.1000\n",
            "Epoch 683/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2139 - mae: 0.1131 - val_loss: 0.1404 - val_mae: 0.1011\n",
            "Epoch 684/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1899 - mae: 0.1061 - val_loss: 0.1430 - val_mae: 0.1016\n",
            "Epoch 685/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2245 - mae: 0.1158 - val_loss: 0.1436 - val_mae: 0.1013\n",
            "Epoch 686/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1746 - mae: 0.1054 - val_loss: 0.1423 - val_mae: 0.1051\n",
            "Epoch 687/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2496 - mae: 0.1168 - val_loss: 0.1450 - val_mae: 0.1056\n",
            "Epoch 688/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2338 - mae: 0.1137 - val_loss: 0.1405 - val_mae: 0.1023\n",
            "Epoch 689/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2373 - mae: 0.1215 - val_loss: 0.1413 - val_mae: 0.1020\n",
            "Epoch 690/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2091 - mae: 0.1149 - val_loss: 0.1396 - val_mae: 0.1011\n",
            "Epoch 691/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1908 - mae: 0.1116 - val_loss: 0.1438 - val_mae: 0.1030\n",
            "Epoch 692/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1923 - mae: 0.1105 - val_loss: 0.1422 - val_mae: 0.1020\n",
            "Epoch 693/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2217 - mae: 0.1127 - val_loss: 0.1414 - val_mae: 0.1022\n",
            "Epoch 694/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2155 - mae: 0.1081 - val_loss: 0.1438 - val_mae: 0.1025\n",
            "Epoch 695/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2098 - mae: 0.1159 - val_loss: 0.1416 - val_mae: 0.1017\n",
            "Epoch 696/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3082 - mae: 0.1208 - val_loss: 0.1437 - val_mae: 0.1013\n",
            "Epoch 697/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3429 - mae: 0.1241 - val_loss: 0.1437 - val_mae: 0.1036\n",
            "Epoch 698/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1233 - mae: 0.1000 - val_loss: 0.1388 - val_mae: 0.0996\n",
            "Epoch 699/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1608 - mae: 0.1127 - val_loss: 0.1431 - val_mae: 0.1039\n",
            "Epoch 700/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1711 - mae: 0.1163 - val_loss: 0.1418 - val_mae: 0.1023\n",
            "Epoch 701/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2063 - mae: 0.1116 - val_loss: 0.1468 - val_mae: 0.1068\n",
            "Epoch 702/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1297 - mae: 0.0995 - val_loss: 0.1397 - val_mae: 0.0997\n",
            "Epoch 703/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1993 - mae: 0.1082 - val_loss: 0.1437 - val_mae: 0.1043\n",
            "Epoch 704/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2176 - mae: 0.1158 - val_loss: 0.1419 - val_mae: 0.1008\n",
            "Epoch 705/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2325 - mae: 0.1197 - val_loss: 0.1420 - val_mae: 0.1016\n",
            "Epoch 706/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2347 - mae: 0.1148 - val_loss: 0.1449 - val_mae: 0.1048\n",
            "Epoch 707/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2053 - mae: 0.1223 - val_loss: 0.1402 - val_mae: 0.1003\n",
            "Epoch 708/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1242 - mae: 0.0914 - val_loss: 0.1421 - val_mae: 0.1042\n",
            "Epoch 709/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1902 - mae: 0.1183 - val_loss: 0.1416 - val_mae: 0.1052\n",
            "Epoch 710/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1546 - mae: 0.1073 - val_loss: 0.1438 - val_mae: 0.1022\n",
            "Epoch 711/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3658 - mae: 0.1373 - val_loss: 0.1444 - val_mae: 0.1028\n",
            "Epoch 712/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1914 - mae: 0.1067 - val_loss: 0.1401 - val_mae: 0.1001\n",
            "Epoch 713/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1700 - mae: 0.0994 - val_loss: 0.1438 - val_mae: 0.1064\n",
            "Epoch 714/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2091 - mae: 0.1171 - val_loss: 0.1437 - val_mae: 0.1055\n",
            "Epoch 715/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1760 - mae: 0.1081 - val_loss: 0.1431 - val_mae: 0.1022\n",
            "Epoch 716/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2525 - mae: 0.1120 - val_loss: 0.1451 - val_mae: 0.1039\n",
            "Epoch 717/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2547 - mae: 0.1145 - val_loss: 0.1444 - val_mae: 0.1040\n",
            "Epoch 718/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1866 - mae: 0.1097 - val_loss: 0.1417 - val_mae: 0.1020\n",
            "Epoch 719/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2088 - mae: 0.1166 - val_loss: 0.1413 - val_mae: 0.1009\n",
            "Epoch 720/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1229 - mae: 0.0965 - val_loss: 0.1421 - val_mae: 0.1026\n",
            "Epoch 721/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2065 - mae: 0.1130 - val_loss: 0.1445 - val_mae: 0.1031\n",
            "Epoch 722/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3412 - mae: 0.1326 - val_loss: 0.1431 - val_mae: 0.1012\n",
            "Epoch 723/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2381 - mae: 0.1181 - val_loss: 0.1426 - val_mae: 0.1021\n",
            "Epoch 724/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2687 - mae: 0.1212 - val_loss: 0.1434 - val_mae: 0.1020\n",
            "Epoch 725/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2152 - mae: 0.1183 - val_loss: 0.1398 - val_mae: 0.1003\n",
            "Epoch 726/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2488 - mae: 0.1186 - val_loss: 0.1414 - val_mae: 0.1035\n",
            "Epoch 727/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1609 - mae: 0.0963 - val_loss: 0.1392 - val_mae: 0.0997\n",
            "Epoch 728/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2250 - mae: 0.1132 - val_loss: 0.1431 - val_mae: 0.1021\n",
            "Epoch 729/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2774 - mae: 0.1195 - val_loss: 0.1444 - val_mae: 0.1037\n",
            "Epoch 730/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1999 - mae: 0.1040 - val_loss: 0.1423 - val_mae: 0.1016\n",
            "Epoch 731/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2694 - mae: 0.1172 - val_loss: 0.1426 - val_mae: 0.1021\n",
            "Epoch 732/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1836 - mae: 0.1030 - val_loss: 0.1409 - val_mae: 0.1002\n",
            "Epoch 733/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2319 - mae: 0.1055 - val_loss: 0.1404 - val_mae: 0.1014\n",
            "Epoch 734/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2031 - mae: 0.1052 - val_loss: 0.1424 - val_mae: 0.1007\n",
            "Epoch 735/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1639 - mae: 0.0966 - val_loss: 0.1383 - val_mae: 0.0986\n",
            "Epoch 736/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1534 - mae: 0.1055 - val_loss: 0.1391 - val_mae: 0.1013\n",
            "Epoch 737/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.3001 - mae: 0.1224 - val_loss: 0.1433 - val_mae: 0.1028\n",
            "Epoch 738/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2098 - mae: 0.1055 - val_loss: 0.1439 - val_mae: 0.1042\n",
            "Epoch 739/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2405 - mae: 0.1217 - val_loss: 0.1428 - val_mae: 0.1033\n",
            "Epoch 740/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1800 - mae: 0.1058 - val_loss: 0.1408 - val_mae: 0.1004\n",
            "Epoch 741/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3385 - mae: 0.1258 - val_loss: 0.1426 - val_mae: 0.1038\n",
            "Epoch 742/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1514 - mae: 0.1040 - val_loss: 0.1432 - val_mae: 0.1025\n",
            "Epoch 743/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2275 - mae: 0.1119 - val_loss: 0.1426 - val_mae: 0.1021\n",
            "Epoch 744/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2345 - mae: 0.1165 - val_loss: 0.1416 - val_mae: 0.1011\n",
            "Epoch 745/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1402 - mae: 0.0948 - val_loss: 0.1404 - val_mae: 0.0995\n",
            "Epoch 746/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2303 - mae: 0.1113 - val_loss: 0.1426 - val_mae: 0.1017\n",
            "Epoch 747/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1417 - mae: 0.0966 - val_loss: 0.1404 - val_mae: 0.1000\n",
            "Epoch 748/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2224 - mae: 0.1103 - val_loss: 0.1439 - val_mae: 0.1021\n",
            "Epoch 749/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1630 - mae: 0.1049 - val_loss: 0.1392 - val_mae: 0.0989\n",
            "Epoch 750/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1732 - mae: 0.1012 - val_loss: 0.1430 - val_mae: 0.1022\n",
            "Epoch 751/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1984 - mae: 0.1142 - val_loss: 0.1416 - val_mae: 0.1006\n",
            "Epoch 752/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2158 - mae: 0.1146 - val_loss: 0.1417 - val_mae: 0.1007\n",
            "Epoch 753/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.3387 - mae: 0.1339 - val_loss: 0.1432 - val_mae: 0.1010\n",
            "Epoch 754/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2365 - mae: 0.1173 - val_loss: 0.1413 - val_mae: 0.0998\n",
            "Epoch 755/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2178 - mae: 0.1098 - val_loss: 0.1418 - val_mae: 0.1009\n",
            "Epoch 756/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2931 - mae: 0.1280 - val_loss: 0.1399 - val_mae: 0.1005\n",
            "Epoch 757/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2114 - mae: 0.1137 - val_loss: 0.1424 - val_mae: 0.1024\n",
            "Epoch 758/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2255 - mae: 0.1151 - val_loss: 0.1404 - val_mae: 0.1009\n",
            "Epoch 759/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1959 - mae: 0.1081 - val_loss: 0.1409 - val_mae: 0.1001\n",
            "Epoch 760/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1401 - mae: 0.0973 - val_loss: 0.1418 - val_mae: 0.1012\n",
            "Epoch 761/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1773 - mae: 0.0997 - val_loss: 0.1437 - val_mae: 0.1019\n",
            "Epoch 762/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2168 - mae: 0.1087 - val_loss: 0.1394 - val_mae: 0.1006\n",
            "Epoch 763/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2533 - mae: 0.1198 - val_loss: 0.1420 - val_mae: 0.1037\n",
            "Epoch 764/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1785 - mae: 0.1102 - val_loss: 0.1389 - val_mae: 0.0988\n",
            "Epoch 765/2000\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.2331 - mae: 0.1149 - val_loss: 0.1429 - val_mae: 0.1018\n",
            "Epoch 766/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1744 - mae: 0.1119 - val_loss: 0.1386 - val_mae: 0.0993\n",
            "Epoch 767/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2217 - mae: 0.1147 - val_loss: 0.1421 - val_mae: 0.1010\n",
            "Epoch 768/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2437 - mae: 0.1151 - val_loss: 0.1436 - val_mae: 0.1016\n",
            "Epoch 769/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1485 - mae: 0.1056 - val_loss: 0.1394 - val_mae: 0.0989\n",
            "Epoch 770/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1686 - mae: 0.1009 - val_loss: 0.1469 - val_mae: 0.1060\n",
            "Epoch 771/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1629 - mae: 0.1177 - val_loss: 0.1404 - val_mae: 0.1034\n",
            "Epoch 772/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2412 - mae: 0.1143 - val_loss: 0.1410 - val_mae: 0.1071\n",
            "Epoch 773/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1801 - mae: 0.1119 - val_loss: 0.1452 - val_mae: 0.1106\n",
            "Epoch 774/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2987 - mae: 0.1352 - val_loss: 0.1453 - val_mae: 0.1067\n",
            "Epoch 775/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3151 - mae: 0.1270 - val_loss: 0.1441 - val_mae: 0.1058\n",
            "Epoch 776/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2501 - mae: 0.1154 - val_loss: 0.1398 - val_mae: 0.1006\n",
            "Epoch 777/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2304 - mae: 0.1138 - val_loss: 0.1413 - val_mae: 0.1001\n",
            "Epoch 778/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2926 - mae: 0.1298 - val_loss: 0.1406 - val_mae: 0.1016\n",
            "Epoch 779/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2644 - mae: 0.1214 - val_loss: 0.1423 - val_mae: 0.1024\n",
            "Epoch 780/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2457 - mae: 0.1217 - val_loss: 0.1411 - val_mae: 0.1020\n",
            "Epoch 781/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1574 - mae: 0.1034 - val_loss: 0.1391 - val_mae: 0.0989\n",
            "Epoch 782/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2615 - mae: 0.1178 - val_loss: 0.1410 - val_mae: 0.1008\n",
            "Epoch 783/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2598 - mae: 0.1190 - val_loss: 0.1444 - val_mae: 0.1023\n",
            "Epoch 784/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1601 - mae: 0.1052 - val_loss: 0.1406 - val_mae: 0.1010\n",
            "Epoch 785/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1421 - mae: 0.0969 - val_loss: 0.1409 - val_mae: 0.0998\n",
            "Epoch 786/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1534 - mae: 0.0954 - val_loss: 0.1429 - val_mae: 0.1012\n",
            "Epoch 787/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1336 - mae: 0.0975 - val_loss: 0.1409 - val_mae: 0.1011\n",
            "Epoch 788/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2484 - mae: 0.1155 - val_loss: 0.1408 - val_mae: 0.1003\n",
            "Epoch 789/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2791 - mae: 0.1214 - val_loss: 0.1730 - val_mae: 0.1286\n",
            "Epoch 790/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1780 - mae: 0.1337 - val_loss: 0.1492 - val_mae: 0.1238\n",
            "Epoch 791/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2744 - mae: 0.1348 - val_loss: 0.1465 - val_mae: 0.1120\n",
            "Epoch 792/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2204 - mae: 0.1149 - val_loss: 0.1472 - val_mae: 0.1076\n",
            "Epoch 793/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2228 - mae: 0.1262 - val_loss: 0.1407 - val_mae: 0.1033\n",
            "Epoch 794/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1994 - mae: 0.1154 - val_loss: 0.1387 - val_mae: 0.1002\n",
            "Epoch 795/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2358 - mae: 0.1200 - val_loss: 0.1419 - val_mae: 0.1015\n",
            "Epoch 796/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3057 - mae: 0.1250 - val_loss: 0.1413 - val_mae: 0.1021\n",
            "Epoch 797/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2491 - mae: 0.1184 - val_loss: 0.1448 - val_mae: 0.1039\n",
            "Epoch 798/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1230 - mae: 0.0950 - val_loss: 0.1394 - val_mae: 0.1005\n",
            "Epoch 799/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1876 - mae: 0.1103 - val_loss: 0.1433 - val_mae: 0.1015\n",
            "Epoch 800/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2348 - mae: 0.1131 - val_loss: 0.1434 - val_mae: 0.1030\n",
            "Epoch 801/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2354 - mae: 0.1164 - val_loss: 0.1424 - val_mae: 0.1018\n",
            "Epoch 802/2000\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.1661 - mae: 0.1085 - val_loss: 0.1391 - val_mae: 0.0982\n",
            "Epoch 803/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1772 - mae: 0.0998 - val_loss: 0.1408 - val_mae: 0.1006\n",
            "Epoch 804/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2463 - mae: 0.1149 - val_loss: 0.1444 - val_mae: 0.1027\n",
            "Epoch 805/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1394 - mae: 0.0960 - val_loss: 0.1407 - val_mae: 0.1019\n",
            "Epoch 806/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2652 - mae: 0.1282 - val_loss: 0.1444 - val_mae: 0.1033\n",
            "Epoch 807/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2258 - mae: 0.1266 - val_loss: 0.1412 - val_mae: 0.1004\n",
            "Epoch 808/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4138 - mae: 0.1508 - val_loss: 0.1430 - val_mae: 0.1009\n",
            "Epoch 809/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2607 - mae: 0.1183 - val_loss: 0.1423 - val_mae: 0.1014\n",
            "Epoch 810/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1315 - mae: 0.0958 - val_loss: 0.1393 - val_mae: 0.0991\n",
            "Epoch 811/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2666 - mae: 0.1177 - val_loss: 0.1413 - val_mae: 0.1009\n",
            "Epoch 812/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1647 - mae: 0.1054 - val_loss: 0.1410 - val_mae: 0.0995\n",
            "Epoch 813/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1481 - mae: 0.1075 - val_loss: 0.1433 - val_mae: 0.1013\n",
            "Epoch 814/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1858 - mae: 0.1115 - val_loss: 0.1437 - val_mae: 0.1029\n",
            "Epoch 815/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2529 - mae: 0.1230 - val_loss: 0.1462 - val_mae: 0.1039\n",
            "Epoch 816/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1431 - mae: 0.1028 - val_loss: 0.1398 - val_mae: 0.0992\n",
            "Epoch 817/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3611 - mae: 0.1427 - val_loss: 0.1443 - val_mae: 0.1032\n",
            "Epoch 818/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1645 - mae: 0.0990 - val_loss: 0.1417 - val_mae: 0.1006\n",
            "Epoch 819/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3407 - mae: 0.1292 - val_loss: 0.1431 - val_mae: 0.1008\n",
            "Epoch 820/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2081 - mae: 0.1120 - val_loss: 0.1422 - val_mae: 0.1011\n",
            "Epoch 821/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1778 - mae: 0.1061 - val_loss: 0.1395 - val_mae: 0.0995\n",
            "Epoch 822/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2215 - mae: 0.1191 - val_loss: 0.1415 - val_mae: 0.1010\n",
            "Epoch 823/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3725 - mae: 0.1301 - val_loss: 0.1417 - val_mae: 0.1018\n",
            "Epoch 824/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2566 - mae: 0.1241 - val_loss: 0.1425 - val_mae: 0.1012\n",
            "Epoch 825/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1265 - mae: 0.0868 - val_loss: 0.1410 - val_mae: 0.0994\n",
            "Epoch 826/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2225 - mae: 0.1215 - val_loss: 0.1416 - val_mae: 0.1011\n",
            "Epoch 827/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3599 - mae: 0.1361 - val_loss: 0.1436 - val_mae: 0.1017\n",
            "Epoch 828/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1694 - mae: 0.1043 - val_loss: 0.1392 - val_mae: 0.0997\n",
            "Epoch 829/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3010 - mae: 0.1175 - val_loss: 0.1418 - val_mae: 0.1006\n",
            "Epoch 830/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1957 - mae: 0.1004 - val_loss: 0.1414 - val_mae: 0.0999\n",
            "Epoch 831/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3242 - mae: 0.1226 - val_loss: 0.1415 - val_mae: 0.1010\n",
            "Epoch 832/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2592 - mae: 0.1201 - val_loss: 0.1410 - val_mae: 0.0999\n",
            "Epoch 833/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2367 - mae: 0.1187 - val_loss: 0.1409 - val_mae: 0.1007\n",
            "Epoch 834/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1774 - mae: 0.1068 - val_loss: 0.1430 - val_mae: 0.1010\n",
            "Epoch 835/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2180 - mae: 0.1124 - val_loss: 0.1399 - val_mae: 0.0997\n",
            "Epoch 836/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1847 - mae: 0.1005 - val_loss: 0.1433 - val_mae: 0.1023\n",
            "Epoch 837/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1961 - mae: 0.1050 - val_loss: 0.1421 - val_mae: 0.1022\n",
            "Epoch 838/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1997 - mae: 0.1105 - val_loss: 0.1414 - val_mae: 0.1015\n",
            "Epoch 839/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2201 - mae: 0.1186 - val_loss: 0.1437 - val_mae: 0.1029\n",
            "Epoch 840/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2666 - mae: 0.1305 - val_loss: 0.1447 - val_mae: 0.1015\n",
            "Epoch 841/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1900 - mae: 0.1128 - val_loss: 0.1421 - val_mae: 0.1012\n",
            "Epoch 842/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1603 - mae: 0.1095 - val_loss: 0.1431 - val_mae: 0.1023\n",
            "Epoch 843/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1365 - mae: 0.1035 - val_loss: 0.1429 - val_mae: 0.1012\n",
            "Epoch 844/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2819 - mae: 0.1220 - val_loss: 0.1510 - val_mae: 0.1091\n",
            "Epoch 845/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2086 - mae: 0.1186 - val_loss: 0.1415 - val_mae: 0.1057\n",
            "Epoch 846/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1530 - mae: 0.1047 - val_loss: 0.1465 - val_mae: 0.1068\n",
            "Epoch 847/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1745 - mae: 0.1159 - val_loss: 0.1453 - val_mae: 0.1061\n",
            "Epoch 848/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2262 - mae: 0.1144 - val_loss: 0.1466 - val_mae: 0.1044\n",
            "Epoch 849/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3261 - mae: 0.1257 - val_loss: 0.1433 - val_mae: 0.1014\n",
            "Epoch 850/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1635 - mae: 0.1048 - val_loss: 0.1397 - val_mae: 0.0994\n",
            "Epoch 851/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2017 - mae: 0.1066 - val_loss: 0.1423 - val_mae: 0.1030\n",
            "Epoch 852/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3434 - mae: 0.1316 - val_loss: 0.1473 - val_mae: 0.1065\n",
            "Epoch 853/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2295 - mae: 0.1105 - val_loss: 0.1431 - val_mae: 0.1027\n",
            "Epoch 854/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2581 - mae: 0.1226 - val_loss: 0.1402 - val_mae: 0.1014\n",
            "Epoch 855/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3994 - mae: 0.1329 - val_loss: 0.1410 - val_mae: 0.0999\n",
            "Epoch 856/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2043 - mae: 0.1135 - val_loss: 0.1389 - val_mae: 0.0980\n",
            "Epoch 857/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1989 - mae: 0.0993 - val_loss: 0.1399 - val_mae: 0.0983\n",
            "Epoch 858/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1768 - mae: 0.1025 - val_loss: 0.1396 - val_mae: 0.0986\n",
            "Epoch 859/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1940 - mae: 0.1040 - val_loss: 0.1412 - val_mae: 0.0999\n",
            "Epoch 860/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2889 - mae: 0.1189 - val_loss: 0.1426 - val_mae: 0.1006\n",
            "Epoch 861/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2081 - mae: 0.1087 - val_loss: 0.1405 - val_mae: 0.1016\n",
            "Epoch 862/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3503 - mae: 0.1358 - val_loss: 0.1417 - val_mae: 0.1010\n",
            "Epoch 863/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2463 - mae: 0.1185 - val_loss: 0.1393 - val_mae: 0.0990\n",
            "Epoch 864/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2420 - mae: 0.1082 - val_loss: 0.1425 - val_mae: 0.1003\n",
            "Epoch 865/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1649 - mae: 0.1059 - val_loss: 0.1404 - val_mae: 0.0998\n",
            "Epoch 866/2000\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1686 - mae: 0.0981 - val_loss: 0.1418 - val_mae: 0.1006\n",
            "Epoch 867/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1929 - mae: 0.1063 - val_loss: 0.1422 - val_mae: 0.1006\n",
            "Epoch 868/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2089 - mae: 0.1199 - val_loss: 0.1409 - val_mae: 0.0997\n",
            "Epoch 869/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1873 - mae: 0.1055 - val_loss: 0.1407 - val_mae: 0.0998\n",
            "Epoch 870/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2234 - mae: 0.1079 - val_loss: 0.1427 - val_mae: 0.1033\n",
            "Epoch 871/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2483 - mae: 0.1180 - val_loss: 0.1410 - val_mae: 0.1004\n",
            "Epoch 872/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2247 - mae: 0.1147 - val_loss: 0.1401 - val_mae: 0.1008\n",
            "Epoch 873/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2572 - mae: 0.1210 - val_loss: 0.1415 - val_mae: 0.1017\n",
            "Epoch 874/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2973 - mae: 0.1279 - val_loss: 0.1424 - val_mae: 0.1003\n",
            "Epoch 875/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2741 - mae: 0.1192 - val_loss: 0.1425 - val_mae: 0.1006\n",
            "Epoch 876/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1802 - mae: 0.1081 - val_loss: 0.1406 - val_mae: 0.0988\n",
            "Epoch 877/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2103 - mae: 0.1085 - val_loss: 0.1408 - val_mae: 0.0996\n",
            "Epoch 878/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2172 - mae: 0.1081 - val_loss: 0.1436 - val_mae: 0.1025\n",
            "Epoch 879/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2825 - mae: 0.1242 - val_loss: 0.1414 - val_mae: 0.1017\n",
            "Epoch 880/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1364 - mae: 0.0930 - val_loss: 0.1411 - val_mae: 0.1026\n",
            "Epoch 881/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1629 - mae: 0.1060 - val_loss: 0.1411 - val_mae: 0.1004\n",
            "Epoch 882/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1960 - mae: 0.1110 - val_loss: 0.1423 - val_mae: 0.1012\n",
            "Epoch 883/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2077 - mae: 0.1103 - val_loss: 0.1416 - val_mae: 0.0991\n",
            "Epoch 884/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2784 - mae: 0.1256 - val_loss: 0.1430 - val_mae: 0.1000\n",
            "Epoch 885/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2138 - mae: 0.1088 - val_loss: 0.1426 - val_mae: 0.1037\n",
            "Epoch 886/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2664 - mae: 0.1170 - val_loss: 0.1403 - val_mae: 0.0991\n",
            "Epoch 887/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3059 - mae: 0.1210 - val_loss: 0.1408 - val_mae: 0.0991\n",
            "Epoch 888/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1505 - mae: 0.0961 - val_loss: 0.1417 - val_mae: 0.1000\n",
            "Epoch 889/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2207 - mae: 0.1088 - val_loss: 0.1420 - val_mae: 0.0995\n",
            "Epoch 890/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1918 - mae: 0.1056 - val_loss: 0.1419 - val_mae: 0.1001\n",
            "Epoch 891/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1729 - mae: 0.1010 - val_loss: 0.1424 - val_mae: 0.1027\n",
            "Epoch 892/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1733 - mae: 0.1017 - val_loss: 0.1393 - val_mae: 0.0997\n",
            "Epoch 893/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1880 - mae: 0.0997 - val_loss: 0.1435 - val_mae: 0.1019\n",
            "Epoch 894/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2475 - mae: 0.1204 - val_loss: 0.1404 - val_mae: 0.1019\n",
            "Epoch 895/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1394 - mae: 0.0964 - val_loss: 0.1399 - val_mae: 0.1000\n",
            "Epoch 896/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1395 - mae: 0.0939 - val_loss: 0.1385 - val_mae: 0.1005\n",
            "Epoch 897/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1358 - mae: 0.0969 - val_loss: 0.1401 - val_mae: 0.0995\n",
            "Epoch 898/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1427 - mae: 0.1026 - val_loss: 0.1414 - val_mae: 0.0994\n",
            "Epoch 899/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1799 - mae: 0.1128 - val_loss: 0.1435 - val_mae: 0.1019\n",
            "Epoch 900/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3377 - mae: 0.1268 - val_loss: 0.1471 - val_mae: 0.1040\n",
            "Epoch 901/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1772 - mae: 0.1046 - val_loss: 0.1433 - val_mae: 0.1006\n",
            "Epoch 902/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2185 - mae: 0.1183 - val_loss: 0.1401 - val_mae: 0.0987\n",
            "Epoch 903/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1738 - mae: 0.1009 - val_loss: 0.1417 - val_mae: 0.1003\n",
            "Epoch 904/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1406 - mae: 0.0920 - val_loss: 0.1409 - val_mae: 0.1014\n",
            "Epoch 905/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1597 - mae: 0.0974 - val_loss: 0.1423 - val_mae: 0.1004\n",
            "Epoch 906/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1902 - mae: 0.1049 - val_loss: 0.1458 - val_mae: 0.1018\n",
            "Epoch 907/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1599 - mae: 0.1026 - val_loss: 0.1410 - val_mae: 0.0984\n",
            "Epoch 908/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1587 - mae: 0.1050 - val_loss: 0.1409 - val_mae: 0.1006\n",
            "Epoch 909/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1925 - mae: 0.1132 - val_loss: 0.1461 - val_mae: 0.1019\n",
            "Epoch 910/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1942 - mae: 0.1115 - val_loss: 0.1440 - val_mae: 0.1018\n",
            "Epoch 911/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1925 - mae: 0.1061 - val_loss: 0.1429 - val_mae: 0.1001\n",
            "Epoch 912/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2235 - mae: 0.1043 - val_loss: 0.1442 - val_mae: 0.1007\n",
            "Epoch 913/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2026 - mae: 0.1090 - val_loss: 0.1414 - val_mae: 0.0994\n",
            "Epoch 914/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1201 - mae: 0.0892 - val_loss: 0.1390 - val_mae: 0.0996\n",
            "Epoch 915/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2912 - mae: 0.1244 - val_loss: 0.1412 - val_mae: 0.1002\n",
            "Epoch 916/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1801 - mae: 0.1068 - val_loss: 0.1415 - val_mae: 0.1000\n",
            "Epoch 917/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1647 - mae: 0.0991 - val_loss: 0.1421 - val_mae: 0.1005\n",
            "Epoch 918/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1870 - mae: 0.1103 - val_loss: 0.1428 - val_mae: 0.1007\n",
            "Epoch 919/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2740 - mae: 0.1143 - val_loss: 0.1420 - val_mae: 0.1005\n",
            "Epoch 920/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1689 - mae: 0.1013 - val_loss: 0.1407 - val_mae: 0.1043\n",
            "Epoch 921/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1733 - mae: 0.1117 - val_loss: 0.1418 - val_mae: 0.1002\n",
            "Epoch 922/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1904 - mae: 0.1022 - val_loss: 0.1424 - val_mae: 0.1000\n",
            "Epoch 923/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.2729 - mae: 0.1218 - val_loss: 0.1439 - val_mae: 0.1009\n",
            "Epoch 924/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3239 - mae: 0.1317 - val_loss: 0.1419 - val_mae: 0.0994\n",
            "Epoch 925/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1462 - mae: 0.0945 - val_loss: 0.1392 - val_mae: 0.0996\n",
            "Epoch 926/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2998 - mae: 0.1212 - val_loss: 0.1421 - val_mae: 0.1004\n",
            "Epoch 927/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2120 - mae: 0.1128 - val_loss: 0.1424 - val_mae: 0.1008\n",
            "Epoch 928/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2916 - mae: 0.1176 - val_loss: 0.1422 - val_mae: 0.1000\n",
            "Epoch 929/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1987 - mae: 0.1099 - val_loss: 0.1399 - val_mae: 0.0991\n",
            "Epoch 930/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2145 - mae: 0.1041 - val_loss: 0.1408 - val_mae: 0.0994\n",
            "Epoch 931/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2216 - mae: 0.1216 - val_loss: 0.1412 - val_mae: 0.0997\n",
            "Epoch 932/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3684 - mae: 0.1331 - val_loss: 0.1441 - val_mae: 0.1015\n",
            "Epoch 933/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1762 - mae: 0.1109 - val_loss: 0.1404 - val_mae: 0.1001\n",
            "Epoch 934/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1220 - mae: 0.0964 - val_loss: 0.1464 - val_mae: 0.1099\n",
            "Epoch 935/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3221 - mae: 0.1291 - val_loss: 0.1505 - val_mae: 0.1114\n",
            "Epoch 936/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2708 - mae: 0.1196 - val_loss: 0.1493 - val_mae: 0.1107\n",
            "Epoch 937/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2212 - mae: 0.1234 - val_loss: 0.1445 - val_mae: 0.1061\n",
            "Epoch 938/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2142 - mae: 0.1180 - val_loss: 0.1431 - val_mae: 0.1069\n",
            "Epoch 939/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2294 - mae: 0.1203 - val_loss: 0.1435 - val_mae: 0.1029\n",
            "Epoch 940/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2837 - mae: 0.1243 - val_loss: 0.1435 - val_mae: 0.1019\n",
            "Epoch 941/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2209 - mae: 0.1173 - val_loss: 0.1421 - val_mae: 0.0994\n",
            "Epoch 942/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3413 - mae: 0.1283 - val_loss: 0.1426 - val_mae: 0.1006\n",
            "Epoch 943/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2657 - mae: 0.1172 - val_loss: 0.1432 - val_mae: 0.1009\n",
            "Epoch 944/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2650 - mae: 0.1117 - val_loss: 0.1422 - val_mae: 0.0994\n",
            "Epoch 945/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1907 - mae: 0.1043 - val_loss: 0.1407 - val_mae: 0.0990\n",
            "Epoch 946/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3066 - mae: 0.1240 - val_loss: 0.1413 - val_mae: 0.0991\n",
            "Epoch 947/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1844 - mae: 0.1031 - val_loss: 0.1402 - val_mae: 0.0983\n",
            "Epoch 948/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1466 - mae: 0.0953 - val_loss: 0.1405 - val_mae: 0.1009\n",
            "Epoch 949/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2292 - mae: 0.1126 - val_loss: 0.1435 - val_mae: 0.1017\n",
            "Epoch 950/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2057 - mae: 0.1063 - val_loss: 0.1440 - val_mae: 0.1007\n",
            "Epoch 951/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2469 - mae: 0.1168 - val_loss: 0.1423 - val_mae: 0.0997\n",
            "Epoch 952/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3105 - mae: 0.1237 - val_loss: 0.1426 - val_mae: 0.1022\n",
            "Epoch 953/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1436 - mae: 0.1003 - val_loss: 0.1391 - val_mae: 0.0974\n",
            "Epoch 954/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2348 - mae: 0.1088 - val_loss: 0.1405 - val_mae: 0.0996\n",
            "Epoch 955/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3281 - mae: 0.1249 - val_loss: 0.1423 - val_mae: 0.0994\n",
            "Epoch 956/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2634 - mae: 0.1206 - val_loss: 0.1422 - val_mae: 0.0994\n",
            "Epoch 957/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2258 - mae: 0.1040 - val_loss: 0.1408 - val_mae: 0.0996\n",
            "Epoch 958/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1375 - mae: 0.0929 - val_loss: 0.1401 - val_mae: 0.0994\n",
            "Epoch 959/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1607 - mae: 0.1047 - val_loss: 0.1396 - val_mae: 0.0996\n",
            "Epoch 960/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1721 - mae: 0.0961 - val_loss: 0.1423 - val_mae: 0.1011\n",
            "Epoch 961/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2408 - mae: 0.1040 - val_loss: 0.1424 - val_mae: 0.0998\n",
            "Epoch 962/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2119 - mae: 0.1108 - val_loss: 0.1414 - val_mae: 0.1003\n",
            "Epoch 963/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1379 - mae: 0.0924 - val_loss: 0.1406 - val_mae: 0.0988\n",
            "Epoch 964/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1402 - mae: 0.0933 - val_loss: 0.1427 - val_mae: 0.1009\n",
            "Epoch 965/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1427 - mae: 0.1011 - val_loss: 0.1402 - val_mae: 0.0994\n",
            "Epoch 966/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2821 - mae: 0.1315 - val_loss: 0.1420 - val_mae: 0.0998\n",
            "Epoch 967/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1889 - mae: 0.1089 - val_loss: 0.1443 - val_mae: 0.1030\n",
            "Epoch 968/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1177 - mae: 0.0893 - val_loss: 0.1397 - val_mae: 0.0985\n",
            "Epoch 969/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1952 - mae: 0.1024 - val_loss: 0.1421 - val_mae: 0.1005\n",
            "Epoch 970/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2624 - mae: 0.1171 - val_loss: 0.1469 - val_mae: 0.1039\n",
            "Epoch 971/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2947 - mae: 0.1204 - val_loss: 0.1417 - val_mae: 0.1005\n",
            "Epoch 972/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3662 - mae: 0.1367 - val_loss: 0.1402 - val_mae: 0.1020\n",
            "Epoch 973/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1491 - mae: 0.1031 - val_loss: 0.1406 - val_mae: 0.1016\n",
            "Epoch 974/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1370 - mae: 0.0995 - val_loss: 0.1414 - val_mae: 0.1038\n",
            "Epoch 975/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1816 - mae: 0.1077 - val_loss: 0.1435 - val_mae: 0.1024\n",
            "Epoch 976/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1926 - mae: 0.1172 - val_loss: 0.1419 - val_mae: 0.1007\n",
            "Epoch 977/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2600 - mae: 0.1150 - val_loss: 0.1434 - val_mae: 0.1019\n",
            "Epoch 978/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1634 - mae: 0.1018 - val_loss: 0.1401 - val_mae: 0.0987\n",
            "Epoch 979/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3774 - mae: 0.1380 - val_loss: 0.1446 - val_mae: 0.1025\n",
            "Epoch 980/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2194 - mae: 0.1196 - val_loss: 0.1425 - val_mae: 0.1003\n",
            "Epoch 981/2000\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1840 - mae: 0.1128 - val_loss: 0.1431 - val_mae: 0.1006\n",
            "Epoch 982/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1711 - mae: 0.1051 - val_loss: 0.1453 - val_mae: 0.1037\n",
            "Epoch 983/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2323 - mae: 0.1164 - val_loss: 0.1450 - val_mae: 0.1014\n",
            "Epoch 984/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2001 - mae: 0.1086 - val_loss: 0.1418 - val_mae: 0.0993\n",
            "Epoch 985/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3062 - mae: 0.1212 - val_loss: 0.1425 - val_mae: 0.0997\n",
            "Epoch 986/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2335 - mae: 0.1104 - val_loss: 0.1406 - val_mae: 0.1011\n",
            "Epoch 987/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1891 - mae: 0.1099 - val_loss: 0.1424 - val_mae: 0.1005\n",
            "Epoch 988/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2497 - mae: 0.1115 - val_loss: 0.1443 - val_mae: 0.1024\n",
            "Epoch 989/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2322 - mae: 0.1193 - val_loss: 0.1422 - val_mae: 0.1017\n",
            "Epoch 990/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3547 - mae: 0.1277 - val_loss: 0.1437 - val_mae: 0.0999\n",
            "Epoch 991/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1827 - mae: 0.1072 - val_loss: 0.1394 - val_mae: 0.0987\n",
            "Epoch 992/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2784 - mae: 0.1132 - val_loss: 0.1406 - val_mae: 0.0989\n",
            "Epoch 993/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2300 - mae: 0.1169 - val_loss: 0.1406 - val_mae: 0.0994\n",
            "Epoch 994/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1857 - mae: 0.1118 - val_loss: 0.1415 - val_mae: 0.0995\n",
            "Epoch 995/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1821 - mae: 0.1131 - val_loss: 0.1409 - val_mae: 0.0996\n",
            "Epoch 996/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1800 - mae: 0.1077 - val_loss: 0.1409 - val_mae: 0.0986\n",
            "Epoch 997/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3258 - mae: 0.1345 - val_loss: 0.1442 - val_mae: 0.1021\n",
            "Epoch 998/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1922 - mae: 0.1031 - val_loss: 0.1412 - val_mae: 0.1015\n",
            "Epoch 999/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1930 - mae: 0.1149 - val_loss: 0.1407 - val_mae: 0.1011\n",
            "Epoch 1000/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1483 - mae: 0.1054 - val_loss: 0.1401 - val_mae: 0.1005\n",
            "Epoch 1001/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1602 - mae: 0.1005 - val_loss: 0.1425 - val_mae: 0.1004\n",
            "Epoch 1002/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1932 - mae: 0.1037 - val_loss: 0.1433 - val_mae: 0.0998\n",
            "Epoch 1003/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2459 - mae: 0.1185 - val_loss: 0.1425 - val_mae: 0.0990\n",
            "Epoch 1004/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2392 - mae: 0.1079 - val_loss: 0.1430 - val_mae: 0.1004\n",
            "Epoch 1005/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1159 - mae: 0.0888 - val_loss: 0.1407 - val_mae: 0.0997\n",
            "Epoch 1006/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1641 - mae: 0.1089 - val_loss: 0.1422 - val_mae: 0.1000\n",
            "Epoch 1007/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2248 - mae: 0.1085 - val_loss: 0.1456 - val_mae: 0.1013\n",
            "Epoch 1008/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2035 - mae: 0.1100 - val_loss: 0.1440 - val_mae: 0.1031\n",
            "Epoch 1009/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2711 - mae: 0.1279 - val_loss: 0.1403 - val_mae: 0.0982\n",
            "Epoch 1010/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1277 - mae: 0.0927 - val_loss: 0.1400 - val_mae: 0.0997\n",
            "Epoch 1011/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1891 - mae: 0.1034 - val_loss: 0.1438 - val_mae: 0.1013\n",
            "Epoch 1012/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2350 - mae: 0.1159 - val_loss: 0.1442 - val_mae: 0.1022\n",
            "Epoch 1013/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1805 - mae: 0.1004 - val_loss: 0.1420 - val_mae: 0.1020\n",
            "Epoch 1014/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2331 - mae: 0.1202 - val_loss: 0.1401 - val_mae: 0.0996\n",
            "Epoch 1015/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2486 - mae: 0.1201 - val_loss: 0.1434 - val_mae: 0.1002\n",
            "Epoch 1016/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1713 - mae: 0.1039 - val_loss: 0.1412 - val_mae: 0.0987\n",
            "Epoch 1017/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2296 - mae: 0.1150 - val_loss: 0.1450 - val_mae: 0.1035\n",
            "Epoch 1018/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2794 - mae: 0.1251 - val_loss: 0.1436 - val_mae: 0.1008\n",
            "Epoch 1019/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3021 - mae: 0.1243 - val_loss: 0.1447 - val_mae: 0.1021\n",
            "Epoch 1020/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2159 - mae: 0.1110 - val_loss: 0.1413 - val_mae: 0.1006\n",
            "Epoch 1021/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2235 - mae: 0.1172 - val_loss: 0.1411 - val_mae: 0.1024\n",
            "Epoch 1022/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2182 - mae: 0.1057 - val_loss: 0.1407 - val_mae: 0.0991\n",
            "Epoch 1023/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1494 - mae: 0.1014 - val_loss: 0.1392 - val_mae: 0.0968\n",
            "Epoch 1024/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2805 - mae: 0.1169 - val_loss: 0.1445 - val_mae: 0.1024\n",
            "Epoch 1025/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2096 - mae: 0.1073 - val_loss: 0.1437 - val_mae: 0.1005\n",
            "Epoch 1026/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1995 - mae: 0.1173 - val_loss: 0.1398 - val_mae: 0.1004\n",
            "Epoch 1027/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1411 - mae: 0.0990 - val_loss: 0.1565 - val_mae: 0.1252\n",
            "Epoch 1028/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2291 - mae: 0.1312 - val_loss: 0.1464 - val_mae: 0.1124\n",
            "Epoch 1029/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1309 - mae: 0.1027 - val_loss: 0.1468 - val_mae: 0.1117\n",
            "Epoch 1030/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3311 - mae: 0.1321 - val_loss: 0.1431 - val_mae: 0.1049\n",
            "Epoch 1031/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3223 - mae: 0.1327 - val_loss: 0.1446 - val_mae: 0.1055\n",
            "Epoch 1032/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2569 - mae: 0.1293 - val_loss: 0.1415 - val_mae: 0.1014\n",
            "Epoch 1033/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2742 - mae: 0.1245 - val_loss: 0.1420 - val_mae: 0.1038\n",
            "Epoch 1034/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2014 - mae: 0.1141 - val_loss: 0.1400 - val_mae: 0.0988\n",
            "Epoch 1035/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1828 - mae: 0.1106 - val_loss: 0.1403 - val_mae: 0.0988\n",
            "Epoch 1036/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2608 - mae: 0.1147 - val_loss: 0.1432 - val_mae: 0.1001\n",
            "Epoch 1037/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.2018 - mae: 0.1112 - val_loss: 0.1442 - val_mae: 0.1006\n",
            "Epoch 1038/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2422 - mae: 0.1153 - val_loss: 0.1418 - val_mae: 0.1000\n",
            "Epoch 1039/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1435 - mae: 0.0903 - val_loss: 0.1410 - val_mae: 0.1008\n",
            "Epoch 1040/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3026 - mae: 0.1177 - val_loss: 0.1439 - val_mae: 0.1012\n",
            "Epoch 1041/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1738 - mae: 0.1032 - val_loss: 0.1420 - val_mae: 0.0995\n",
            "Epoch 1042/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1723 - mae: 0.0967 - val_loss: 0.1416 - val_mae: 0.0997\n",
            "Epoch 1043/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1446 - mae: 0.0962 - val_loss: 0.1400 - val_mae: 0.0977\n",
            "Epoch 1044/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1671 - mae: 0.0974 - val_loss: 0.1425 - val_mae: 0.0997\n",
            "Epoch 1045/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1698 - mae: 0.1000 - val_loss: 0.1416 - val_mae: 0.0996\n",
            "Epoch 1046/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2300 - mae: 0.1202 - val_loss: 0.1420 - val_mae: 0.0996\n",
            "Epoch 1047/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1965 - mae: 0.1062 - val_loss: 0.1415 - val_mae: 0.0996\n",
            "Epoch 1048/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2093 - mae: 0.1113 - val_loss: 0.1416 - val_mae: 0.1013\n",
            "Epoch 1049/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1901 - mae: 0.0961 - val_loss: 0.1416 - val_mae: 0.0997\n",
            "Epoch 1050/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3004 - mae: 0.1227 - val_loss: 0.1443 - val_mae: 0.1013\n",
            "Epoch 1051/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2699 - mae: 0.1227 - val_loss: 0.1415 - val_mae: 0.1005\n",
            "Epoch 1052/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2219 - mae: 0.1122 - val_loss: 0.1396 - val_mae: 0.1004\n",
            "Epoch 1053/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1978 - mae: 0.1098 - val_loss: 0.1392 - val_mae: 0.1091\n",
            "Epoch 1054/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2642 - mae: 0.1232 - val_loss: 0.1410 - val_mae: 0.1067\n",
            "Epoch 1055/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4088 - mae: 0.1504 - val_loss: 0.1437 - val_mae: 0.1044\n",
            "Epoch 1056/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2481 - mae: 0.1150 - val_loss: 0.1427 - val_mae: 0.0998\n",
            "Epoch 1057/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2901 - mae: 0.1197 - val_loss: 0.1395 - val_mae: 0.0980\n",
            "Epoch 1058/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1586 - mae: 0.0968 - val_loss: 0.1394 - val_mae: 0.0976\n",
            "Epoch 1059/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2410 - mae: 0.1100 - val_loss: 0.1400 - val_mae: 0.1002\n",
            "Epoch 1060/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2367 - mae: 0.1206 - val_loss: 0.1486 - val_mae: 0.1066\n",
            "Epoch 1061/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1740 - mae: 0.1106 - val_loss: 0.1402 - val_mae: 0.1015\n",
            "Epoch 1062/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1285 - mae: 0.0945 - val_loss: 0.1403 - val_mae: 0.0993\n",
            "Epoch 1063/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2070 - mae: 0.1080 - val_loss: 0.1441 - val_mae: 0.1000\n",
            "Epoch 1064/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2600 - mae: 0.1159 - val_loss: 0.1458 - val_mae: 0.1022\n",
            "Epoch 1065/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1403 - mae: 0.0995 - val_loss: 0.1398 - val_mae: 0.0973\n",
            "Epoch 1066/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1566 - mae: 0.1054 - val_loss: 0.1399 - val_mae: 0.0996\n",
            "Epoch 1067/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2814 - mae: 0.1271 - val_loss: 0.1409 - val_mae: 0.1002\n",
            "Epoch 1068/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1536 - mae: 0.1009 - val_loss: 0.1426 - val_mae: 0.1003\n",
            "Epoch 1069/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2403 - mae: 0.1111 - val_loss: 0.1396 - val_mae: 0.0979\n",
            "Epoch 1070/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1954 - mae: 0.1112 - val_loss: 0.1407 - val_mae: 0.0995\n",
            "Epoch 1071/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1621 - mae: 0.0943 - val_loss: 0.1416 - val_mae: 0.1001\n",
            "Epoch 1072/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2872 - mae: 0.1185 - val_loss: 0.1435 - val_mae: 0.1013\n",
            "Epoch 1073/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1683 - mae: 0.0985 - val_loss: 0.1412 - val_mae: 0.0997\n",
            "Epoch 1074/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1715 - mae: 0.0994 - val_loss: 0.1398 - val_mae: 0.0984\n",
            "Epoch 1075/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2987 - mae: 0.1173 - val_loss: 0.1446 - val_mae: 0.1021\n",
            "Epoch 1076/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2934 - mae: 0.1218 - val_loss: 0.1416 - val_mae: 0.1012\n",
            "Epoch 1077/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3134 - mae: 0.1258 - val_loss: 0.1440 - val_mae: 0.1029\n",
            "Epoch 1078/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2340 - mae: 0.1170 - val_loss: 0.1410 - val_mae: 0.0996\n",
            "Epoch 1079/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2113 - mae: 0.1019 - val_loss: 0.1431 - val_mae: 0.0999\n",
            "Epoch 1080/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1922 - mae: 0.1026 - val_loss: 0.1430 - val_mae: 0.1000\n",
            "Epoch 1081/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1454 - mae: 0.1005 - val_loss: 0.1393 - val_mae: 0.0980\n",
            "Epoch 1082/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2302 - mae: 0.1123 - val_loss: 0.1412 - val_mae: 0.0991\n",
            "Epoch 1083/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1559 - mae: 0.0965 - val_loss: 0.1393 - val_mae: 0.0974\n",
            "Epoch 1084/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1295 - mae: 0.0927 - val_loss: 0.1398 - val_mae: 0.0980\n",
            "Epoch 1085/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2328 - mae: 0.1204 - val_loss: 0.1433 - val_mae: 0.0999\n",
            "Epoch 1086/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2494 - mae: 0.1215 - val_loss: 0.1440 - val_mae: 0.1001\n",
            "Epoch 1087/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1933 - mae: 0.1101 - val_loss: 0.1416 - val_mae: 0.0989\n",
            "Epoch 1088/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1927 - mae: 0.1109 - val_loss: 0.1432 - val_mae: 0.1014\n",
            "Epoch 1089/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2817 - mae: 0.1134 - val_loss: 0.1421 - val_mae: 0.0996\n",
            "Epoch 1090/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2836 - mae: 0.1340 - val_loss: 0.1425 - val_mae: 0.0995\n",
            "Epoch 1091/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1360 - mae: 0.0925 - val_loss: 0.1391 - val_mae: 0.0970\n",
            "Epoch 1092/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1345 - mae: 0.0890 - val_loss: 0.1403 - val_mae: 0.0986\n",
            "Epoch 1093/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1869 - mae: 0.1139 - val_loss: 0.1413 - val_mae: 0.1023\n",
            "Epoch 1094/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3868 - mae: 0.1341 - val_loss: 0.1428 - val_mae: 0.1003\n",
            "Epoch 1095/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1984 - mae: 0.1089 - val_loss: 0.1419 - val_mae: 0.0988\n",
            "Epoch 1096/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2253 - mae: 0.1027 - val_loss: 0.1408 - val_mae: 0.0985\n",
            "Epoch 1097/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2220 - mae: 0.1197 - val_loss: 0.1429 - val_mae: 0.1001\n",
            "Epoch 1098/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2390 - mae: 0.1098 - val_loss: 0.1441 - val_mae: 0.1003\n",
            "Epoch 1099/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1336 - mae: 0.0906 - val_loss: 0.1406 - val_mae: 0.0977\n",
            "Epoch 1100/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1727 - mae: 0.1042 - val_loss: 0.1429 - val_mae: 0.1014\n",
            "Epoch 1101/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1758 - mae: 0.1035 - val_loss: 0.1447 - val_mae: 0.1020\n",
            "Epoch 1102/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2022 - mae: 0.1073 - val_loss: 0.1428 - val_mae: 0.0990\n",
            "Epoch 1103/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1826 - mae: 0.0992 - val_loss: 0.1427 - val_mae: 0.0985\n",
            "Epoch 1104/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2467 - mae: 0.1156 - val_loss: 0.1425 - val_mae: 0.0996\n",
            "Epoch 1105/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1731 - mae: 0.1036 - val_loss: 0.1396 - val_mae: 0.0985\n",
            "Epoch 1106/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3073 - mae: 0.1222 - val_loss: 0.1418 - val_mae: 0.1017\n",
            "Epoch 1107/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1969 - mae: 0.1026 - val_loss: 0.1420 - val_mae: 0.0999\n",
            "Epoch 1108/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1997 - mae: 0.1127 - val_loss: 0.1394 - val_mae: 0.0977\n",
            "Epoch 1109/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1358 - mae: 0.0982 - val_loss: 0.1414 - val_mae: 0.1005\n",
            "Epoch 1110/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1429 - mae: 0.0915 - val_loss: 0.1439 - val_mae: 0.1002\n",
            "Epoch 1111/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1806 - mae: 0.1078 - val_loss: 0.1425 - val_mae: 0.0998\n",
            "Epoch 1112/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1613 - mae: 0.1028 - val_loss: 0.1435 - val_mae: 0.1009\n",
            "Epoch 1113/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2269 - mae: 0.1149 - val_loss: 0.1403 - val_mae: 0.0982\n",
            "Epoch 1114/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2775 - mae: 0.1191 - val_loss: 0.1420 - val_mae: 0.0984\n",
            "Epoch 1115/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1770 - mae: 0.1047 - val_loss: 0.1425 - val_mae: 0.0996\n",
            "Epoch 1116/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1814 - mae: 0.1030 - val_loss: 0.1421 - val_mae: 0.0994\n",
            "Epoch 1117/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1568 - mae: 0.1023 - val_loss: 0.1420 - val_mae: 0.0980\n",
            "Epoch 1118/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1214 - mae: 0.0881 - val_loss: 0.1410 - val_mae: 0.0988\n",
            "Epoch 1119/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1860 - mae: 0.1090 - val_loss: 0.1420 - val_mae: 0.0996\n",
            "Epoch 1120/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1861 - mae: 0.1019 - val_loss: 0.1426 - val_mae: 0.0991\n",
            "Epoch 1121/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1463 - mae: 0.0919 - val_loss: 0.1420 - val_mae: 0.0987\n",
            "Epoch 1122/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2312 - mae: 0.1133 - val_loss: 0.1451 - val_mae: 0.0998\n",
            "Epoch 1123/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1878 - mae: 0.1078 - val_loss: 0.1420 - val_mae: 0.0993\n",
            "Epoch 1124/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1640 - mae: 0.0968 - val_loss: 0.1414 - val_mae: 0.0983\n",
            "Epoch 1125/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3003 - mae: 0.1175 - val_loss: 0.1431 - val_mae: 0.1000\n",
            "Epoch 1126/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1678 - mae: 0.1018 - val_loss: 0.1392 - val_mae: 0.0967\n",
            "Epoch 1127/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3158 - mae: 0.1227 - val_loss: 0.1408 - val_mae: 0.0989\n",
            "Epoch 1128/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2768 - mae: 0.1126 - val_loss: 0.1420 - val_mae: 0.0992\n",
            "Epoch 1129/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2172 - mae: 0.1109 - val_loss: 0.1425 - val_mae: 0.1006\n",
            "Epoch 1130/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2490 - mae: 0.1171 - val_loss: 0.1429 - val_mae: 0.1007\n",
            "Epoch 1131/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2241 - mae: 0.1088 - val_loss: 0.1423 - val_mae: 0.1005\n",
            "Epoch 1132/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1916 - mae: 0.1030 - val_loss: 0.1400 - val_mae: 0.0976\n",
            "Epoch 1133/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3070 - mae: 0.1134 - val_loss: 0.1421 - val_mae: 0.0978\n",
            "Epoch 1134/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2662 - mae: 0.1159 - val_loss: 0.1416 - val_mae: 0.0993\n",
            "Epoch 1135/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3298 - mae: 0.1228 - val_loss: 0.1400 - val_mae: 0.0987\n",
            "Epoch 1136/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2117 - mae: 0.1054 - val_loss: 0.1398 - val_mae: 0.0994\n",
            "Epoch 1137/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3276 - mae: 0.1256 - val_loss: 0.1415 - val_mae: 0.1006\n",
            "Epoch 1138/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2079 - mae: 0.1121 - val_loss: 0.1416 - val_mae: 0.0995\n",
            "Epoch 1139/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3798 - mae: 0.1348 - val_loss: 0.1419 - val_mae: 0.0994\n",
            "Epoch 1140/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1974 - mae: 0.1102 - val_loss: 0.1392 - val_mae: 0.0983\n",
            "Epoch 1141/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1427 - mae: 0.0936 - val_loss: 0.1405 - val_mae: 0.0983\n",
            "Epoch 1142/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2175 - mae: 0.1143 - val_loss: 0.1421 - val_mae: 0.0991\n",
            "Epoch 1143/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2190 - mae: 0.1126 - val_loss: 0.1420 - val_mae: 0.0989\n",
            "Epoch 1144/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2435 - mae: 0.1178 - val_loss: 0.1425 - val_mae: 0.0991\n",
            "Epoch 1145/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2188 - mae: 0.1194 - val_loss: 0.1415 - val_mae: 0.0978\n",
            "Epoch 1146/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2542 - mae: 0.1143 - val_loss: 0.1440 - val_mae: 0.1000\n",
            "Epoch 1147/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2518 - mae: 0.1117 - val_loss: 0.1417 - val_mae: 0.0987\n",
            "Epoch 1148/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1828 - mae: 0.1035 - val_loss: 0.1425 - val_mae: 0.0989\n",
            "Epoch 1149/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3100 - mae: 0.1218 - val_loss: 0.1433 - val_mae: 0.1008\n",
            "Epoch 1150/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3047 - mae: 0.1301 - val_loss: 0.1431 - val_mae: 0.1034\n",
            "Epoch 1151/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2471 - mae: 0.1182 - val_loss: 0.1424 - val_mae: 0.1001\n",
            "Epoch 1152/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1720 - mae: 0.1112 - val_loss: 0.1391 - val_mae: 0.0968\n",
            "Epoch 1153/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1571 - mae: 0.0969 - val_loss: 0.1410 - val_mae: 0.0983\n",
            "Epoch 1154/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2429 - mae: 0.1166 - val_loss: 0.1406 - val_mae: 0.0986\n",
            "Epoch 1155/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2256 - mae: 0.1149 - val_loss: 0.1403 - val_mae: 0.0973\n",
            "Epoch 1156/2000\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.2309 - mae: 0.1066 - val_loss: 0.1419 - val_mae: 0.0984\n",
            "Epoch 1157/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2597 - mae: 0.1149 - val_loss: 0.1414 - val_mae: 0.0986\n",
            "Epoch 1158/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1248 - mae: 0.0915 - val_loss: 0.1414 - val_mae: 0.0984\n",
            "Epoch 1159/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1914 - mae: 0.1175 - val_loss: 0.1454 - val_mae: 0.1014\n",
            "Epoch 1160/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2682 - mae: 0.1144 - val_loss: 0.1447 - val_mae: 0.0994\n",
            "Epoch 1161/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2066 - mae: 0.1076 - val_loss: 0.1412 - val_mae: 0.0994\n",
            "Epoch 1162/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1388 - mae: 0.0952 - val_loss: 0.1419 - val_mae: 0.0993\n",
            "Epoch 1163/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1886 - mae: 0.1081 - val_loss: 0.1422 - val_mae: 0.0995\n",
            "Epoch 1164/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1576 - mae: 0.0959 - val_loss: 0.1434 - val_mae: 0.0993\n",
            "Epoch 1165/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1977 - mae: 0.1167 - val_loss: 0.1415 - val_mae: 0.1004\n",
            "Epoch 1166/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1831 - mae: 0.1026 - val_loss: 0.1409 - val_mae: 0.0984\n",
            "Epoch 1167/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2465 - mae: 0.1128 - val_loss: 0.1418 - val_mae: 0.1006\n",
            "Epoch 1168/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2841 - mae: 0.1214 - val_loss: 0.1402 - val_mae: 0.1041\n",
            "Epoch 1169/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3263 - mae: 0.1306 - val_loss: 0.1413 - val_mae: 0.1040\n",
            "Epoch 1170/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3462 - mae: 0.1293 - val_loss: 0.1407 - val_mae: 0.1079\n",
            "Epoch 1171/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3258 - mae: 0.1231 - val_loss: 0.1412 - val_mae: 0.1033\n",
            "Epoch 1172/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1262 - mae: 0.0890 - val_loss: 0.1396 - val_mae: 0.1024\n",
            "Epoch 1173/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1696 - mae: 0.1058 - val_loss: 0.1410 - val_mae: 0.1006\n",
            "Epoch 1174/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1910 - mae: 0.1043 - val_loss: 0.1419 - val_mae: 0.1002\n",
            "Epoch 1175/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1981 - mae: 0.1019 - val_loss: 0.1447 - val_mae: 0.1004\n",
            "Epoch 1176/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2579 - mae: 0.1185 - val_loss: 0.1426 - val_mae: 0.1009\n",
            "Epoch 1177/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2132 - mae: 0.1097 - val_loss: 0.1422 - val_mae: 0.1021\n",
            "Epoch 1178/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2383 - mae: 0.1112 - val_loss: 0.1414 - val_mae: 0.0999\n",
            "Epoch 1179/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1279 - mae: 0.0939 - val_loss: 0.1405 - val_mae: 0.1001\n",
            "Epoch 1180/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1724 - mae: 0.1068 - val_loss: 0.1413 - val_mae: 0.0980\n",
            "Epoch 1181/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3096 - mae: 0.1255 - val_loss: 0.1427 - val_mae: 0.1000\n",
            "Epoch 1182/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2309 - mae: 0.1149 - val_loss: 0.1426 - val_mae: 0.0993\n",
            "Epoch 1183/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1605 - mae: 0.1015 - val_loss: 0.1408 - val_mae: 0.0976\n",
            "Epoch 1184/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2865 - mae: 0.1177 - val_loss: 0.1420 - val_mae: 0.0989\n",
            "Epoch 1185/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2530 - mae: 0.1183 - val_loss: 0.1438 - val_mae: 0.1007\n",
            "Epoch 1186/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2005 - mae: 0.1093 - val_loss: 0.1413 - val_mae: 0.0994\n",
            "Epoch 1187/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1764 - mae: 0.1082 - val_loss: 0.1409 - val_mae: 0.0989\n",
            "Epoch 1188/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1523 - mae: 0.0969 - val_loss: 0.1408 - val_mae: 0.0979\n",
            "Epoch 1189/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1654 - mae: 0.0978 - val_loss: 0.1435 - val_mae: 0.1006\n",
            "Epoch 1190/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2716 - mae: 0.1110 - val_loss: 0.1439 - val_mae: 0.1001\n",
            "Epoch 1191/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3000 - mae: 0.1191 - val_loss: 0.1408 - val_mae: 0.0987\n",
            "Epoch 1192/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2832 - mae: 0.1209 - val_loss: 0.1408 - val_mae: 0.0982\n",
            "Epoch 1193/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2964 - mae: 0.1175 - val_loss: 0.1426 - val_mae: 0.1005\n",
            "Epoch 1194/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2029 - mae: 0.1033 - val_loss: 0.1405 - val_mae: 0.0979\n",
            "Epoch 1195/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1557 - mae: 0.1003 - val_loss: 0.1397 - val_mae: 0.0986\n",
            "Epoch 1196/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1638 - mae: 0.1039 - val_loss: 0.1407 - val_mae: 0.0978\n",
            "Epoch 1197/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2292 - mae: 0.1212 - val_loss: 0.1447 - val_mae: 0.1002\n",
            "Epoch 1198/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1857 - mae: 0.1029 - val_loss: 0.1427 - val_mae: 0.0989\n",
            "Epoch 1199/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1952 - mae: 0.1029 - val_loss: 0.1413 - val_mae: 0.0993\n",
            "Epoch 1200/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2420 - mae: 0.1106 - val_loss: 0.1421 - val_mae: 0.0997\n",
            "Epoch 1201/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3133 - mae: 0.1246 - val_loss: 0.1429 - val_mae: 0.1024\n",
            "Epoch 1202/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1546 - mae: 0.0969 - val_loss: 0.1410 - val_mae: 0.0987\n",
            "Epoch 1203/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2218 - mae: 0.1133 - val_loss: 0.1417 - val_mae: 0.0989\n",
            "Epoch 1204/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1614 - mae: 0.0973 - val_loss: 0.1410 - val_mae: 0.0998\n",
            "Epoch 1205/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3065 - mae: 0.1216 - val_loss: 0.1413 - val_mae: 0.0992\n",
            "Epoch 1206/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1803 - mae: 0.1023 - val_loss: 0.1419 - val_mae: 0.1004\n",
            "Epoch 1207/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1334 - mae: 0.0923 - val_loss: 0.1396 - val_mae: 0.0972\n",
            "Epoch 1208/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1701 - mae: 0.1049 - val_loss: 0.1431 - val_mae: 0.0997\n",
            "Epoch 1209/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1844 - mae: 0.1123 - val_loss: 0.1460 - val_mae: 0.1004\n",
            "Epoch 1210/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2349 - mae: 0.1119 - val_loss: 0.1429 - val_mae: 0.0991\n",
            "Epoch 1211/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1956 - mae: 0.1052 - val_loss: 0.1416 - val_mae: 0.0985\n",
            "Epoch 1212/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1602 - mae: 0.1000 - val_loss: 0.1406 - val_mae: 0.0976\n",
            "Epoch 1213/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1276 - mae: 0.0934 - val_loss: 0.1405 - val_mae: 0.0978\n",
            "Epoch 1214/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2242 - mae: 0.1086 - val_loss: 0.1437 - val_mae: 0.1008\n",
            "Epoch 1215/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1601 - mae: 0.1022 - val_loss: 0.1432 - val_mae: 0.0997\n",
            "Epoch 1216/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1600 - mae: 0.1002 - val_loss: 0.1429 - val_mae: 0.0993\n",
            "Epoch 1217/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2263 - mae: 0.1190 - val_loss: 0.1431 - val_mae: 0.0997\n",
            "Epoch 1218/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3178 - mae: 0.1253 - val_loss: 0.1445 - val_mae: 0.0998\n",
            "Epoch 1219/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1286 - mae: 0.0941 - val_loss: 0.1391 - val_mae: 0.0970\n",
            "Epoch 1220/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1946 - mae: 0.1095 - val_loss: 0.1437 - val_mae: 0.1006\n",
            "Epoch 1221/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2364 - mae: 0.1246 - val_loss: 0.1434 - val_mae: 0.1001\n",
            "Epoch 1222/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1934 - mae: 0.1047 - val_loss: 0.1433 - val_mae: 0.0996\n",
            "Epoch 1223/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2006 - mae: 0.1117 - val_loss: 0.1422 - val_mae: 0.0991\n",
            "Epoch 1224/2000\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.2231 - mae: 0.1206 - val_loss: 0.1420 - val_mae: 0.0990\n",
            "Epoch 1225/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2274 - mae: 0.1047 - val_loss: 0.1452 - val_mae: 0.0998\n",
            "Epoch 1226/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2270 - mae: 0.1117 - val_loss: 0.1416 - val_mae: 0.0993\n",
            "Epoch 1227/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2895 - mae: 0.1131 - val_loss: 0.1412 - val_mae: 0.0976\n",
            "Epoch 1228/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2318 - mae: 0.1068 - val_loss: 0.1404 - val_mae: 0.0975\n",
            "Epoch 1229/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1935 - mae: 0.0997 - val_loss: 0.1423 - val_mae: 0.0993\n",
            "Epoch 1230/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1701 - mae: 0.1009 - val_loss: 0.1417 - val_mae: 0.0983\n",
            "Epoch 1231/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1964 - mae: 0.1079 - val_loss: 0.1433 - val_mae: 0.1008\n",
            "Epoch 1232/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1958 - mae: 0.1115 - val_loss: 0.1431 - val_mae: 0.1014\n",
            "Epoch 1233/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2225 - mae: 0.1051 - val_loss: 0.1409 - val_mae: 0.0980\n",
            "Epoch 1234/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1488 - mae: 0.1044 - val_loss: 0.1403 - val_mae: 0.0981\n",
            "Epoch 1235/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2328 - mae: 0.1131 - val_loss: 0.1446 - val_mae: 0.1001\n",
            "Epoch 1236/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2275 - mae: 0.1190 - val_loss: 0.1418 - val_mae: 0.0993\n",
            "Epoch 1237/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3717 - mae: 0.1360 - val_loss: 0.1435 - val_mae: 0.1000\n",
            "Epoch 1238/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1886 - mae: 0.1016 - val_loss: 0.1432 - val_mae: 0.0997\n",
            "Epoch 1239/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1347 - mae: 0.0989 - val_loss: 0.1398 - val_mae: 0.0985\n",
            "Epoch 1240/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2030 - mae: 0.1038 - val_loss: 0.1410 - val_mae: 0.0983\n",
            "Epoch 1241/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2488 - mae: 0.1161 - val_loss: 0.1433 - val_mae: 0.0992\n",
            "Epoch 1242/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1634 - mae: 0.1002 - val_loss: 0.1415 - val_mae: 0.0983\n",
            "Epoch 1243/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3043 - mae: 0.1155 - val_loss: 0.1443 - val_mae: 0.1000\n",
            "Epoch 1244/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1975 - mae: 0.1094 - val_loss: 0.1401 - val_mae: 0.0974\n",
            "Epoch 1245/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2380 - mae: 0.1105 - val_loss: 0.1409 - val_mae: 0.0985\n",
            "Epoch 1246/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2818 - mae: 0.1296 - val_loss: 0.1409 - val_mae: 0.1006\n",
            "Epoch 1247/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2866 - mae: 0.1037 - val_loss: 0.1456 - val_mae: 0.1006\n",
            "Epoch 1248/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2029 - mae: 0.1201 - val_loss: 0.1397 - val_mae: 0.0972\n",
            "Epoch 1249/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2159 - mae: 0.1092 - val_loss: 0.1413 - val_mae: 0.0987\n",
            "Epoch 1250/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1840 - mae: 0.1021 - val_loss: 0.1403 - val_mae: 0.0977\n",
            "Epoch 1251/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1623 - mae: 0.0994 - val_loss: 0.1396 - val_mae: 0.0978\n",
            "Epoch 1252/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2887 - mae: 0.1190 - val_loss: 0.1432 - val_mae: 0.1008\n",
            "Epoch 1253/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1851 - mae: 0.1067 - val_loss: 0.1425 - val_mae: 0.1006\n",
            "Epoch 1254/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2431 - mae: 0.1091 - val_loss: 0.1429 - val_mae: 0.0995\n",
            "Epoch 1255/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1784 - mae: 0.1120 - val_loss: 0.1404 - val_mae: 0.0972\n",
            "Epoch 1256/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2104 - mae: 0.1138 - val_loss: 0.1428 - val_mae: 0.1003\n",
            "Epoch 1257/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2051 - mae: 0.1052 - val_loss: 0.1435 - val_mae: 0.0995\n",
            "Epoch 1258/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2177 - mae: 0.1058 - val_loss: 0.1417 - val_mae: 0.0985\n",
            "Epoch 1259/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2654 - mae: 0.1190 - val_loss: 0.1404 - val_mae: 0.0983\n",
            "Epoch 1260/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2295 - mae: 0.1102 - val_loss: 0.1412 - val_mae: 0.0982\n",
            "Epoch 1261/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2732 - mae: 0.1184 - val_loss: 0.1421 - val_mae: 0.0998\n",
            "Epoch 1262/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2509 - mae: 0.1159 - val_loss: 0.1420 - val_mae: 0.0990\n",
            "Epoch 1263/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2898 - mae: 0.1151 - val_loss: 0.1406 - val_mae: 0.0990\n",
            "Epoch 1264/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2787 - mae: 0.1218 - val_loss: 0.1435 - val_mae: 0.0991\n",
            "Epoch 1265/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2701 - mae: 0.1214 - val_loss: 0.1419 - val_mae: 0.0984\n",
            "Epoch 1266/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1859 - mae: 0.0992 - val_loss: 0.1409 - val_mae: 0.0983\n",
            "Epoch 1267/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1687 - mae: 0.1043 - val_loss: 0.1404 - val_mae: 0.0974\n",
            "Epoch 1268/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2005 - mae: 0.1011 - val_loss: 0.1430 - val_mae: 0.0995\n",
            "Epoch 1269/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2440 - mae: 0.1080 - val_loss: 0.1426 - val_mae: 0.1006\n",
            "Epoch 1270/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2671 - mae: 0.1138 - val_loss: 0.1422 - val_mae: 0.0995\n",
            "Epoch 1271/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2849 - mae: 0.1181 - val_loss: 0.1403 - val_mae: 0.0993\n",
            "Epoch 1272/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1810 - mae: 0.1100 - val_loss: 0.1403 - val_mae: 0.0998\n",
            "Epoch 1273/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1404 - mae: 0.0958 - val_loss: 0.1404 - val_mae: 0.0972\n",
            "Epoch 1274/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2712 - mae: 0.1191 - val_loss: 0.1417 - val_mae: 0.0990\n",
            "Epoch 1275/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2234 - mae: 0.1063 - val_loss: 0.1430 - val_mae: 0.0989\n",
            "Epoch 1276/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2093 - mae: 0.1127 - val_loss: 0.1408 - val_mae: 0.0969\n",
            "Epoch 1277/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2225 - mae: 0.1090 - val_loss: 0.1421 - val_mae: 0.1004\n",
            "Epoch 1278/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1347 - mae: 0.0986 - val_loss: 0.1424 - val_mae: 0.1031\n",
            "Epoch 1279/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3250 - mae: 0.1263 - val_loss: 0.1444 - val_mae: 0.1035\n",
            "Epoch 1280/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1464 - mae: 0.0967 - val_loss: 0.1414 - val_mae: 0.0991\n",
            "Epoch 1281/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2792 - mae: 0.1190 - val_loss: 0.1408 - val_mae: 0.0982\n",
            "Epoch 1282/2000\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1777 - mae: 0.1084 - val_loss: 0.1387 - val_mae: 0.0970\n",
            "Epoch 1283/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1357 - mae: 0.1047 - val_loss: 0.1397 - val_mae: 0.0994\n",
            "Epoch 1284/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2318 - mae: 0.1138 - val_loss: 0.1460 - val_mae: 0.1009\n",
            "Epoch 1285/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1795 - mae: 0.1078 - val_loss: 0.1440 - val_mae: 0.1010\n",
            "Epoch 1286/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2818 - mae: 0.1162 - val_loss: 0.1409 - val_mae: 0.1002\n",
            "Epoch 1287/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3001 - mae: 0.1204 - val_loss: 0.1418 - val_mae: 0.0997\n",
            "Epoch 1288/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2041 - mae: 0.1063 - val_loss: 0.1430 - val_mae: 0.1005\n",
            "Epoch 1289/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1664 - mae: 0.1052 - val_loss: 0.1403 - val_mae: 0.0985\n",
            "Epoch 1290/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1710 - mae: 0.1048 - val_loss: 0.1407 - val_mae: 0.0979\n",
            "Epoch 1291/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1942 - mae: 0.1107 - val_loss: 0.1423 - val_mae: 0.0986\n",
            "Epoch 1292/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1856 - mae: 0.1053 - val_loss: 0.1435 - val_mae: 0.0994\n",
            "Epoch 1293/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2211 - mae: 0.1049 - val_loss: 0.1437 - val_mae: 0.1007\n",
            "Epoch 1294/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1187 - mae: 0.0930 - val_loss: 0.1411 - val_mae: 0.0973\n",
            "Epoch 1295/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1154 - mae: 0.0882 - val_loss: 0.1424 - val_mae: 0.0981\n",
            "Epoch 1296/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2473 - mae: 0.1146 - val_loss: 0.1445 - val_mae: 0.0996\n",
            "Epoch 1297/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2094 - mae: 0.1078 - val_loss: 0.1435 - val_mae: 0.1003\n",
            "Epoch 1298/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2219 - mae: 0.1189 - val_loss: 0.1426 - val_mae: 0.0985\n",
            "Epoch 1299/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1544 - mae: 0.1031 - val_loss: 0.1412 - val_mae: 0.0983\n",
            "Epoch 1300/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2065 - mae: 0.1081 - val_loss: 0.1408 - val_mae: 0.0983\n",
            "Epoch 1301/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1351 - mae: 0.0983 - val_loss: 0.1403 - val_mae: 0.0980\n",
            "Epoch 1302/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2252 - mae: 0.1142 - val_loss: 0.1432 - val_mae: 0.0999\n",
            "Epoch 1303/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3389 - mae: 0.1308 - val_loss: 0.1440 - val_mae: 0.1000\n",
            "Epoch 1304/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2329 - mae: 0.1092 - val_loss: 0.1427 - val_mae: 0.1008\n",
            "Epoch 1305/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2848 - mae: 0.1292 - val_loss: 0.1421 - val_mae: 0.0981\n",
            "Epoch 1306/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3107 - mae: 0.1249 - val_loss: 0.1413 - val_mae: 0.0986\n",
            "Epoch 1307/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1454 - mae: 0.0955 - val_loss: 0.1394 - val_mae: 0.0972\n",
            "Epoch 1308/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1492 - mae: 0.0937 - val_loss: 0.1410 - val_mae: 0.0991\n",
            "Epoch 1309/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1497 - mae: 0.1029 - val_loss: 0.1422 - val_mae: 0.0983\n",
            "Epoch 1310/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1492 - mae: 0.0970 - val_loss: 0.1407 - val_mae: 0.0999\n",
            "Epoch 1311/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1649 - mae: 0.1143 - val_loss: 0.1422 - val_mae: 0.1022\n",
            "Epoch 1312/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2704 - mae: 0.1120 - val_loss: 0.1433 - val_mae: 0.1007\n",
            "Epoch 1313/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1803 - mae: 0.1121 - val_loss: 0.1404 - val_mae: 0.0989\n",
            "Epoch 1314/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2522 - mae: 0.1183 - val_loss: 0.1432 - val_mae: 0.0997\n",
            "Epoch 1315/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2127 - mae: 0.1091 - val_loss: 0.1414 - val_mae: 0.0977\n",
            "Epoch 1316/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2586 - mae: 0.1179 - val_loss: 0.1429 - val_mae: 0.0994\n",
            "Epoch 1317/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2062 - mae: 0.1006 - val_loss: 0.1408 - val_mae: 0.0989\n",
            "Epoch 1318/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2401 - mae: 0.1059 - val_loss: 0.1411 - val_mae: 0.0985\n",
            "Epoch 1319/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1556 - mae: 0.0957 - val_loss: 0.1413 - val_mae: 0.0986\n",
            "Epoch 1320/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1889 - mae: 0.1081 - val_loss: 0.1419 - val_mae: 0.0986\n",
            "Epoch 1321/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1591 - mae: 0.1078 - val_loss: 0.1410 - val_mae: 0.0985\n",
            "Epoch 1322/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1779 - mae: 0.0938 - val_loss: 0.1418 - val_mae: 0.0986\n",
            "Epoch 1323/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2912 - mae: 0.1125 - val_loss: 0.1433 - val_mae: 0.0994\n",
            "Epoch 1324/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2121 - mae: 0.1127 - val_loss: 0.1415 - val_mae: 0.0981\n",
            "Epoch 1325/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1792 - mae: 0.1011 - val_loss: 0.1429 - val_mae: 0.0984\n",
            "Epoch 1326/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1955 - mae: 0.1143 - val_loss: 0.1395 - val_mae: 0.0969\n",
            "Epoch 1327/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1578 - mae: 0.1002 - val_loss: 0.1426 - val_mae: 0.0994\n",
            "Epoch 1328/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1768 - mae: 0.1048 - val_loss: 0.1444 - val_mae: 0.1004\n",
            "Epoch 1329/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2900 - mae: 0.1319 - val_loss: 0.1468 - val_mae: 0.1019\n",
            "Epoch 1330/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2170 - mae: 0.1070 - val_loss: 0.1455 - val_mae: 0.1014\n",
            "Epoch 1331/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1888 - mae: 0.1127 - val_loss: 0.1416 - val_mae: 0.0989\n",
            "Epoch 1332/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1884 - mae: 0.1014 - val_loss: 0.1412 - val_mae: 0.0995\n",
            "Epoch 1333/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2873 - mae: 0.1182 - val_loss: 0.1415 - val_mae: 0.0990\n",
            "Epoch 1334/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1975 - mae: 0.1037 - val_loss: 0.1441 - val_mae: 0.0996\n",
            "Epoch 1335/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2244 - mae: 0.1121 - val_loss: 0.1421 - val_mae: 0.0990\n",
            "Epoch 1336/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2736 - mae: 0.1160 - val_loss: 0.1430 - val_mae: 0.0991\n",
            "Epoch 1337/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1980 - mae: 0.1170 - val_loss: 0.1413 - val_mae: 0.0989\n",
            "Epoch 1338/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2614 - mae: 0.1241 - val_loss: 0.1408 - val_mae: 0.0986\n",
            "Epoch 1339/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2071 - mae: 0.1135 - val_loss: 0.1404 - val_mae: 0.0992\n",
            "Epoch 1340/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3245 - mae: 0.1211 - val_loss: 0.1431 - val_mae: 0.1006\n",
            "Epoch 1341/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2484 - mae: 0.1217 - val_loss: 0.1400 - val_mae: 0.0983\n",
            "Epoch 1342/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1601 - mae: 0.1021 - val_loss: 0.1434 - val_mae: 0.0995\n",
            "Epoch 1343/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1750 - mae: 0.0977 - val_loss: 0.1426 - val_mae: 0.1003\n",
            "Epoch 1344/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3056 - mae: 0.1203 - val_loss: 0.1423 - val_mae: 0.0982\n",
            "Epoch 1345/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2180 - mae: 0.1087 - val_loss: 0.1414 - val_mae: 0.0978\n",
            "Epoch 1346/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2477 - mae: 0.1089 - val_loss: 0.1428 - val_mae: 0.0989\n",
            "Epoch 1347/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1981 - mae: 0.1053 - val_loss: 0.1416 - val_mae: 0.0975\n",
            "Epoch 1348/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3581 - mae: 0.1213 - val_loss: 0.1441 - val_mae: 0.0995\n",
            "Epoch 1349/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1961 - mae: 0.1081 - val_loss: 0.1417 - val_mae: 0.0989\n",
            "Epoch 1350/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2566 - mae: 0.1139 - val_loss: 0.1418 - val_mae: 0.0992\n",
            "Epoch 1351/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2582 - mae: 0.1250 - val_loss: 0.1402 - val_mae: 0.0980\n",
            "Epoch 1352/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1462 - mae: 0.1001 - val_loss: 0.1412 - val_mae: 0.0980\n",
            "Epoch 1353/2000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2860 - mae: 0.1137 - val_loss: 0.1438 - val_mae: 0.0987\n",
            "Epoch 1354/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1412 - mae: 0.0999 - val_loss: 0.1399 - val_mae: 0.0978\n",
            "Epoch 1355/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2669 - mae: 0.1173 - val_loss: 0.1423 - val_mae: 0.0991\n",
            "Epoch 1356/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2003 - mae: 0.1110 - val_loss: 0.1399 - val_mae: 0.0967\n",
            "Epoch 1357/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1542 - mae: 0.0950 - val_loss: 0.1423 - val_mae: 0.0981\n",
            "Epoch 1358/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1719 - mae: 0.0965 - val_loss: 0.1431 - val_mae: 0.0987\n",
            "Epoch 1359/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1632 - mae: 0.0979 - val_loss: 0.1414 - val_mae: 0.0989\n",
            "Epoch 1360/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2664 - mae: 0.1114 - val_loss: 0.1442 - val_mae: 0.1000\n",
            "Epoch 1361/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2756 - mae: 0.1204 - val_loss: 0.1427 - val_mae: 0.1001\n",
            "Epoch 1362/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2434 - mae: 0.1178 - val_loss: 0.1410 - val_mae: 0.1005\n",
            "Epoch 1363/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1678 - mae: 0.0999 - val_loss: 0.1413 - val_mae: 0.0977\n",
            "Epoch 1364/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3271 - mae: 0.1336 - val_loss: 0.1433 - val_mae: 0.1001\n",
            "Epoch 1365/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2553 - mae: 0.1168 - val_loss: 0.1401 - val_mae: 0.0979\n",
            "Epoch 1366/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2271 - mae: 0.1073 - val_loss: 0.1407 - val_mae: 0.0987\n",
            "Epoch 1367/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1701 - mae: 0.1030 - val_loss: 0.1416 - val_mae: 0.0984\n",
            "Epoch 1368/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2189 - mae: 0.1076 - val_loss: 0.1430 - val_mae: 0.0996\n",
            "Epoch 1369/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2386 - mae: 0.1148 - val_loss: 0.1427 - val_mae: 0.0994\n",
            "Epoch 1370/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1766 - mae: 0.1079 - val_loss: 0.1405 - val_mae: 0.1001\n",
            "Epoch 1371/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1324 - mae: 0.0950 - val_loss: 0.1427 - val_mae: 0.0993\n",
            "Epoch 1372/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1434 - mae: 0.0945 - val_loss: 0.1794 - val_mae: 0.1052\n",
            "Epoch 1373/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1981 - mae: 0.1121 - val_loss: 0.1526 - val_mae: 0.1162\n",
            "Epoch 1374/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1577 - mae: 0.1256 - val_loss: 0.1766 - val_mae: 0.1639\n",
            "Epoch 1375/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1633 - mae: 0.1576 - val_loss: 0.1677 - val_mae: 0.1523\n",
            "Epoch 1376/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4161 - mae: 0.1802 - val_loss: 0.1542 - val_mae: 0.1300\n",
            "Epoch 1377/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1610 - mae: 0.1291 - val_loss: 0.1459 - val_mae: 0.1148\n",
            "Epoch 1378/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2415 - mae: 0.1236 - val_loss: 0.1450 - val_mae: 0.1096\n",
            "Epoch 1379/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2001 - mae: 0.1152 - val_loss: 0.1425 - val_mae: 0.1044\n",
            "Epoch 1380/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1628 - mae: 0.1067 - val_loss: 0.1437 - val_mae: 0.1021\n",
            "Epoch 1381/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1596 - mae: 0.1068 - val_loss: 0.1422 - val_mae: 0.1004\n",
            "Epoch 1382/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1848 - mae: 0.1075 - val_loss: 0.1408 - val_mae: 0.0990\n",
            "Epoch 1383/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1466 - mae: 0.0947 - val_loss: 0.1428 - val_mae: 0.0991\n",
            "Epoch 1384/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2750 - mae: 0.1224 - val_loss: 0.1458 - val_mae: 0.1009\n",
            "Epoch 1385/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1704 - mae: 0.1041 - val_loss: 0.1424 - val_mae: 0.0994\n",
            "Epoch 1386/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2651 - mae: 0.1230 - val_loss: 0.1442 - val_mae: 0.1010\n",
            "Epoch 1387/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2265 - mae: 0.1170 - val_loss: 0.1426 - val_mae: 0.0989\n",
            "Epoch 1388/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1606 - mae: 0.1014 - val_loss: 0.1416 - val_mae: 0.0990\n",
            "Epoch 1389/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3257 - mae: 0.1262 - val_loss: 0.1415 - val_mae: 0.0988\n",
            "Epoch 1390/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1259 - mae: 0.0995 - val_loss: 0.1400 - val_mae: 0.0972\n",
            "Epoch 1391/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2229 - mae: 0.1029 - val_loss: 0.1416 - val_mae: 0.0997\n",
            "Epoch 1392/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1734 - mae: 0.1000 - val_loss: 0.1432 - val_mae: 0.0997\n",
            "Epoch 1393/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1864 - mae: 0.1180 - val_loss: 0.1397 - val_mae: 0.0978\n",
            "Epoch 1394/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2230 - mae: 0.1120 - val_loss: 0.1432 - val_mae: 0.0996\n",
            "Epoch 1395/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2145 - mae: 0.1112 - val_loss: 0.1428 - val_mae: 0.0993\n",
            "Epoch 1396/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1959 - mae: 0.1017 - val_loss: 0.1422 - val_mae: 0.0983\n",
            "Epoch 1397/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1927 - mae: 0.0994 - val_loss: 0.1424 - val_mae: 0.0988\n",
            "Epoch 1398/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2101 - mae: 0.1219 - val_loss: 0.1404 - val_mae: 0.0977\n",
            "Epoch 1399/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2287 - mae: 0.1165 - val_loss: 0.1426 - val_mae: 0.0989\n",
            "Epoch 1400/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3579 - mae: 0.1279 - val_loss: 0.1433 - val_mae: 0.0990\n",
            "Epoch 1401/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2343 - mae: 0.1131 - val_loss: 0.1438 - val_mae: 0.1009\n",
            "Epoch 1402/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2381 - mae: 0.1143 - val_loss: 0.1416 - val_mae: 0.0987\n",
            "Epoch 1403/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1447 - mae: 0.0913 - val_loss: 0.1401 - val_mae: 0.0986\n",
            "Epoch 1404/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2660 - mae: 0.1132 - val_loss: 0.1414 - val_mae: 0.0997\n",
            "Epoch 1405/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2592 - mae: 0.1177 - val_loss: 0.1424 - val_mae: 0.0981\n",
            "Epoch 1406/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3484 - mae: 0.1290 - val_loss: 0.1441 - val_mae: 0.1005\n",
            "Epoch 1407/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2684 - mae: 0.1154 - val_loss: 0.1412 - val_mae: 0.0980\n",
            "Epoch 1408/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1342 - mae: 0.1012 - val_loss: 0.1394 - val_mae: 0.0962\n",
            "Epoch 1409/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2191 - mae: 0.1093 - val_loss: 0.1412 - val_mae: 0.0977\n",
            "Epoch 1410/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2657 - mae: 0.1057 - val_loss: 0.1427 - val_mae: 0.0986\n",
            "Epoch 1411/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1892 - mae: 0.1069 - val_loss: 0.1419 - val_mae: 0.0995\n",
            "Epoch 1412/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2772 - mae: 0.1200 - val_loss: 0.1426 - val_mae: 0.0993\n",
            "Epoch 1413/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2492 - mae: 0.1163 - val_loss: 0.1428 - val_mae: 0.0991\n",
            "Epoch 1414/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1489 - mae: 0.0989 - val_loss: 0.1405 - val_mae: 0.0978\n",
            "Epoch 1415/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2186 - mae: 0.1214 - val_loss: 0.1404 - val_mae: 0.0983\n",
            "Epoch 1416/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3280 - mae: 0.1278 - val_loss: 0.1418 - val_mae: 0.0985\n",
            "Epoch 1417/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1913 - mae: 0.1036 - val_loss: 0.1411 - val_mae: 0.0979\n",
            "Epoch 1418/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2079 - mae: 0.1018 - val_loss: 0.1411 - val_mae: 0.0973\n",
            "Epoch 1419/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1885 - mae: 0.1019 - val_loss: 0.1409 - val_mae: 0.0980\n",
            "Epoch 1420/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2345 - mae: 0.1131 - val_loss: 0.1415 - val_mae: 0.0985\n",
            "Epoch 1421/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2130 - mae: 0.1118 - val_loss: 0.1442 - val_mae: 0.1016\n",
            "Epoch 1422/2000\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.2681 - mae: 0.1222 - val_loss: 0.1427 - val_mae: 0.0985\n",
            "Epoch 1423/2000\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.2342 - mae: 0.1148 - val_loss: 0.1415 - val_mae: 0.0981\n",
            "Epoch 1424/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2301 - mae: 0.1150 - val_loss: 0.1407 - val_mae: 0.0980\n",
            "Epoch 1425/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2597 - mae: 0.1185 - val_loss: 0.1431 - val_mae: 0.0998\n",
            "Epoch 1426/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1783 - mae: 0.1006 - val_loss: 0.1418 - val_mae: 0.0980\n",
            "Epoch 1427/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1988 - mae: 0.1016 - val_loss: 0.1408 - val_mae: 0.0983\n",
            "Epoch 1428/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2900 - mae: 0.1183 - val_loss: 0.1426 - val_mae: 0.0982\n",
            "Epoch 1429/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2531 - mae: 0.1125 - val_loss: 0.1416 - val_mae: 0.0978\n",
            "Epoch 1430/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2781 - mae: 0.1130 - val_loss: 0.1417 - val_mae: 0.0980\n",
            "Epoch 1431/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1916 - mae: 0.1029 - val_loss: 0.1407 - val_mae: 0.0974\n",
            "Epoch 1432/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1827 - mae: 0.1013 - val_loss: 0.1398 - val_mae: 0.0979\n",
            "Epoch 1433/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1618 - mae: 0.0928 - val_loss: 0.1410 - val_mae: 0.0992\n",
            "Epoch 1434/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3043 - mae: 0.1176 - val_loss: 0.1433 - val_mae: 0.1009\n",
            "Epoch 1435/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2046 - mae: 0.1018 - val_loss: 0.1418 - val_mae: 0.0980\n",
            "Epoch 1436/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2084 - mae: 0.1147 - val_loss: 0.1411 - val_mae: 0.0973\n",
            "Epoch 1437/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1941 - mae: 0.1075 - val_loss: 0.1420 - val_mae: 0.0978\n",
            "Epoch 1438/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2783 - mae: 0.1126 - val_loss: 0.1451 - val_mae: 0.1013\n",
            "Epoch 1439/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2178 - mae: 0.1120 - val_loss: 0.1416 - val_mae: 0.0985\n",
            "Epoch 1440/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1397 - mae: 0.1017 - val_loss: 0.1405 - val_mae: 0.1006\n",
            "Epoch 1441/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2009 - mae: 0.1090 - val_loss: 0.1416 - val_mae: 0.0980\n",
            "Epoch 1442/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2060 - mae: 0.1052 - val_loss: 0.1418 - val_mae: 0.0986\n",
            "Epoch 1443/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3505 - mae: 0.1227 - val_loss: 0.1450 - val_mae: 0.1004\n",
            "Epoch 1444/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1736 - mae: 0.1055 - val_loss: 0.1403 - val_mae: 0.0967\n",
            "Epoch 1445/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2663 - mae: 0.1071 - val_loss: 0.1400 - val_mae: 0.0967\n",
            "Epoch 1446/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1792 - mae: 0.1005 - val_loss: 0.1414 - val_mae: 0.0976\n",
            "Epoch 1447/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3642 - mae: 0.1350 - val_loss: 0.1432 - val_mae: 0.0992\n",
            "Epoch 1448/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2826 - mae: 0.1191 - val_loss: 0.1416 - val_mae: 0.0974\n",
            "Epoch 1449/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1926 - mae: 0.1085 - val_loss: 0.1410 - val_mae: 0.0971\n",
            "Epoch 1450/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2138 - mae: 0.1042 - val_loss: 0.1418 - val_mae: 0.0992\n",
            "Epoch 1451/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1872 - mae: 0.1033 - val_loss: 0.1411 - val_mae: 0.0974\n",
            "Epoch 1452/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2172 - mae: 0.1057 - val_loss: 0.1417 - val_mae: 0.0978\n",
            "Epoch 1453/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1623 - mae: 0.1020 - val_loss: 0.1420 - val_mae: 0.1001\n",
            "Epoch 1454/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1799 - mae: 0.1085 - val_loss: 0.1421 - val_mae: 0.1005\n",
            "Epoch 1455/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1405 - mae: 0.0981 - val_loss: 0.1410 - val_mae: 0.0994\n",
            "Epoch 1456/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1488 - mae: 0.0946 - val_loss: 0.1425 - val_mae: 0.0981\n",
            "Epoch 1457/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2848 - mae: 0.1250 - val_loss: 0.1435 - val_mae: 0.0997\n",
            "Epoch 1458/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1962 - mae: 0.1160 - val_loss: 0.1423 - val_mae: 0.0989\n",
            "Epoch 1459/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2454 - mae: 0.1192 - val_loss: 0.1446 - val_mae: 0.0989\n",
            "Epoch 1460/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2178 - mae: 0.1128 - val_loss: 0.1413 - val_mae: 0.0987\n",
            "Epoch 1461/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1763 - mae: 0.0908 - val_loss: 0.1422 - val_mae: 0.0979\n",
            "Epoch 1462/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2158 - mae: 0.1064 - val_loss: 0.1405 - val_mae: 0.0966\n",
            "Epoch 1463/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2527 - mae: 0.1082 - val_loss: 0.1429 - val_mae: 0.0987\n",
            "Epoch 1464/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2034 - mae: 0.0956 - val_loss: 0.1420 - val_mae: 0.0975\n",
            "Epoch 1465/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1637 - mae: 0.1022 - val_loss: 0.1423 - val_mae: 0.0982\n",
            "Epoch 1466/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1910 - mae: 0.1055 - val_loss: 0.1420 - val_mae: 0.0979\n",
            "Epoch 1467/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2048 - mae: 0.1081 - val_loss: 0.1413 - val_mae: 0.0972\n",
            "Epoch 1468/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2105 - mae: 0.1110 - val_loss: 0.1424 - val_mae: 0.0990\n",
            "Epoch 1469/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1768 - mae: 0.0985 - val_loss: 0.1428 - val_mae: 0.0999\n",
            "Epoch 1470/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2520 - mae: 0.1065 - val_loss: 0.1429 - val_mae: 0.0987\n",
            "Epoch 1471/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1334 - mae: 0.1007 - val_loss: 0.1401 - val_mae: 0.0973\n",
            "Epoch 1472/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2104 - mae: 0.1071 - val_loss: 0.1410 - val_mae: 0.0993\n",
            "Epoch 1473/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1890 - mae: 0.0975 - val_loss: 0.1420 - val_mae: 0.0980\n",
            "Epoch 1474/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1958 - mae: 0.0983 - val_loss: 0.1421 - val_mae: 0.0980\n",
            "Epoch 1475/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2664 - mae: 0.1185 - val_loss: 0.1441 - val_mae: 0.1011\n",
            "Epoch 1476/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2537 - mae: 0.1116 - val_loss: 0.1428 - val_mae: 0.0995\n",
            "Epoch 1477/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1975 - mae: 0.1077 - val_loss: 0.1418 - val_mae: 0.0998\n",
            "Epoch 1478/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2805 - mae: 0.1188 - val_loss: 0.1414 - val_mae: 0.0985\n",
            "Epoch 1479/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1864 - mae: 0.1028 - val_loss: 0.1428 - val_mae: 0.0992\n",
            "Epoch 1480/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1712 - mae: 0.0993 - val_loss: 0.1414 - val_mae: 0.0977\n",
            "Epoch 1481/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1971 - mae: 0.1057 - val_loss: 0.1412 - val_mae: 0.0969\n",
            "Epoch 1482/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2199 - mae: 0.1038 - val_loss: 0.1436 - val_mae: 0.1003\n",
            "Epoch 1483/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1963 - mae: 0.1051 - val_loss: 0.1415 - val_mae: 0.0973\n",
            "Epoch 1484/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1660 - mae: 0.0990 - val_loss: 0.1413 - val_mae: 0.0979\n",
            "Epoch 1485/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2539 - mae: 0.1151 - val_loss: 0.1425 - val_mae: 0.1008\n",
            "Epoch 1486/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2053 - mae: 0.1074 - val_loss: 0.1415 - val_mae: 0.0997\n",
            "Epoch 1487/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3554 - mae: 0.1328 - val_loss: 0.1409 - val_mae: 0.0974\n",
            "Epoch 1488/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2152 - mae: 0.1043 - val_loss: 0.1415 - val_mae: 0.0978\n",
            "Epoch 1489/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1450 - mae: 0.0941 - val_loss: 0.1416 - val_mae: 0.0985\n",
            "Epoch 1490/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1938 - mae: 0.1056 - val_loss: 0.1422 - val_mae: 0.0985\n",
            "Epoch 1491/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2033 - mae: 0.1063 - val_loss: 0.1420 - val_mae: 0.0983\n",
            "Epoch 1492/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.2880 - mae: 0.1186 - val_loss: 0.1445 - val_mae: 0.0991\n",
            "Epoch 1493/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3166 - mae: 0.1224 - val_loss: 0.1425 - val_mae: 0.0989\n",
            "Epoch 1494/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3815 - mae: 0.1310 - val_loss: 0.1426 - val_mae: 0.0988\n",
            "Epoch 1495/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1864 - mae: 0.1102 - val_loss: 0.1393 - val_mae: 0.0958\n",
            "Epoch 1496/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2368 - mae: 0.1148 - val_loss: 0.1418 - val_mae: 0.0987\n",
            "Epoch 1497/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2052 - mae: 0.1090 - val_loss: 0.1414 - val_mae: 0.0995\n",
            "Epoch 1498/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1660 - mae: 0.1028 - val_loss: 0.1406 - val_mae: 0.0991\n",
            "Epoch 1499/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1756 - mae: 0.1037 - val_loss: 0.1433 - val_mae: 0.1003\n",
            "Epoch 1500/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1779 - mae: 0.1096 - val_loss: 0.1431 - val_mae: 0.1025\n",
            "Epoch 1501/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1937 - mae: 0.1054 - val_loss: 0.1422 - val_mae: 0.1005\n",
            "Epoch 1502/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2563 - mae: 0.1196 - val_loss: 0.1440 - val_mae: 0.0999\n",
            "Epoch 1503/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1708 - mae: 0.1007 - val_loss: 0.1441 - val_mae: 0.0994\n",
            "Epoch 1504/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1841 - mae: 0.1003 - val_loss: 0.1421 - val_mae: 0.0984\n",
            "Epoch 1505/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3159 - mae: 0.1368 - val_loss: 0.1423 - val_mae: 0.0982\n",
            "Epoch 1506/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1627 - mae: 0.0993 - val_loss: 0.1425 - val_mae: 0.0989\n",
            "Epoch 1507/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2482 - mae: 0.1155 - val_loss: 0.1415 - val_mae: 0.0973\n",
            "Epoch 1508/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2487 - mae: 0.1163 - val_loss: 0.1404 - val_mae: 0.0969\n",
            "Epoch 1509/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1794 - mae: 0.1027 - val_loss: 0.1415 - val_mae: 0.0972\n",
            "Epoch 1510/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1897 - mae: 0.1037 - val_loss: 0.1413 - val_mae: 0.0974\n",
            "Epoch 1511/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1888 - mae: 0.0982 - val_loss: 0.1433 - val_mae: 0.0986\n",
            "Epoch 1512/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1642 - mae: 0.1042 - val_loss: 0.1421 - val_mae: 0.1007\n",
            "Epoch 1513/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1805 - mae: 0.1059 - val_loss: 0.1407 - val_mae: 0.0985\n",
            "Epoch 1514/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3789 - mae: 0.1327 - val_loss: 0.1427 - val_mae: 0.0983\n",
            "Epoch 1515/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2043 - mae: 0.1042 - val_loss: 0.1411 - val_mae: 0.0989\n",
            "Epoch 1516/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2179 - mae: 0.1056 - val_loss: 0.1420 - val_mae: 0.1013\n",
            "Epoch 1517/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2531 - mae: 0.1194 - val_loss: 0.1438 - val_mae: 0.1019\n",
            "Epoch 1518/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1425 - mae: 0.0968 - val_loss: 0.1398 - val_mae: 0.0963\n",
            "Epoch 1519/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1728 - mae: 0.0984 - val_loss: 0.1413 - val_mae: 0.0981\n",
            "Epoch 1520/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2276 - mae: 0.1067 - val_loss: 0.1413 - val_mae: 0.0977\n",
            "Epoch 1521/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2011 - mae: 0.1097 - val_loss: 0.1426 - val_mae: 0.0995\n",
            "Epoch 1522/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1990 - mae: 0.1086 - val_loss: 0.1392 - val_mae: 0.0954\n",
            "Epoch 1523/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2122 - mae: 0.1054 - val_loss: 0.1410 - val_mae: 0.0976\n",
            "Epoch 1524/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2740 - mae: 0.1191 - val_loss: 0.1407 - val_mae: 0.0973\n",
            "Epoch 1525/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1463 - mae: 0.0975 - val_loss: 0.1406 - val_mae: 0.0975\n",
            "Epoch 1526/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1372 - mae: 0.0973 - val_loss: 0.1411 - val_mae: 0.0982\n",
            "Epoch 1527/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2313 - mae: 0.1016 - val_loss: 0.1432 - val_mae: 0.0985\n",
            "Epoch 1528/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2689 - mae: 0.1129 - val_loss: 0.1433 - val_mae: 0.0991\n",
            "Epoch 1529/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1811 - mae: 0.1095 - val_loss: 0.1406 - val_mae: 0.0965\n",
            "Epoch 1530/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1619 - mae: 0.1018 - val_loss: 0.1400 - val_mae: 0.0990\n",
            "Epoch 1531/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3664 - mae: 0.1273 - val_loss: 0.1437 - val_mae: 0.1007\n",
            "Epoch 1532/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1959 - mae: 0.1067 - val_loss: 0.1428 - val_mae: 0.1021\n",
            "Epoch 1533/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2980 - mae: 0.1175 - val_loss: 0.1431 - val_mae: 0.1010\n",
            "Epoch 1534/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1928 - mae: 0.1022 - val_loss: 0.1419 - val_mae: 0.0995\n",
            "Epoch 1535/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2026 - mae: 0.1068 - val_loss: 0.1415 - val_mae: 0.0979\n",
            "Epoch 1536/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2925 - mae: 0.1133 - val_loss: 0.1410 - val_mae: 0.0976\n",
            "Epoch 1537/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2275 - mae: 0.1068 - val_loss: 0.1415 - val_mae: 0.0993\n",
            "Epoch 1538/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1480 - mae: 0.1036 - val_loss: 0.1402 - val_mae: 0.0986\n",
            "Epoch 1539/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1548 - mae: 0.1108 - val_loss: 0.1405 - val_mae: 0.0989\n",
            "Epoch 1540/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1722 - mae: 0.1083 - val_loss: 0.1436 - val_mae: 0.1004\n",
            "Epoch 1541/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2301 - mae: 0.1186 - val_loss: 0.1458 - val_mae: 0.1003\n",
            "Epoch 1542/2000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2583 - mae: 0.1111 - val_loss: 0.1437 - val_mae: 0.0984\n",
            "Epoch 1543/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3255 - mae: 0.1205 - val_loss: 0.1425 - val_mae: 0.0983\n",
            "Epoch 1544/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2714 - mae: 0.1151 - val_loss: 0.1430 - val_mae: 0.0985\n",
            "Epoch 1545/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3215 - mae: 0.1342 - val_loss: 0.1409 - val_mae: 0.0974\n",
            "Epoch 1546/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3037 - mae: 0.1228 - val_loss: 0.1428 - val_mae: 0.0982\n",
            "Epoch 1547/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3638 - mae: 0.1276 - val_loss: 0.1420 - val_mae: 0.0972\n",
            "Epoch 1548/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1255 - mae: 0.0840 - val_loss: 0.1397 - val_mae: 0.0959\n",
            "Epoch 1549/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3183 - mae: 0.1214 - val_loss: 0.1423 - val_mae: 0.0981\n",
            "Epoch 1550/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1546 - mae: 0.1026 - val_loss: 0.1391 - val_mae: 0.0970\n",
            "Epoch 1551/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2517 - mae: 0.1077 - val_loss: 0.1436 - val_mae: 0.0999\n",
            "Epoch 1552/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3307 - mae: 0.1365 - val_loss: 0.1420 - val_mae: 0.0989\n",
            "Epoch 1553/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1824 - mae: 0.1074 - val_loss: 0.1417 - val_mae: 0.0970\n",
            "Epoch 1554/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1484 - mae: 0.0957 - val_loss: 0.1407 - val_mae: 0.0968\n",
            "Epoch 1555/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1538 - mae: 0.0851 - val_loss: 0.1422 - val_mae: 0.0974\n",
            "Epoch 1556/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1766 - mae: 0.1040 - val_loss: 0.1418 - val_mae: 0.0981\n",
            "Epoch 1557/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2106 - mae: 0.1025 - val_loss: 0.1421 - val_mae: 0.0982\n",
            "Epoch 1558/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2018 - mae: 0.0989 - val_loss: 0.1428 - val_mae: 0.0990\n",
            "Epoch 1559/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2332 - mae: 0.1191 - val_loss: 0.1404 - val_mae: 0.0970\n",
            "Epoch 1560/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1941 - mae: 0.0901 - val_loss: 0.1443 - val_mae: 0.0990\n",
            "Epoch 1561/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1950 - mae: 0.1112 - val_loss: 0.1411 - val_mae: 0.0972\n",
            "Epoch 1562/2000\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1892 - mae: 0.1040 - val_loss: 0.1413 - val_mae: 0.0976\n",
            "Epoch 1563/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3372 - mae: 0.1240 - val_loss: 0.1418 - val_mae: 0.0974\n",
            "Epoch 1564/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2049 - mae: 0.1029 - val_loss: 0.1408 - val_mae: 0.0969\n",
            "Epoch 1565/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1531 - mae: 0.1038 - val_loss: 0.1387 - val_mae: 0.0954\n",
            "Epoch 1566/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2309 - mae: 0.1129 - val_loss: 0.1421 - val_mae: 0.0989\n",
            "Epoch 1567/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2419 - mae: 0.1170 - val_loss: 0.1409 - val_mae: 0.0976\n",
            "Epoch 1568/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1564 - mae: 0.1026 - val_loss: 0.1418 - val_mae: 0.0996\n",
            "Epoch 1569/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2597 - mae: 0.1186 - val_loss: 0.1431 - val_mae: 0.0987\n",
            "Epoch 1570/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1888 - mae: 0.1008 - val_loss: 0.1423 - val_mae: 0.0980\n",
            "Epoch 1571/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1969 - mae: 0.1039 - val_loss: 0.1421 - val_mae: 0.0977\n",
            "Epoch 1572/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3120 - mae: 0.1217 - val_loss: 0.1428 - val_mae: 0.0999\n",
            "Epoch 1573/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1909 - mae: 0.0997 - val_loss: 0.1435 - val_mae: 0.1003\n",
            "Epoch 1574/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1774 - mae: 0.1000 - val_loss: 0.1427 - val_mae: 0.1000\n",
            "Epoch 1575/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2639 - mae: 0.1164 - val_loss: 0.1432 - val_mae: 0.0986\n",
            "Epoch 1576/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2743 - mae: 0.1156 - val_loss: 0.1419 - val_mae: 0.0981\n",
            "Epoch 1577/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3105 - mae: 0.1184 - val_loss: 0.1439 - val_mae: 0.0998\n",
            "Epoch 1578/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2141 - mae: 0.1129 - val_loss: 0.1408 - val_mae: 0.0973\n",
            "Epoch 1579/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1522 - mae: 0.0964 - val_loss: 0.1410 - val_mae: 0.0983\n",
            "Epoch 1580/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3164 - mae: 0.1217 - val_loss: 0.1414 - val_mae: 0.0979\n",
            "Epoch 1581/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2100 - mae: 0.1140 - val_loss: 0.1437 - val_mae: 0.1012\n",
            "Epoch 1582/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2353 - mae: 0.1158 - val_loss: 0.1414 - val_mae: 0.0992\n",
            "Epoch 1583/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1997 - mae: 0.1007 - val_loss: 0.1413 - val_mae: 0.0978\n",
            "Epoch 1584/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2164 - mae: 0.1072 - val_loss: 0.1416 - val_mae: 0.0974\n",
            "Epoch 1585/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2040 - mae: 0.1008 - val_loss: 0.1437 - val_mae: 0.0989\n",
            "Epoch 1586/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1765 - mae: 0.1017 - val_loss: 0.1423 - val_mae: 0.0989\n",
            "Epoch 1587/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1367 - mae: 0.1010 - val_loss: 0.1409 - val_mae: 0.0981\n",
            "Epoch 1588/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2148 - mae: 0.1104 - val_loss: 0.1428 - val_mae: 0.1006\n",
            "Epoch 1589/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2570 - mae: 0.1261 - val_loss: 0.1420 - val_mae: 0.0998\n",
            "Epoch 1590/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2717 - mae: 0.1213 - val_loss: 0.1433 - val_mae: 0.0988\n",
            "Epoch 1591/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3070 - mae: 0.1333 - val_loss: 0.1425 - val_mae: 0.0980\n",
            "Epoch 1592/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3450 - mae: 0.1220 - val_loss: 0.1424 - val_mae: 0.0977\n",
            "Epoch 1593/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2754 - mae: 0.1059 - val_loss: 0.1409 - val_mae: 0.0972\n",
            "Epoch 1594/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2874 - mae: 0.1166 - val_loss: 0.1405 - val_mae: 0.0987\n",
            "Epoch 1595/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3030 - mae: 0.1262 - val_loss: 0.1398 - val_mae: 0.0966\n",
            "Epoch 1596/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2484 - mae: 0.1096 - val_loss: 0.1429 - val_mae: 0.0984\n",
            "Epoch 1597/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1968 - mae: 0.0958 - val_loss: 0.1423 - val_mae: 0.0977\n",
            "Epoch 1598/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1983 - mae: 0.1048 - val_loss: 0.1414 - val_mae: 0.1004\n",
            "Epoch 1599/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2336 - mae: 0.1102 - val_loss: 0.1410 - val_mae: 0.0978\n",
            "Epoch 1600/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2674 - mae: 0.1172 - val_loss: 0.1417 - val_mae: 0.0974\n",
            "Epoch 1601/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2147 - mae: 0.1160 - val_loss: 0.1399 - val_mae: 0.0973\n",
            "Epoch 1602/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1613 - mae: 0.0932 - val_loss: 0.1399 - val_mae: 0.0976\n",
            "Epoch 1603/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3228 - mae: 0.1288 - val_loss: 0.1421 - val_mae: 0.0981\n",
            "Epoch 1604/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2240 - mae: 0.1109 - val_loss: 0.1413 - val_mae: 0.0970\n",
            "Epoch 1605/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3432 - mae: 0.1243 - val_loss: 0.1412 - val_mae: 0.0969\n",
            "Epoch 1606/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1721 - mae: 0.0948 - val_loss: 0.1409 - val_mae: 0.0973\n",
            "Epoch 1607/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2254 - mae: 0.1138 - val_loss: 0.1412 - val_mae: 0.1010\n",
            "Epoch 1608/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3248 - mae: 0.1403 - val_loss: 0.1427 - val_mae: 0.1014\n",
            "Epoch 1609/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2504 - mae: 0.1234 - val_loss: 0.1427 - val_mae: 0.0997\n",
            "Epoch 1610/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4214 - mae: 0.1386 - val_loss: 0.1417 - val_mae: 0.0984\n",
            "Epoch 1611/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1828 - mae: 0.1054 - val_loss: 0.1406 - val_mae: 0.0969\n",
            "Epoch 1612/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2011 - mae: 0.1092 - val_loss: 0.1413 - val_mae: 0.0974\n",
            "Epoch 1613/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2035 - mae: 0.0996 - val_loss: 0.1424 - val_mae: 0.0983\n",
            "Epoch 1614/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2612 - mae: 0.1205 - val_loss: 0.1422 - val_mae: 0.0990\n",
            "Epoch 1615/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1348 - mae: 0.0964 - val_loss: 0.1399 - val_mae: 0.0971\n",
            "Epoch 1616/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2791 - mae: 0.1149 - val_loss: 0.1434 - val_mae: 0.0997\n",
            "Epoch 1617/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2014 - mae: 0.1053 - val_loss: 0.1412 - val_mae: 0.0970\n",
            "Epoch 1618/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2219 - mae: 0.1131 - val_loss: 0.1417 - val_mae: 0.0973\n",
            "Epoch 1619/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1561 - mae: 0.0961 - val_loss: 0.1413 - val_mae: 0.0978\n",
            "Epoch 1620/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2110 - mae: 0.1102 - val_loss: 0.1422 - val_mae: 0.0991\n",
            "Epoch 1621/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3259 - mae: 0.1245 - val_loss: 0.1419 - val_mae: 0.0980\n",
            "Epoch 1622/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2712 - mae: 0.1228 - val_loss: 0.1499 - val_mae: 0.1129\n",
            "Epoch 1623/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1781 - mae: 0.1079 - val_loss: 0.1459 - val_mae: 0.1143\n",
            "Epoch 1624/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2966 - mae: 0.1370 - val_loss: 0.1412 - val_mae: 0.1080\n",
            "Epoch 1625/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2811 - mae: 0.1272 - val_loss: 0.1437 - val_mae: 0.1047\n",
            "Epoch 1626/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3013 - mae: 0.1233 - val_loss: 0.1426 - val_mae: 0.0996\n",
            "Epoch 1627/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1397 - mae: 0.1001 - val_loss: 0.1400 - val_mae: 0.0968\n",
            "Epoch 1628/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2764 - mae: 0.1212 - val_loss: 0.1427 - val_mae: 0.0990\n",
            "Epoch 1629/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2279 - mae: 0.1109 - val_loss: 0.1423 - val_mae: 0.0990\n",
            "Epoch 1630/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1918 - mae: 0.1030 - val_loss: 0.1418 - val_mae: 0.0982\n",
            "Epoch 1631/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1691 - mae: 0.1007 - val_loss: 0.1401 - val_mae: 0.0964\n",
            "Epoch 1632/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.3568 - mae: 0.1314 - val_loss: 0.1423 - val_mae: 0.0985\n",
            "Epoch 1633/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3008 - mae: 0.1258 - val_loss: 0.1406 - val_mae: 0.0972\n",
            "Epoch 1634/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3406 - mae: 0.1237 - val_loss: 0.1411 - val_mae: 0.0979\n",
            "Epoch 1635/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2097 - mae: 0.0999 - val_loss: 0.1408 - val_mae: 0.0976\n",
            "Epoch 1636/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2384 - mae: 0.1137 - val_loss: 0.1407 - val_mae: 0.0966\n",
            "Epoch 1637/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3308 - mae: 0.1346 - val_loss: 0.1403 - val_mae: 0.0965\n",
            "Epoch 1638/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2783 - mae: 0.1087 - val_loss: 0.1411 - val_mae: 0.0966\n",
            "Epoch 1639/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1935 - mae: 0.1092 - val_loss: 0.1411 - val_mae: 0.0970\n",
            "Epoch 1640/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1803 - mae: 0.1006 - val_loss: 0.1424 - val_mae: 0.0985\n",
            "Epoch 1641/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1890 - mae: 0.1016 - val_loss: 0.1427 - val_mae: 0.0988\n",
            "Epoch 1642/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1403 - mae: 0.1002 - val_loss: 0.1394 - val_mae: 0.0964\n",
            "Epoch 1643/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2483 - mae: 0.1066 - val_loss: 0.1423 - val_mae: 0.0975\n",
            "Epoch 1644/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2145 - mae: 0.1010 - val_loss: 0.1426 - val_mae: 0.0981\n",
            "Epoch 1645/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2942 - mae: 0.1151 - val_loss: 0.1423 - val_mae: 0.0976\n",
            "Epoch 1646/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3254 - mae: 0.1272 - val_loss: 0.1411 - val_mae: 0.0971\n",
            "Epoch 1647/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1653 - mae: 0.0987 - val_loss: 0.1406 - val_mae: 0.0966\n",
            "Epoch 1648/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1762 - mae: 0.0977 - val_loss: 0.1416 - val_mae: 0.0971\n",
            "Epoch 1649/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1687 - mae: 0.0952 - val_loss: 0.1422 - val_mae: 0.0976\n",
            "Epoch 1650/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2816 - mae: 0.1197 - val_loss: 0.1433 - val_mae: 0.0985\n",
            "Epoch 1651/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1711 - mae: 0.1004 - val_loss: 0.1418 - val_mae: 0.0973\n",
            "Epoch 1652/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3363 - mae: 0.1199 - val_loss: 0.1432 - val_mae: 0.0982\n",
            "Epoch 1653/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1869 - mae: 0.0947 - val_loss: 0.1404 - val_mae: 0.0965\n",
            "Epoch 1654/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1721 - mae: 0.0935 - val_loss: 0.1406 - val_mae: 0.0968\n",
            "Epoch 1655/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2628 - mae: 0.1126 - val_loss: 0.1422 - val_mae: 0.0975\n",
            "Epoch 1656/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2397 - mae: 0.1104 - val_loss: 0.1415 - val_mae: 0.0971\n",
            "Epoch 1657/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2221 - mae: 0.1068 - val_loss: 0.1409 - val_mae: 0.0970\n",
            "Epoch 1658/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1764 - mae: 0.1018 - val_loss: 0.1420 - val_mae: 0.0970\n",
            "Epoch 1659/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1979 - mae: 0.1012 - val_loss: 0.1419 - val_mae: 0.0973\n",
            "Epoch 1660/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1879 - mae: 0.1044 - val_loss: 0.1416 - val_mae: 0.0978\n",
            "Epoch 1661/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1914 - mae: 0.1037 - val_loss: 0.1418 - val_mae: 0.0972\n",
            "Epoch 1662/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2045 - mae: 0.1078 - val_loss: 0.1415 - val_mae: 0.0973\n",
            "Epoch 1663/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3016 - mae: 0.1175 - val_loss: 0.1402 - val_mae: 0.0974\n",
            "Epoch 1664/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1810 - mae: 0.0988 - val_loss: 0.1401 - val_mae: 0.0965\n",
            "Epoch 1665/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1800 - mae: 0.1046 - val_loss: 0.1420 - val_mae: 0.0979\n",
            "Epoch 1666/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3605 - mae: 0.1288 - val_loss: 0.1438 - val_mae: 0.0992\n",
            "Epoch 1667/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1726 - mae: 0.0990 - val_loss: 0.1405 - val_mae: 0.0965\n",
            "Epoch 1668/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1785 - mae: 0.1083 - val_loss: 0.1407 - val_mae: 0.0982\n",
            "Epoch 1669/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2022 - mae: 0.0992 - val_loss: 0.1428 - val_mae: 0.0988\n",
            "Epoch 1670/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2300 - mae: 0.1168 - val_loss: 0.1405 - val_mae: 0.0974\n",
            "Epoch 1671/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1955 - mae: 0.1052 - val_loss: 0.1429 - val_mae: 0.0985\n",
            "Epoch 1672/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2434 - mae: 0.1194 - val_loss: 0.1420 - val_mae: 0.0974\n",
            "Epoch 1673/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3209 - mae: 0.1247 - val_loss: 0.1428 - val_mae: 0.0985\n",
            "Epoch 1674/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1751 - mae: 0.1043 - val_loss: 0.1410 - val_mae: 0.0977\n",
            "Epoch 1675/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1728 - mae: 0.1052 - val_loss: 0.1403 - val_mae: 0.0962\n",
            "Epoch 1676/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1691 - mae: 0.1018 - val_loss: 0.1407 - val_mae: 0.0972\n",
            "Epoch 1677/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1705 - mae: 0.0921 - val_loss: 0.1418 - val_mae: 0.0977\n",
            "Epoch 1678/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2507 - mae: 0.1140 - val_loss: 0.1416 - val_mae: 0.0979\n",
            "Epoch 1679/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1149 - mae: 0.0859 - val_loss: 0.1408 - val_mae: 0.0965\n",
            "Epoch 1680/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2670 - mae: 0.1180 - val_loss: 0.1427 - val_mae: 0.0975\n",
            "Epoch 1681/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1935 - mae: 0.1073 - val_loss: 0.1432 - val_mae: 0.0982\n",
            "Epoch 1682/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2548 - mae: 0.1144 - val_loss: 0.1421 - val_mae: 0.0979\n",
            "Epoch 1683/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2432 - mae: 0.1107 - val_loss: 0.1449 - val_mae: 0.0995\n",
            "Epoch 1684/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2068 - mae: 0.1108 - val_loss: 0.1428 - val_mae: 0.0971\n",
            "Epoch 1685/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2466 - mae: 0.1116 - val_loss: 0.1418 - val_mae: 0.0972\n",
            "Epoch 1686/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1796 - mae: 0.1032 - val_loss: 0.1403 - val_mae: 0.0964\n",
            "Epoch 1687/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1384 - mae: 0.0968 - val_loss: 0.1406 - val_mae: 0.0970\n",
            "Epoch 1688/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2615 - mae: 0.1055 - val_loss: 0.1412 - val_mae: 0.0984\n",
            "Epoch 1689/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2469 - mae: 0.1159 - val_loss: 0.1423 - val_mae: 0.0985\n",
            "Epoch 1690/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2388 - mae: 0.1126 - val_loss: 0.1438 - val_mae: 0.0986\n",
            "Epoch 1691/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3370 - mae: 0.1289 - val_loss: 0.1431 - val_mae: 0.0993\n",
            "Epoch 1692/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1768 - mae: 0.1006 - val_loss: 0.1427 - val_mae: 0.0979\n",
            "Epoch 1693/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2922 - mae: 0.1125 - val_loss: 0.1421 - val_mae: 0.0975\n",
            "Epoch 1694/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3436 - mae: 0.1314 - val_loss: 0.1428 - val_mae: 0.0982\n",
            "Epoch 1695/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2596 - mae: 0.1157 - val_loss: 0.1415 - val_mae: 0.0973\n",
            "Epoch 1696/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2231 - mae: 0.1049 - val_loss: 0.1416 - val_mae: 0.0982\n",
            "Epoch 1697/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2113 - mae: 0.1040 - val_loss: 0.1422 - val_mae: 0.0985\n",
            "Epoch 1698/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1983 - mae: 0.1049 - val_loss: 0.1406 - val_mae: 0.0968\n",
            "Epoch 1699/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1891 - mae: 0.1047 - val_loss: 0.1409 - val_mae: 0.0973\n",
            "Epoch 1700/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2001 - mae: 0.0997 - val_loss: 0.1419 - val_mae: 0.0994\n",
            "Epoch 1701/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2007 - mae: 0.1036 - val_loss: 0.1406 - val_mae: 0.0974\n",
            "Epoch 1702/2000\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1151 - mae: 0.0870 - val_loss: 0.1401 - val_mae: 0.0965\n",
            "Epoch 1703/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3077 - mae: 0.1251 - val_loss: 0.1418 - val_mae: 0.0975\n",
            "Epoch 1704/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1597 - mae: 0.1020 - val_loss: 0.1426 - val_mae: 0.0980\n",
            "Epoch 1705/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1478 - mae: 0.0956 - val_loss: 0.1435 - val_mae: 0.0989\n",
            "Epoch 1706/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1785 - mae: 0.1051 - val_loss: 0.1445 - val_mae: 0.0994\n",
            "Epoch 1707/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2340 - mae: 0.1134 - val_loss: 0.1455 - val_mae: 0.1000\n",
            "Epoch 1708/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2919 - mae: 0.1128 - val_loss: 0.1429 - val_mae: 0.0984\n",
            "Epoch 1709/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1747 - mae: 0.1020 - val_loss: 0.1411 - val_mae: 0.0981\n",
            "Epoch 1710/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2331 - mae: 0.1087 - val_loss: 0.1429 - val_mae: 0.0983\n",
            "Epoch 1711/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3092 - mae: 0.1186 - val_loss: 0.1436 - val_mae: 0.0985\n",
            "Epoch 1712/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1894 - mae: 0.1049 - val_loss: 0.1407 - val_mae: 0.1005\n",
            "Epoch 1713/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1910 - mae: 0.1098 - val_loss: 0.1426 - val_mae: 0.1040\n",
            "Epoch 1714/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2473 - mae: 0.1166 - val_loss: 0.1437 - val_mae: 0.1023\n",
            "Epoch 1715/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2105 - mae: 0.1031 - val_loss: 0.1433 - val_mae: 0.0994\n",
            "Epoch 1716/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1710 - mae: 0.1068 - val_loss: 0.1426 - val_mae: 0.0981\n",
            "Epoch 1717/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3376 - mae: 0.1246 - val_loss: 0.1433 - val_mae: 0.0986\n",
            "Epoch 1718/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1546 - mae: 0.1012 - val_loss: 0.1403 - val_mae: 0.0971\n",
            "Epoch 1719/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1517 - mae: 0.0978 - val_loss: 0.1415 - val_mae: 0.1004\n",
            "Epoch 1720/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1618 - mae: 0.0929 - val_loss: 0.1431 - val_mae: 0.0995\n",
            "Epoch 1721/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2008 - mae: 0.1005 - val_loss: 0.1444 - val_mae: 0.0999\n",
            "Epoch 1722/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1455 - mae: 0.0999 - val_loss: 0.1402 - val_mae: 0.0972\n",
            "Epoch 1723/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2170 - mae: 0.1177 - val_loss: 0.1424 - val_mae: 0.0979\n",
            "Epoch 1724/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1811 - mae: 0.1051 - val_loss: 0.1425 - val_mae: 0.0988\n",
            "Epoch 1725/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1783 - mae: 0.0999 - val_loss: 0.1419 - val_mae: 0.0972\n",
            "Epoch 1726/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1720 - mae: 0.0980 - val_loss: 0.1416 - val_mae: 0.0981\n",
            "Epoch 1727/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1395 - mae: 0.0935 - val_loss: 0.1408 - val_mae: 0.0976\n",
            "Epoch 1728/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1475 - mae: 0.0928 - val_loss: 0.1419 - val_mae: 0.0972\n",
            "Epoch 1729/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2981 - mae: 0.1178 - val_loss: 0.1446 - val_mae: 0.1005\n",
            "Epoch 1730/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2000 - mae: 0.1068 - val_loss: 0.1418 - val_mae: 0.0976\n",
            "Epoch 1731/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1498 - mae: 0.0969 - val_loss: 0.1414 - val_mae: 0.0995\n",
            "Epoch 1732/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1740 - mae: 0.1001 - val_loss: 0.1420 - val_mae: 0.0982\n",
            "Epoch 1733/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2499 - mae: 0.1173 - val_loss: 0.1429 - val_mae: 0.0995\n",
            "Epoch 1734/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1231 - mae: 0.0927 - val_loss: 0.1411 - val_mae: 0.0972\n",
            "Epoch 1735/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1666 - mae: 0.1001 - val_loss: 0.1425 - val_mae: 0.0986\n",
            "Epoch 1736/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2109 - mae: 0.1034 - val_loss: 0.1424 - val_mae: 0.0975\n",
            "Epoch 1737/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1910 - mae: 0.1051 - val_loss: 0.1414 - val_mae: 0.0976\n",
            "Epoch 1738/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2895 - mae: 0.1152 - val_loss: 0.1432 - val_mae: 0.0981\n",
            "Epoch 1739/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2026 - mae: 0.1083 - val_loss: 0.1414 - val_mae: 0.0980\n",
            "Epoch 1740/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3737 - mae: 0.1296 - val_loss: 0.1426 - val_mae: 0.0980\n",
            "Epoch 1741/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2649 - mae: 0.1175 - val_loss: 0.1420 - val_mae: 0.0972\n",
            "Epoch 1742/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1870 - mae: 0.1020 - val_loss: 0.1404 - val_mae: 0.0968\n",
            "Epoch 1743/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1950 - mae: 0.1006 - val_loss: 0.1412 - val_mae: 0.0984\n",
            "Epoch 1744/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1870 - mae: 0.1083 - val_loss: 0.1415 - val_mae: 0.0978\n",
            "Epoch 1745/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1971 - mae: 0.1061 - val_loss: 0.1425 - val_mae: 0.0985\n",
            "Epoch 1746/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1723 - mae: 0.1058 - val_loss: 0.1423 - val_mae: 0.0978\n",
            "Epoch 1747/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1471 - mae: 0.1056 - val_loss: 0.1405 - val_mae: 0.0973\n",
            "Epoch 1748/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1675 - mae: 0.0983 - val_loss: 0.1427 - val_mae: 0.0984\n",
            "Epoch 1749/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1979 - mae: 0.1069 - val_loss: 0.1420 - val_mae: 0.0988\n",
            "Epoch 1750/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2833 - mae: 0.1171 - val_loss: 0.1442 - val_mae: 0.0991\n",
            "Epoch 1751/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1547 - mae: 0.0939 - val_loss: 0.1420 - val_mae: 0.0971\n",
            "Epoch 1752/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2439 - mae: 0.1138 - val_loss: 0.1425 - val_mae: 0.0969\n",
            "Epoch 1753/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3304 - mae: 0.1307 - val_loss: 0.1410 - val_mae: 0.0968\n",
            "Epoch 1754/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2784 - mae: 0.1155 - val_loss: 0.1420 - val_mae: 0.0974\n",
            "Epoch 1755/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2960 - mae: 0.1164 - val_loss: 0.1421 - val_mae: 0.0994\n",
            "Epoch 1756/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1867 - mae: 0.1044 - val_loss: 0.1413 - val_mae: 0.0977\n",
            "Epoch 1757/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1678 - mae: 0.0950 - val_loss: 0.1411 - val_mae: 0.0966\n",
            "Epoch 1758/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2156 - mae: 0.1004 - val_loss: 0.1422 - val_mae: 0.0977\n",
            "Epoch 1759/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1772 - mae: 0.0952 - val_loss: 0.1410 - val_mae: 0.0983\n",
            "Epoch 1760/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1756 - mae: 0.1027 - val_loss: 0.1421 - val_mae: 0.0972\n",
            "Epoch 1761/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2798 - mae: 0.1154 - val_loss: 0.1431 - val_mae: 0.0982\n",
            "Epoch 1762/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2065 - mae: 0.1107 - val_loss: 0.1422 - val_mae: 0.0975\n",
            "Epoch 1763/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1622 - mae: 0.0979 - val_loss: 0.1412 - val_mae: 0.0965\n",
            "Epoch 1764/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2375 - mae: 0.1116 - val_loss: 0.1433 - val_mae: 0.0989\n",
            "Epoch 1765/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1722 - mae: 0.1012 - val_loss: 0.1415 - val_mae: 0.0985\n",
            "Epoch 1766/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1563 - mae: 0.0927 - val_loss: 0.1411 - val_mae: 0.0989\n",
            "Epoch 1767/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2294 - mae: 0.1115 - val_loss: 0.1424 - val_mae: 0.0977\n",
            "Epoch 1768/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1343 - mae: 0.0938 - val_loss: 0.1408 - val_mae: 0.0990\n",
            "Epoch 1769/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2553 - mae: 0.1165 - val_loss: 0.1431 - val_mae: 0.1002\n",
            "Epoch 1770/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2472 - mae: 0.1087 - val_loss: 0.1417 - val_mae: 0.0989\n",
            "Epoch 1771/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3238 - mae: 0.1255 - val_loss: 0.1418 - val_mae: 0.0982\n",
            "Epoch 1772/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1608 - mae: 0.0986 - val_loss: 0.1407 - val_mae: 0.0971\n",
            "Epoch 1773/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2274 - mae: 0.1083 - val_loss: 0.1420 - val_mae: 0.1002\n",
            "Epoch 1774/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1988 - mae: 0.1128 - val_loss: 0.1414 - val_mae: 0.0987\n",
            "Epoch 1775/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2264 - mae: 0.1122 - val_loss: 0.1414 - val_mae: 0.0972\n",
            "Epoch 1776/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2233 - mae: 0.0954 - val_loss: 0.1413 - val_mae: 0.0968\n",
            "Epoch 1777/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3255 - mae: 0.1164 - val_loss: 0.1423 - val_mae: 0.0983\n",
            "Epoch 1778/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1686 - mae: 0.1047 - val_loss: 0.1400 - val_mae: 0.0968\n",
            "Epoch 1779/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1503 - mae: 0.1029 - val_loss: 0.1408 - val_mae: 0.0972\n",
            "Epoch 1780/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1934 - mae: 0.1051 - val_loss: 0.1421 - val_mae: 0.0984\n",
            "Epoch 1781/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2718 - mae: 0.1184 - val_loss: 0.1433 - val_mae: 0.0981\n",
            "Epoch 1782/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1984 - mae: 0.1078 - val_loss: 0.1409 - val_mae: 0.0967\n",
            "Epoch 1783/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1546 - mae: 0.0998 - val_loss: 0.1427 - val_mae: 0.0987\n",
            "Epoch 1784/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1969 - mae: 0.1026 - val_loss: 0.1434 - val_mae: 0.0986\n",
            "Epoch 1785/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1871 - mae: 0.1107 - val_loss: 0.1405 - val_mae: 0.0970\n",
            "Epoch 1786/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2169 - mae: 0.1102 - val_loss: 0.1444 - val_mae: 0.1008\n",
            "Epoch 1787/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1782 - mae: 0.0982 - val_loss: 0.1447 - val_mae: 0.1050\n",
            "Epoch 1788/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2369 - mae: 0.1160 - val_loss: 0.1440 - val_mae: 0.1100\n",
            "Epoch 1789/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1600 - mae: 0.1147 - val_loss: 0.1413 - val_mae: 0.1040\n",
            "Epoch 1790/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2641 - mae: 0.1267 - val_loss: 0.1423 - val_mae: 0.0992\n",
            "Epoch 1791/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1867 - mae: 0.1117 - val_loss: 0.1415 - val_mae: 0.0993\n",
            "Epoch 1792/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2289 - mae: 0.1097 - val_loss: 0.1431 - val_mae: 0.1002\n",
            "Epoch 1793/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1631 - mae: 0.1042 - val_loss: 0.1422 - val_mae: 0.0988\n",
            "Epoch 1794/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1822 - mae: 0.0960 - val_loss: 0.1424 - val_mae: 0.0991\n",
            "Epoch 1795/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2409 - mae: 0.1079 - val_loss: 0.1435 - val_mae: 0.0989\n",
            "Epoch 1796/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2677 - mae: 0.1198 - val_loss: 0.1418 - val_mae: 0.0987\n",
            "Epoch 1797/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2640 - mae: 0.1275 - val_loss: 0.1411 - val_mae: 0.0979\n",
            "Epoch 1798/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1913 - mae: 0.1096 - val_loss: 0.1402 - val_mae: 0.0969\n",
            "Epoch 1799/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2585 - mae: 0.1085 - val_loss: 0.1420 - val_mae: 0.0981\n",
            "Epoch 1800/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2640 - mae: 0.1203 - val_loss: 0.1424 - val_mae: 0.0979\n",
            "Epoch 1801/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3684 - mae: 0.1293 - val_loss: 0.1423 - val_mae: 0.0979\n",
            "Epoch 1802/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2096 - mae: 0.1070 - val_loss: 0.1407 - val_mae: 0.0965\n",
            "Epoch 1803/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1310 - mae: 0.0925 - val_loss: 0.1407 - val_mae: 0.0969\n",
            "Epoch 1804/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2355 - mae: 0.1162 - val_loss: 0.1431 - val_mae: 0.0985\n",
            "Epoch 1805/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1882 - mae: 0.1078 - val_loss: 0.1444 - val_mae: 0.0998\n",
            "Epoch 1806/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2161 - mae: 0.1157 - val_loss: 0.1418 - val_mae: 0.0990\n",
            "Epoch 1807/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1946 - mae: 0.1007 - val_loss: 0.1425 - val_mae: 0.0977\n",
            "Epoch 1808/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3239 - mae: 0.1205 - val_loss: 0.1432 - val_mae: 0.0992\n",
            "Epoch 1809/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2706 - mae: 0.1200 - val_loss: 0.1427 - val_mae: 0.0987\n",
            "Epoch 1810/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2370 - mae: 0.1072 - val_loss: 0.1420 - val_mae: 0.0975\n",
            "Epoch 1811/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1529 - mae: 0.0980 - val_loss: 0.1406 - val_mae: 0.0975\n",
            "Epoch 1812/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2780 - mae: 0.1209 - val_loss: 0.1425 - val_mae: 0.0988\n",
            "Epoch 1813/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2445 - mae: 0.1189 - val_loss: 0.1420 - val_mae: 0.0977\n",
            "Epoch 1814/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2235 - mae: 0.1079 - val_loss: 0.1428 - val_mae: 0.0981\n",
            "Epoch 1815/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2545 - mae: 0.1072 - val_loss: 0.1421 - val_mae: 0.0975\n",
            "Epoch 1816/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1791 - mae: 0.1038 - val_loss: 0.1396 - val_mae: 0.0953\n",
            "Epoch 1817/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2230 - mae: 0.1022 - val_loss: 0.1417 - val_mae: 0.0977\n",
            "Epoch 1818/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3625 - mae: 0.1251 - val_loss: 0.1427 - val_mae: 0.0980\n",
            "Epoch 1819/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1363 - mae: 0.0936 - val_loss: 0.1409 - val_mae: 0.0974\n",
            "Epoch 1820/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1482 - mae: 0.0968 - val_loss: 0.1418 - val_mae: 0.0979\n",
            "Epoch 1821/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2087 - mae: 0.1140 - val_loss: 0.1419 - val_mae: 0.0978\n",
            "Epoch 1822/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2000 - mae: 0.1142 - val_loss: 0.1429 - val_mae: 0.0990\n",
            "Epoch 1823/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1729 - mae: 0.0994 - val_loss: 0.1424 - val_mae: 0.0980\n",
            "Epoch 1824/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1786 - mae: 0.1106 - val_loss: 0.1419 - val_mae: 0.0974\n",
            "Epoch 1825/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1400 - mae: 0.0905 - val_loss: 0.1442 - val_mae: 0.0995\n",
            "Epoch 1826/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2497 - mae: 0.1102 - val_loss: 0.1441 - val_mae: 0.0985\n",
            "Epoch 1827/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1690 - mae: 0.1024 - val_loss: 0.1423 - val_mae: 0.0977\n",
            "Epoch 1828/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1647 - mae: 0.1002 - val_loss: 0.1410 - val_mae: 0.0974\n",
            "Epoch 1829/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1830 - mae: 0.1116 - val_loss: 0.1422 - val_mae: 0.0994\n",
            "Epoch 1830/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2017 - mae: 0.1065 - val_loss: 0.1496 - val_mae: 0.1070\n",
            "Epoch 1831/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2037 - mae: 0.1170 - val_loss: 0.1429 - val_mae: 0.1029\n",
            "Epoch 1832/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1649 - mae: 0.1045 - val_loss: 0.1415 - val_mae: 0.0989\n",
            "Epoch 1833/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1755 - mae: 0.1101 - val_loss: 0.1408 - val_mae: 0.0995\n",
            "Epoch 1834/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3049 - mae: 0.1320 - val_loss: 0.1427 - val_mae: 0.0995\n",
            "Epoch 1835/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2749 - mae: 0.1250 - val_loss: 0.1427 - val_mae: 0.0992\n",
            "Epoch 1836/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1901 - mae: 0.1034 - val_loss: 0.1420 - val_mae: 0.0978\n",
            "Epoch 1837/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1699 - mae: 0.0986 - val_loss: 0.1419 - val_mae: 0.0975\n",
            "Epoch 1838/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3360 - mae: 0.1256 - val_loss: 0.1445 - val_mae: 0.0988\n",
            "Epoch 1839/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2024 - mae: 0.1066 - val_loss: 0.1414 - val_mae: 0.0972\n",
            "Epoch 1840/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1638 - mae: 0.1046 - val_loss: 0.1400 - val_mae: 0.0962\n",
            "Epoch 1841/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3102 - mae: 0.1249 - val_loss: 0.1433 - val_mae: 0.0990\n",
            "Epoch 1842/2000\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.2163 - mae: 0.1091 - val_loss: 0.1408 - val_mae: 0.0966\n",
            "Epoch 1843/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1752 - mae: 0.0967 - val_loss: 0.1413 - val_mae: 0.0976\n",
            "Epoch 1844/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1813 - mae: 0.1050 - val_loss: 0.1405 - val_mae: 0.0963\n",
            "Epoch 1845/2000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3122 - mae: 0.1233 - val_loss: 0.1425 - val_mae: 0.0977\n",
            "Epoch 1846/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2255 - mae: 0.1134 - val_loss: 0.1411 - val_mae: 0.0981\n",
            "Epoch 1847/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1712 - mae: 0.1068 - val_loss: 0.1414 - val_mae: 0.1002\n",
            "Epoch 1848/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1490 - mae: 0.0993 - val_loss: 0.1407 - val_mae: 0.1005\n",
            "Epoch 1849/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1942 - mae: 0.1104 - val_loss: 0.1420 - val_mae: 0.1013\n",
            "Epoch 1850/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2214 - mae: 0.1110 - val_loss: 0.1428 - val_mae: 0.0982\n",
            "Epoch 1851/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2758 - mae: 0.1203 - val_loss: 0.1426 - val_mae: 0.0992\n",
            "Epoch 1852/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1609 - mae: 0.1030 - val_loss: 0.1416 - val_mae: 0.0971\n",
            "Epoch 1853/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3030 - mae: 0.1111 - val_loss: 0.1431 - val_mae: 0.0986\n",
            "Epoch 1854/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1747 - mae: 0.0981 - val_loss: 0.1434 - val_mae: 0.0992\n",
            "Epoch 1855/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2470 - mae: 0.1102 - val_loss: 0.1435 - val_mae: 0.1001\n",
            "Epoch 1856/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1745 - mae: 0.1058 - val_loss: 0.1415 - val_mae: 0.0969\n",
            "Epoch 1857/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2702 - mae: 0.1182 - val_loss: 0.1410 - val_mae: 0.0977\n",
            "Epoch 1858/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1568 - mae: 0.0935 - val_loss: 0.1406 - val_mae: 0.0967\n",
            "Epoch 1859/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2229 - mae: 0.1046 - val_loss: 0.1425 - val_mae: 0.0979\n",
            "Epoch 1860/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1727 - mae: 0.0952 - val_loss: 0.1426 - val_mae: 0.0984\n",
            "Epoch 1861/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1988 - mae: 0.1083 - val_loss: 0.1447 - val_mae: 0.0995\n",
            "Epoch 1862/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2196 - mae: 0.1181 - val_loss: 0.1428 - val_mae: 0.0973\n",
            "Epoch 1863/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1834 - mae: 0.1000 - val_loss: 0.1415 - val_mae: 0.0990\n",
            "Epoch 1864/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2417 - mae: 0.1081 - val_loss: 0.1420 - val_mae: 0.0975\n",
            "Epoch 1865/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1422 - mae: 0.0865 - val_loss: 0.1434 - val_mae: 0.0978\n",
            "Epoch 1866/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2667 - mae: 0.1154 - val_loss: 0.1420 - val_mae: 0.0974\n",
            "Epoch 1867/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1677 - mae: 0.1043 - val_loss: 0.1406 - val_mae: 0.0966\n",
            "Epoch 1868/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1587 - mae: 0.1045 - val_loss: 0.1429 - val_mae: 0.0981\n",
            "Epoch 1869/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1335 - mae: 0.0887 - val_loss: 0.1445 - val_mae: 0.0984\n",
            "Epoch 1870/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2420 - mae: 0.1167 - val_loss: 0.1429 - val_mae: 0.0973\n",
            "Epoch 1871/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2012 - mae: 0.1027 - val_loss: 0.1424 - val_mae: 0.0974\n",
            "Epoch 1872/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2013 - mae: 0.1017 - val_loss: 0.1416 - val_mae: 0.0968\n",
            "Epoch 1873/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1927 - mae: 0.0999 - val_loss: 0.1416 - val_mae: 0.0973\n",
            "Epoch 1874/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1753 - mae: 0.1069 - val_loss: 0.1415 - val_mae: 0.0976\n",
            "Epoch 1875/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2369 - mae: 0.1155 - val_loss: 0.1421 - val_mae: 0.0971\n",
            "Epoch 1876/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2644 - mae: 0.1084 - val_loss: 0.1413 - val_mae: 0.0988\n",
            "Epoch 1877/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2395 - mae: 0.1200 - val_loss: 0.1422 - val_mae: 0.0978\n",
            "Epoch 1878/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2238 - mae: 0.1122 - val_loss: 0.1425 - val_mae: 0.0973\n",
            "Epoch 1879/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1603 - mae: 0.1031 - val_loss: 0.1409 - val_mae: 0.0966\n",
            "Epoch 1880/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2541 - mae: 0.1134 - val_loss: 0.1435 - val_mae: 0.0980\n",
            "Epoch 1881/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3048 - mae: 0.1212 - val_loss: 0.1434 - val_mae: 0.0978\n",
            "Epoch 1882/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2233 - mae: 0.1153 - val_loss: 0.1427 - val_mae: 0.0987\n",
            "Epoch 1883/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2646 - mae: 0.1154 - val_loss: 0.1440 - val_mae: 0.0984\n",
            "Epoch 1884/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2661 - mae: 0.1164 - val_loss: 0.1419 - val_mae: 0.0969\n",
            "Epoch 1885/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3162 - mae: 0.1181 - val_loss: 0.1426 - val_mae: 0.0984\n",
            "Epoch 1886/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1709 - mae: 0.0979 - val_loss: 0.1416 - val_mae: 0.0975\n",
            "Epoch 1887/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1704 - mae: 0.0982 - val_loss: 0.1424 - val_mae: 0.0981\n",
            "Epoch 1888/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1978 - mae: 0.1067 - val_loss: 0.1427 - val_mae: 0.0987\n",
            "Epoch 1889/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1772 - mae: 0.0954 - val_loss: 0.1438 - val_mae: 0.0983\n",
            "Epoch 1890/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2464 - mae: 0.1162 - val_loss: 0.1422 - val_mae: 0.0975\n",
            "Epoch 1891/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2059 - mae: 0.1039 - val_loss: 0.1430 - val_mae: 0.0981\n",
            "Epoch 1892/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2943 - mae: 0.1197 - val_loss: 0.1433 - val_mae: 0.0989\n",
            "Epoch 1893/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1592 - mae: 0.0976 - val_loss: 0.1417 - val_mae: 0.0973\n",
            "Epoch 1894/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1715 - mae: 0.0993 - val_loss: 0.1410 - val_mae: 0.0960\n",
            "Epoch 1895/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3034 - mae: 0.1172 - val_loss: 0.1438 - val_mae: 0.0993\n",
            "Epoch 1896/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1720 - mae: 0.0967 - val_loss: 0.1417 - val_mae: 0.0981\n",
            "Epoch 1897/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3269 - mae: 0.1319 - val_loss: 0.1410 - val_mae: 0.0975\n",
            "Epoch 1898/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2309 - mae: 0.1111 - val_loss: 0.1557 - val_mae: 0.1159\n",
            "Epoch 1899/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2527 - mae: 0.1345 - val_loss: 0.1525 - val_mae: 0.1212\n",
            "Epoch 1900/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2030 - mae: 0.1266 - val_loss: 0.1516 - val_mae: 0.1223\n",
            "Epoch 1901/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3749 - mae: 0.1567 - val_loss: 0.1708 - val_mae: 0.1343\n",
            "Epoch 1902/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2618 - mae: 0.1382 - val_loss: 0.1482 - val_mae: 0.1181\n",
            "Epoch 1903/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.3257 - mae: 0.1473 - val_loss: 0.1437 - val_mae: 0.1148\n",
            "Epoch 1904/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2494 - mae: 0.1218 - val_loss: 0.1407 - val_mae: 0.1044\n",
            "Epoch 1905/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2647 - mae: 0.1243 - val_loss: 0.1418 - val_mae: 0.1014\n",
            "Epoch 1906/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2241 - mae: 0.1122 - val_loss: 0.1408 - val_mae: 0.0994\n",
            "Epoch 1907/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1533 - mae: 0.1092 - val_loss: 0.1391 - val_mae: 0.0975\n",
            "Epoch 1908/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2004 - mae: 0.0977 - val_loss: 0.1429 - val_mae: 0.0999\n",
            "Epoch 1909/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2256 - mae: 0.1149 - val_loss: 0.1435 - val_mae: 0.0993\n",
            "Epoch 1910/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1729 - mae: 0.1035 - val_loss: 0.1417 - val_mae: 0.0985\n",
            "Epoch 1911/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2325 - mae: 0.1059 - val_loss: 0.1431 - val_mae: 0.0990\n",
            "Epoch 1912/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1678 - mae: 0.1035 - val_loss: 0.1403 - val_mae: 0.0962\n",
            "Epoch 1913/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1553 - mae: 0.0920 - val_loss: 0.1410 - val_mae: 0.0973\n",
            "Epoch 1914/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1378 - mae: 0.0940 - val_loss: 0.1408 - val_mae: 0.0976\n",
            "Epoch 1915/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2685 - mae: 0.1179 - val_loss: 0.1436 - val_mae: 0.0986\n",
            "Epoch 1916/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2060 - mae: 0.1115 - val_loss: 0.1434 - val_mae: 0.0973\n",
            "Epoch 1917/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2146 - mae: 0.1027 - val_loss: 0.1436 - val_mae: 0.0978\n",
            "Epoch 1918/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1257 - mae: 0.0887 - val_loss: 0.1409 - val_mae: 0.0969\n",
            "Epoch 1919/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1669 - mae: 0.1001 - val_loss: 0.1408 - val_mae: 0.0966\n",
            "Epoch 1920/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2696 - mae: 0.1154 - val_loss: 0.1423 - val_mae: 0.0977\n",
            "Epoch 1921/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2288 - mae: 0.1105 - val_loss: 0.1426 - val_mae: 0.0976\n",
            "Epoch 1922/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1642 - mae: 0.1058 - val_loss: 0.1410 - val_mae: 0.0966\n",
            "Epoch 1923/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1568 - mae: 0.0984 - val_loss: 0.1413 - val_mae: 0.0984\n",
            "Epoch 1924/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2867 - mae: 0.1172 - val_loss: 0.1438 - val_mae: 0.0999\n",
            "Epoch 1925/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2370 - mae: 0.1073 - val_loss: 0.1416 - val_mae: 0.0967\n",
            "Epoch 1926/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1606 - mae: 0.0943 - val_loss: 0.1436 - val_mae: 0.0987\n",
            "Epoch 1927/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2890 - mae: 0.1216 - val_loss: 0.1443 - val_mae: 0.0995\n",
            "Epoch 1928/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2431 - mae: 0.1218 - val_loss: 0.1437 - val_mae: 0.0983\n",
            "Epoch 1929/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1450 - mae: 0.0886 - val_loss: 0.1417 - val_mae: 0.0972\n",
            "Epoch 1930/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2127 - mae: 0.0957 - val_loss: 0.1426 - val_mae: 0.0972\n",
            "Epoch 1931/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1591 - mae: 0.0972 - val_loss: 0.1419 - val_mae: 0.0981\n",
            "Epoch 1932/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1991 - mae: 0.1107 - val_loss: 0.1414 - val_mae: 0.0970\n",
            "Epoch 1933/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1806 - mae: 0.1025 - val_loss: 0.1418 - val_mae: 0.0975\n",
            "Epoch 1934/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1231 - mae: 0.0912 - val_loss: 0.1406 - val_mae: 0.0965\n",
            "Epoch 1935/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2657 - mae: 0.1196 - val_loss: 0.1433 - val_mae: 0.0978\n",
            "Epoch 1936/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2002 - mae: 0.1014 - val_loss: 0.1425 - val_mae: 0.0968\n",
            "Epoch 1937/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3413 - mae: 0.1252 - val_loss: 0.1432 - val_mae: 0.0975\n",
            "Epoch 1938/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2279 - mae: 0.1084 - val_loss: 0.1440 - val_mae: 0.0986\n",
            "Epoch 1939/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2049 - mae: 0.1120 - val_loss: 0.1429 - val_mae: 0.0983\n",
            "Epoch 1940/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3141 - mae: 0.1234 - val_loss: 0.1426 - val_mae: 0.0968\n",
            "Epoch 1941/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2215 - mae: 0.1069 - val_loss: 0.1420 - val_mae: 0.0967\n",
            "Epoch 1942/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1225 - mae: 0.0908 - val_loss: 0.1398 - val_mae: 0.0966\n",
            "Epoch 1943/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1799 - mae: 0.1000 - val_loss: 0.1438 - val_mae: 0.0984\n",
            "Epoch 1944/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1967 - mae: 0.1033 - val_loss: 0.1433 - val_mae: 0.0975\n",
            "Epoch 1945/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1900 - mae: 0.1065 - val_loss: 0.1413 - val_mae: 0.0966\n",
            "Epoch 1946/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2188 - mae: 0.1116 - val_loss: 0.1450 - val_mae: 0.0986\n",
            "Epoch 1947/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2157 - mae: 0.1034 - val_loss: 0.1456 - val_mae: 0.0994\n",
            "Epoch 1948/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1830 - mae: 0.1068 - val_loss: 0.1421 - val_mae: 0.0977\n",
            "Epoch 1949/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1803 - mae: 0.1034 - val_loss: 0.1425 - val_mae: 0.0990\n",
            "Epoch 1950/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1629 - mae: 0.0949 - val_loss: 0.1443 - val_mae: 0.1000\n",
            "Epoch 1951/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2083 - mae: 0.1019 - val_loss: 0.1428 - val_mae: 0.0986\n",
            "Epoch 1952/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3247 - mae: 0.1253 - val_loss: 0.1428 - val_mae: 0.0984\n",
            "Epoch 1953/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2551 - mae: 0.1149 - val_loss: 0.1409 - val_mae: 0.0961\n",
            "Epoch 1954/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1619 - mae: 0.1014 - val_loss: 0.1419 - val_mae: 0.0977\n",
            "Epoch 1955/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2275 - mae: 0.1164 - val_loss: 0.1425 - val_mae: 0.0988\n",
            "Epoch 1956/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2410 - mae: 0.1192 - val_loss: 0.1417 - val_mae: 0.0974\n",
            "Epoch 1957/2000\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2689 - mae: 0.1208 - val_loss: 0.1424 - val_mae: 0.0974\n",
            "Epoch 1958/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4072 - mae: 0.1293 - val_loss: 0.1424 - val_mae: 0.0971\n",
            "Epoch 1959/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2372 - mae: 0.1066 - val_loss: 0.1426 - val_mae: 0.0981\n",
            "Epoch 1960/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1623 - mae: 0.0891 - val_loss: 0.1409 - val_mae: 0.0964\n",
            "Epoch 1961/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2131 - mae: 0.1085 - val_loss: 0.1415 - val_mae: 0.0977\n",
            "Epoch 1962/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1643 - mae: 0.1013 - val_loss: 0.1409 - val_mae: 0.0968\n",
            "Epoch 1963/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2056 - mae: 0.1074 - val_loss: 0.1414 - val_mae: 0.0966\n",
            "Epoch 1964/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1388 - mae: 0.0989 - val_loss: 0.1409 - val_mae: 0.0966\n",
            "Epoch 1965/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2159 - mae: 0.1130 - val_loss: 0.1438 - val_mae: 0.0981\n",
            "Epoch 1966/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3657 - mae: 0.1364 - val_loss: 0.1436 - val_mae: 0.0984\n",
            "Epoch 1967/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1260 - mae: 0.0880 - val_loss: 0.1416 - val_mae: 0.0967\n",
            "Epoch 1968/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2189 - mae: 0.1045 - val_loss: 0.1443 - val_mae: 0.0987\n",
            "Epoch 1969/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2348 - mae: 0.1020 - val_loss: 0.1436 - val_mae: 0.0979\n",
            "Epoch 1970/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2160 - mae: 0.1026 - val_loss: 0.1407 - val_mae: 0.0965\n",
            "Epoch 1971/2000\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2944 - mae: 0.1159 - val_loss: 0.1418 - val_mae: 0.0973\n",
            "Epoch 1972/2000\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.2200 - mae: 0.1096 - val_loss: 0.1412 - val_mae: 0.0965\n",
            "Epoch 1973/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1566 - mae: 0.0971 - val_loss: 0.1418 - val_mae: 0.0978\n",
            "Epoch 1974/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3126 - mae: 0.1163 - val_loss: 0.1439 - val_mae: 0.0991\n",
            "Epoch 1975/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1440 - mae: 0.0942 - val_loss: 0.1407 - val_mae: 0.0958\n",
            "Epoch 1976/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3478 - mae: 0.1250 - val_loss: 0.1418 - val_mae: 0.0973\n",
            "Epoch 1977/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1899 - mae: 0.0999 - val_loss: 0.1419 - val_mae: 0.0973\n",
            "Epoch 1978/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2323 - mae: 0.1121 - val_loss: 0.1422 - val_mae: 0.0980\n",
            "Epoch 1979/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1775 - mae: 0.1002 - val_loss: 0.1410 - val_mae: 0.0964\n",
            "Epoch 1980/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1671 - mae: 0.1022 - val_loss: 0.1423 - val_mae: 0.0978\n",
            "Epoch 1981/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1694 - mae: 0.0981 - val_loss: 0.1422 - val_mae: 0.0970\n",
            "Epoch 1982/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2613 - mae: 0.1169 - val_loss: 0.1429 - val_mae: 0.0976\n",
            "Epoch 1983/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2567 - mae: 0.1071 - val_loss: 0.1434 - val_mae: 0.0984\n",
            "Epoch 1984/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2813 - mae: 0.1203 - val_loss: 0.1420 - val_mae: 0.0969\n",
            "Epoch 1985/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1310 - mae: 0.0947 - val_loss: 0.1406 - val_mae: 0.0966\n",
            "Epoch 1986/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1651 - mae: 0.1020 - val_loss: 0.1408 - val_mae: 0.0973\n",
            "Epoch 1987/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2976 - mae: 0.1115 - val_loss: 0.1420 - val_mae: 0.0980\n",
            "Epoch 1988/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1705 - mae: 0.1032 - val_loss: 0.1417 - val_mae: 0.0978\n",
            "Epoch 1989/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2751 - mae: 0.1121 - val_loss: 0.1425 - val_mae: 0.0970\n",
            "Epoch 1990/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2858 - mae: 0.1155 - val_loss: 0.1422 - val_mae: 0.0973\n",
            "Epoch 1991/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1452 - mae: 0.0948 - val_loss: 0.1400 - val_mae: 0.0960\n",
            "Epoch 1992/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3102 - mae: 0.1250 - val_loss: 0.1421 - val_mae: 0.0981\n",
            "Epoch 1993/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2261 - mae: 0.1136 - val_loss: 0.1430 - val_mae: 0.0986\n",
            "Epoch 1994/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1847 - mae: 0.1032 - val_loss: 0.1415 - val_mae: 0.0970\n",
            "Epoch 1995/2000\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1998 - mae: 0.1037 - val_loss: 0.1428 - val_mae: 0.0991\n",
            "Epoch 1996/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1746 - mae: 0.1012 - val_loss: 0.1406 - val_mae: 0.0979\n",
            "Epoch 1997/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2293 - mae: 0.1108 - val_loss: 0.1410 - val_mae: 0.0973\n",
            "Epoch 1998/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2828 - mae: 0.1119 - val_loss: 0.1406 - val_mae: 0.0971\n",
            "Epoch 1999/2000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2108 - mae: 0.1143 - val_loss: 0.1405 - val_mae: 0.0982\n",
            "Epoch 2000/2000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1473 - mae: 0.1016 - val_loss: 0.1406 - val_mae: 0.0967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALev_-U4lFCh",
        "outputId": "5ae756d4-d27c-46fd-faf6-1afd7b3bdb16"
      },
      "source": [
        "# モデルの評価\n",
        "score = model_4.evaluate([x_fs_test_n, x_fp_test_n], y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test mae:', score[1])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255/255 [==============================] - 0s 1ms/step - loss: 0.2383 - mae: 0.1052\n",
            "Test loss: 0.23834212124347687\n",
            "Test mae: 0.1051580086350441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "7JxULSMKlFCi",
        "outputId": "0f78681c-1e00-4b7f-ae83-31433ca1361b"
      },
      "source": [
        "# 学習経過の可視化\n",
        "loss     = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "nb_epoch = len(loss)\n",
        "for i in range(900):\n",
        "  if max(loss)>2: \n",
        "    loss = loss[1:]\n",
        "    val_loss = val_loss[1:]\n",
        "  else:\n",
        "    plt.plot(range(i,nb_epoch), loss, marker='.', label='loss')\n",
        "    plt.plot(range(i,nb_epoch), val_loss, marker='.', label='val_loss')\n",
        "    break\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "EKQ8Bss7lFCi",
        "outputId": "029272b8-d8e6-47ec-a5b2-1e08e72e0f85"
      },
      "source": [
        "# 学習経過の可視化\n",
        "mae     = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "nb_epoch = len(mae)\n",
        "for i in range(900):\n",
        "  if max(mae)>2: \n",
        "    mae = mae[1:]\n",
        "    val_mae = val_mae[1:]\n",
        "  else:\n",
        "    plt.plot(range(i,nb_epoch), mae,     marker='.', label='mae')\n",
        "    plt.plot(range(i,nb_epoch), val_mae, marker='.', label='val_mae')\n",
        "    break\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('mae')\n",
        "plt.show()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnFvMF1FlFCi"
      },
      "source": [
        "# 学習モデルの保存\n",
        "model_4.save(str(n)+\"_random.seed(\"+str(seed)+\")_train\"+str(train)+\".h5\")"
      ],
      "execution_count": 126,
      "outputs": []
    }
  ]
}